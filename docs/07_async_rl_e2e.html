<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>07_async_rl_e2e.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>07 async rl e2e</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-DGasP9Lh.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/preload-helper-DItdS47A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-BGmjiNul.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/compiler-runtime-DeeZ7FnK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/badge-Ce8wRjuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEventListener-DIUKKfEy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/button-YC1gW_kJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-dom-C9fstfnp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Combination-CMPwuAmi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/menu-items-CJhvWPOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-uzvC4uAK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createLucideIcon-CnW3RofX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/check-DdfN0k2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/select-V5IdpNiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-CEc2ajau.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/use-toast-rmUWldD_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEvent-DO6uJBas.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/zod-Cg4WLWh2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utils-DXvhzCGS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Deferred-CrO5-0RA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/config-CIrPQIbt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/uuid-DercMavo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/DeferredRequestRegistry-CO2AyNfd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/requests-BsVD4CdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useLifecycle-D35CBukS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNonce-_Aax6sXd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useTheme-DUdVAZI8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createReducer-Dnna-AUO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BIKFl48f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-B0VqT_4z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-TiFCI16_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Cayq-K1c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BYyu59D8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/stex-CtmkcLz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toDate-CgbKQM5E.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/database-zap-B9y7063w.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-BpZ7g6ok.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spinner-DaIKav-i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chevron-right-DwagBitu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dropdown-menu-B-6unW-7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/kbd-C3JY7O_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/renderShortcut-DEwfrKeS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/multi-map-C8GlnP-4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-BrGyZf9c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-dialog-DwQffb13.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dialog-CxGKN4C_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CdxIjAOP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/label-Be1daUcS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDebounce-D5NcotGm.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/textarea-DBO30D7K.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/numbers-iQunIAXf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/SSRProvider-CEHRCdjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/context-JwD-oSsl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNumberFormatter-c6GXymzg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/usePress-Bup4EGrp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/input-pAun1m1X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/links-DHZUhGz-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/popover-Gz-GJzym.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/switch-8sn_4qbh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-C8uQmBAN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/mode-DX8pdI-l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAsyncData-C4XRy1BE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/errors-2SszdW9t.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/error-banner-DUzsIXtq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-Bv2DBpIS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-CQ15EONK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/plus-BD5o34_i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-cw-CQd-1kjx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/trash-2-CyqGun26.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/triangle-alert-B65rDESJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ai-model-dropdown-71lgLrLy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-D_rSvXvJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/precisionRound-BMPhtTJQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-C92Rrpmf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/vega-loader.browser-CRZ52CKf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-BGrCWNss.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ErrorBoundary-ChCiwl15.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useInstallPackage-Bdnnp5fe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ImperativeModal-CUbWEBci.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cell-link-Bw5bzt4a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/datasource-B0OJBphG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/state-BfXVTTtD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/MarimoErrorOutput-5rudBbo3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-icon-BhONVREY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/html-to-image-DjukyIj4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/focus-D51fcwZX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/LazyAnyLanguageCodeMirror-yzHjsVJt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-5FQGJX7Z-CVUXBqX6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/katex-Dc8yG8NU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DhMlG2dP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/command-DhzFN2CJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-BhCZMKuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useRunCells-24p6hn99.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/purify.es-DNVQZNFu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/RenderHTML-CQZqVk1Z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useIframeCapabilities-DuIDx9mD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/formats-W1SWxSE3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/en-US-pRRbZZHE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isValid-DcYggVWP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dates-Dhn1r-h6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/maps-t9yNKYA8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/extends-B2LJnKU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/emotion-is-prop-valid.esm-DD4AwVTU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDateFormatter-CS4kbWl2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-DZR6ewbN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-CknFTI_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-Cs1JbsV6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/play-BPIh-ZEU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-components-CGlO4yUw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-display-B4mGvJ0X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeleteCell-5uYlTcQZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/icons-BhEXrzsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/process-output-CagdHMzs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/blob-CuXvdYPX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/objectWithoutPropertiesLoose-DaPAPabU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/esm-DpMp6qko.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/add-cell-with-ai-pVFp5LZG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chart-no-axes-column-W42b2ZIs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-function-CqXXKtIq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spec-D1kBp3jX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/column-preview-CxMrs0B_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toggle-jWKnIArU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/globals-DKH14XH0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/share-CbPtIlnM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-resizable-panels.browser.esm-Ctj_10o2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utilities.esm-CIPARd6-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/floating-outline-DcxjrFFt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAddCell-BmeZUK02.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/eye-off-BhExYOph.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/readonly-python-code-DyP9LVLc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-video-camera-DW3v07j2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-DuQOSW7G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-ccw-DLEiQDS3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/form-DUA_Rz_a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/field-BEg1eC0P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useBoolean-B1Xeh6vA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeepCompareMemoize-ZPd9PxYl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-CS34eOZi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/prop-types-BiQYf0aU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/es-D8BOePqo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/code-xml-XLwHyDBr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-B9SUL40m.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/house-DhFkiXz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/settings-DOXWMfVd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-C8Tw_XXG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/bundle.esm-2AjO7UK5.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-CikhHYAB.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "07_async_rl_e2e.py",
            "mode": "read",
            "version": "0.19.7",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "# Environment setup for Monarch subprocesses\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"HF_HUB_OFFLINE\"] = \"1\"\nos.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n# Note: CUDA_VISIBLE_DEVICES is set per-actor in setup()\n# Note: PYTORCH_ALLOC_CONF is set at module level for RDMA\n\nimport sys\n_src_dir = os.path.abspath(os.path.join(os.path.dirname(__file__) if \"__file__\" in dir() else os.getcwd(), \"..\", \"src\"))\nif _src_dir not in sys.path:\n    sys.path.insert(0, _src_dir)\n\n# Set PYTHONPATH for Monarch subprocesses\n_existing = os.environ.get(\"PYTHONPATH\", \"\")\nos.environ[\"PYTHONPATH\"] = f\"{_src_dir}:{_existing}\" if _existing else _src_dir", "code_hash": "9d2da1a64a7c48c53bbbd693ac608cce", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n# Closing the Loop: Async RL Training\n\nIn **Notebook 04**, we introduced the Zorplex benchmark and saw that Qwen 0.5B\nstruggles with compositional tasks -- it gets ~60-70% accuracy when it needs to\nchain multiple tool calls.\n\n**Now we close the loop**: train the model to get better at these tasks.\n\nWe'll build on patterns from across the series:\n- **`this_host()` from NB02** -- spawning actors on the local machine for interactive development\n- **`try/except` from NB03** -- fault tolerance in generation loops\n- **RDMA weight sync from NB06** -- circular buffer + CPU staging for efficient weight transfer\n\nThe architecture: multiple generators feed trajectories into a replay buffer while\na trainer continuously samples and updates the policy. We'll measure *before* and\n*after* accuracy to see if training actually helps.\n\"\"\")", "code_hash": "04edb86c0f1dd0688c1bac819263149e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "from typing import Optional\nfrom collections import deque\nimport random\nimport torch\nimport torch.nn.functional as F\n\n# Model imports\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# Zorplex imports\nfrom zorplex_rl import get_spec, Task\nfrom zorplex_rl.evaluate import generate_with_tools\n\n# RL primitives (shared dataclasses)\nfrom rl_primitives import Trajectory, TrainMetrics\n\n# RDMA imports (with fallback)\ntry:\n    from monarch.rdma import RDMABuffer, is_rdma_available\n    _rdma_available = is_rdma_available()\nexcept Exception:\n    RDMABuffer = None\n    _rdma_available = False\n\ndef rdma_available():\n    return _rdma_available", "code_hash": "f03f72962704b86b8fde7b5a0d9845e9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "from monarch.actor import Actor, endpoint, current_rank", "code_hash": "5fc990d636c1d12556a4677252891c16", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "import dataclasses as _dc\n_traj_fields = [(f.name, f.type.__name__ if hasattr(f.type, '__name__') else str(f.type)) for f in _dc.fields(Trajectory)]\n_metrics_fields = [(f.name, f.type.__name__ if hasattr(f.type, '__name__') else str(f.type)) for f in _dc.fields(TrainMetrics)]\n\nmo.md(f\"\"\"\n## Shared Data Structures\n\n**Trajectory** -- one rollout from a generator:\n\n| Field | Type |\n|-------|------|\n{\"\".join(f\"| `{n}` | `{t}` |{chr(10)}\" for n, t in _traj_fields)}\n\n**TrainMetrics** -- returned after each training step:\n\n| Field | Type |\n|-------|------|\n{\"\".join(f\"| `{n}` | `{t}` |{chr(10)}\" for n, t in _metrics_fields)}\n\nThe `model_only_text` field stores the model's generated tokens without injected tool\nresults, so the trainer can compute log-probabilities on exactly what the model produced.\n\"\"\")", "code_hash": "fee169ea6b0e7445704b9d9dae9027a9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Service Infrastructure\n\nWe import a **custom Service abstraction** from `monarch_utils` that manages worker\nreplicas with health tracking and round-robin routing. This is a utility we built\nfor this notebook series -- the canonical Monarch pattern uses direct actor\nreferences and slicing, which is what the Service wraps internally.\n\n(See notebook 05 for the full implementation.)\n\"\"\")", "code_hash": "4e6c895b9547643bc1a0087250cf6b27", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "from monarch_utils.services import Service, register_service", "code_hash": "e644d8e238271c0dcb2c797fbb8e561f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n## The `setup()` Pattern\n\nMonarch actors use a two-phase initialization:\n\n1. **`__init__`** runs during `spawn()` -- keep it lightweight (store config, set rank)\n2. **`setup()`** is an endpoint called explicitly after spawn -- do heavy work here\n   (load models, allocate GPU memory, register RDMA buffers)\n\nWhy not do everything in `__init__`? Two reasons:\n\n- **`spawn()` is asynchronous** -- it returns immediately, and `__init__` runs in\n  the remote process before the first endpoint call. But you don't control *when*,\n  and you can't confirm it completed. An explicit `setup()` call lets you sequence\n  initialization (e.g., set `CUDA_VISIBLE_DEVICES` and confirm it took effect before\n  loading a model).\n- **Coordination** -- you often need to initialize actors in a specific order (set up\n  the trainer before generators try to sync weights). Endpoint calls give you that\n  sequencing; `__init__` doesn't.\n\"\"\")", "code_hash": "daa9bf7142584931a46045dbe2c26323", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Actor 1: ZorplexWorker\n\nTool execution environments (docker containers, sandboxes, API endpoints) naturally\nform a fleet -- you want many instances running in parallel to keep up with\ngeneration throughput. That makes them a good fit for a **Service** (from NB05)\nwith health tracking and round-robin routing.\n\nOur ZorplexWorker actors handle Zorplex tasks:\n- `generate_task()` -- creates a new problem\n- `execute_tool()` -- handles LOOKUP calls\n- `check_answer()` -- verifies correctness\n\"\"\")", "code_hash": "ab05f41981edfe1bd8f40d35bf3c4949", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "class ZorplexWorker(Actor):\n    \"\"\"Worker actor that handles Zorplex tool execution.\n\n    Managed by a Service for load balancing across replicas.\n    \"\"\"\n\n    def __init__(self, difficulty: str = \"easy\", seed: int = 42):\n        self.rank = current_rank().rank\n        self.spec = get_spec(\"compositional\", difficulty=difficulty, seed=seed + self.rank)\n        self.calls_served = 0\n        print(f\"[ZorplexWorker:{self.rank}] Initialized with difficulty={difficulty}\")\n\n    @endpoint\n    def ping(self) -\u003E bool:\n        return True\n\n    @endpoint\n    def generate_task(self) -\u003E tuple[str, int]:\n        \"\"\"Generate a new task. Returns (question, correct_answer).\"\"\"\n        task = self.spec.generate_task()\n        return task.question, task.correct_answer\n\n    @endpoint\n    def execute_tool(self, tool_name: str, argument: str) -\u003E str:\n        \"\"\"Execute a tool call.\"\"\"\n        from zorplex_rl.task_specs import ToolCall\n        tc = ToolCall(tool_name, argument)\n        result = self.spec.execute_tool(tc)\n        self.calls_served += 1\n        return str(result)\n\n    @endpoint\n    def get_system_prompt(self) -\u003E str:\n        \"\"\"Get the system prompt with tool hints.\"\"\"\n        return self.spec.get_system_prompt(with_hint=True)\n\n    @endpoint\n    def check_answer(self, model_output: str, correct_answer: int) -\u003E tuple[bool, int | None]:\n        \"\"\"Check if model output contains the correct answer.\"\"\"\n        extracted = self.spec.extract_answer(model_output, [])\n        is_correct = extracted == correct_answer\n        return is_correct, extracted\n\n    @endpoint\n    def stats(self) -\u003E dict:\n        return {\"rank\": self.rank, \"calls_served\": self.calls_served}", "code_hash": "5b736dfec5189aa58d1c4d7bd99b7601", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Actor 2: ReplayBuffer\n\nA simple actor that stores trajectories. Generators push trajectories in,\nthe trainer samples batches out. The `clear()` endpoint lets us reset between\nsync and async runs for a fair comparison.\n\nThis enables async RL -- generation and training happen independently,\nconnected only through the buffer.\n\"\"\")", "code_hash": "c0885ae43fdc631e7ea9060c5b7ed490", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "class ReplayBuffer(Actor):\n    \"\"\"Stores trajectories for async RL training.\"\"\"\n\n    def __init__(self, max_size: int = 1000):\n        self.buffer: deque[Trajectory] = deque(maxlen=max_size)\n        self.total_added = 0\n        print(f\"[ReplayBuffer] Initialized with max_size={max_size}\")\n\n    @endpoint\n    def add(self, trajectory: Trajectory) -\u003E None:\n        \"\"\"Add a trajectory to the buffer.\"\"\"\n        self.buffer.append(trajectory)\n        self.total_added += 1\n\n    @endpoint\n    def sample(self, batch_size: int) -\u003E list[Trajectory]:\n        \"\"\"Sample a batch of trajectories.\"\"\"\n        if len(self.buffer) == 0:\n            return []\n        n = min(batch_size, len(self.buffer))\n        return random.sample(list(self.buffer), n)\n\n    @endpoint\n    def size(self) -\u003E int:\n        return len(self.buffer)\n\n    @endpoint\n    def clear(self) -\u003E int:\n        \"\"\"Clear the buffer. Returns number of items removed.\"\"\"\n        count = len(self.buffer)\n        self.buffer.clear()\n        return count\n\n    @endpoint\n    def stats(self) -\u003E dict:\n        if len(self.buffer) == 0:\n            return {\"size\": 0, \"total_added\": self.total_added, \"avg_reward\": 0.0}\n        rewards = [t.reward for t in self.buffer]\n        return {\n            \"size\": len(self.buffer),\n            \"total_added\": self.total_added,\n            \"avg_reward\": sum(rewards) / len(rewards),\n            \"correct_rate\": sum(1 for t in self.buffer if t.is_correct) / len(self.buffer),\n        }", "code_hash": "7b1d6f17134e908391a42f035734452f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Actor 3: TrainerActor\n\nThe trainer loads the model, receives batches of trajectories, and computes\nREINFORCE updates.\n\n**REINFORCE**: For each trajectory, we compute per-token log-probabilities on\nthe *response tokens only* (using `model_only_text`, not the full text with\ninjected tool results). The loss is:\n\n```\nloss = -sum(log_prob(token_i)) * (reward - baseline)\n```\n\nThis weights the entire response by the advantage. Positive advantage reinforces\nthe response; negative advantage suppresses it.\n\n**Circular buffer with CPU staging** (from NB06): Instead of registering RDMA\nhandles directly on GPU parameters (which blocks training during reads), we\nmaintain N CPU staging slots. After each training step, weights are copied\nGPU -\u003E CPU (D2H) into the current slot. Generators read from CPU via RDMA,\nthen copy to their own GPU (H2D). The data flow:\n\n```\nTrainer GPU --D2H--\u003E CPU slot[v % 3] --RDMA--\u003E Generator CPU staging --H2D--\u003E Generator GPU\n```\n\nThis decouples training from weight distribution.\n\"\"\")", "code_hash": "6ccacd8bc6cf97ad62a3c339362ab42e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "class TrainerActor(Actor):\n    \"\"\"Trains the model on trajectories.\n\n    Uses setup() for heavy initialization (model loading, RDMA registration).\n    Implements circular buffer with CPU staging for weight distribution.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"Qwen/Qwen2.5-0.5B-Instruct\",\n        lr: float = 1e-5,\n        device: str = \"cuda\",\n        n_buffer_slots: int = 3,\n    ):\n        # Lightweight init - just store config\n        self.model_name = model_name\n        self.lr = lr\n        self.device_config = device\n        self.n_buffer_slots = n_buffer_slots\n        self.rank = current_rank().rank\n        self._ready = False\n        print(f\"[Trainer:{self.rank}] Spawned, waiting for setup()...\")\n\n    @endpoint\n    def setup(self) -\u003E dict:\n        \"\"\"Heavy initialization: load model, create optimizer, set up circular buffer.\"\"\"\n        import os\n\n        if self._ready:\n            return {\"status\": \"already_ready\"}\n\n        # Trainer always uses GPU 0\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.policy_version = 0\n        self.train_steps = 0\n\n        print(f\"[Trainer:{self.rank}] Loading model {self.model_name} on GPU 0...\")\n\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(\n            self.model_name,\n            dtype=torch.bfloat16 if self.device == \"cuda\" else torch.float32,\n        ).to(self.device)\n\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=self.lr)\n\n        # Store system prompt for log-prob computation in train_step\n        self.spec = get_spec(\"compositional\", seed=42)\n        self._system_prompt = self.spec.get_system_prompt(with_hint=True)\n\n        # --- Circular buffer with CPU staging ---\n        # Compute total bytes for all parameters\n        total_bytes = sum(p.numel() * p.element_size() for p in self.model.parameters())\n\n        # Create N CPU slots for weight staging\n        # Note: we use regular (non-pinned) CPU memory here because\n        # pin_memory=True triggers dmabuf MR registration in the RDMA\n        # subsystem, which can fail on some host configurations.\n        self._slots = [\n            torch.empty(total_bytes, dtype=torch.uint8)\n            for _ in range(self.n_buffer_slots)\n        ]\n\n        # Register each slot with RDMA (if available)\n        self._slot_handles = []\n        if rdma_available() and RDMABuffer is not None:\n            try:\n                for slot in self._slots:\n                    self._slot_handles.append(RDMABuffer(slot))\n                print(f\"[Trainer:{self.rank}] RDMA handles registered for {self.n_buffer_slots} circular buffer slots\")\n            except Exception as e:\n                print(f\"[Trainer:{self.rank}] RDMA registration failed: {e}\")\n                self._slot_handles = []\n\n        # Store parameter metadata for scatter on generator side\n        self._param_meta = {}\n        offset = 0\n        for name, p in self.model.named_parameters():\n            self._param_meta[name] = (offset, tuple(p.shape), p.dtype)\n            offset += p.numel() * p.element_size()\n\n        # Publish initial weights to slot 0\n        self._publish_weights()\n\n        self._ready = True\n        param_count = sum(p.numel() for p in self.model.parameters())\n        print(f\"[Trainer:{self.rank}] Ready! {param_count:,} params, \"\n              f\"RDMA={len(self._slot_handles) \u003E 0}, \"\n              f\"buffer_slots={self.n_buffer_slots}\")\n\n        return {\n            \"status\": \"ready\",\n            \"params\": param_count,\n            \"rdma\": len(self._slot_handles) \u003E 0,\n            \"buffer_slots\": self.n_buffer_slots,\n        }\n\n    def _publish_weights(self):\n        \"\"\"Copy GPU params to the current circular buffer slot (D2H).\"\"\"\n        slot_idx = self.policy_version % self.n_buffer_slots\n        slot = self._slots[slot_idx]\n        for name, p in self.model.named_parameters():\n            off, shape, dtype = self._param_meta[name]\n            nbytes = p.numel() * p.element_size()\n            slot[off:off + nbytes].copy_(\n                p.data.view(-1).view(torch.uint8).cpu(), non_blocking=True\n            )\n        torch.cuda.synchronize()  # Ensure D2H complete before RDMA reads\n\n    @endpoint\n    def get_weight_handle(self) -\u003E tuple:\n        \"\"\"Get RDMA handle for the latest weight slot.\n\n        Returns (handle_or_None, param_meta, version).\n        If RDMA unavailable, handle is None and caller should use get_state_dict().\n        \"\"\"\n        if self._slot_handles:\n            slot_idx = self.policy_version % self.n_buffer_slots\n            return self._slot_handles[slot_idx], self._param_meta, self.policy_version\n        return None, self._param_meta, self.policy_version\n\n    @endpoint\n    def get_state_dict(self) -\u003E tuple[dict, int]:\n        \"\"\"Fallback: get state dict directly (when RDMA not available).\"\"\"\n        return self.model.state_dict(), self.policy_version\n\n    @endpoint\n    def get_version(self) -\u003E int:\n        return self.policy_version\n\n    @endpoint\n    def train_step(self, trajectories: list[Trajectory], baseline: float) -\u003E TrainMetrics:\n        \"\"\"Train on a batch of trajectories using REINFORCE.\n\n        For each trajectory:\n        1. Reconstruct the prompt using the system prompt + task question\n        2. Tokenize prompt to find the boundary\n        3. Compute per-token log-probs on response tokens only (model_only_text)\n        4. Weight by advantage (reward - baseline)\n        \"\"\"\n        if len(trajectories) == 0:\n            return TrainMetrics(\n                step=self.train_steps, loss=0.0, batch_size=0,\n                avg_reward=0.0, policy_version=self.policy_version,\n            )\n\n        self.model.train()\n        self.optimizer.zero_grad()\n\n        total_loss = torch.tensor(0.0, device=self.device, requires_grad=True)\n        valid_count = 0\n\n        for traj in trajectories:\n            # Reconstruct prompt using system prompt + task question\n            messages = [\n                {\"role\": \"system\", \"content\": self._system_prompt},\n                {\"role\": \"user\", \"content\": traj.task_question},\n            ]\n            prompt_text = self.tokenizer.apply_chat_template(\n                messages, tokenize=False, add_generation_prompt=True\n            )\n\n            # Tokenize prompt to find boundary\n            prompt_ids = self.tokenizer(\n                prompt_text, return_tensors=\"pt\", add_special_tokens=False\n            )[\"input_ids\"]\n            prompt_len = prompt_ids.shape[1]\n\n            # Use model_only_text if available, fall back to response_text\n            response = traj.model_only_text if traj.model_only_text else traj.response_text\n\n            # Tokenize prompt + response together\n            full_ids = self.tokenizer(\n                prompt_text + response,\n                return_tensors=\"pt\",\n                add_special_tokens=False,\n                truncation=True,\n                max_length=1024,\n            )[\"input_ids\"].to(self.device)\n\n            if full_ids.shape[1] \u003C= prompt_len + 1:\n                continue\n\n            with torch.amp.autocast('cuda', enabled=self.device == \"cuda\"):\n                logits = self.model(full_ids).logits\n\n            # Per-token log-probs on response tokens only\n            shift_logits = logits[:, prompt_len - 1:-1, :]\n            shift_labels = full_ids[:, prompt_len:]\n            log_probs = F.log_softmax(shift_logits, dim=-1)\n            token_log_probs = log_probs.gather(2, shift_labels.unsqueeze(-1)).squeeze(-1)\n\n            advantage = traj.reward - baseline\n            total_loss = total_loss + (-token_log_probs.sum() * advantage)\n            valid_count += 1\n\n        if valid_count \u003E 0:\n            avg_loss = total_loss / valid_count\n        else:\n            avg_loss = total_loss\n\n        if avg_loss.requires_grad:\n            avg_loss.backward()\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n            self.optimizer.step()\n\n        self.policy_version += 1\n        self.train_steps += 1\n\n        # Publish weights to circular buffer (GPU -\u003E CPU)\n        self._publish_weights()\n\n        avg_reward = sum(t.reward for t in trajectories) / len(trajectories)\n\n        return TrainMetrics(\n            step=self.train_steps,\n            loss=avg_loss.item() if torch.is_tensor(avg_loss) else avg_loss,\n            batch_size=len(trajectories),\n            avg_reward=avg_reward,\n            policy_version=self.policy_version,\n        )\n\n    @endpoint\n    def evaluate_zorplex(self, num_samples: int = 10, seed: int = 42) -\u003E dict:\n        \"\"\"Evaluate current model on compositional Zorplex tasks.\"\"\"\n        self.model.eval()\n        spec = get_spec(\"compositional\", seed=seed)\n        correct = 0\n        total_turns = 0\n        total_tools = 0\n        for _ in range(num_samples):\n            task = spec.generate_task()\n            result = generate_with_tools(\n                self.model, self.tokenizer, spec, task,\n                self.device, max_turns=5,\n            )\n            correct += int(result.is_correct)\n            total_turns += len(result.turns)\n            total_tools += result.total_tool_calls\n        return {\n            \"accuracy\": correct / num_samples,\n            \"correct\": correct,\n            \"total\": num_samples,\n            \"avg_turns\": total_turns / num_samples,\n            \"avg_tools\": total_tools / num_samples,\n        }", "code_hash": "f9d8a5361cadff8d6fbe5fa47747c170", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Actor 4: GeneratorWorker\n\nEach generator loads its own copy of the model and runs inference independently.\nWeight sync uses the circular buffer pattern:\n\n1. Generator calls `trainer.get_weight_handle()` to get the RDMA handle + metadata\n2. A single RDMA read pulls the entire contiguous buffer into a pre-allocated\n   CPU staging buffer\n3. The generator scatters from CPU staging into GPU model params (H2D)\n\nThis avoids the RDMA API's internal temporary copy (which happens when the\ndestination is a GPU tensor) and gives explicit control over timing.\n\nFallback path (`sync_weights` using `state_dict`) stays for when RDMA is unavailable.\n\"\"\")", "code_hash": "bcd4eb96b31cf2279d2041641dc5259e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "class GeneratorWorker(Actor):\n    \"\"\"Individual generator worker.\n\n    Uses setup() for heavy initialization (model loading).\n    Weight sync uses CPU staging buffer for explicit RDMA -\u003E H2D flow.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"Qwen/Qwen2.5-0.5B-Instruct\",\n        difficulty: str = \"easy\",\n        device: str = \"cuda\",\n    ):\n        # Lightweight init - just store config\n        self.model_name = model_name\n        self.difficulty = difficulty\n        self.device_config = device\n        self.rank = current_rank().rank\n        self._ready = False\n        print(f\"[GeneratorWorker:{self.rank}] Spawned, waiting for setup()...\")\n\n    @endpoint\n    def setup(self) -\u003E dict:\n        \"\"\"Heavy initialization: load model, create weight buffer.\"\"\"\n        import os\n\n        if self._ready:\n            return {\"status\": \"already_ready\"}\n\n        # Generators use GPU 1 + rank (trainer uses GPU 0)\n        gpu_id = 1 + self.rank\n        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.policy_version = 0\n        self.generations = 0\n\n        print(f\"[GeneratorWorker:{self.rank}] Loading model {self.model_name} on GPU {gpu_id}...\")\n\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModelForCausalLM.from_pretrained(\n            self.model_name,\n            dtype=torch.bfloat16 if self.device == \"cuda\" else torch.float32,\n        ).to(self.device)\n\n        if self.tokenizer.pad_token is None:\n            self.tokenizer.pad_token = self.tokenizer.eos_token\n\n        self.spec = get_spec(\"compositional\", difficulty=self.difficulty, seed=42 + self.rank)\n\n        # Pre-allocate CPU staging buffer for weight sync (sized during first sync)\n        self._staging_buf = None\n\n        self._ready = True\n        print(f\"[GeneratorWorker:{self.rank}] Ready on GPU {gpu_id}!\")\n\n        return {\"status\": \"ready\", \"rank\": self.rank, \"gpu\": gpu_id}\n\n    @endpoint\n    def get_version(self) -\u003E int:\n        return self.policy_version\n\n    @endpoint\n    def sync_weights_from_buffer(self, handle, param_meta: dict, version: int) -\u003E bool:\n        \"\"\"Sync weights via RDMA from trainer's circular buffer.\n\n        Flow: Trainer CPU slot --RDMA--\u003E Generator CPU staging --H2D--\u003E Generator GPU\n        \"\"\"\n        if version \u003C= self.policy_version:\n            return False\n\n        buf_size = handle.size()\n\n        # Allocate staging buffer on first sync (reuse for subsequent syncs)\n        if self._staging_buf is None or self._staging_buf.numel() \u003C buf_size:\n            self._staging_buf = torch.empty(buf_size, dtype=torch.uint8)\n\n        # RDMA read: trainer CPU memory -\u003E generator CPU memory\n        handle.read_into(self._staging_buf[:buf_size]).get()\n\n        # Scatter from CPU staging buffer into GPU model params (H2D)\n        for name, p in self.model.named_parameters():\n            off, shape, dtype = param_meta[name]\n            nbytes = p.numel() * p.element_size()\n            src = self._staging_buf[off:off + nbytes].view(dtype).view(shape)\n            p.data.copy_(src)  # H2D copy (src is CPU, p.data is on self.device)\n        self.policy_version = version\n        return True\n\n    @endpoint\n    def sync_weights(self, state_dict: dict, version: int) -\u003E bool:\n        \"\"\"Sync weights directly (fallback when RDMA unavailable).\"\"\"\n        if version \u003C= self.policy_version:\n            return False\n        self.model.load_state_dict(state_dict)\n        self.policy_version = version\n        return True\n\n    @endpoint\n    def generate(self, question: str, answer: int, max_turns: int = 5) -\u003E Trajectory:\n        \"\"\"Generate a trajectory for the given task.\"\"\"\n        self.model.eval()\n\n        task = Task(question=question, correct_answer=answer, metadata={})\n\n        result = generate_with_tools(\n            self.model, self.tokenizer, self.spec, task, self.device,\n            max_turns=max_turns, max_tokens_per_turn=150,\n        )\n\n        self.generations += 1\n\n        # Build model-only text (generated tokens without injected tool results)\n        model_only_text = \"\".join(t.generated_text for t in result.turns)\n\n        return Trajectory(\n            task_question=task.question,\n            task_answer=task.correct_answer,\n            response_text=result.final_text,\n            reward=1.0 if result.is_correct else 0.0,\n            is_correct=result.is_correct,\n            num_turns=len(result.turns),\n            num_tool_calls=result.total_tool_calls,\n            generator_id=self.rank,\n            policy_version=self.policy_version,\n            model_only_text=model_only_text,\n        )", "code_hash": "821538daae476e77b8bc28dfc828871f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Architecture Overview\n\nNow we have all our actors defined. Here's how they connect -- this is the\n**single-controller paradigm** from NB01: the notebook process orchestrates\neverything, but actors do the heavy lifting on their own GPUs.\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ZorplexService     \u2502                    \u2502  GeneratorWorkers   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502     tasks          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 ZorplexWorker \u2502  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u003E \u2502  \u2502 GenWorker 0   \u2502  \u2502\n\u2502  \u2502 ZorplexWorker \u2502  \u2502                    \u2502  \u2502 GenWorker 1   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                      \u2502 trajectories\n                                                      v\n                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                           \u2502    ReplayBuffer     \u2502\n                                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                      \u2502 sample batch\n                                                      v\n                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                           \u2502      Trainer        \u2502\n                                           \u2502  (circular buffer)  \u2502\u2500\u2500\u003E RDMA weight sync\n                                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      to GenWorkers\n```\n\"\"\")", "code_hash": "2045c45cc338c476d9412b45b94536ea", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Sync vs Async RL\n\n**Sync RL** (traditional):\n```\n|--generate--|--train--|--generate--|--train--|--generate--|--train--|\n```\nOnly ONE thing happens at a time. GPU sits idle during generation,\ngenerator sits idle during training.\n\n**Async RL** (what we're building):\n```\nGen0:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\nGen1:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\nTrain:      |\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593|\n```\nEverything runs concurrently. More data collected, better GPU utilization.\n\n**Why threads?** Python's GIL is released during I/O operations and CUDA kernel\nlaunches. Since our actor calls are remote I/O (`.call_one().get()`) and training\nis GPU-bound, threads achieve real concurrency here. Each generator gets its own\nthread; training runs in the main thread. We cannot use async endpoints in this\nenvironment, so threading is the right tool.\n\nWe'll run BOTH modes with the **same actors** and compare wall time, throughput,\nand utilization.\n\"\"\")", "code_hash": "0df8102d17dc31886823bcea77088b04", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "num_steps_slider = mo.ui.slider(3, 20, value=5, label=\"Training steps\")\nnum_generators_slider = mo.ui.slider(1, 4, value=2, label=\"Generators\")\nbatch_size_slider = mo.ui.slider(2, 8, value=4, label=\"Batch size\")\n\nmo.md(f\"\"\"\n## Configuration\n\nAdjust parameters for the training run. Actors are spawned once and reused\nfor both sync and async modes.\n\n{num_steps_slider}\n\n{num_generators_slider}\n\n{batch_size_slider}\n\"\"\")", "code_hash": "aeda65c06281c399d29731a1a4e1fe83", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "import threading\nimport time\nfrom dataclasses import dataclass, field\n\nfrom monarch.actor import this_host\n\n@dataclass\nclass TimingEvent:\n    \"\"\"A single timed event for timeline visualization.\"\"\"\n    actor_id: str\n    event_type: str  # \"generate\", \"train\", \"sync\"\n    start_time: float\n    duration: float\n\n@dataclass\nclass TimingStats:\n    \"\"\"Timing statistics for a training run.\"\"\"\n    mode: str\n    num_generators: int\n    num_steps: int\n    total_generations: int\n    wall_time: float\n    gen_times: list = field(default_factory=list)\n    train_times: list = field(default_factory=list)\n    events: list = field(default_factory=list)  # List of TimingEvent\n    rdma_syncs: int = 0\n    direct_syncs: int = 0\n\n    @property\n    def gens_per_second(self) -\u003E float:\n        return self.total_generations / self.wall_time if self.wall_time \u003E 0 else 0\n\n    @property\n    def steps_per_second(self) -\u003E float:\n        return self.num_steps / self.wall_time if self.wall_time \u003E 0 else 0\n\nNUM_STEPS = num_steps_slider.value\nNUM_GENERATORS = num_generators_slider.value\nNUM_ZORPLEX = 2\nBATCH_SIZE = batch_size_slider.value\n\ndef setup_actors():\n    \"\"\"Spawn and initialize all actors. Returns them for reuse.\"\"\"\n    host = this_host()\n\n    # 1. ZorplexWorkers -- Service spawns workers internally\n    zorplex_worker_procs = host.spawn_procs(per_host={\"procs\": NUM_ZORPLEX})\n    zorplex_svc_procs = host.spawn_procs(per_host={\"procs\": 1})\n    zorplex_svc = zorplex_svc_procs.spawn(\"zorplex_svc\", Service,\n        service_name=\"zorplex\", worker_class=ZorplexWorker,\n        procs=zorplex_worker_procs, procs_per_replica=1,\n        difficulty=\"easy\")\n\n    # 2. GeneratorWorkers -- spawned directly (no Service wrapper for individual access)\n    gen_worker_procs = host.spawn_procs(per_host={\"procs\": NUM_GENERATORS})\n    gen_svc_procs = host.spawn_procs(per_host={\"procs\": 1})\n    gen_svc = gen_svc_procs.spawn(\"gen_svc\", Service,\n        service_name=\"generators\", worker_class=GeneratorWorker,\n        procs=gen_worker_procs, procs_per_replica=1)\n\n    # 3. ReplayBuffer\n    buffer_procs = host.spawn_procs(per_host={\"procs\": 1})\n    buffer = buffer_procs.spawn(\"buffer\", ReplayBuffer, max_size=500)\n\n    # 4. Trainer\n    trainer_procs = host.spawn_procs(per_host={\"procs\": 1})\n    trainer = trainer_procs.spawn(\"trainer\", TrainerActor)\n\n    # Initialize actors that need setup\n    zorplex_svc.ping.call_one().get()\n\n    print(\"[SETUP] Setting up generator workers...\")\n    gen_worker_list = gen_svc.get_all_replicas.call_one().get()\n    for w in gen_worker_list:\n        w.setup.call_one().get()\n\n    gen_svc.ping.call_one().get()\n    buffer.stats.call_one().get()\n\n    print(\"[SETUP] Setting up trainer...\")\n    trainer.setup.call_one().get()\n\n    register_service(\"zorplex\", zorplex_svc)\n    register_service(\"generators\", gen_svc)\n\n    print(f\"[SETUP] All actors ready! {NUM_GENERATORS} generators, {NUM_ZORPLEX} zorplex workers\")\n\n    return {\n        \"trainer\": trainer,\n        \"buffer\": buffer,\n        \"gen_worker_list\": gen_worker_list,\n        \"gen_svc\": gen_svc,\n        \"zorplex_svc\": zorplex_svc,\n    }\n\nactors = setup_actors()", "code_hash": "e76e3afde5d13ee09373fa0106e23129", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Before Training: Zorplex Baseline\n\nLet's evaluate the model *before* any training to establish a baseline.\nWe run 10 compositional Zorplex tasks and record accuracy, average turns,\nand tool usage. This gives us a concrete \"before\" snapshot to compare against.\n\"\"\")", "code_hash": "476adcec390e4d09fb048f4c447bb22f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ulZA", "name": "_"}, {"code": "print(\"Evaluating pre-training baseline...\")\npre_eval = actors[\"trainer\"].evaluate_zorplex.call_one(num_samples=10, seed=42).get()\n\nmo.md(f\"\"\"\n### Pre-Training Results\n\n| Metric | Value |\n|--------|-------|\n| Accuracy | {pre_eval['accuracy']:.0%} ({pre_eval['correct']}/{pre_eval['total']}) |\n| Avg turns | {pre_eval['avg_turns']:.1f} |\n| Avg tool calls | {pre_eval['avg_tools']:.1f} |\n\nThis is our starting point. Let's see if training improves it.\n\"\"\")", "code_hash": "1169355ff5fdae5e41d054486a321275", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "def run_sync_loop() -\u003E TimingStats:\n    \"\"\"\n    SYNC MODE: Rotate through ALL generators sequentially.\n    Pattern: generate -\u003E train -\u003E generate -\u003E train ...\n\n    Uses all generators in round-robin so the comparison with async\n    is fair -- same number of generators, just used sequentially.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(\"SYNC MODE: Sequential Generate -\u003E Train\")\n    print(\"=\" * 60)\n\n    trainer = actors[\"trainer\"]\n    buffer = actors[\"buffer\"]\n    gen_worker_list = actors[\"gen_worker_list\"]\n    zorplex_svc = actors[\"zorplex_svc\"]\n\n    stats = TimingStats(\n        mode=\"SYNC\",\n        num_generators=len(gen_worker_list),\n        num_steps=NUM_STEPS,\n        total_generations=0,\n        wall_time=0,\n    )\n\n    baseline = 0.5\n    t0 = time.perf_counter()\n\n    for step in range(NUM_STEPS):\n        # Rotate through ALL generators (fair comparison with async)\n        gen_worker = gen_worker_list[step % len(gen_worker_list)]\n\n        # Generate ONE trajectory (blocking)\n        gen_start = time.perf_counter()\n        zorplex_worker, _ = zorplex_svc.get_replica_with_idx.call_one().get()\n        question, answer = zorplex_worker.generate_task.call_one().get()\n        traj = gen_worker.generate.call_one(question, answer).get()\n        buffer.add.call_one(traj).get()\n        gen_time = time.perf_counter() - gen_start\n        stats.gen_times.append(gen_time)\n        stats.total_generations += 1\n        stats.events.append(TimingEvent(\n            actor_id=f\"Gen{step % len(gen_worker_list)}\",\n            event_type=\"generate\",\n            start_time=gen_start - t0,\n            duration=gen_time,\n        ))\n\n        # Train on buffer (blocking)\n        train_start = time.perf_counter()\n        batch = buffer.sample.call_one(BATCH_SIZE).get()\n        if batch:\n            metrics = trainer.train_step.call_one(batch, baseline).get()\n            baseline = 0.9 * baseline + 0.1 * metrics.avg_reward\n        train_time = time.perf_counter() - train_start\n        stats.train_times.append(train_time)\n        stats.events.append(TimingEvent(\n            actor_id=\"Train\",\n            event_type=\"train\",\n            start_time=train_start - t0,\n            duration=train_time,\n        ))\n\n        status = \"correct\" if traj.is_correct else \"wrong\"\n        print(f\"[SYNC {step + 1:2d}] {status} gen={gen_time * 1000:.0f}ms train={train_time * 1000:.0f}ms\")\n\n    stats.wall_time = time.perf_counter() - t0\n    return stats", "code_hash": "7266fad0179363a5c184f774a5f98058", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Pvdt", "name": "_"}, {"code": "def run_async_loop() -\u003E TimingStats:\n    \"\"\"\n    ASYNC MODE: All generators running concurrently with trainer.\n    - 1 thread per generator (each runs its own generation loop)\n    - 1 separate weight sync thread\n    - Training in main thread\n\n    Uses try/except pattern from NB03 for fault tolerance in generation loops.\n    \"\"\"\n    print(\"\\n\" + \"=\" * 60)\n    print(f\"ASYNC MODE: {len(actors['gen_worker_list'])} Generators + 1 Trainer (Concurrent)\")\n    print(\"=\" * 60)\n\n    trainer = actors[\"trainer\"]\n    buffer = actors[\"buffer\"]\n    gen_worker_list = actors[\"gen_worker_list\"]\n    zorplex_svc = actors[\"zorplex_svc\"]\n\n    stats = TimingStats(\n        mode=\"ASYNC\",\n        num_generators=len(gen_worker_list),\n        num_steps=NUM_STEPS,\n        total_generations=0,\n        wall_time=0,\n    )\n\n    lock = threading.Lock()\n    stop_flag = threading.Event()\n    t0 = time.perf_counter()\n\n    def generation_loop(gen_idx, gen_worker):\n        \"\"\"Each generator gets its own thread.\"\"\"\n        while not stop_flag.is_set():\n            gen_start = time.perf_counter()\n\n            zorplex_worker, _ = zorplex_svc.get_replica_with_idx.call_one().get()\n            question, answer = zorplex_worker.generate_task.call_one().get()\n\n            try:\n                traj = gen_worker.generate.call_one(question, answer).get()\n                buffer.add.call_one(traj).get()\n\n                gen_time = time.perf_counter() - gen_start\n                with lock:\n                    stats.gen_times.append(gen_time)\n                    stats.total_generations += 1\n                    count = stats.total_generations\n                    stats.events.append(TimingEvent(\n                        actor_id=f\"Gen{gen_idx}\",\n                        event_type=\"generate\",\n                        start_time=gen_start - t0,\n                        duration=gen_time,\n                    ))\n\n                status = \"correct\" if traj.is_correct else \"wrong\"\n                print(f\"[GEN{gen_idx} #{count:2d}] {status} gen={gen_time * 1000:.0f}ms\")\n\n            except Exception as e:\n                # try/except pattern from NB03 -- log and continue\n                print(f\"[GEN{gen_idx}] Error: {e}, retrying...\")\n                continue\n\n    def weight_sync_loop():\n        \"\"\"Periodically sync weights to all generators.\"\"\"\n        while not stop_flag.is_set():\n            time.sleep(0.5)  # Sync every 500ms\n            if stop_flag.is_set():\n                break\n\n            sync_start = time.perf_counter()\n            try:\n                handle, param_meta, version = trainer.get_weight_handle.call_one().get()\n                for w in gen_worker_list:\n                    try:\n                        if handle is not None:\n                            synced = w.sync_weights_from_buffer.call_one(handle, param_meta, version).get()\n                            if synced:\n                                with lock:\n                                    stats.rdma_syncs += 1\n                        else:\n                            state_dict, ver = trainer.get_state_dict.call_one().get()\n                            synced = w.sync_weights.call_one(state_dict, ver).get()\n                            if synced:\n                                with lock:\n                                    stats.direct_syncs += 1\n                    except Exception:\n                        pass\n\n                sync_time = time.perf_counter() - sync_start\n                with lock:\n                    stats.events.append(TimingEvent(\n                        actor_id=\"Sync\",\n                        event_type=\"sync\",\n                        start_time=sync_start - t0,\n                        duration=sync_time,\n                    ))\n            except Exception:\n                pass\n\n    # Start 1 thread per generator\n    gen_threads = []\n    for idx, worker in enumerate(gen_worker_list):\n        t = threading.Thread(target=generation_loop, args=(idx, worker), daemon=True)\n        t.start()\n        gen_threads.append(t)\n\n    # Start weight sync thread\n    sync_thread = threading.Thread(target=weight_sync_loop, daemon=True)\n    sync_thread.start()\n\n    # Training in main thread\n    train_steps_done = 0\n    baseline = 0.5\n\n    while train_steps_done \u003C NUM_STEPS:\n        # Wait for enough samples\n        while True:\n            size = buffer.size.call_one().get()\n            if size \u003E= BATCH_SIZE:\n                break\n            time.sleep(0.02)\n\n        train_start = time.perf_counter()\n        batch = buffer.sample.call_one(BATCH_SIZE).get()\n        if batch:\n            metrics = trainer.train_step.call_one(batch, baseline).get()\n            baseline = 0.9 * baseline + 0.1 * metrics.avg_reward\n\n        train_time = time.perf_counter() - train_start\n        with lock:\n            stats.train_times.append(train_time)\n            stats.events.append(TimingEvent(\n                actor_id=\"Train\",\n                event_type=\"train\",\n                start_time=train_start - t0,\n                duration=train_time,\n            ))\n        train_steps_done += 1\n\n        print(f\"[TRAIN {train_steps_done:2d}] time={train_time * 1000:.0f}ms buffer={size}\")\n\n    stop_flag.set()\n\n    for t in gen_threads:\n        t.join(timeout=2.0)\n    sync_thread.join(timeout=2.0)\n\n    stats.wall_time = time.perf_counter() - t0\n    return stats", "code_hash": "8f3ebc1763574a871b339cf4a1abd648", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZBYS", "name": "_"}, {"code": "# Clear buffer to start fresh\n_cleared = actors[\"buffer\"].clear.call_one().get()\nprint(f\"Buffer cleared ({_cleared} items removed)\")\n\nsync_stats = run_sync_loop()\nprint(f\"\\nSync complete: {sync_stats.wall_time:.2f}s, \"\n      f\"{sync_stats.total_generations} generations, \"\n      f\"{sync_stats.gens_per_second:.2f} gens/s\")", "code_hash": "a9790d26ee5638d6443b1fe20f8b3494", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aLJB", "name": "_"}, {"code": "# Clear buffer between runs for fair comparison\n_cleared = actors[\"buffer\"].clear.call_one().get()\nprint(f\"Buffer cleared ({_cleared} items removed)\")\n\nasync_stats = run_async_loop()\nprint(f\"\\nAsync complete: {async_stats.wall_time:.2f}s, \"\n      f\"{async_stats.total_generations} generations, \"\n      f\"{async_stats.gens_per_second:.2f} gens/s\")", "code_hash": "0b75000775587103ec4994dd39384427", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nHfw", "name": "_"}, {"code": "def _build_comparison(sync_s, async_s) -\u003E str:\n    speedup = sync_s.wall_time / async_s.wall_time if async_s.wall_time \u003E 0 else 0\n    gen_ratio = async_s.gens_per_second / sync_s.gens_per_second if sync_s.gens_per_second \u003E 0 else 0\n\n    avg_sync_gen = sum(sync_s.gen_times) / len(sync_s.gen_times) * 1000 if sync_s.gen_times else 0\n    avg_async_gen = sum(async_s.gen_times) / len(async_s.gen_times) * 1000 if async_s.gen_times else 0\n    avg_sync_train = sum(sync_s.train_times) / len(sync_s.train_times) * 1000 if sync_s.train_times else 0\n    avg_async_train = sum(async_s.train_times) / len(async_s.train_times) * 1000 if async_s.train_times else 0\n\n    sync_type = f\"{async_s.rdma_syncs} RDMA\" if async_s.rdma_syncs \u003E 0 else f\"{async_s.direct_syncs} direct\"\n\n    return f\"\"\"\n## Sync vs Async Comparison\n\n| Metric | SYNC | ASYNC | Ratio |\n|--------|------|-------|-------|\n| Wall time | {sync_s.wall_time:.2f}s | {async_s.wall_time:.2f}s | **{speedup:.2f}x** speedup |\n| Generations | {sync_s.total_generations} | {async_s.total_generations} | {async_s.total_generations / max(sync_s.total_generations, 1):.1f}x |\n| Gens/second | {sync_s.gens_per_second:.2f} | {async_s.gens_per_second:.2f} | **{gen_ratio:.1f}x** throughput |\n| Avg gen time | {avg_sync_gen:.0f}ms | {avg_async_gen:.0f}ms | |\n| Avg train time | {avg_sync_train:.0f}ms | {avg_async_train:.0f}ms | |\n| Weight syncs | -- | {sync_type} | |\n\n### Key Observations\n\n- **Data throughput**: Async collected **{gen_ratio:.1f}x** more trajectories per second.\n  More data means better gradient estimates.\n- **GPU utilization**: In sync mode, the trainer GPU sits idle during generation and\n  vice versa. Async keeps both busy.\n- **Generators ran in parallel**: {async_s.num_generators} generators each had their own\n  thread, producing data independently.\n- The trainer consumed from the replay buffer continuously, never waiting for a specific\n  generator to finish.\n\nIn production with more generators, the throughput advantage grows further.\n\"\"\"\n\ncomparison_md = _build_comparison(sync_stats, async_stats)\nmo.md(comparison_md)", "code_hash": "fd4b2315b3a12417972985822e59355e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "xXTn", "name": "_"}, {"code": "import matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\ndef _plot_timeline(stats, ax, title):\n    \"\"\"Plot a Gantt chart of timing events.\"\"\"\n    color_map = {\n        \"generate\": \"#4CAF50\",  # green\n        \"train\": \"#E91E63\",     # pink\n        \"sync\": \"#9C27B0\",      # purple\n    }\n\n    # Collect unique actor IDs and assign y positions\n    actor_ids = []\n    for ev in stats.events:\n        if ev.actor_id not in actor_ids:\n            actor_ids.append(ev.actor_id)\n\n    # Sort: Gen0, Gen1, ..., Train, Sync\n    gen_ids = sorted([a for a in actor_ids if a.startswith(\"Gen\")])\n    other_ids = [a for a in [\"Train\", \"Sync\"] if a in actor_ids]\n    actor_ids = gen_ids + other_ids\n\n    y_map = {aid: i for i, aid in enumerate(actor_ids)}\n\n    for ev in stats.events:\n        if ev.actor_id in y_map:\n            y = y_map[ev.actor_id]\n            color = color_map.get(ev.event_type, \"#999999\")\n            ax.barh(y, ev.duration, left=ev.start_time, height=0.6,\n                    color=color, alpha=0.8, edgecolor=\"white\", linewidth=0.5)\n\n    ax.set_yticks(range(len(actor_ids)))\n    ax.set_yticklabels(actor_ids)\n    ax.set_xlabel(\"Wall time (seconds)\")\n    ax.set_title(title)\n    ax.invert_yaxis()\n\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6), sharex=False)\n\n_plot_timeline(sync_stats, ax1, f\"SYNC ({sync_stats.wall_time:.1f}s)\")\n_plot_timeline(async_stats, ax2, f\"ASYNC ({async_stats.wall_time:.1f}s)\")\n\n# Legend\nlegend_patches = [\n    mpatches.Patch(color=\"#4CAF50\", label=\"Generate\"),\n    mpatches.Patch(color=\"#E91E63\", label=\"Train\"),\n    mpatches.Patch(color=\"#9C27B0\", label=\"Weight Sync\"),\n]\nfig.legend(handles=legend_patches, loc=\"upper right\", framealpha=0.9)\n\nplt.tight_layout()\nmo.md(\"### Timeline Visualization\")", "code_hash": "33487768b481ba1e786eff59f88da13f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "AjVT", "name": "_"}, {"code": "mo.md(r\"\"\"\n## After Training: Did It Improve?\n\nWe've now run both sync and async training loops. The model has been updated\nthrough multiple training steps. Let's evaluate the same set of compositional\ntasks to see if accuracy changed.\n\nNote: We're using a small model (0.5B) with few training steps, so dramatic\nimprovement isn't guaranteed. The point is the *infrastructure* -- showing that\nthe full loop works end to end.\n\"\"\")", "code_hash": "54f542b094098b6f232b8d9fb583cb5b", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "pHFh", "name": "_"}, {"code": "print(\"Evaluating post-training performance...\")\npost_eval = actors[\"trainer\"].evaluate_zorplex.call_one(num_samples=10, seed=42).get()\nprint(f\"Post-training accuracy: {post_eval['accuracy']:.0%}\")", "code_hash": "d0b49fa52a3632e4f6799fbcda88cd60", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "NCOB", "name": "_"}, {"code": "_acc_delta = post_eval[\"accuracy\"] - pre_eval[\"accuracy\"]\n_direction = \"improved\" if _acc_delta \u003E 0 else (\"unchanged\" if _acc_delta == 0 else \"decreased\")\n\nmo.md(f\"\"\"\n### Before vs After Training\n\n| Metric | Before | After | Delta |\n|--------|--------|-------|-------|\n| Accuracy | {pre_eval['accuracy']:.0%} | {post_eval['accuracy']:.0%} | {_acc_delta:+.0%} |\n| Avg turns | {pre_eval['avg_turns']:.1f} | {post_eval['avg_turns']:.1f} | {post_eval['avg_turns'] - pre_eval['avg_turns']:+.1f} |\n| Avg tool calls | {pre_eval['avg_tools']:.1f} | {post_eval['avg_tools']:.1f} | {post_eval['avg_tools'] - pre_eval['avg_tools']:+.1f} |\n\nAccuracy {_direction} by {abs(_acc_delta):.0%}.\n\nWith a 0.5B model and only a few training steps, large gains are unlikely.\nThe key result is that the full pipeline works: generation, buffering, training,\nweight sync, and evaluation all compose correctly through Monarch actors.\n\"\"\")", "code_hash": "079db20abc6eda0625239d3706587790", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aqbW", "name": "_"}, {"code": "mo.md(r\"\"\"\n## What's Happening Under the Hood\n\nWhen you run the training loop, here's what each layer does:\n\n**Actor isolation**: Each actor (trainer, generators, buffer, zorplex workers)\nruns in its own process with its own GPU assignment. `CUDA_VISIBLE_DEVICES` is\nset in `setup()`, not at spawn time -- the `procs` dimension in `spawn_procs`\nis just a dimension name, not a GPU assignment.\n\n**Weight sync data flow** (circular buffer + CPU staging from NB06):\n```\nTrainer GPU  --D2H--\u003E  CPU slot[v % 3]  --RDMA--\u003E  Generator CPU staging  --H2D--\u003E  Generator GPU\n```\n- Trainer publishes weights to a circular buffer after each train step\n- Generators pull from the buffer via RDMA into a pre-allocated staging buffer\n- Explicit H2D copy scatters into GPU model parameters\n- The circular buffer has 3 slots, so training never blocks on reads\n\n**Async concurrency** (via threads):\n- 1 thread per generator, each running its own generation loop\n- 1 weight sync thread, periodically pulling from trainer and pushing to generators\n- Training in the main thread\n- `threading.Event` coordinates shutdown when training completes\n- GIL is released during I/O (actor calls) and CUDA (GPU compute), so threads\n  achieve real concurrency\n\n**Fault tolerance** (from NB03):\n- Generation loops wrap `generate.call_one().get()` in `try/except`\n- On failure, the generator logs and retries instead of crashing the loop\n\"\"\")", "code_hash": "b3cf7c2aa2f9dacb9bd46c27c0ef15eb", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TRpd", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Scaling Up\n\nWhat we built here scales naturally with Monarch:\n\n| Scale | What Changes |\n|-------|--------------|\n| More generators | Increase `num_generators` slider -- spawns larger ActorMesh |\n| More zorplex workers | Increase `NUM_ZORPLEX` -- parallel task generation |\n| Multi-node | Use `SlurmJob` instead of `this_host()` |\n| Better algorithms | Swap REINFORCE for PPO/GRPO |\n| More services | Add reward models, search APIs as actors |\n\n**The patterns stay the same:**\n- Actors for isolation and GPU assignment\n- Endpoints for communication (`.call_one().get()`)\n- RDMA + circular buffer for efficient weight transfer\n- Version tracking for consistency across actors\n\nThis is the foundation for production systems like Forge GRPO, which uses the\nsame Monarch actor patterns at much larger scale.\n\"\"\")", "code_hash": "dac2d2a64136b4ff96e79c8da3ac85d6", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TXez", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Recap: The Full Journey\n\nWe've come a long way in this notebook series:\n\n| Notebook | What We Learned |\n|----------|-----------------|\n| 01 | Monarch's history and the single-controller paradigm |\n| 02 | Interactive development with `this_host()` |\n| 03 | Fault tolerance with `try/except` on actor calls |\n| 04 | Zorplex benchmark -- where Qwen 0.5B struggles |\n| 05 | Services for managing worker pools with health tracking |\n| 06 | RDMA weight sync, circular buffers, CPU staging |\n| **07** | **Closing the loop: async RL training end to end** |\n\n**Key takeaways from this notebook:**\n\n- Monarch makes distributed RL feel like local Python -- actors, endpoints,\n  and slicing compose naturally into a full training system\n- Async RL collects more data per unit wall time by running generators\n  and trainer concurrently\n- The circular buffer + CPU staging pattern from NB06 decouples training\n  from weight distribution\n- Before/after evaluation closes the loop: we can measure whether training\n  actually improves the model\n\n**Where to go next:** Forge GRPO implements these same patterns at production\nscale -- multiple nodes, larger models, PPO/GRPO instead of REINFORCE, and\nproper reward modeling. The Monarch primitives you've learned here are the\nbuilding blocks for all of it.\n\"\"\")", "code_hash": "9a72d57f1ff9de84d9d2eb14d2d94ed3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "dNNg", "name": "_"}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "9d2da1a64a7c48c53bbbd693ac608cce", "console": [], "id": "MJUe", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "04edb86c0f1dd0688c1bac819263149e", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"closing-the-loop-async-rl-training\"\u003EClosing the Loop: Async RL Training\u003C/h1\u003E\n\u003Cspan class=\"paragraph\"\u003EIn \u003Cstrong\u003ENotebook 04\u003C/strong\u003E, we introduced the Zorplex benchmark and saw that Qwen 0.5B\nstruggles with compositional tasks -- it gets ~60-70% accuracy when it needs to\nchain multiple tool calls.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ENow we close the loop\u003C/strong\u003E: train the model to get better at these tasks.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWe'll build on patterns from across the series:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003E\u003Ccode\u003Ethis_host()\u003C/code\u003E from NB02\u003C/strong\u003E -- spawning actors on the local machine for interactive development\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003E\u003Ccode\u003Etry/except\u003C/code\u003E from NB03\u003C/strong\u003E -- fault tolerance in generation loops\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERDMA weight sync from NB06\u003C/strong\u003E -- circular buffer + CPU staging for efficient weight transfer\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThe architecture: multiple generators feed trajectories into a replay buffer while\na trainer continuously samples and updates the policy. We'll measure \u003Cem\u003Ebefore\u003C/em\u003E and\n\u003Cem\u003Eafter\u003C/em\u003E accuracy to see if training actually helps.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "f03f72962704b86b8fde7b5a0d9845e9", "console": [], "id": "bkHC", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "5fc990d636c1d12556a4677252891c16", "console": [], "id": "lEQa", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "fee169ea6b0e7445704b9d9dae9027a9", "console": [], "id": "PKri", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"shared-data-structures\"\u003EShared Data Structures\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ETrajectory\u003C/strong\u003E -- one rollout from a generator:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EField\u003C/th\u003E\n\u003Cth\u003EType\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Etask_question\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Estr\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Etask_answer\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint | str\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Eresponse_text\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Estr\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Ereward\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Efloat\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Eis_correct\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Ebool\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Enum_turns\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Enum_tool_calls\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Egenerator_id\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Epolicy_version\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Emodel_only_text\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Estr\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ETrainMetrics\u003C/strong\u003E -- returned after each training step:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EField\u003C/th\u003E\n\u003Cth\u003EType\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Estep\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Eloss\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Efloat\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Ebatch_size\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Eavg_reward\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Efloat\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003Epolicy_version\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003Eint\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThe \u003Ccode\u003Emodel_only_text\u003C/code\u003E field stores the model's generated tokens without injected tool\nresults, so the trainer can compute log-probabilities on exactly what the model produced.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "4e6c895b9547643bc1a0087250cf6b27", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"service-infrastructure\"\u003EService Infrastructure\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWe import a \u003Cstrong\u003Ecustom Service abstraction\u003C/strong\u003E from \u003Ccode\u003Emonarch_utils\u003C/code\u003E that manages worker\nreplicas with health tracking and round-robin routing. This is a utility we built\nfor this notebook series -- the canonical Monarch pattern uses direct actor\nreferences and slicing, which is what the Service wraps internally.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E(See notebook 05 for the full implementation.)\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e644d8e238271c0dcb2c797fbb8e561f", "console": [], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "daa9bf7142584931a46045dbe2c26323", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"the-setup-pattern\"\u003EThe \u003Ccode\u003Esetup()\u003C/code\u003E Pattern\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch actors use a two-phase initialization:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003E\u003Ccode\u003E__init__\u003C/code\u003E\u003C/strong\u003E runs during \u003Ccode\u003Espawn()\u003C/code\u003E -- keep it lightweight (store config, set rank)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003E\u003Ccode\u003Esetup()\u003C/code\u003E\u003C/strong\u003E is an endpoint called explicitly after spawn -- do heavy work here\n   (load models, allocate GPU memory, register RDMA buffers)\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EWhy not do everything in \u003Ccode\u003E__init__\u003C/code\u003E? Two reasons:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003E\u003Ccode\u003Espawn()\u003C/code\u003E is asynchronous\u003C/strong\u003E -- it returns immediately, and \u003Ccode\u003E__init__\u003C/code\u003E runs in\n  the remote process before the first endpoint call. But you don't control \u003Cem\u003Ewhen\u003C/em\u003E,\n  and you can't confirm it completed. An explicit \u003Ccode\u003Esetup()\u003C/code\u003E call lets you sequence\n  initialization (e.g., set \u003Ccode\u003ECUDA_VISIBLE_DEVICES\u003C/code\u003E and confirm it took effect before\n  loading a model).\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECoordination\u003C/strong\u003E -- you often need to initialize actors in a specific order (set up\n  the trainer before generators try to sync weights). Endpoint calls give you that\n  sequencing; \u003Ccode\u003E__init__\u003C/code\u003E doesn't.\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "ab05f41981edfe1bd8f40d35bf3c4949", "console": [], "id": "RGSE", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"actor-1-zorplexworker\"\u003EActor 1: ZorplexWorker\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ETool execution environments (docker containers, sandboxes, API endpoints) naturally\nform a fleet -- you want many instances running in parallel to keep up with\ngeneration throughput. That makes them a good fit for a \u003Cstrong\u003EService\u003C/strong\u003E (from NB05)\nwith health tracking and round-robin routing.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EOur ZorplexWorker actors handle Zorplex tasks:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ccode\u003Egenerate_task()\u003C/code\u003E -- creates a new problem\u003C/li\u003E\n\u003Cli\u003E\u003Ccode\u003Eexecute_tool()\u003C/code\u003E -- handles LOOKUP calls\u003C/li\u003E\n\u003Cli\u003E\u003Ccode\u003Echeck_answer()\u003C/code\u003E -- verifies correctness\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "5b736dfec5189aa58d1c4d7bd99b7601", "console": [], "id": "Kclp", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "c0885ae43fdc631e7ea9060c5b7ed490", "console": [], "id": "emfo", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"actor-2-replaybuffer\"\u003EActor 2: ReplayBuffer\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EA simple actor that stores trajectories. Generators push trajectories in,\nthe trainer samples batches out. The \u003Ccode\u003Eclear()\u003C/code\u003E endpoint lets us reset between\nsync and async runs for a fair comparison.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis enables async RL -- generation and training happen independently,\nconnected only through the buffer.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "7b1d6f17134e908391a42f035734452f", "console": [], "id": "Hstk", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "6ccacd8bc6cf97ad62a3c339362ab42e", "console": [], "id": "nWHF", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"actor-3-traineractor\"\u003EActor 3: TrainerActor\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe trainer loads the model, receives batches of trajectories, and computes\nREINFORCE updates.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EREINFORCE\u003C/strong\u003E: For each trajectory, we compute per-token log-probabilities on\nthe \u003Cem\u003Eresponse tokens only\u003C/em\u003E (using \u003Ccode\u003Emodel_only_text\u003C/code\u003E, not the full text with\ninjected tool results). The loss is:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003Eloss = -sum(log_prob(token_i)) * (reward - baseline)\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis weights the entire response by the advantage. Positive advantage reinforces\nthe response; negative advantage suppresses it.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECircular buffer with CPU staging\u003C/strong\u003E (from NB06): Instead of registering RDMA\nhandles directly on GPU parameters (which blocks training during reads), we\nmaintain N CPU staging slots. After each training step, weights are copied\nGPU -\u0026gt; CPU (D2H) into the current slot. Generators read from CPU via RDMA,\nthen copy to their own GPU (H2D). The data flow:\u003C/span\u003E\n\u003Cdiv class=\"language-ecl codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u003C/span\u003E\u003Cspan class=\"n\"\u003ED2H\u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Ev\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E%\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u003C/span\u003E\u003Cspan class=\"n\"\u003EH2D\u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis decouples training from weight distribution.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "f9d8a5361cadff8d6fbe5fa47747c170", "console": [], "id": "iLit", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "bcd4eb96b31cf2279d2041641dc5259e", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"actor-4-generatorworker\"\u003EActor 4: GeneratorWorker\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EEach generator loads its own copy of the model and runs inference independently.\nWeight sync uses the circular buffer pattern:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EGenerator calls \u003Ccode\u003Etrainer.get_weight_handle()\u003C/code\u003E to get the RDMA handle + metadata\u003C/li\u003E\n\u003Cli\u003EA single RDMA read pulls the entire contiguous buffer into a pre-allocated\n   CPU staging buffer\u003C/li\u003E\n\u003Cli\u003EThe generator scatters from CPU staging into GPU model params (H2D)\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EThis avoids the RDMA API's internal temporary copy (which happens when the\ndestination is a GPU tensor) and gives explicit control over timing.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EFallback path (\u003Ccode\u003Esync_weights\u003C/code\u003E using \u003Ccode\u003Estate_dict\u003C/code\u003E) stays for when RDMA is unavailable.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "821538daae476e77b8bc28dfc828871f", "console": [], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "2045c45cc338c476d9412b45b94536ea", "console": [], "id": "qnkX", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"architecture-overview\"\u003EArchitecture Overview\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ENow we have all our actors defined. Here's how they connect -- this is the\n\u003Cstrong\u003Esingle-controller paradigm\u003C/strong\u003E from NB01: the notebook process orchestrates\neverything, but actors do the heavy lifting on their own GPUs.\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  ZorplexService     \u2502                    \u2502  GeneratorWorkers   \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502     tasks          \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502 ZorplexWorker \u2502  \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u0026gt; \u2502  \u2502 GenWorker 0   \u2502  \u2502\n\u2502  \u2502 ZorplexWorker \u2502  \u2502                    \u2502  \u2502 GenWorker 1   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                      \u2502 trajectories\n                                                      v\n                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                           \u2502    ReplayBuffer     \u2502\n                                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                      \u2502 sample batch\n                                                      v\n                                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                           \u2502      Trainer        \u2502\n                                           \u2502  (circular buffer)  \u2502\u2500\u2500\u0026gt; RDMA weight sync\n                                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      to GenWorkers\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "0df8102d17dc31886823bcea77088b04", "console": [], "id": "TqIu", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"sync-vs-async-rl\"\u003ESync vs Async RL\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ESync RL\u003C/strong\u003E (traditional):\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E|--generate--|--train--|--generate--|--train--|--generate--|--train--|\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\nOnly ONE thing happens at a time. GPU sits idle during generation,\ngenerator sits idle during training.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EAsync RL\u003C/strong\u003E (what we're building):\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EGen0:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\nGen1:  |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588|\nTrain:      |\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593\u2593|\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\nEverything runs concurrently. More data collected, better GPU utilization.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhy threads?\u003C/strong\u003E Python's GIL is released during I/O operations and CUDA kernel\nlaunches. Since our actor calls are remote I/O (\u003Ccode\u003E.call_one().get()\u003C/code\u003E) and training\nis GPU-bound, threads achieve real concurrency here. Each generator gets its own\nthread; training runs in the main thread. We cannot use async endpoints in this\nenvironment, so threading is the right tool.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWe'll run BOTH modes with the \u003Cstrong\u003Esame actors\u003C/strong\u003E and compare wall time, throughput,\nand utilization.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "aeda65c06281c399d29731a1a4e1fe83", "console": [], "id": "Vxnm", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"configuration\"\u003EConfiguration\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EAdjust parameters for the training run. Actors are spawned once and reused\nfor both sync and async modes.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cmarimo-ui-element object-id='Vxnm-0' random-id='92e6458b-1285-aea4-b8fc-deff5fd96ed0'\u003E\u003Cmarimo-slider data-initial-value='5' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Training steps\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='3' data-stop='20' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cmarimo-ui-element object-id='Vxnm-1' random-id='8bd10b8b-7fb2-20a0-d8d7-c487ae5b76e0'\u003E\u003Cmarimo-slider data-initial-value='2' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Generators\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='1' data-stop='4' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cmarimo-ui-element object-id='Vxnm-2' random-id='7c7e6d5b-1423-7eb9-2425-aad2cebe4150'\u003E\u003Cmarimo-slider data-initial-value='4' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Batch size\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='2' data-stop='8' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e76e3afde5d13ee09373fa0106e23129", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-06_14:31_737\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "[ReplayBuffer] Initialized with max_size=500\n[SERVICE:zorplex] 2 replicas x 1 procs each\n[SETUP] Setting up generator workers...\n[SERVICE:generators] 2 replicas x 1 procs each\n[ZorplexWorker:0] Initialized with difficulty=easy\n[ZorplexWorker:0] Initialized with difficulty=easy\n[Trainer:0] Spawned, waiting for setup()...\n[GeneratorWorker:0] Spawned, waiting for setup()...\n[GeneratorWorker:0] Spawned, waiting for setup()...\n[GeneratorWorker:0] Loading model Qwen/Qwen2.5-0.5B-Instruct on GPU 1...\n[GeneratorWorker:0] Ready on GPU 1!\n[GeneratorWorker:0] Loading model Qwen/Qwen2.5-0.5B-Instruct on GPU 1...\n[GeneratorWorker:0] Ready on GPU 1!\n[SETUP] Setting up trainer...\n[Trainer:0] Loading model Qwen/Qwen2.5-0.5B-Instruct on GPU 0...\n[Trainer:0] RDMA handles registered for 3 circular buffer slots\n[Trainer:0] Ready! 494,032,768 params, RDMA=True, buffer_slots=3\n[REGISTRY] ServiceRegistry spawned\n[REGISTRY] Registered 'zorplex'\n[REGISTRY] Registered 'generators'\n[SETUP] All actors ready! 2 generators, 2 zorplex workers\n", "type": "stream"}], "id": "DnEU", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "476adcec390e4d09fb048f4c447bb22f", "console": [], "id": "ulZA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"before-training-zorplex-baseline\"\u003EBefore Training: Zorplex Baseline\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's evaluate the model \u003Cem\u003Ebefore\u003C/em\u003E any training to establish a baseline.\nWe run 10 compositional Zorplex tasks and record accuracy, average turns,\nand tool usage. This gives us a concrete \"before\" snapshot to compare against.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "1169355ff5fdae5e41d054486a321275", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Evaluating pre-training baseline...\n", "type": "stream"}], "id": "ecfG", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"pre-training-results\"\u003EPre-Training Results\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EMetric\u003C/th\u003E\n\u003Cth\u003EValue\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAccuracy\u003C/td\u003E\n\u003Ctd\u003E30% (3/10)\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAvg turns\u003C/td\u003E\n\u003Ctd\u003E4.3\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAvg tool calls\u003C/td\u003E\n\u003Ctd\u003E3.7\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is our starting point. Let's see if training improves it.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "7266fad0179363a5c184f774a5f98058", "console": [], "id": "Pvdt", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8f3ebc1763574a871b339cf4a1abd648", "console": [], "id": "ZBYS", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "a9790d26ee5638d6443b1fe20f8b3494", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Buffer cleared (0 items removed)\n\n============================================================\nSYNC MODE: Sequential Generate -\u003E Train\n============================================================\n[SYNC  1] wrong gen=1148ms train=617ms\n[SYNC  2] correct gen=988ms train=466ms\n[SYNC  3] wrong gen=701ms train=527ms\n[SYNC  4] wrong gen=605ms train=577ms\n[SYNC  5] wrong gen=409ms train=535ms\n\nSync complete: 6.57s, 5 generations, 0.76 gens/s\n", "type": "stream"}], "id": "aLJB", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "0b75000775587103ec4994dd39384427", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Buffer cleared (5 items removed)\n\n============================================================\nASYNC MODE: 2 Generators + 1 Trainer (Concurrent)\n============================================================\n[GEN1 # 1] correct gen=446ms\n[GEN0 # 2] correct gen=642ms\n[GEN1 # 3] wrong gen=476ms\n[GEN1 # 4] wrong gen=375ms\n[GEN1 # 5] correct gen=409ms\n[GEN0 # 6] wrong gen=1078ms\n[GEN0 # 7] wrong gen=137ms\n[TRAIN  1] time=559ms buffer=4\n[GEN0 # 8] wrong gen=120ms\n[GEN0 # 9] wrong gen=119ms\n[GEN0 #10] wrong gen=120ms\n[GEN0 #11] wrong gen=136ms\n[TRAIN  2] time=571ms buffer=7\n[GEN0 #12] wrong gen=138ms\n[GEN0 #13] wrong gen=119ms\n[GEN0 #14] wrong gen=129ms\n[GEN1 #15] wrong gen=1099ms\n[GEN0 #16] wrong gen=149ms\n[TRAIN  3] time=524ms buffer=11\n[GEN1 #17] wrong gen=171ms\n[GEN0 #18] wrong gen=133ms\n[GEN1 #19] wrong gen=145ms\n[GEN0 #20] wrong gen=131ms\n[GEN1 #21] wrong gen=130ms\n[GEN0 #22] wrong gen=129ms\n[GEN1 #23] wrong gen=139ms\n[GEN0 #24] wrong gen=117ms\n[TRAIN  4] time=512ms buffer=16\n[GEN1 #25] wrong gen=132ms\n[GEN0 #26] wrong gen=128ms\n[GEN1 #27] wrong gen=119ms\n[GEN0 #28] wrong gen=323ms\n[GEN0 #29] wrong gen=106ms\n[TRAIN  5] time=535ms buffer=24\n[GEN0 #30] wrong gen=102ms\n[GEN1 #31] wrong gen=1641ms\n\nAsync complete: 5.46s, 31 generations, 5.67 gens/s\n", "type": "stream"}], "id": "nHfw", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "fd4b2315b3a12417972985822e59355e", "console": [], "id": "xXTn", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"sync-vs-async-comparison\"\u003ESync vs Async Comparison\u003C/h2\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EMetric\u003C/th\u003E\n\u003Cth\u003ESYNC\u003C/th\u003E\n\u003Cth\u003EASYNC\u003C/th\u003E\n\u003Cth\u003ERatio\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EWall time\u003C/td\u003E\n\u003Ctd\u003E6.57s\u003C/td\u003E\n\u003Ctd\u003E5.46s\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E1.20x\u003C/strong\u003E speedup\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGenerations\u003C/td\u003E\n\u003Ctd\u003E5\u003C/td\u003E\n\u003Ctd\u003E31\u003C/td\u003E\n\u003Ctd\u003E6.2x\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGens/second\u003C/td\u003E\n\u003Ctd\u003E0.76\u003C/td\u003E\n\u003Ctd\u003E5.67\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003E7.5x\u003C/strong\u003E throughput\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAvg gen time\u003C/td\u003E\n\u003Ctd\u003E770ms\u003C/td\u003E\n\u003Ctd\u003E301ms\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAvg train time\u003C/td\u003E\n\u003Ctd\u003E545ms\u003C/td\u003E\n\u003Ctd\u003E540ms\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EWeight syncs\u003C/td\u003E\n\u003Ctd\u003E--\u003C/td\u003E\n\u003Ctd\u003E4 RDMA\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Ch3 id=\"key-observations\"\u003EKey Observations\u003C/h3\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EData throughput\u003C/strong\u003E: Async collected \u003Cstrong\u003E7.5x\u003C/strong\u003E more trajectories per second.\n  More data means better gradient estimates.\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EGPU utilization\u003C/strong\u003E: In sync mode, the trainer GPU sits idle during generation and\n  vice versa. Async keeps both busy.\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EGenerators ran in parallel\u003C/strong\u003E: 2 generators each had their own\n  thread, producing data independently.\u003C/li\u003E\n\u003Cli\u003EThe trainer consumed from the replay buffer continuously, never waiting for a specific\n  generator to finish.\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EIn production with more generators, the throughput advantage grows further.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "33487768b481ba1e786eff59f88da13f", "console": [], "id": "AjVT", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"timeline-visualization\"\u003ETimeline Visualization\u003C/h3\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "54f542b094098b6f232b8d9fb583cb5b", "console": [], "id": "pHFh", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"after-training-did-it-improve\"\u003EAfter Training: Did It Improve?\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWe've now run both sync and async training loops. The model has been updated\nthrough multiple training steps. Let's evaluate the same set of compositional\ntasks to see if accuracy changed.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ENote: We're using a small model (0.5B) with few training steps, so dramatic\nimprovement isn't guaranteed. The point is the \u003Cem\u003Einfrastructure\u003C/em\u003E -- showing that\nthe full loop works end to end.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "d0b49fa52a3632e4f6799fbcda88cd60", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Evaluating post-training performance...\nPost-training accuracy: 0%\n", "type": "stream"}], "id": "NCOB", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "079db20abc6eda0625239d3706587790", "console": [], "id": "aqbW", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"before-vs-after-training\"\u003EBefore vs After Training\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EMetric\u003C/th\u003E\n\u003Cth\u003EBefore\u003C/th\u003E\n\u003Cth\u003EAfter\u003C/th\u003E\n\u003Cth\u003EDelta\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAccuracy\u003C/td\u003E\n\u003Ctd\u003E30%\u003C/td\u003E\n\u003Ctd\u003E0%\u003C/td\u003E\n\u003Ctd\u003E-30%\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAvg turns\u003C/td\u003E\n\u003Ctd\u003E4.3\u003C/td\u003E\n\u003Ctd\u003E1.0\u003C/td\u003E\n\u003Ctd\u003E-3.3\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EAvg tool calls\u003C/td\u003E\n\u003Ctd\u003E3.7\u003C/td\u003E\n\u003Ctd\u003E0.0\u003C/td\u003E\n\u003Ctd\u003E-3.7\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EAccuracy decreased by 30%.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWith a 0.5B model and only a few training steps, large gains are unlikely.\nThe key result is that the full pipeline works: generation, buffering, training,\nweight sync, and evaluation all compose correctly through Monarch actors.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b3cf7c2aa2f9dacb9bd46c27c0ef15eb", "console": [], "id": "TRpd", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"whats-happening-under-the-hood\"\u003EWhat's Happening Under the Hood\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWhen you run the training loop, here's what each layer does:\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EActor isolation\u003C/strong\u003E: Each actor (trainer, generators, buffer, zorplex workers)\nruns in its own process with its own GPU assignment. \u003Ccode\u003ECUDA_VISIBLE_DEVICES\u003C/code\u003E is\nset in \u003Ccode\u003Esetup()\u003C/code\u003E, not at spawn time -- the \u003Ccode\u003Eprocs\u003C/code\u003E dimension in \u003Ccode\u003Espawn_procs\u003C/code\u003E\nis just a dimension name, not a GPU assignment.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWeight sync data flow\u003C/strong\u003E (circular buffer + CPU staging from NB06):\n\u003Cdiv class=\"language-ecl codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u003C/span\u003E\u003Cspan class=\"n\"\u003ED2H\u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Ev\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E%\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u003C/span\u003E\u003Cspan class=\"n\"\u003EH2D\u003C/span\u003E\u003Cspan class=\"o\"\u003E--\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ETrainer publishes weights to a circular buffer after each train step\u003C/li\u003E\n\u003Cli\u003EGenerators pull from the buffer via RDMA into a pre-allocated staging buffer\u003C/li\u003E\n\u003Cli\u003EExplicit H2D copy scatters into GPU model parameters\u003C/li\u003E\n\u003Cli\u003EThe circular buffer has 3 slots, so training never blocks on reads\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EAsync concurrency\u003C/strong\u003E (via threads):\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E1 thread per generator, each running its own generation loop\u003C/li\u003E\n\u003Cli\u003E1 weight sync thread, periodically pulling from trainer and pushing to generators\u003C/li\u003E\n\u003Cli\u003ETraining in the main thread\u003C/li\u003E\n\u003Cli\u003E\u003Ccode\u003Ethreading.Event\u003C/code\u003E coordinates shutdown when training completes\u003C/li\u003E\n\u003Cli\u003EGIL is released during I/O (actor calls) and CUDA (GPU compute), so threads\n  achieve real concurrency\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EFault tolerance\u003C/strong\u003E (from NB03):\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EGeneration loops wrap \u003Ccode\u003Egenerate.call_one().get()\u003C/code\u003E in \u003Ccode\u003Etry/except\u003C/code\u003E\u003C/li\u003E\n\u003Cli\u003EOn failure, the generator logs and retries instead of crashing the loop\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "dac2d2a64136b4ff96e79c8da3ac85d6", "console": [], "id": "TXez", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"scaling-up\"\u003EScaling Up\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWhat we built here scales naturally with Monarch:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EScale\u003C/th\u003E\n\u003Cth\u003EWhat Changes\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMore generators\u003C/td\u003E\n\u003Ctd\u003EIncrease \u003Ccode\u003Enum_generators\u003C/code\u003E slider -- spawns larger ActorMesh\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMore zorplex workers\u003C/td\u003E\n\u003Ctd\u003EIncrease \u003Ccode\u003ENUM_ZORPLEX\u003C/code\u003E -- parallel task generation\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMulti-node\u003C/td\u003E\n\u003Ctd\u003EUse \u003Ccode\u003ESlurmJob\u003C/code\u003E instead of \u003Ccode\u003Ethis_host()\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EBetter algorithms\u003C/td\u003E\n\u003Ctd\u003ESwap REINFORCE for PPO/GRPO\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMore services\u003C/td\u003E\n\u003Ctd\u003EAdd reward models, search APIs as actors\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EThe patterns stay the same:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EActors for isolation and GPU assignment\u003C/li\u003E\n\u003Cli\u003EEndpoints for communication (\u003Ccode\u003E.call_one().get()\u003C/code\u003E)\u003C/li\u003E\n\u003Cli\u003ERDMA + circular buffer for efficient weight transfer\u003C/li\u003E\n\u003Cli\u003EVersion tracking for consistency across actors\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is the foundation for production systems like Forge GRPO, which uses the\nsame Monarch actor patterns at much larger scale.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "9a72d57f1ff9de84d9d2eb14d2d94ed3", "console": [], "id": "dNNg", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"recap-the-full-journey\"\u003ERecap: The Full Journey\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWe've come a long way in this notebook series:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ENotebook\u003C/th\u003E\n\u003Cth\u003EWhat We Learned\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E01\u003C/td\u003E\n\u003Ctd\u003EMonarch's history and the single-controller paradigm\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E02\u003C/td\u003E\n\u003Ctd\u003EInteractive development with \u003Ccode\u003Ethis_host()\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E03\u003C/td\u003E\n\u003Ctd\u003EFault tolerance with \u003Ccode\u003Etry/except\u003C/code\u003E on actor calls\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E04\u003C/td\u003E\n\u003Ctd\u003EZorplex benchmark -- where Qwen 0.5B struggles\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E05\u003C/td\u003E\n\u003Ctd\u003EServices for managing worker pools with health tracking\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E06\u003C/td\u003E\n\u003Ctd\u003ERDMA weight sync, circular buffers, CPU staging\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003E07\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003Cstrong\u003EClosing the loop: async RL training end to end\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey takeaways from this notebook:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EMonarch makes distributed RL feel like local Python -- actors, endpoints,\n  and slicing compose naturally into a full training system\u003C/li\u003E\n\u003Cli\u003EAsync RL collects more data per unit wall time by running generators\n  and trainer concurrently\u003C/li\u003E\n\u003Cli\u003EThe circular buffer + CPU staging pattern from NB06 decouples training\n  from weight distribution\u003C/li\u003E\n\u003Cli\u003EBefore/after evaluation closes the loop: we can measure whether training\n  actually improves the model\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhere to go next:\u003C/strong\u003E Forge GRPO implements these same patterns at production\nscale -- multiple nodes, larger models, PPO/GRPO instead of REINFORCE, and\nproper reward modeling. The Monarch primitives you've learned here are the\nbuilding blocks for all of it.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    %23!%2Fusr%2Fbin%2Fenv%20python3%0A%22%22%22%0ANotebook%2007%3A%20Closing%20the%20Loop%20-%20Async%20RL%20Training%0A%0AIn%20Notebook%2004%2C%20we%20saw%20that%20Qwen%200.5B%20struggles%20with%20compositional%20Zorplex%20tasks.%0ANow%20we%20close%20the%20loop%3A%20train%20the%20model%20using%20async%20RL%20with%20Monarch.%0A%0AThis%20notebook%20demonstrates%3A%0A-%20Building%20RL%20actors%20(Trainer%2C%20Generator%2C%20ReplayBuffer)%0A-%20Running%20concurrent%20generation%20and%20training%0A-%20Weight%20synchronization%20between%20actors%20(circular%20buffer%20%2B%20CPU%20staging)%0A-%20Real%20training%20metrics%20and%20before%2Fafter%20evaluation%0A%0ARun%20with%3A%20uv%20run%20marimo%20edit%20notebooks%2F07_async_rl_e2e.py%0A%22%22%22%0A%0A%23%20CRITICAL%3A%20Set%20allocator%20config%20BEFORE%20any%20PyTorch%20imports%20(including%20in%20subprocesses)%0A%23%20Set%20both%20names%20for%20compatibility%20(old%20and%20new%20PyTorch%20versions)%0A%0Aimport%20marimo%0A%0A__generated_with%20%3D%20%220.19.7%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23%20Environment%20setup%20for%20Monarch%20subprocesses%0A%20%20%20%20import%20os%0A%20%20%20%20os.environ%5B%22TOKENIZERS_PARALLELISM%22%5D%20%3D%20%22false%22%0A%20%20%20%20os.environ%5B%22HF_HUB_OFFLINE%22%5D%20%3D%20%221%22%0A%20%20%20%20os.environ%5B%22TRANSFORMERS_OFFLINE%22%5D%20%3D%20%221%22%0A%20%20%20%20%23%20Note%3A%20CUDA_VISIBLE_DEVICES%20is%20set%20per-actor%20in%20setup()%0A%20%20%20%20%23%20Note%3A%20PYTORCH_ALLOC_CONF%20is%20set%20at%20module%20level%20for%20RDMA%0A%0A%20%20%20%20import%20sys%0A%20%20%20%20_src_dir%20%3D%20os.path.abspath(os.path.join(os.path.dirname(__file__)%20if%20%22__file__%22%20in%20dir()%20else%20os.getcwd()%2C%20%22..%22%2C%20%22src%22))%0A%20%20%20%20if%20_src_dir%20not%20in%20sys.path%3A%0A%20%20%20%20%20%20%20%20sys.path.insert(0%2C%20_src_dir)%0A%0A%20%20%20%20%23%20Set%20PYTHONPATH%20for%20Monarch%20subprocesses%0A%20%20%20%20_existing%20%3D%20os.environ.get(%22PYTHONPATH%22%2C%20%22%22)%0A%20%20%20%20os.environ%5B%22PYTHONPATH%22%5D%20%3D%20f%22%7B_src_dir%7D%3A%7B_existing%7D%22%20if%20_existing%20else%20_src_dir%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20Closing%20the%20Loop%3A%20Async%20RL%20Training%0A%0A%20%20%20%20In%20**Notebook%2004**%2C%20we%20introduced%20the%20Zorplex%20benchmark%20and%20saw%20that%20Qwen%200.5B%0A%20%20%20%20struggles%20with%20compositional%20tasks%20--%20it%20gets%20~60-70%25%20accuracy%20when%20it%20needs%20to%0A%20%20%20%20chain%20multiple%20tool%20calls.%0A%0A%20%20%20%20**Now%20we%20close%20the%20loop**%3A%20train%20the%20model%20to%20get%20better%20at%20these%20tasks.%0A%0A%20%20%20%20We'll%20build%20on%20patterns%20from%20across%20the%20series%3A%0A%20%20%20%20-%20**%60this_host()%60%20from%20NB02**%20--%20spawning%20actors%20on%20the%20local%20machine%20for%20interactive%20development%0A%20%20%20%20-%20**%60try%2Fexcept%60%20from%20NB03**%20--%20fault%20tolerance%20in%20generation%20loops%0A%20%20%20%20-%20**RDMA%20weight%20sync%20from%20NB06**%20--%20circular%20buffer%20%2B%20CPU%20staging%20for%20efficient%20weight%20transfer%0A%0A%20%20%20%20The%20architecture%3A%20multiple%20generators%20feed%20trajectories%20into%20a%20replay%20buffer%20while%0A%20%20%20%20a%20trainer%20continuously%20samples%20and%20updates%20the%20policy.%20We'll%20measure%20*before*%20and%0A%20%20%20%20*after*%20accuracy%20to%20see%20if%20training%20actually%20helps.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20typing%20import%20Optional%0A%20%20%20%20from%20collections%20import%20deque%0A%20%20%20%20import%20random%0A%20%20%20%20import%20torch%0A%20%20%20%20import%20torch.nn.functional%20as%20F%0A%0A%20%20%20%20%23%20Model%20imports%0A%20%20%20%20from%20transformers%20import%20AutoModelForCausalLM%2C%20AutoTokenizer%0A%0A%20%20%20%20%23%20Zorplex%20imports%0A%20%20%20%20from%20zorplex_rl%20import%20get_spec%2C%20Task%0A%20%20%20%20from%20zorplex_rl.evaluate%20import%20generate_with_tools%0A%0A%20%20%20%20%23%20RL%20primitives%20(shared%20dataclasses)%0A%20%20%20%20from%20rl_primitives%20import%20Trajectory%2C%20TrainMetrics%0A%0A%20%20%20%20%23%20RDMA%20imports%20(with%20fallback)%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%2C%20is_rdma_available%0A%20%20%20%20%20%20%20%20_rdma_available%20%3D%20is_rdma_available()%0A%20%20%20%20except%20Exception%3A%0A%20%20%20%20%20%20%20%20RDMABuffer%20%3D%20None%0A%20%20%20%20%20%20%20%20_rdma_available%20%3D%20False%0A%0A%20%20%20%20def%20rdma_available()%3A%0A%20%20%20%20%20%20%20%20return%20_rdma_available%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20AutoModelForCausalLM%2C%0A%20%20%20%20%20%20%20%20AutoTokenizer%2C%0A%20%20%20%20%20%20%20%20F%2C%0A%20%20%20%20%20%20%20%20RDMABuffer%2C%0A%20%20%20%20%20%20%20%20Task%2C%0A%20%20%20%20%20%20%20%20TrainMetrics%2C%0A%20%20%20%20%20%20%20%20Trajectory%2C%0A%20%20%20%20%20%20%20%20deque%2C%0A%20%20%20%20%20%20%20%20generate_with_tools%2C%0A%20%20%20%20%20%20%20%20get_spec%2C%0A%20%20%20%20%20%20%20%20random%2C%0A%20%20%20%20%20%20%20%20rdma_available%2C%0A%20%20%20%20%20%20%20%20torch%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20current_rank%0A%20%20%20%20return%20Actor%2C%20current_rank%2C%20endpoint%0A%0A%0A%40app.cell%0Adef%20_(TrainMetrics%2C%20Trajectory%2C%20mo)%3A%0A%20%20%20%20import%20dataclasses%20as%20_dc%0A%20%20%20%20_traj_fields%20%3D%20%5B(f.name%2C%20f.type.__name__%20if%20hasattr(f.type%2C%20'__name__')%20else%20str(f.type))%20for%20f%20in%20_dc.fields(Trajectory)%5D%0A%20%20%20%20_metrics_fields%20%3D%20%5B(f.name%2C%20f.type.__name__%20if%20hasattr(f.type%2C%20'__name__')%20else%20str(f.type))%20for%20f%20in%20_dc.fields(TrainMetrics)%5D%0A%0A%20%20%20%20mo.md(f%22%22%22%0A%20%20%20%20%23%23%20Shared%20Data%20Structures%0A%0A%20%20%20%20**Trajectory**%20--%20one%20rollout%20from%20a%20generator%3A%0A%0A%20%20%20%20%7C%20Field%20%7C%20Type%20%7C%0A%20%20%20%20%7C-------%7C------%7C%0A%20%20%20%20%7B%22%22.join(f%22%7C%20%60%7Bn%7D%60%20%7C%20%60%7Bt%7D%60%20%7C%7Bchr(10)%7D%22%20for%20n%2C%20t%20in%20_traj_fields)%7D%0A%0A%20%20%20%20**TrainMetrics**%20--%20returned%20after%20each%20training%20step%3A%0A%0A%20%20%20%20%7C%20Field%20%7C%20Type%20%7C%0A%20%20%20%20%7C-------%7C------%7C%0A%20%20%20%20%7B%22%22.join(f%22%7C%20%60%7Bn%7D%60%20%7C%20%60%7Bt%7D%60%20%7C%7Bchr(10)%7D%22%20for%20n%2C%20t%20in%20_metrics_fields)%7D%0A%0A%20%20%20%20The%20%60model_only_text%60%20field%20stores%20the%20model's%20generated%20tokens%20without%20injected%20tool%0A%20%20%20%20results%2C%20so%20the%20trainer%20can%20compute%20log-probabilities%20on%20exactly%20what%20the%20model%20produced.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Service%20Infrastructure%0A%0A%20%20%20%20We%20import%20a%20**custom%20Service%20abstraction**%20from%20%60monarch_utils%60%20that%20manages%20worker%0A%20%20%20%20replicas%20with%20health%20tracking%20and%20round-robin%20routing.%20This%20is%20a%20utility%20we%20built%0A%20%20%20%20for%20this%20notebook%20series%20--%20the%20canonical%20Monarch%20pattern%20uses%20direct%20actor%0A%20%20%20%20references%20and%20slicing%2C%20which%20is%20what%20the%20Service%20wraps%20internally.%0A%0A%20%20%20%20(See%20notebook%2005%20for%20the%20full%20implementation.)%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20monarch_utils.services%20import%20Service%2C%20register_service%0A%20%20%20%20return%20Service%2C%20register_service%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20The%20%60setup()%60%20Pattern%0A%0A%20%20%20%20Monarch%20actors%20use%20a%20two-phase%20initialization%3A%0A%0A%20%20%20%201.%20**%60__init__%60**%20runs%20during%20%60spawn()%60%20--%20keep%20it%20lightweight%20(store%20config%2C%20set%20rank)%0A%20%20%20%202.%20**%60setup()%60**%20is%20an%20endpoint%20called%20explicitly%20after%20spawn%20--%20do%20heavy%20work%20here%0A%20%20%20%20%20%20%20(load%20models%2C%20allocate%20GPU%20memory%2C%20register%20RDMA%20buffers)%0A%0A%20%20%20%20Why%20not%20do%20everything%20in%20%60__init__%60%3F%20Two%20reasons%3A%0A%0A%20%20%20%20-%20**%60spawn()%60%20is%20asynchronous**%20--%20it%20returns%20immediately%2C%20and%20%60__init__%60%20runs%20in%0A%20%20%20%20%20%20the%20remote%20process%20before%20the%20first%20endpoint%20call.%20But%20you%20don't%20control%20*when*%2C%0A%20%20%20%20%20%20and%20you%20can't%20confirm%20it%20completed.%20An%20explicit%20%60setup()%60%20call%20lets%20you%20sequence%0A%20%20%20%20%20%20initialization%20(e.g.%2C%20set%20%60CUDA_VISIBLE_DEVICES%60%20and%20confirm%20it%20took%20effect%20before%0A%20%20%20%20%20%20loading%20a%20model).%0A%20%20%20%20-%20**Coordination**%20--%20you%20often%20need%20to%20initialize%20actors%20in%20a%20specific%20order%20(set%20up%0A%20%20%20%20%20%20the%20trainer%20before%20generators%20try%20to%20sync%20weights).%20Endpoint%20calls%20give%20you%20that%0A%20%20%20%20%20%20sequencing%3B%20%60__init__%60%20doesn't.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Actor%201%3A%20ZorplexWorker%0A%0A%20%20%20%20Tool%20execution%20environments%20(docker%20containers%2C%20sandboxes%2C%20API%20endpoints)%20naturally%0A%20%20%20%20form%20a%20fleet%20--%20you%20want%20many%20instances%20running%20in%20parallel%20to%20keep%20up%20with%0A%20%20%20%20generation%20throughput.%20That%20makes%20them%20a%20good%20fit%20for%20a%20**Service**%20(from%20NB05)%0A%20%20%20%20with%20health%20tracking%20and%20round-robin%20routing.%0A%0A%20%20%20%20Our%20ZorplexWorker%20actors%20handle%20Zorplex%20tasks%3A%0A%20%20%20%20-%20%60generate_task()%60%20--%20creates%20a%20new%20problem%0A%20%20%20%20-%20%60execute_tool()%60%20--%20handles%20LOOKUP%20calls%0A%20%20%20%20-%20%60check_answer()%60%20--%20verifies%20correctness%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20current_rank%2C%20endpoint%2C%20get_spec)%3A%0A%20%20%20%20class%20ZorplexWorker(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Worker%20actor%20that%20handles%20Zorplex%20tool%20execution.%0A%0A%20%20%20%20%20%20%20%20Managed%20by%20a%20Service%20for%20load%20balancing%20across%20replicas.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20difficulty%3A%20str%20%3D%20%22easy%22%2C%20seed%3A%20int%20%3D%2042)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.spec%20%3D%20get_spec(%22compositional%22%2C%20difficulty%3Ddifficulty%2C%20seed%3Dseed%20%2B%20self.rank)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.calls_served%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BZorplexWorker%3A%7Bself.rank%7D%5D%20Initialized%20with%20difficulty%3D%7Bdifficulty%7D%22)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20ping(self)%20-%3E%20bool%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20True%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20generate_task(self)%20-%3E%20tuple%5Bstr%2C%20int%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Generate%20a%20new%20task.%20Returns%20(question%2C%20correct_answer).%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20task%20%3D%20self.spec.generate_task()%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20task.question%2C%20task.correct_answer%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20execute_tool(self%2C%20tool_name%3A%20str%2C%20argument%3A%20str)%20-%3E%20str%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Execute%20a%20tool%20call.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20from%20zorplex_rl.task_specs%20import%20ToolCall%0A%20%20%20%20%20%20%20%20%20%20%20%20tc%20%3D%20ToolCall(tool_name%2C%20argument)%0A%20%20%20%20%20%20%20%20%20%20%20%20result%20%3D%20self.spec.execute_tool(tc)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.calls_served%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20str(result)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_system_prompt(self)%20-%3E%20str%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Get%20the%20system%20prompt%20with%20tool%20hints.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.spec.get_system_prompt(with_hint%3DTrue)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20check_answer(self%2C%20model_output%3A%20str%2C%20correct_answer%3A%20int)%20-%3E%20tuple%5Bbool%2C%20int%20%7C%20None%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Check%20if%20model%20output%20contains%20the%20correct%20answer.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20extracted%20%3D%20self.spec.extract_answer(model_output%2C%20%5B%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20is_correct%20%3D%20extracted%20%3D%3D%20correct_answer%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20is_correct%2C%20extracted%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20stats(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22rank%22%3A%20self.rank%2C%20%22calls_served%22%3A%20self.calls_served%7D%0A%20%20%20%20return%20(ZorplexWorker%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Actor%202%3A%20ReplayBuffer%0A%0A%20%20%20%20A%20simple%20actor%20that%20stores%20trajectories.%20Generators%20push%20trajectories%20in%2C%0A%20%20%20%20the%20trainer%20samples%20batches%20out.%20The%20%60clear()%60%20endpoint%20lets%20us%20reset%20between%0A%20%20%20%20sync%20and%20async%20runs%20for%20a%20fair%20comparison.%0A%0A%20%20%20%20This%20enables%20async%20RL%20--%20generation%20and%20training%20happen%20independently%2C%0A%20%20%20%20connected%20only%20through%20the%20buffer.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20Trajectory%2C%20deque%2C%20endpoint%2C%20random)%3A%0A%20%20%20%20class%20ReplayBuffer(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Stores%20trajectories%20for%20async%20RL%20training.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20max_size%3A%20int%20%3D%201000)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%3A%20deque%5BTrajectory%5D%20%3D%20deque(maxlen%3Dmax_size)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.total_added%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BReplayBuffer%5D%20Initialized%20with%20max_size%3D%7Bmax_size%7D%22)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20add(self%2C%20trajectory%3A%20Trajectory)%20-%3E%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Add%20a%20trajectory%20to%20the%20buffer.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer.append(trajectory)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.total_added%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20sample(self%2C%20batch_size%3A%20int)%20-%3E%20list%5BTrajectory%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Sample%20a%20batch%20of%20trajectories.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20len(self.buffer)%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20n%20%3D%20min(batch_size%2C%20len(self.buffer))%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20random.sample(list(self.buffer)%2C%20n)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20size(self)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20len(self.buffer)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20clear(self)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Clear%20the%20buffer.%20Returns%20number%20of%20items%20removed.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20count%20%3D%20len(self.buffer)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer.clear()%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20count%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20stats(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20len(self.buffer)%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22size%22%3A%200%2C%20%22total_added%22%3A%20self.total_added%2C%20%22avg_reward%22%3A%200.0%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20rewards%20%3D%20%5Bt.reward%20for%20t%20in%20self.buffer%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22size%22%3A%20len(self.buffer)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22total_added%22%3A%20self.total_added%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22avg_reward%22%3A%20sum(rewards)%20%2F%20len(rewards)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22correct_rate%22%3A%20sum(1%20for%20t%20in%20self.buffer%20if%20t.is_correct)%20%2F%20len(self.buffer)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20return%20(ReplayBuffer%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Actor%203%3A%20TrainerActor%0A%0A%20%20%20%20The%20trainer%20loads%20the%20model%2C%20receives%20batches%20of%20trajectories%2C%20and%20computes%0A%20%20%20%20REINFORCE%20updates.%0A%0A%20%20%20%20**REINFORCE**%3A%20For%20each%20trajectory%2C%20we%20compute%20per-token%20log-probabilities%20on%0A%20%20%20%20the%20*response%20tokens%20only*%20(using%20%60model_only_text%60%2C%20not%20the%20full%20text%20with%0A%20%20%20%20injected%20tool%20results).%20The%20loss%20is%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20loss%20%3D%20-sum(log_prob(token_i))%20*%20(reward%20-%20baseline)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20weights%20the%20entire%20response%20by%20the%20advantage.%20Positive%20advantage%20reinforces%0A%20%20%20%20the%20response%3B%20negative%20advantage%20suppresses%20it.%0A%0A%20%20%20%20**Circular%20buffer%20with%20CPU%20staging**%20(from%20NB06)%3A%20Instead%20of%20registering%20RDMA%0A%20%20%20%20handles%20directly%20on%20GPU%20parameters%20(which%20blocks%20training%20during%20reads)%2C%20we%0A%20%20%20%20maintain%20N%20CPU%20staging%20slots.%20After%20each%20training%20step%2C%20weights%20are%20copied%0A%20%20%20%20GPU%20-%3E%20CPU%20(D2H)%20into%20the%20current%20slot.%20Generators%20read%20from%20CPU%20via%20RDMA%2C%0A%20%20%20%20then%20copy%20to%20their%20own%20GPU%20(H2D).%20The%20data%20flow%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20GPU%20--D2H--%3E%20CPU%20slot%5Bv%20%25%203%5D%20--RDMA--%3E%20Generator%20CPU%20staging%20--H2D--%3E%20Generator%20GPU%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20decouples%20training%20from%20weight%20distribution.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Actor%2C%0A%20%20%20%20AutoModelForCausalLM%2C%0A%20%20%20%20AutoTokenizer%2C%0A%20%20%20%20F%2C%0A%20%20%20%20RDMABuffer%2C%0A%20%20%20%20TrainMetrics%2C%0A%20%20%20%20Trajectory%2C%0A%20%20%20%20current_rank%2C%0A%20%20%20%20endpoint%2C%0A%20%20%20%20generate_with_tools%2C%0A%20%20%20%20get_spec%2C%0A%20%20%20%20rdma_available%2C%0A%20%20%20%20torch%2C%0A)%3A%0A%20%20%20%20class%20TrainerActor(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Trains%20the%20model%20on%20trajectories.%0A%0A%20%20%20%20%20%20%20%20Uses%20setup()%20for%20heavy%20initialization%20(model%20loading%2C%20RDMA%20registration).%0A%20%20%20%20%20%20%20%20Implements%20circular%20buffer%20with%20CPU%20staging%20for%20weight%20distribution.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(%0A%20%20%20%20%20%20%20%20%20%20%20%20self%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20model_name%3A%20str%20%3D%20%22Qwen%2FQwen2.5-0.5B-Instruct%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20lr%3A%20float%20%3D%201e-5%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20device%3A%20str%20%3D%20%22cuda%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20n_buffer_slots%3A%20int%20%3D%203%2C%0A%20%20%20%20%20%20%20%20)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Lightweight%20init%20-%20just%20store%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model_name%20%3D%20model_name%0A%20%20%20%20%20%20%20%20%20%20%20%20self.lr%20%3D%20lr%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_config%20%3D%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20self.n_buffer_slots%20%3D%20n_buffer_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self._ready%20%3D%20False%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%3A%7Bself.rank%7D%5D%20Spawned%2C%20waiting%20for%20setup()...%22)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20setup(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Heavy%20initialization%3A%20load%20model%2C%20create%20optimizer%2C%20set%20up%20circular%20buffer.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20import%20os%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self._ready%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22status%22%3A%20%22already_ready%22%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Trainer%20always%20uses%20GPU%200%0A%20%20%20%20%20%20%20%20%20%20%20%20os.environ%5B%22CUDA_VISIBLE_DEVICES%22%5D%20%3D%20%220%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device%20%3D%20%22cuda%22%20if%20torch.cuda.is_available()%20else%20%22cpu%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.policy_version%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20self.train_steps%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%3A%7Bself.rank%7D%5D%20Loading%20model%20%7Bself.model_name%7D%20on%20GPU%200...%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.tokenizer%20%3D%20AutoTokenizer.from_pretrained(self.model_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model%20%3D%20AutoModelForCausalLM.from_pretrained(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.model_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20dtype%3Dtorch.bfloat16%20if%20self.device%20%3D%3D%20%22cuda%22%20else%20torch.float32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20).to(self.device)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self.tokenizer.pad_token%20is%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.tokenizer.pad_token%20%3D%20self.tokenizer.eos_token%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.optimizer%20%3D%20torch.optim.AdamW(self.model.parameters()%2C%20lr%3Dself.lr)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Store%20system%20prompt%20for%20log-prob%20computation%20in%20train_step%0A%20%20%20%20%20%20%20%20%20%20%20%20self.spec%20%3D%20get_spec(%22compositional%22%2C%20seed%3D42)%0A%20%20%20%20%20%20%20%20%20%20%20%20self._system_prompt%20%3D%20self.spec.get_system_prompt(with_hint%3DTrue)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20---%20Circular%20buffer%20with%20CPU%20staging%20---%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Compute%20total%20bytes%20for%20all%20parameters%0A%20%20%20%20%20%20%20%20%20%20%20%20total_bytes%20%3D%20sum(p.numel()%20*%20p.element_size()%20for%20p%20in%20self.model.parameters())%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20N%20CPU%20slots%20for%20weight%20staging%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Note%3A%20we%20use%20regular%20(non-pinned)%20CPU%20memory%20here%20because%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20pin_memory%3DTrue%20triggers%20dmabuf%20MR%20registration%20in%20the%20RDMA%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20subsystem%2C%20which%20can%20fail%20on%20some%20host%20configurations.%0A%20%20%20%20%20%20%20%20%20%20%20%20self._slots%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.empty(total_bytes%2C%20dtype%3Dtorch.uint8)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(self.n_buffer_slots)%0A%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20each%20slot%20with%20RDMA%20(if%20available)%0A%20%20%20%20%20%20%20%20%20%20%20%20self._slot_handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20rdma_available()%20and%20RDMABuffer%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20slot%20in%20self._slots%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self._slot_handles.append(RDMABuffer(slot))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%3A%7Bself.rank%7D%5D%20RDMA%20handles%20registered%20for%20%7Bself.n_buffer_slots%7D%20circular%20buffer%20slots%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%3A%7Bself.rank%7D%5D%20RDMA%20registration%20failed%3A%20%7Be%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self._slot_handles%20%3D%20%5B%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Store%20parameter%20metadata%20for%20scatter%20on%20generator%20side%0A%20%20%20%20%20%20%20%20%20%20%20%20self._param_meta%20%3D%20%7B%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20p%20in%20self.model.named_parameters()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self._param_meta%5Bname%5D%20%3D%20(offset%2C%20tuple(p.shape)%2C%20p.dtype)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%20%2B%3D%20p.numel()%20*%20p.element_size()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Publish%20initial%20weights%20to%20slot%200%0A%20%20%20%20%20%20%20%20%20%20%20%20self._publish_weights()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self._ready%20%3D%20True%0A%20%20%20%20%20%20%20%20%20%20%20%20param_count%20%3D%20sum(p.numel()%20for%20p%20in%20self.model.parameters())%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%3A%7Bself.rank%7D%5D%20Ready!%20%7Bparam_count%3A%2C%7D%20params%2C%20%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22RDMA%3D%7Blen(self._slot_handles)%20%3E%200%7D%2C%20%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f%22buffer_slots%3D%7Bself.n_buffer_slots%7D%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22status%22%3A%20%22ready%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22params%22%3A%20param_count%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22rdma%22%3A%20len(self._slot_handles)%20%3E%200%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22buffer_slots%22%3A%20self.n_buffer_slots%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20def%20_publish_weights(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Copy%20GPU%20params%20to%20the%20current%20circular%20buffer%20slot%20(D2H).%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20self.policy_version%20%25%20self.n_buffer_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20slot%20%3D%20self._slots%5Bslot_idx%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20p%20in%20self.model.named_parameters()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20off%2C%20shape%2C%20dtype%20%3D%20self._param_meta%5Bname%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nbytes%20%3D%20p.numel()%20*%20p.element_size()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot%5Boff%3Aoff%20%2B%20nbytes%5D.copy_(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p.data.view(-1).view(torch.uint8).cpu()%2C%20non_blocking%3DTrue%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20torch.cuda.synchronize()%20%20%23%20Ensure%20D2H%20complete%20before%20RDMA%20reads%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_weight_handle(self)%20-%3E%20tuple%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Get%20RDMA%20handle%20for%20the%20latest%20weight%20slot.%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20Returns%20(handle_or_None%2C%20param_meta%2C%20version).%0A%20%20%20%20%20%20%20%20%20%20%20%20If%20RDMA%20unavailable%2C%20handle%20is%20None%20and%20caller%20should%20use%20get_state_dict().%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self._slot_handles%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20self.policy_version%20%25%20self.n_buffer_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self._slot_handles%5Bslot_idx%5D%2C%20self._param_meta%2C%20self.policy_version%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20None%2C%20self._param_meta%2C%20self.policy_version%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_state_dict(self)%20-%3E%20tuple%5Bdict%2C%20int%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Fallback%3A%20get%20state%20dict%20directly%20(when%20RDMA%20not%20available).%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.model.state_dict()%2C%20self.policy_version%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_version(self)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.policy_version%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20train_step(self%2C%20trajectories%3A%20list%5BTrajectory%5D%2C%20baseline%3A%20float)%20-%3E%20TrainMetrics%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Train%20on%20a%20batch%20of%20trajectories%20using%20REINFORCE.%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20For%20each%20trajectory%3A%0A%20%20%20%20%20%20%20%20%20%20%20%201.%20Reconstruct%20the%20prompt%20using%20the%20system%20prompt%20%2B%20task%20question%0A%20%20%20%20%20%20%20%20%20%20%20%202.%20Tokenize%20prompt%20to%20find%20the%20boundary%0A%20%20%20%20%20%20%20%20%20%20%20%203.%20Compute%20per-token%20log-probs%20on%20response%20tokens%20only%20(model_only_text)%0A%20%20%20%20%20%20%20%20%20%20%20%204.%20Weight%20by%20advantage%20(reward%20-%20baseline)%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20len(trajectories)%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20TrainMetrics(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20step%3Dself.train_steps%2C%20loss%3D0.0%2C%20batch_size%3D0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20avg_reward%3D0.0%2C%20policy_version%3Dself.policy_version%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model.train()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.optimizer.zero_grad()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20total_loss%20%3D%20torch.tensor(0.0%2C%20device%3Dself.device%2C%20requires_grad%3DTrue)%0A%20%20%20%20%20%20%20%20%20%20%20%20valid_count%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20traj%20in%20trajectories%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Reconstruct%20prompt%20using%20system%20prompt%20%2B%20task%20question%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20messages%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22role%22%3A%20%22system%22%2C%20%22content%22%3A%20self._system_prompt%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7B%22role%22%3A%20%22user%22%2C%20%22content%22%3A%20traj.task_question%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20prompt_text%20%3D%20self.tokenizer.apply_chat_template(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20messages%2C%20tokenize%3DFalse%2C%20add_generation_prompt%3DTrue%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Tokenize%20prompt%20to%20find%20boundary%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20prompt_ids%20%3D%20self.tokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20prompt_text%2C%20return_tensors%3D%22pt%22%2C%20add_special_tokens%3DFalse%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%5B%22input_ids%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20prompt_len%20%3D%20prompt_ids.shape%5B1%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Use%20model_only_text%20if%20available%2C%20fall%20back%20to%20response_text%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20response%20%3D%20traj.model_only_text%20if%20traj.model_only_text%20else%20traj.response_text%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Tokenize%20prompt%20%2B%20response%20together%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20full_ids%20%3D%20self.tokenizer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20prompt_text%20%2B%20response%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return_tensors%3D%22pt%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20add_special_tokens%3DFalse%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20truncation%3DTrue%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20max_length%3D1024%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%5B%22input_ids%22%5D.to(self.device)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20full_ids.shape%5B1%5D%20%3C%3D%20prompt_len%20%2B%201%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20continue%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20with%20torch.amp.autocast('cuda'%2C%20enabled%3Dself.device%20%3D%3D%20%22cuda%22)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20logits%20%3D%20self.model(full_ids).logits%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Per-token%20log-probs%20on%20response%20tokens%20only%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20shift_logits%20%3D%20logits%5B%3A%2C%20prompt_len%20-%201%3A-1%2C%20%3A%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20shift_labels%20%3D%20full_ids%5B%3A%2C%20prompt_len%3A%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20log_probs%20%3D%20F.log_softmax(shift_logits%2C%20dim%3D-1)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20token_log_probs%20%3D%20log_probs.gather(2%2C%20shift_labels.unsqueeze(-1)).squeeze(-1)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20advantage%20%3D%20traj.reward%20-%20baseline%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20total_loss%20%3D%20total_loss%20%2B%20(-token_log_probs.sum()%20*%20advantage)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20valid_count%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20valid_count%20%3E%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20avg_loss%20%3D%20total_loss%20%2F%20valid_count%0A%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20avg_loss%20%3D%20total_loss%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20avg_loss.requires_grad%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20avg_loss.backward()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.nn.utils.clip_grad_norm_(self.model.parameters()%2C%20max_norm%3D1.0)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.optimizer.step()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.policy_version%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20self.train_steps%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Publish%20weights%20to%20circular%20buffer%20(GPU%20-%3E%20CPU)%0A%20%20%20%20%20%20%20%20%20%20%20%20self._publish_weights()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20avg_reward%20%3D%20sum(t.reward%20for%20t%20in%20trajectories)%20%2F%20len(trajectories)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20TrainMetrics(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20step%3Dself.train_steps%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss%3Davg_loss.item()%20if%20torch.is_tensor(avg_loss)%20else%20avg_loss%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20batch_size%3Dlen(trajectories)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20avg_reward%3Davg_reward%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20policy_version%3Dself.policy_version%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20evaluate_zorplex(self%2C%20num_samples%3A%20int%20%3D%2010%2C%20seed%3A%20int%20%3D%2042)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Evaluate%20current%20model%20on%20compositional%20Zorplex%20tasks.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model.eval()%0A%20%20%20%20%20%20%20%20%20%20%20%20spec%20%3D%20get_spec(%22compositional%22%2C%20seed%3Dseed)%0A%20%20%20%20%20%20%20%20%20%20%20%20correct%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20total_turns%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20total_tools%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(num_samples)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20task%20%3D%20spec.generate_task()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20result%20%3D%20generate_with_tools(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.model%2C%20self.tokenizer%2C%20spec%2C%20task%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.device%2C%20max_turns%3D5%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20correct%20%2B%3D%20int(result.is_correct)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20total_turns%20%2B%3D%20len(result.turns)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20total_tools%20%2B%3D%20result.total_tool_calls%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22accuracy%22%3A%20correct%20%2F%20num_samples%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22correct%22%3A%20correct%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22total%22%3A%20num_samples%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22avg_turns%22%3A%20total_turns%20%2F%20num_samples%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22avg_tools%22%3A%20total_tools%20%2F%20num_samples%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20return%20(TrainerActor%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Actor%204%3A%20GeneratorWorker%0A%0A%20%20%20%20Each%20generator%20loads%20its%20own%20copy%20of%20the%20model%20and%20runs%20inference%20independently.%0A%20%20%20%20Weight%20sync%20uses%20the%20circular%20buffer%20pattern%3A%0A%0A%20%20%20%201.%20Generator%20calls%20%60trainer.get_weight_handle()%60%20to%20get%20the%20RDMA%20handle%20%2B%20metadata%0A%20%20%20%202.%20A%20single%20RDMA%20read%20pulls%20the%20entire%20contiguous%20buffer%20into%20a%20pre-allocated%0A%20%20%20%20%20%20%20CPU%20staging%20buffer%0A%20%20%20%203.%20The%20generator%20scatters%20from%20CPU%20staging%20into%20GPU%20model%20params%20(H2D)%0A%0A%20%20%20%20This%20avoids%20the%20RDMA%20API's%20internal%20temporary%20copy%20(which%20happens%20when%20the%0A%20%20%20%20destination%20is%20a%20GPU%20tensor)%20and%20gives%20explicit%20control%20over%20timing.%0A%0A%20%20%20%20Fallback%20path%20(%60sync_weights%60%20using%20%60state_dict%60)%20stays%20for%20when%20RDMA%20is%20unavailable.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Actor%2C%0A%20%20%20%20AutoModelForCausalLM%2C%0A%20%20%20%20AutoTokenizer%2C%0A%20%20%20%20Task%2C%0A%20%20%20%20Trajectory%2C%0A%20%20%20%20current_rank%2C%0A%20%20%20%20endpoint%2C%0A%20%20%20%20generate_with_tools%2C%0A%20%20%20%20get_spec%2C%0A%20%20%20%20torch%2C%0A)%3A%0A%20%20%20%20class%20GeneratorWorker(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Individual%20generator%20worker.%0A%0A%20%20%20%20%20%20%20%20Uses%20setup()%20for%20heavy%20initialization%20(model%20loading).%0A%20%20%20%20%20%20%20%20Weight%20sync%20uses%20CPU%20staging%20buffer%20for%20explicit%20RDMA%20-%3E%20H2D%20flow.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(%0A%20%20%20%20%20%20%20%20%20%20%20%20self%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20model_name%3A%20str%20%3D%20%22Qwen%2FQwen2.5-0.5B-Instruct%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20difficulty%3A%20str%20%3D%20%22easy%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20device%3A%20str%20%3D%20%22cuda%22%2C%0A%20%20%20%20%20%20%20%20)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Lightweight%20init%20-%20just%20store%20config%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model_name%20%3D%20model_name%0A%20%20%20%20%20%20%20%20%20%20%20%20self.difficulty%20%3D%20difficulty%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_config%20%3D%20device%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self._ready%20%3D%20False%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGeneratorWorker%3A%7Bself.rank%7D%5D%20Spawned%2C%20waiting%20for%20setup()...%22)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20setup(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Heavy%20initialization%3A%20load%20model%2C%20create%20weight%20buffer.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20import%20os%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self._ready%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22status%22%3A%20%22already_ready%22%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Generators%20use%20GPU%201%20%2B%20rank%20(trainer%20uses%20GPU%200)%0A%20%20%20%20%20%20%20%20%20%20%20%20gpu_id%20%3D%201%20%2B%20self.rank%0A%20%20%20%20%20%20%20%20%20%20%20%20os.environ%5B%22CUDA_VISIBLE_DEVICES%22%5D%20%3D%20str(gpu_id)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device%20%3D%20%22cuda%22%20if%20torch.cuda.is_available()%20else%20%22cpu%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.policy_version%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20self.generations%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGeneratorWorker%3A%7Bself.rank%7D%5D%20Loading%20model%20%7Bself.model_name%7D%20on%20GPU%20%7Bgpu_id%7D...%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.tokenizer%20%3D%20AutoTokenizer.from_pretrained(self.model_name)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model%20%3D%20AutoModelForCausalLM.from_pretrained(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.model_name%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20dtype%3Dtorch.bfloat16%20if%20self.device%20%3D%3D%20%22cuda%22%20else%20torch.float32%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20).to(self.device)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self.tokenizer.pad_token%20is%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.tokenizer.pad_token%20%3D%20self.tokenizer.eos_token%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.spec%20%3D%20get_spec(%22compositional%22%2C%20difficulty%3Dself.difficulty%2C%20seed%3D42%20%2B%20self.rank)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Pre-allocate%20CPU%20staging%20buffer%20for%20weight%20sync%20(sized%20during%20first%20sync)%0A%20%20%20%20%20%20%20%20%20%20%20%20self._staging_buf%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self._ready%20%3D%20True%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGeneratorWorker%3A%7Bself.rank%7D%5D%20Ready%20on%20GPU%20%7Bgpu_id%7D!%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22status%22%3A%20%22ready%22%2C%20%22rank%22%3A%20self.rank%2C%20%22gpu%22%3A%20gpu_id%7D%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_version(self)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.policy_version%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20sync_weights_from_buffer(self%2C%20handle%2C%20param_meta%3A%20dict%2C%20version%3A%20int)%20-%3E%20bool%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Sync%20weights%20via%20RDMA%20from%20trainer's%20circular%20buffer.%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20Flow%3A%20Trainer%20CPU%20slot%20--RDMA--%3E%20Generator%20CPU%20staging%20--H2D--%3E%20Generator%20GPU%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3C%3D%20self.policy_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20False%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20buf_size%20%3D%20handle.size()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Allocate%20staging%20buffer%20on%20first%20sync%20(reuse%20for%20subsequent%20syncs)%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20self._staging_buf%20is%20None%20or%20self._staging_buf.numel()%20%3C%20buf_size%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self._staging_buf%20%3D%20torch.empty(buf_size%2C%20dtype%3Dtorch.uint8)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20RDMA%20read%3A%20trainer%20CPU%20memory%20-%3E%20generator%20CPU%20memory%0A%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(self._staging_buf%5B%3Abuf_size%5D).get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Scatter%20from%20CPU%20staging%20buffer%20into%20GPU%20model%20params%20(H2D)%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20p%20in%20self.model.named_parameters()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20off%2C%20shape%2C%20dtype%20%3D%20param_meta%5Bname%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20nbytes%20%3D%20p.numel()%20*%20p.element_size()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20src%20%3D%20self._staging_buf%5Boff%3Aoff%20%2B%20nbytes%5D.view(dtype).view(shape)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20p.data.copy_(src)%20%20%23%20H2D%20copy%20(src%20is%20CPU%2C%20p.data%20is%20on%20self.device)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.policy_version%20%3D%20version%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20True%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20sync_weights(self%2C%20state_dict%3A%20dict%2C%20version%3A%20int)%20-%3E%20bool%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Sync%20weights%20directly%20(fallback%20when%20RDMA%20unavailable).%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3C%3D%20self.policy_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20False%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model.load_state_dict(state_dict)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.policy_version%20%3D%20version%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20True%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20generate(self%2C%20question%3A%20str%2C%20answer%3A%20int%2C%20max_turns%3A%20int%20%3D%205)%20-%3E%20Trajectory%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Generate%20a%20trajectory%20for%20the%20given%20task.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.model.eval()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20task%20%3D%20Task(question%3Dquestion%2C%20correct_answer%3Danswer%2C%20metadata%3D%7B%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20result%20%3D%20generate_with_tools(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.model%2C%20self.tokenizer%2C%20self.spec%2C%20task%2C%20self.device%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20max_turns%3Dmax_turns%2C%20max_tokens_per_turn%3D150%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.generations%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Build%20model-only%20text%20(generated%20tokens%20without%20injected%20tool%20results)%0A%20%20%20%20%20%20%20%20%20%20%20%20model_only_text%20%3D%20%22%22.join(t.generated_text%20for%20t%20in%20result.turns)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20Trajectory(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20task_question%3Dtask.question%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20task_answer%3Dtask.correct_answer%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20response_text%3Dresult.final_text%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20reward%3D1.0%20if%20result.is_correct%20else%200.0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20is_correct%3Dresult.is_correct%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20num_turns%3Dlen(result.turns)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20num_tool_calls%3Dresult.total_tool_calls%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20generator_id%3Dself.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20policy_version%3Dself.policy_version%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20model_only_text%3Dmodel_only_text%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20return%20(GeneratorWorker%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Architecture%20Overview%0A%0A%20%20%20%20Now%20we%20have%20all%20our%20actors%20defined.%20Here's%20how%20they%20connect%20--%20this%20is%20the%0A%20%20%20%20**single-controller%20paradigm**%20from%20NB01%3A%20the%20notebook%20process%20orchestrates%0A%20%20%20%20everything%2C%20but%20actors%20do%20the%20heavy%20lifting%20on%20their%20own%20GPUs.%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20ZorplexService%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20GeneratorWorkers%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%E2%94%82%20%20%20%20%20tasks%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%E2%94%82%20ZorplexWorker%20%E2%94%82%20%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%3E%20%E2%94%82%20%20%E2%94%82%20GenWorker%200%20%20%20%E2%94%82%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%E2%94%82%20ZorplexWorker%20%E2%94%82%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%E2%94%82%20GenWorker%201%20%20%20%E2%94%82%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20trajectories%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20ReplayBuffer%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20sample%20batch%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20Trainer%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20(circular%20buffer)%20%20%E2%94%82%E2%94%80%E2%94%80%3E%20RDMA%20weight%20sync%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20to%20GenWorkers%0A%20%20%20%20%60%60%60%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Sync%20vs%20Async%20RL%0A%0A%20%20%20%20**Sync%20RL**%20(traditional)%3A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%7C--generate--%7C--train--%7C--generate--%7C--train--%7C--generate--%7C--train--%7C%0A%20%20%20%20%60%60%60%0A%20%20%20%20Only%20ONE%20thing%20happens%20at%20a%20time.%20GPU%20sits%20idle%20during%20generation%2C%0A%20%20%20%20generator%20sits%20idle%20during%20training.%0A%0A%20%20%20%20**Async%20RL**%20(what%20we're%20building)%3A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Gen0%3A%20%20%7C%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%7C%0A%20%20%20%20Gen1%3A%20%20%7C%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%E2%96%88%7C%0A%20%20%20%20Train%3A%20%20%20%20%20%20%7C%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%E2%96%93%7C%0A%20%20%20%20%60%60%60%0A%20%20%20%20Everything%20runs%20concurrently.%20More%20data%20collected%2C%20better%20GPU%20utilization.%0A%0A%20%20%20%20**Why%20threads%3F**%20Python's%20GIL%20is%20released%20during%20I%2FO%20operations%20and%20CUDA%20kernel%0A%20%20%20%20launches.%20Since%20our%20actor%20calls%20are%20remote%20I%2FO%20(%60.call_one().get()%60)%20and%20training%0A%20%20%20%20is%20GPU-bound%2C%20threads%20achieve%20real%20concurrency%20here.%20Each%20generator%20gets%20its%20own%0A%20%20%20%20thread%3B%20training%20runs%20in%20the%20main%20thread.%20We%20cannot%20use%20async%20endpoints%20in%20this%0A%20%20%20%20environment%2C%20so%20threading%20is%20the%20right%20tool.%0A%0A%20%20%20%20We'll%20run%20BOTH%20modes%20with%20the%20**same%20actors**%20and%20compare%20wall%20time%2C%20throughput%2C%0A%20%20%20%20and%20utilization.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20num_steps_slider%20%3D%20mo.ui.slider(3%2C%2020%2C%20value%3D5%2C%20label%3D%22Training%20steps%22)%0A%20%20%20%20num_generators_slider%20%3D%20mo.ui.slider(1%2C%204%2C%20value%3D2%2C%20label%3D%22Generators%22)%0A%20%20%20%20batch_size_slider%20%3D%20mo.ui.slider(2%2C%208%2C%20value%3D4%2C%20label%3D%22Batch%20size%22)%0A%0A%20%20%20%20mo.md(f%22%22%22%0A%20%20%20%20%23%23%20Configuration%0A%0A%20%20%20%20Adjust%20parameters%20for%20the%20training%20run.%20Actors%20are%20spawned%20once%20and%20reused%0A%20%20%20%20for%20both%20sync%20and%20async%20modes.%0A%0A%20%20%20%20%7Bnum_steps_slider%7D%0A%0A%20%20%20%20%7Bnum_generators_slider%7D%0A%0A%20%20%20%20%7Bbatch_size_slider%7D%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%20batch_size_slider%2C%20num_generators_slider%2C%20num_steps_slider%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20GeneratorWorker%2C%0A%20%20%20%20ReplayBuffer%2C%0A%20%20%20%20Service%2C%0A%20%20%20%20TrainerActor%2C%0A%20%20%20%20ZorplexWorker%2C%0A%20%20%20%20batch_size_slider%2C%0A%20%20%20%20num_generators_slider%2C%0A%20%20%20%20num_steps_slider%2C%0A%20%20%20%20register_service%2C%0A)%3A%0A%20%20%20%20import%20threading%0A%20%20%20%20import%20time%0A%20%20%20%20from%20dataclasses%20import%20dataclass%2C%20field%0A%0A%20%20%20%20from%20monarch.actor%20import%20this_host%0A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20TimingEvent%3A%0A%20%20%20%20%20%20%20%20%22%22%22A%20single%20timed%20event%20for%20timeline%20visualization.%22%22%22%0A%20%20%20%20%20%20%20%20actor_id%3A%20str%0A%20%20%20%20%20%20%20%20event_type%3A%20str%20%20%23%20%22generate%22%2C%20%22train%22%2C%20%22sync%22%0A%20%20%20%20%20%20%20%20start_time%3A%20float%0A%20%20%20%20%20%20%20%20duration%3A%20float%0A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20TimingStats%3A%0A%20%20%20%20%20%20%20%20%22%22%22Timing%20statistics%20for%20a%20training%20run.%22%22%22%0A%20%20%20%20%20%20%20%20mode%3A%20str%0A%20%20%20%20%20%20%20%20num_generators%3A%20int%0A%20%20%20%20%20%20%20%20num_steps%3A%20int%0A%20%20%20%20%20%20%20%20total_generations%3A%20int%0A%20%20%20%20%20%20%20%20wall_time%3A%20float%0A%20%20%20%20%20%20%20%20gen_times%3A%20list%20%3D%20field(default_factory%3Dlist)%0A%20%20%20%20%20%20%20%20train_times%3A%20list%20%3D%20field(default_factory%3Dlist)%0A%20%20%20%20%20%20%20%20events%3A%20list%20%3D%20field(default_factory%3Dlist)%20%20%23%20List%20of%20TimingEvent%0A%20%20%20%20%20%20%20%20rdma_syncs%3A%20int%20%3D%200%0A%20%20%20%20%20%20%20%20direct_syncs%3A%20int%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%40property%0A%20%20%20%20%20%20%20%20def%20gens_per_second(self)%20-%3E%20float%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.total_generations%20%2F%20self.wall_time%20if%20self.wall_time%20%3E%200%20else%200%0A%0A%20%20%20%20%20%20%20%20%40property%0A%20%20%20%20%20%20%20%20def%20steps_per_second(self)%20-%3E%20float%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.num_steps%20%2F%20self.wall_time%20if%20self.wall_time%20%3E%200%20else%200%0A%0A%20%20%20%20NUM_STEPS%20%3D%20num_steps_slider.value%0A%20%20%20%20NUM_GENERATORS%20%3D%20num_generators_slider.value%0A%20%20%20%20NUM_ZORPLEX%20%3D%202%0A%20%20%20%20BATCH_SIZE%20%3D%20batch_size_slider.value%0A%0A%20%20%20%20def%20setup_actors()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Spawn%20and%20initialize%20all%20actors.%20Returns%20them%20for%20reuse.%22%22%22%0A%20%20%20%20%20%20%20%20host%20%3D%20this_host()%0A%0A%20%20%20%20%20%20%20%20%23%201.%20ZorplexWorkers%20--%20Service%20spawns%20workers%20internally%0A%20%20%20%20%20%20%20%20zorplex_worker_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%20NUM_ZORPLEX%7D)%0A%20%20%20%20%20%20%20%20zorplex_svc_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20zorplex_svc%20%3D%20zorplex_svc_procs.spawn(%22zorplex_svc%22%2C%20Service%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20service_name%3D%22zorplex%22%2C%20worker_class%3DZorplexWorker%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20procs%3Dzorplex_worker_procs%2C%20procs_per_replica%3D1%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20difficulty%3D%22easy%22)%0A%0A%20%20%20%20%20%20%20%20%23%202.%20GeneratorWorkers%20--%20spawned%20directly%20(no%20Service%20wrapper%20for%20individual%20access)%0A%20%20%20%20%20%20%20%20gen_worker_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%20NUM_GENERATORS%7D)%0A%20%20%20%20%20%20%20%20gen_svc_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20gen_svc%20%3D%20gen_svc_procs.spawn(%22gen_svc%22%2C%20Service%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20service_name%3D%22generators%22%2C%20worker_class%3DGeneratorWorker%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20procs%3Dgen_worker_procs%2C%20procs_per_replica%3D1)%0A%0A%20%20%20%20%20%20%20%20%23%203.%20ReplayBuffer%0A%20%20%20%20%20%20%20%20buffer_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20buffer%20%3D%20buffer_procs.spawn(%22buffer%22%2C%20ReplayBuffer%2C%20max_size%3D500)%0A%0A%20%20%20%20%20%20%20%20%23%204.%20Trainer%0A%20%20%20%20%20%20%20%20trainer_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20trainer%20%3D%20trainer_procs.spawn(%22trainer%22%2C%20TrainerActor)%0A%0A%20%20%20%20%20%20%20%20%23%20Initialize%20actors%20that%20need%20setup%0A%20%20%20%20%20%20%20%20zorplex_svc.ping.call_one().get()%0A%0A%20%20%20%20%20%20%20%20print(%22%5BSETUP%5D%20Setting%20up%20generator%20workers...%22)%0A%20%20%20%20%20%20%20%20gen_worker_list%20%3D%20gen_svc.get_all_replicas.call_one().get()%0A%20%20%20%20%20%20%20%20for%20w%20in%20gen_worker_list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20w.setup.call_one().get()%0A%0A%20%20%20%20%20%20%20%20gen_svc.ping.call_one().get()%0A%20%20%20%20%20%20%20%20buffer.stats.call_one().get()%0A%0A%20%20%20%20%20%20%20%20print(%22%5BSETUP%5D%20Setting%20up%20trainer...%22)%0A%20%20%20%20%20%20%20%20trainer.setup.call_one().get()%0A%0A%20%20%20%20%20%20%20%20register_service(%22zorplex%22%2C%20zorplex_svc)%0A%20%20%20%20%20%20%20%20register_service(%22generators%22%2C%20gen_svc)%0A%0A%20%20%20%20%20%20%20%20print(f%22%5BSETUP%5D%20All%20actors%20ready!%20%7BNUM_GENERATORS%7D%20generators%2C%20%7BNUM_ZORPLEX%7D%20zorplex%20workers%22)%0A%0A%20%20%20%20%20%20%20%20return%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22trainer%22%3A%20trainer%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22buffer%22%3A%20buffer%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22gen_worker_list%22%3A%20gen_worker_list%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22gen_svc%22%3A%20gen_svc%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%22zorplex_svc%22%3A%20zorplex_svc%2C%0A%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20actors%20%3D%20setup_actors()%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20BATCH_SIZE%2C%0A%20%20%20%20%20%20%20%20NUM_STEPS%2C%0A%20%20%20%20%20%20%20%20TimingEvent%2C%0A%20%20%20%20%20%20%20%20TimingStats%2C%0A%20%20%20%20%20%20%20%20actors%2C%0A%20%20%20%20%20%20%20%20threading%2C%0A%20%20%20%20%20%20%20%20time%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Before%20Training%3A%20Zorplex%20Baseline%0A%0A%20%20%20%20Let's%20evaluate%20the%20model%20*before*%20any%20training%20to%20establish%20a%20baseline.%0A%20%20%20%20We%20run%2010%20compositional%20Zorplex%20tasks%20and%20record%20accuracy%2C%20average%20turns%2C%0A%20%20%20%20and%20tool%20usage.%20This%20gives%20us%20a%20concrete%20%22before%22%20snapshot%20to%20compare%20against.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(actors%2C%20mo)%3A%0A%20%20%20%20print(%22Evaluating%20pre-training%20baseline...%22)%0A%20%20%20%20pre_eval%20%3D%20actors%5B%22trainer%22%5D.evaluate_zorplex.call_one(num_samples%3D10%2C%20seed%3D42).get()%0A%0A%20%20%20%20mo.md(f%22%22%22%0A%20%20%20%20%23%23%23%20Pre-Training%20Results%0A%0A%20%20%20%20%7C%20Metric%20%7C%20Value%20%7C%0A%20%20%20%20%7C--------%7C-------%7C%0A%20%20%20%20%7C%20Accuracy%20%7C%20%7Bpre_eval%5B'accuracy'%5D%3A.0%25%7D%20(%7Bpre_eval%5B'correct'%5D%7D%2F%7Bpre_eval%5B'total'%5D%7D)%20%7C%0A%20%20%20%20%7C%20Avg%20turns%20%7C%20%7Bpre_eval%5B'avg_turns'%5D%3A.1f%7D%20%7C%0A%20%20%20%20%7C%20Avg%20tool%20calls%20%7C%20%7Bpre_eval%5B'avg_tools'%5D%3A.1f%7D%20%7C%0A%0A%20%20%20%20This%20is%20our%20starting%20point.%20Let's%20see%20if%20training%20improves%20it.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%20(pre_eval%2C)%0A%0A%0A%40app.cell%0Adef%20_(BATCH_SIZE%2C%20NUM_STEPS%2C%20TimingEvent%2C%20TimingStats%2C%20actors%2C%20time)%3A%0A%20%20%20%20def%20run_sync_loop()%20-%3E%20TimingStats%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20SYNC%20MODE%3A%20Rotate%20through%20ALL%20generators%20sequentially.%0A%20%20%20%20%20%20%20%20Pattern%3A%20generate%20-%3E%20train%20-%3E%20generate%20-%3E%20train%20...%0A%0A%20%20%20%20%20%20%20%20Uses%20all%20generators%20in%20round-robin%20so%20the%20comparison%20with%20async%0A%20%20%20%20%20%20%20%20is%20fair%20--%20same%20number%20of%20generators%2C%20just%20used%20sequentially.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20print(%22%5Cn%22%20%2B%20%22%3D%22%20*%2060)%0A%20%20%20%20%20%20%20%20print(%22SYNC%20MODE%3A%20Sequential%20Generate%20-%3E%20Train%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2060)%0A%0A%20%20%20%20%20%20%20%20trainer%20%3D%20actors%5B%22trainer%22%5D%0A%20%20%20%20%20%20%20%20buffer%20%3D%20actors%5B%22buffer%22%5D%0A%20%20%20%20%20%20%20%20gen_worker_list%20%3D%20actors%5B%22gen_worker_list%22%5D%0A%20%20%20%20%20%20%20%20zorplex_svc%20%3D%20actors%5B%22zorplex_svc%22%5D%0A%0A%20%20%20%20%20%20%20%20stats%20%3D%20TimingStats(%0A%20%20%20%20%20%20%20%20%20%20%20%20mode%3D%22SYNC%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20num_generators%3Dlen(gen_worker_list)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20num_steps%3DNUM_STEPS%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20total_generations%3D0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20wall_time%3D0%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20baseline%20%3D%200.5%0A%20%20%20%20%20%20%20%20t0%20%3D%20time.perf_counter()%0A%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(NUM_STEPS)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Rotate%20through%20ALL%20generators%20(fair%20comparison%20with%20async)%0A%20%20%20%20%20%20%20%20%20%20%20%20gen_worker%20%3D%20gen_worker_list%5Bstep%20%25%20len(gen_worker_list)%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Generate%20ONE%20trajectory%20(blocking)%0A%20%20%20%20%20%20%20%20%20%20%20%20gen_start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20zorplex_worker%2C%20_%20%3D%20zorplex_svc.get_replica_with_idx.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20question%2C%20answer%20%3D%20zorplex_worker.generate_task.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20traj%20%3D%20gen_worker.generate.call_one(question%2C%20answer).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20buffer.add.call_one(traj).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20gen_time%20%3D%20time.perf_counter()%20-%20gen_start%0A%20%20%20%20%20%20%20%20%20%20%20%20stats.gen_times.append(gen_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20stats.total_generations%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20stats.events.append(TimingEvent(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actor_id%3Df%22Gen%7Bstep%20%25%20len(gen_worker_list)%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20event_type%3D%22generate%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20start_time%3Dgen_start%20-%20t0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20duration%3Dgen_time%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Train%20on%20buffer%20(blocking)%0A%20%20%20%20%20%20%20%20%20%20%20%20train_start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20batch%20%3D%20buffer.sample.call_one(BATCH_SIZE).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20batch%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20metrics%20%3D%20trainer.train_step.call_one(batch%2C%20baseline).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20baseline%20%3D%200.9%20*%20baseline%20%2B%200.1%20*%20metrics.avg_reward%0A%20%20%20%20%20%20%20%20%20%20%20%20train_time%20%3D%20time.perf_counter()%20-%20train_start%0A%20%20%20%20%20%20%20%20%20%20%20%20stats.train_times.append(train_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20stats.events.append(TimingEvent(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actor_id%3D%22Train%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20event_type%3D%22train%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20start_time%3Dtrain_start%20-%20t0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20duration%3Dtrain_time%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20status%20%3D%20%22correct%22%20if%20traj.is_correct%20else%20%22wrong%22%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BSYNC%20%7Bstep%20%2B%201%3A2d%7D%5D%20%7Bstatus%7D%20gen%3D%7Bgen_time%20*%201000%3A.0f%7Dms%20train%3D%7Btrain_time%20*%201000%3A.0f%7Dms%22)%0A%0A%20%20%20%20%20%20%20%20stats.wall_time%20%3D%20time.perf_counter()%20-%20t0%0A%20%20%20%20%20%20%20%20return%20stats%0A%20%20%20%20return%20(run_sync_loop%2C)%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20BATCH_SIZE%2C%0A%20%20%20%20NUM_STEPS%2C%0A%20%20%20%20TimingEvent%2C%0A%20%20%20%20TimingStats%2C%0A%20%20%20%20actors%2C%0A%20%20%20%20threading%2C%0A%20%20%20%20time%2C%0A)%3A%0A%20%20%20%20def%20run_async_loop()%20-%3E%20TimingStats%3A%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20ASYNC%20MODE%3A%20All%20generators%20running%20concurrently%20with%20trainer.%0A%20%20%20%20%20%20%20%20-%201%20thread%20per%20generator%20(each%20runs%20its%20own%20generation%20loop)%0A%20%20%20%20%20%20%20%20-%201%20separate%20weight%20sync%20thread%0A%20%20%20%20%20%20%20%20-%20Training%20in%20main%20thread%0A%0A%20%20%20%20%20%20%20%20Uses%20try%2Fexcept%20pattern%20from%20NB03%20for%20fault%20tolerance%20in%20generation%20loops.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20print(%22%5Cn%22%20%2B%20%22%3D%22%20*%2060)%0A%20%20%20%20%20%20%20%20print(f%22ASYNC%20MODE%3A%20%7Blen(actors%5B'gen_worker_list'%5D)%7D%20Generators%20%2B%201%20Trainer%20(Concurrent)%22)%0A%20%20%20%20%20%20%20%20print(%22%3D%22%20*%2060)%0A%0A%20%20%20%20%20%20%20%20trainer%20%3D%20actors%5B%22trainer%22%5D%0A%20%20%20%20%20%20%20%20buffer%20%3D%20actors%5B%22buffer%22%5D%0A%20%20%20%20%20%20%20%20gen_worker_list%20%3D%20actors%5B%22gen_worker_list%22%5D%0A%20%20%20%20%20%20%20%20zorplex_svc%20%3D%20actors%5B%22zorplex_svc%22%5D%0A%0A%20%20%20%20%20%20%20%20stats%20%3D%20TimingStats(%0A%20%20%20%20%20%20%20%20%20%20%20%20mode%3D%22ASYNC%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20num_generators%3Dlen(gen_worker_list)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20num_steps%3DNUM_STEPS%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20total_generations%3D0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20wall_time%3D0%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20lock%20%3D%20threading.Lock()%0A%20%20%20%20%20%20%20%20stop_flag%20%3D%20threading.Event()%0A%20%20%20%20%20%20%20%20t0%20%3D%20time.perf_counter()%0A%0A%20%20%20%20%20%20%20%20def%20generation_loop(gen_idx%2C%20gen_worker)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Each%20generator%20gets%20its%20own%20thread.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20while%20not%20stop_flag.is_set()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gen_start%20%3D%20time.perf_counter()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20zorplex_worker%2C%20_%20%3D%20zorplex_svc.get_replica_with_idx.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20question%2C%20answer%20%3D%20zorplex_worker.generate_task.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20traj%20%3D%20gen_worker.generate.call_one(question%2C%20answer).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20buffer.add.call_one(traj).get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gen_time%20%3D%20time.perf_counter()%20-%20gen_start%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20with%20lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.gen_times.append(gen_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.total_generations%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20count%20%3D%20stats.total_generations%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.events.append(TimingEvent(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actor_id%3Df%22Gen%7Bgen_idx%7D%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20event_type%3D%22generate%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20start_time%3Dgen_start%20-%20t0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20duration%3Dgen_time%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20status%20%3D%20%22correct%22%20if%20traj.is_correct%20else%20%22wrong%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGEN%7Bgen_idx%7D%20%23%7Bcount%3A2d%7D%5D%20%7Bstatus%7D%20gen%3D%7Bgen_time%20*%201000%3A.0f%7Dms%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20try%2Fexcept%20pattern%20from%20NB03%20--%20log%20and%20continue%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGEN%7Bgen_idx%7D%5D%20Error%3A%20%7Be%7D%2C%20retrying...%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20continue%0A%0A%20%20%20%20%20%20%20%20def%20weight_sync_loop()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Periodically%20sync%20weights%20to%20all%20generators.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20while%20not%20stop_flag.is_set()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(0.5)%20%20%23%20Sync%20every%20500ms%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20stop_flag.is_set()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sync_start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle%2C%20param_meta%2C%20version%20%3D%20trainer.get_weight_handle.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20w%20in%20gen_worker_list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20handle%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20synced%20%3D%20w.sync_weights_from_buffer.call_one(handle%2C%20param_meta%2C%20version).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20synced%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20with%20lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.rdma_syncs%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20state_dict%2C%20ver%20%3D%20trainer.get_state_dict.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20synced%20%3D%20w.sync_weights.call_one(state_dict%2C%20ver).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20synced%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20with%20lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.direct_syncs%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20except%20Exception%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20pass%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sync_time%20%3D%20time.perf_counter()%20-%20sync_start%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20with%20lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.events.append(TimingEvent(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actor_id%3D%22Sync%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20event_type%3D%22sync%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20start_time%3Dsync_start%20-%20t0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20duration%3Dsync_time%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20except%20Exception%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20pass%0A%0A%20%20%20%20%20%20%20%20%23%20Start%201%20thread%20per%20generator%0A%20%20%20%20%20%20%20%20gen_threads%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20idx%2C%20worker%20in%20enumerate(gen_worker_list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20t%20%3D%20threading.Thread(target%3Dgeneration_loop%2C%20args%3D(idx%2C%20worker)%2C%20daemon%3DTrue)%0A%20%20%20%20%20%20%20%20%20%20%20%20t.start()%0A%20%20%20%20%20%20%20%20%20%20%20%20gen_threads.append(t)%0A%0A%20%20%20%20%20%20%20%20%23%20Start%20weight%20sync%20thread%0A%20%20%20%20%20%20%20%20sync_thread%20%3D%20threading.Thread(target%3Dweight_sync_loop%2C%20daemon%3DTrue)%0A%20%20%20%20%20%20%20%20sync_thread.start()%0A%0A%20%20%20%20%20%20%20%20%23%20Training%20in%20main%20thread%0A%20%20%20%20%20%20%20%20train_steps_done%20%3D%200%0A%20%20%20%20%20%20%20%20baseline%20%3D%200.5%0A%0A%20%20%20%20%20%20%20%20while%20train_steps_done%20%3C%20NUM_STEPS%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Wait%20for%20enough%20samples%0A%20%20%20%20%20%20%20%20%20%20%20%20while%20True%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20size%20%3D%20buffer.size.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20size%20%3E%3D%20BATCH_SIZE%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20break%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(0.02)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20train_start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20batch%20%3D%20buffer.sample.call_one(BATCH_SIZE).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20batch%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20metrics%20%3D%20trainer.train_step.call_one(batch%2C%20baseline).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20baseline%20%3D%200.9%20*%20baseline%20%2B%200.1%20*%20metrics.avg_reward%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20train_time%20%3D%20time.perf_counter()%20-%20train_start%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.train_times.append(train_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20stats.events.append(TimingEvent(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actor_id%3D%22Train%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20event_type%3D%22train%22%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20start_time%3Dtrain_start%20-%20t0%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20duration%3Dtrain_time%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20))%0A%20%20%20%20%20%20%20%20%20%20%20%20train_steps_done%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTRAIN%20%7Btrain_steps_done%3A2d%7D%5D%20time%3D%7Btrain_time%20*%201000%3A.0f%7Dms%20buffer%3D%7Bsize%7D%22)%0A%0A%20%20%20%20%20%20%20%20stop_flag.set()%0A%0A%20%20%20%20%20%20%20%20for%20t%20in%20gen_threads%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20t.join(timeout%3D2.0)%0A%20%20%20%20%20%20%20%20sync_thread.join(timeout%3D2.0)%0A%0A%20%20%20%20%20%20%20%20stats.wall_time%20%3D%20time.perf_counter()%20-%20t0%0A%20%20%20%20%20%20%20%20return%20stats%0A%20%20%20%20return%20(run_async_loop%2C)%0A%0A%0A%40app.cell%0Adef%20_(actors%2C%20run_sync_loop)%3A%0A%20%20%20%20%23%20Clear%20buffer%20to%20start%20fresh%0A%20%20%20%20_cleared%20%3D%20actors%5B%22buffer%22%5D.clear.call_one().get()%0A%20%20%20%20print(f%22Buffer%20cleared%20(%7B_cleared%7D%20items%20removed)%22)%0A%0A%20%20%20%20sync_stats%20%3D%20run_sync_loop()%0A%20%20%20%20print(f%22%5CnSync%20complete%3A%20%7Bsync_stats.wall_time%3A.2f%7Ds%2C%20%22%0A%20%20%20%20%20%20%20%20%20%20f%22%7Bsync_stats.total_generations%7D%20generations%2C%20%22%0A%20%20%20%20%20%20%20%20%20%20f%22%7Bsync_stats.gens_per_second%3A.2f%7D%20gens%2Fs%22)%0A%20%20%20%20return%20(sync_stats%2C)%0A%0A%0A%40app.cell%0Adef%20_(actors%2C%20run_async_loop)%3A%0A%20%20%20%20%23%20Clear%20buffer%20between%20runs%20for%20fair%20comparison%0A%20%20%20%20_cleared%20%3D%20actors%5B%22buffer%22%5D.clear.call_one().get()%0A%20%20%20%20print(f%22Buffer%20cleared%20(%7B_cleared%7D%20items%20removed)%22)%0A%0A%20%20%20%20async_stats%20%3D%20run_async_loop()%0A%20%20%20%20print(f%22%5CnAsync%20complete%3A%20%7Basync_stats.wall_time%3A.2f%7Ds%2C%20%22%0A%20%20%20%20%20%20%20%20%20%20f%22%7Basync_stats.total_generations%7D%20generations%2C%20%22%0A%20%20%20%20%20%20%20%20%20%20f%22%7Basync_stats.gens_per_second%3A.2f%7D%20gens%2Fs%22)%0A%20%20%20%20return%20(async_stats%2C)%0A%0A%0A%40app.cell%0Adef%20_(async_stats%2C%20mo%2C%20sync_stats)%3A%0A%20%20%20%20def%20_build_comparison(sync_s%2C%20async_s)%20-%3E%20str%3A%0A%20%20%20%20%20%20%20%20speedup%20%3D%20sync_s.wall_time%20%2F%20async_s.wall_time%20if%20async_s.wall_time%20%3E%200%20else%200%0A%20%20%20%20%20%20%20%20gen_ratio%20%3D%20async_s.gens_per_second%20%2F%20sync_s.gens_per_second%20if%20sync_s.gens_per_second%20%3E%200%20else%200%0A%0A%20%20%20%20%20%20%20%20avg_sync_gen%20%3D%20sum(sync_s.gen_times)%20%2F%20len(sync_s.gen_times)%20*%201000%20if%20sync_s.gen_times%20else%200%0A%20%20%20%20%20%20%20%20avg_async_gen%20%3D%20sum(async_s.gen_times)%20%2F%20len(async_s.gen_times)%20*%201000%20if%20async_s.gen_times%20else%200%0A%20%20%20%20%20%20%20%20avg_sync_train%20%3D%20sum(sync_s.train_times)%20%2F%20len(sync_s.train_times)%20*%201000%20if%20sync_s.train_times%20else%200%0A%20%20%20%20%20%20%20%20avg_async_train%20%3D%20sum(async_s.train_times)%20%2F%20len(async_s.train_times)%20*%201000%20if%20async_s.train_times%20else%200%0A%0A%20%20%20%20%20%20%20%20sync_type%20%3D%20f%22%7Basync_s.rdma_syncs%7D%20RDMA%22%20if%20async_s.rdma_syncs%20%3E%200%20else%20f%22%7Basync_s.direct_syncs%7D%20direct%22%0A%0A%20%20%20%20%20%20%20%20return%20f%22%22%22%0A%20%20%20%20%23%23%20Sync%20vs%20Async%20Comparison%0A%0A%20%20%20%20%7C%20Metric%20%7C%20SYNC%20%7C%20ASYNC%20%7C%20Ratio%20%7C%0A%20%20%20%20%7C--------%7C------%7C-------%7C-------%7C%0A%20%20%20%20%7C%20Wall%20time%20%7C%20%7Bsync_s.wall_time%3A.2f%7Ds%20%7C%20%7Basync_s.wall_time%3A.2f%7Ds%20%7C%20**%7Bspeedup%3A.2f%7Dx**%20speedup%20%7C%0A%20%20%20%20%7C%20Generations%20%7C%20%7Bsync_s.total_generations%7D%20%7C%20%7Basync_s.total_generations%7D%20%7C%20%7Basync_s.total_generations%20%2F%20max(sync_s.total_generations%2C%201)%3A.1f%7Dx%20%7C%0A%20%20%20%20%7C%20Gens%2Fsecond%20%7C%20%7Bsync_s.gens_per_second%3A.2f%7D%20%7C%20%7Basync_s.gens_per_second%3A.2f%7D%20%7C%20**%7Bgen_ratio%3A.1f%7Dx**%20throughput%20%7C%0A%20%20%20%20%7C%20Avg%20gen%20time%20%7C%20%7Bavg_sync_gen%3A.0f%7Dms%20%7C%20%7Bavg_async_gen%3A.0f%7Dms%20%7C%20%7C%0A%20%20%20%20%7C%20Avg%20train%20time%20%7C%20%7Bavg_sync_train%3A.0f%7Dms%20%7C%20%7Bavg_async_train%3A.0f%7Dms%20%7C%20%7C%0A%20%20%20%20%7C%20Weight%20syncs%20%7C%20--%20%7C%20%7Bsync_type%7D%20%7C%20%7C%0A%0A%20%20%20%20%23%23%23%20Key%20Observations%0A%0A%20%20%20%20-%20**Data%20throughput**%3A%20Async%20collected%20**%7Bgen_ratio%3A.1f%7Dx**%20more%20trajectories%20per%20second.%0A%20%20%20%20%20%20More%20data%20means%20better%20gradient%20estimates.%0A%20%20%20%20-%20**GPU%20utilization**%3A%20In%20sync%20mode%2C%20the%20trainer%20GPU%20sits%20idle%20during%20generation%20and%0A%20%20%20%20%20%20vice%20versa.%20Async%20keeps%20both%20busy.%0A%20%20%20%20-%20**Generators%20ran%20in%20parallel**%3A%20%7Basync_s.num_generators%7D%20generators%20each%20had%20their%20own%0A%20%20%20%20%20%20thread%2C%20producing%20data%20independently.%0A%20%20%20%20-%20The%20trainer%20consumed%20from%20the%20replay%20buffer%20continuously%2C%20never%20waiting%20for%20a%20specific%0A%20%20%20%20%20%20generator%20to%20finish.%0A%0A%20%20%20%20In%20production%20with%20more%20generators%2C%20the%20throughput%20advantage%20grows%20further.%0A%20%20%20%20%22%22%22%0A%0A%20%20%20%20comparison_md%20%3D%20_build_comparison(sync_stats%2C%20async_stats)%0A%20%20%20%20mo.md(comparison_md)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(async_stats%2C%20mo%2C%20sync_stats)%3A%0A%20%20%20%20import%20matplotlib.pyplot%20as%20plt%0A%20%20%20%20import%20matplotlib.patches%20as%20mpatches%0A%0A%20%20%20%20def%20_plot_timeline(stats%2C%20ax%2C%20title)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Plot%20a%20Gantt%20chart%20of%20timing%20events.%22%22%22%0A%20%20%20%20%20%20%20%20color_map%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%22generate%22%3A%20%22%234CAF50%22%2C%20%20%23%20green%0A%20%20%20%20%20%20%20%20%20%20%20%20%22train%22%3A%20%22%23E91E63%22%2C%20%20%20%20%20%23%20pink%0A%20%20%20%20%20%20%20%20%20%20%20%20%22sync%22%3A%20%22%239C27B0%22%2C%20%20%20%20%20%20%23%20purple%0A%20%20%20%20%20%20%20%20%7D%0A%0A%20%20%20%20%20%20%20%20%23%20Collect%20unique%20actor%20IDs%20and%20assign%20y%20positions%0A%20%20%20%20%20%20%20%20actor_ids%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20ev%20in%20stats.events%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20ev.actor_id%20not%20in%20actor_ids%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actor_ids.append(ev.actor_id)%0A%0A%20%20%20%20%20%20%20%20%23%20Sort%3A%20Gen0%2C%20Gen1%2C%20...%2C%20Train%2C%20Sync%0A%20%20%20%20%20%20%20%20gen_ids%20%3D%20sorted(%5Ba%20for%20a%20in%20actor_ids%20if%20a.startswith(%22Gen%22)%5D)%0A%20%20%20%20%20%20%20%20other_ids%20%3D%20%5Ba%20for%20a%20in%20%5B%22Train%22%2C%20%22Sync%22%5D%20if%20a%20in%20actor_ids%5D%0A%20%20%20%20%20%20%20%20actor_ids%20%3D%20gen_ids%20%2B%20other_ids%0A%0A%20%20%20%20%20%20%20%20y_map%20%3D%20%7Baid%3A%20i%20for%20i%2C%20aid%20in%20enumerate(actor_ids)%7D%0A%0A%20%20%20%20%20%20%20%20for%20ev%20in%20stats.events%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20ev.actor_id%20in%20y_map%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20y%20%3D%20y_map%5Bev.actor_id%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20color%20%3D%20color_map.get(ev.event_type%2C%20%22%23999999%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ax.barh(y%2C%20ev.duration%2C%20left%3Dev.start_time%2C%20height%3D0.6%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20color%3Dcolor%2C%20alpha%3D0.8%2C%20edgecolor%3D%22white%22%2C%20linewidth%3D0.5)%0A%0A%20%20%20%20%20%20%20%20ax.set_yticks(range(len(actor_ids)))%0A%20%20%20%20%20%20%20%20ax.set_yticklabels(actor_ids)%0A%20%20%20%20%20%20%20%20ax.set_xlabel(%22Wall%20time%20(seconds)%22)%0A%20%20%20%20%20%20%20%20ax.set_title(title)%0A%20%20%20%20%20%20%20%20ax.invert_yaxis()%0A%0A%20%20%20%20fig%2C%20(ax1%2C%20ax2)%20%3D%20plt.subplots(2%2C%201%2C%20figsize%3D(12%2C%206)%2C%20sharex%3DFalse)%0A%0A%20%20%20%20_plot_timeline(sync_stats%2C%20ax1%2C%20f%22SYNC%20(%7Bsync_stats.wall_time%3A.1f%7Ds)%22)%0A%20%20%20%20_plot_timeline(async_stats%2C%20ax2%2C%20f%22ASYNC%20(%7Basync_stats.wall_time%3A.1f%7Ds)%22)%0A%0A%20%20%20%20%23%20Legend%0A%20%20%20%20legend_patches%20%3D%20%5B%0A%20%20%20%20%20%20%20%20mpatches.Patch(color%3D%22%234CAF50%22%2C%20label%3D%22Generate%22)%2C%0A%20%20%20%20%20%20%20%20mpatches.Patch(color%3D%22%23E91E63%22%2C%20label%3D%22Train%22)%2C%0A%20%20%20%20%20%20%20%20mpatches.Patch(color%3D%22%239C27B0%22%2C%20label%3D%22Weight%20Sync%22)%2C%0A%20%20%20%20%5D%0A%20%20%20%20fig.legend(handles%3Dlegend_patches%2C%20loc%3D%22upper%20right%22%2C%20framealpha%3D0.9)%0A%0A%20%20%20%20plt.tight_layout()%0A%20%20%20%20mo.md(%22%23%23%23%20Timeline%20Visualization%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20After%20Training%3A%20Did%20It%20Improve%3F%0A%0A%20%20%20%20We've%20now%20run%20both%20sync%20and%20async%20training%20loops.%20The%20model%20has%20been%20updated%0A%20%20%20%20through%20multiple%20training%20steps.%20Let's%20evaluate%20the%20same%20set%20of%20compositional%0A%20%20%20%20tasks%20to%20see%20if%20accuracy%20changed.%0A%0A%20%20%20%20Note%3A%20We're%20using%20a%20small%20model%20(0.5B)%20with%20few%20training%20steps%2C%20so%20dramatic%0A%20%20%20%20improvement%20isn't%20guaranteed.%20The%20point%20is%20the%20*infrastructure*%20--%20showing%20that%0A%20%20%20%20the%20full%20loop%20works%20end%20to%20end.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(actors)%3A%0A%20%20%20%20print(%22Evaluating%20post-training%20performance...%22)%0A%20%20%20%20post_eval%20%3D%20actors%5B%22trainer%22%5D.evaluate_zorplex.call_one(num_samples%3D10%2C%20seed%3D42).get()%0A%20%20%20%20print(f%22Post-training%20accuracy%3A%20%7Bpost_eval%5B'accuracy'%5D%3A.0%25%7D%22)%0A%20%20%20%20return%20(post_eval%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo%2C%20post_eval%2C%20pre_eval)%3A%0A%20%20%20%20_acc_delta%20%3D%20post_eval%5B%22accuracy%22%5D%20-%20pre_eval%5B%22accuracy%22%5D%0A%20%20%20%20_direction%20%3D%20%22improved%22%20if%20_acc_delta%20%3E%200%20else%20(%22unchanged%22%20if%20_acc_delta%20%3D%3D%200%20else%20%22decreased%22)%0A%0A%20%20%20%20mo.md(f%22%22%22%0A%20%20%20%20%23%23%23%20Before%20vs%20After%20Training%0A%0A%20%20%20%20%7C%20Metric%20%7C%20Before%20%7C%20After%20%7C%20Delta%20%7C%0A%20%20%20%20%7C--------%7C--------%7C-------%7C-------%7C%0A%20%20%20%20%7C%20Accuracy%20%7C%20%7Bpre_eval%5B'accuracy'%5D%3A.0%25%7D%20%7C%20%7Bpost_eval%5B'accuracy'%5D%3A.0%25%7D%20%7C%20%7B_acc_delta%3A%2B.0%25%7D%20%7C%0A%20%20%20%20%7C%20Avg%20turns%20%7C%20%7Bpre_eval%5B'avg_turns'%5D%3A.1f%7D%20%7C%20%7Bpost_eval%5B'avg_turns'%5D%3A.1f%7D%20%7C%20%7Bpost_eval%5B'avg_turns'%5D%20-%20pre_eval%5B'avg_turns'%5D%3A%2B.1f%7D%20%7C%0A%20%20%20%20%7C%20Avg%20tool%20calls%20%7C%20%7Bpre_eval%5B'avg_tools'%5D%3A.1f%7D%20%7C%20%7Bpost_eval%5B'avg_tools'%5D%3A.1f%7D%20%7C%20%7Bpost_eval%5B'avg_tools'%5D%20-%20pre_eval%5B'avg_tools'%5D%3A%2B.1f%7D%20%7C%0A%0A%20%20%20%20Accuracy%20%7B_direction%7D%20by%20%7Babs(_acc_delta)%3A.0%25%7D.%0A%0A%20%20%20%20With%20a%200.5B%20model%20and%20only%20a%20few%20training%20steps%2C%20large%20gains%20are%20unlikely.%0A%20%20%20%20The%20key%20result%20is%20that%20the%20full%20pipeline%20works%3A%20generation%2C%20buffering%2C%20training%2C%0A%20%20%20%20weight%20sync%2C%20and%20evaluation%20all%20compose%20correctly%20through%20Monarch%20actors.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20What's%20Happening%20Under%20the%20Hood%0A%0A%20%20%20%20When%20you%20run%20the%20training%20loop%2C%20here's%20what%20each%20layer%20does%3A%0A%0A%20%20%20%20**Actor%20isolation**%3A%20Each%20actor%20(trainer%2C%20generators%2C%20buffer%2C%20zorplex%20workers)%0A%20%20%20%20runs%20in%20its%20own%20process%20with%20its%20own%20GPU%20assignment.%20%60CUDA_VISIBLE_DEVICES%60%20is%0A%20%20%20%20set%20in%20%60setup()%60%2C%20not%20at%20spawn%20time%20--%20the%20%60procs%60%20dimension%20in%20%60spawn_procs%60%0A%20%20%20%20is%20just%20a%20dimension%20name%2C%20not%20a%20GPU%20assignment.%0A%0A%20%20%20%20**Weight%20sync%20data%20flow**%20(circular%20buffer%20%2B%20CPU%20staging%20from%20NB06)%3A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20GPU%20%20--D2H--%3E%20%20CPU%20slot%5Bv%20%25%203%5D%20%20--RDMA--%3E%20%20Generator%20CPU%20staging%20%20--H2D--%3E%20%20Generator%20GPU%0A%20%20%20%20%60%60%60%0A%20%20%20%20-%20Trainer%20publishes%20weights%20to%20a%20circular%20buffer%20after%20each%20train%20step%0A%20%20%20%20-%20Generators%20pull%20from%20the%20buffer%20via%20RDMA%20into%20a%20pre-allocated%20staging%20buffer%0A%20%20%20%20-%20Explicit%20H2D%20copy%20scatters%20into%20GPU%20model%20parameters%0A%20%20%20%20-%20The%20circular%20buffer%20has%203%20slots%2C%20so%20training%20never%20blocks%20on%20reads%0A%0A%20%20%20%20**Async%20concurrency**%20(via%20threads)%3A%0A%20%20%20%20-%201%20thread%20per%20generator%2C%20each%20running%20its%20own%20generation%20loop%0A%20%20%20%20-%201%20weight%20sync%20thread%2C%20periodically%20pulling%20from%20trainer%20and%20pushing%20to%20generators%0A%20%20%20%20-%20Training%20in%20the%20main%20thread%0A%20%20%20%20-%20%60threading.Event%60%20coordinates%20shutdown%20when%20training%20completes%0A%20%20%20%20-%20GIL%20is%20released%20during%20I%2FO%20(actor%20calls)%20and%20CUDA%20(GPU%20compute)%2C%20so%20threads%0A%20%20%20%20%20%20achieve%20real%20concurrency%0A%0A%20%20%20%20**Fault%20tolerance**%20(from%20NB03)%3A%0A%20%20%20%20-%20Generation%20loops%20wrap%20%60generate.call_one().get()%60%20in%20%60try%2Fexcept%60%0A%20%20%20%20-%20On%20failure%2C%20the%20generator%20logs%20and%20retries%20instead%20of%20crashing%20the%20loop%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Scaling%20Up%0A%0A%20%20%20%20What%20we%20built%20here%20scales%20naturally%20with%20Monarch%3A%0A%0A%20%20%20%20%7C%20Scale%20%7C%20What%20Changes%20%7C%0A%20%20%20%20%7C-------%7C--------------%7C%0A%20%20%20%20%7C%20More%20generators%20%7C%20Increase%20%60num_generators%60%20slider%20--%20spawns%20larger%20ActorMesh%20%7C%0A%20%20%20%20%7C%20More%20zorplex%20workers%20%7C%20Increase%20%60NUM_ZORPLEX%60%20--%20parallel%20task%20generation%20%7C%0A%20%20%20%20%7C%20Multi-node%20%7C%20Use%20%60SlurmJob%60%20instead%20of%20%60this_host()%60%20%7C%0A%20%20%20%20%7C%20Better%20algorithms%20%7C%20Swap%20REINFORCE%20for%20PPO%2FGRPO%20%7C%0A%20%20%20%20%7C%20More%20services%20%7C%20Add%20reward%20models%2C%20search%20APIs%20as%20actors%20%7C%0A%0A%20%20%20%20**The%20patterns%20stay%20the%20same%3A**%0A%20%20%20%20-%20Actors%20for%20isolation%20and%20GPU%20assignment%0A%20%20%20%20-%20Endpoints%20for%20communication%20(%60.call_one().get()%60)%0A%20%20%20%20-%20RDMA%20%2B%20circular%20buffer%20for%20efficient%20weight%20transfer%0A%20%20%20%20-%20Version%20tracking%20for%20consistency%20across%20actors%0A%0A%20%20%20%20This%20is%20the%20foundation%20for%20production%20systems%20like%20Forge%20GRPO%2C%20which%20uses%20the%0A%20%20%20%20same%20Monarch%20actor%20patterns%20at%20much%20larger%20scale.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Recap%3A%20The%20Full%20Journey%0A%0A%20%20%20%20We've%20come%20a%20long%20way%20in%20this%20notebook%20series%3A%0A%0A%20%20%20%20%7C%20Notebook%20%7C%20What%20We%20Learned%20%7C%0A%20%20%20%20%7C----------%7C-----------------%7C%0A%20%20%20%20%7C%2001%20%7C%20Monarch's%20history%20and%20the%20single-controller%20paradigm%20%7C%0A%20%20%20%20%7C%2002%20%7C%20Interactive%20development%20with%20%60this_host()%60%20%7C%0A%20%20%20%20%7C%2003%20%7C%20Fault%20tolerance%20with%20%60try%2Fexcept%60%20on%20actor%20calls%20%7C%0A%20%20%20%20%7C%2004%20%7C%20Zorplex%20benchmark%20--%20where%20Qwen%200.5B%20struggles%20%7C%0A%20%20%20%20%7C%2005%20%7C%20Services%20for%20managing%20worker%20pools%20with%20health%20tracking%20%7C%0A%20%20%20%20%7C%2006%20%7C%20RDMA%20weight%20sync%2C%20circular%20buffers%2C%20CPU%20staging%20%7C%0A%20%20%20%20%7C%20**07**%20%7C%20**Closing%20the%20loop%3A%20async%20RL%20training%20end%20to%20end**%20%7C%0A%0A%20%20%20%20**Key%20takeaways%20from%20this%20notebook%3A**%0A%0A%20%20%20%20-%20Monarch%20makes%20distributed%20RL%20feel%20like%20local%20Python%20--%20actors%2C%20endpoints%2C%0A%20%20%20%20%20%20and%20slicing%20compose%20naturally%20into%20a%20full%20training%20system%0A%20%20%20%20-%20Async%20RL%20collects%20more%20data%20per%20unit%20wall%20time%20by%20running%20generators%0A%20%20%20%20%20%20and%20trainer%20concurrently%0A%20%20%20%20-%20The%20circular%20buffer%20%2B%20CPU%20staging%20pattern%20from%20NB06%20decouples%20training%0A%20%20%20%20%20%20from%20weight%20distribution%0A%20%20%20%20-%20Before%2Fafter%20evaluation%20closes%20the%20loop%3A%20we%20can%20measure%20whether%20training%0A%20%20%20%20%20%20actually%20improves%20the%20model%0A%0A%20%20%20%20**Where%20to%20go%20next%3A**%20Forge%20GRPO%20implements%20these%20same%20patterns%20at%20production%0A%20%20%20%20scale%20--%20multiple%20nodes%2C%20larger%20models%2C%20PPO%2FGRPO%20instead%20of%20REINFORCE%2C%20and%0A%20%20%20%20proper%20reward%20modeling.%20The%20Monarch%20primitives%20you've%20learned%20here%20are%20the%0A%20%20%20%20building%20blocks%20for%20all%20of%20it.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">174d1a83503d71f24bcec8d35f3630fd</marimo-code-hash>
</body>
</html>
