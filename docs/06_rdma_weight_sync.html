<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>06_rdma_weight_sync.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>06 rdma weight sync</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-DGasP9Lh.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/preload-helper-DItdS47A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-BGmjiNul.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/compiler-runtime-DeeZ7FnK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/badge-Ce8wRjuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEventListener-DIUKKfEy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/button-YC1gW_kJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-dom-C9fstfnp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Combination-CMPwuAmi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/menu-items-CJhvWPOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-uzvC4uAK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createLucideIcon-CnW3RofX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/check-DdfN0k2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/select-V5IdpNiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-CEc2ajau.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/use-toast-rmUWldD_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEvent-DO6uJBas.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/zod-Cg4WLWh2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utils-DXvhzCGS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Deferred-CrO5-0RA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/config-CIrPQIbt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/uuid-DercMavo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/DeferredRequestRegistry-CO2AyNfd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/requests-BsVD4CdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useLifecycle-D35CBukS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNonce-_Aax6sXd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useTheme-DUdVAZI8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createReducer-Dnna-AUO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BIKFl48f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-B0VqT_4z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-TiFCI16_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Cayq-K1c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BYyu59D8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/stex-CtmkcLz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toDate-CgbKQM5E.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/database-zap-B9y7063w.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-BpZ7g6ok.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spinner-DaIKav-i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chevron-right-DwagBitu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dropdown-menu-B-6unW-7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/kbd-C3JY7O_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/renderShortcut-DEwfrKeS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/multi-map-C8GlnP-4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-BrGyZf9c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-dialog-DwQffb13.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dialog-CxGKN4C_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CdxIjAOP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/label-Be1daUcS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDebounce-D5NcotGm.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/textarea-DBO30D7K.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/numbers-iQunIAXf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/SSRProvider-CEHRCdjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/context-JwD-oSsl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNumberFormatter-c6GXymzg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/usePress-Bup4EGrp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/input-pAun1m1X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/links-DHZUhGz-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/popover-Gz-GJzym.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/switch-8sn_4qbh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-C8uQmBAN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/mode-DX8pdI-l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAsyncData-C4XRy1BE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/errors-2SszdW9t.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/error-banner-DUzsIXtq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-Bv2DBpIS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-CQ15EONK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/plus-BD5o34_i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-cw-CQd-1kjx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/trash-2-CyqGun26.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/triangle-alert-B65rDESJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ai-model-dropdown-71lgLrLy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-D_rSvXvJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/precisionRound-BMPhtTJQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-C92Rrpmf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/vega-loader.browser-CRZ52CKf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-BGrCWNss.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ErrorBoundary-ChCiwl15.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useInstallPackage-Bdnnp5fe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ImperativeModal-CUbWEBci.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cell-link-Bw5bzt4a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/datasource-B0OJBphG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/state-BfXVTTtD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/MarimoErrorOutput-5rudBbo3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-icon-BhONVREY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/html-to-image-DjukyIj4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/focus-D51fcwZX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/LazyAnyLanguageCodeMirror-yzHjsVJt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-5FQGJX7Z-CVUXBqX6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/katex-Dc8yG8NU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DhMlG2dP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/command-DhzFN2CJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-BhCZMKuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useRunCells-24p6hn99.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/purify.es-DNVQZNFu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/RenderHTML-CQZqVk1Z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useIframeCapabilities-DuIDx9mD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/formats-W1SWxSE3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/en-US-pRRbZZHE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isValid-DcYggVWP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dates-Dhn1r-h6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/maps-t9yNKYA8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/extends-B2LJnKU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/emotion-is-prop-valid.esm-DD4AwVTU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDateFormatter-CS4kbWl2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-DZR6ewbN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-CknFTI_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-Cs1JbsV6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/play-BPIh-ZEU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-components-CGlO4yUw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-display-B4mGvJ0X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeleteCell-5uYlTcQZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/icons-BhEXrzsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/process-output-CagdHMzs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/blob-CuXvdYPX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/objectWithoutPropertiesLoose-DaPAPabU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/esm-DpMp6qko.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/add-cell-with-ai-pVFp5LZG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chart-no-axes-column-W42b2ZIs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-function-CqXXKtIq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spec-D1kBp3jX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/column-preview-CxMrs0B_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toggle-jWKnIArU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/globals-DKH14XH0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/share-CbPtIlnM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-resizable-panels.browser.esm-Ctj_10o2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utilities.esm-CIPARd6-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/floating-outline-DcxjrFFt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAddCell-BmeZUK02.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/eye-off-BhExYOph.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/readonly-python-code-DyP9LVLc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-video-camera-DW3v07j2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-DuQOSW7G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-ccw-DLEiQDS3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/form-DUA_Rz_a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/field-BEg1eC0P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useBoolean-B1Xeh6vA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeepCompareMemoize-ZPd9PxYl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-CS34eOZi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/prop-types-BiQYf0aU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/es-D8BOePqo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/code-xml-XLwHyDBr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-B9SUL40m.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/house-DhFkiXz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/settings-DOXWMfVd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-C8Tw_XXG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/bundle.esm-2AjO7UK5.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-CikhHYAB.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "06_rdma_weight_sync.py",
            "mode": "read",
            "version": "0.19.7",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "# Shared imports for the notebook\nimport time\nimport torch\nfrom monarch.actor import Actor, endpoint, this_host, current_rank\nfrom monarch.rdma import RDMABuffer, is_rdma_available", "code_hash": "8e01abc14814a6848ee5704e220ac262", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n# RDMA \u0026 Weight Synchronization\n\nThis notebook explores efficient weight synchronization for async RL systems.\n\n**Outline:**\n\n1. **Why Weight Sync Matters** - On-policy vs off-policy, model scale\n2. **The Bandwidth Hierarchy** - NVLink, InfiniBand, PCIe\n3. **The Problem: Collectives Are Blocking** - Why RL needs something different\n4. **The Magic Pointer Pattern** - Control plane vs data plane separation\n5. **CPU Staging** - Decoupling trainer and generator timing\n6. **Circular Weight Buffers** - Versioning without memory churn\n7. **Weight Re-sharding** - Handling different tensor layouts\n8. **Putting It All Together** - Live demo with concurrent loops\n\n**Want to go deeper?** Check out **06b_weight_sync_deep_dive.py** for ibverbs internals,\nmemory registration benchmarks, and full implementations. This notebook focuses on\nthe concepts and patterns you need to know for async RL.\n\"\"\")", "code_hash": "cfa8b7221506f6f53e461b2b4219ee21", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 1. Why Weight Sync Matters\n\n### The On-Policy Problem\n\nTraditional RL algorithms want to be **on-policy**: generate experience using the current\npolicy, then immediately use that experience to update the policy. This creates a tight loop:\n\n```\nOn-Policy RL:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  generate(policy_v1) \u2192 train(samples) \u2192 policy_v2 \u2192 repeat       \u2502\n\u2502                                                                  \u2502\n\u2502  Experience from v1 is only valid for updating v1                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Async RL breaks this rule.** Generators run continuously while the trainer updates weights.\nBy the time a sample reaches the trainer, it was generated by an old policy version:\n\n```\nAsync RL (off-policy):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator: policy_v1 \u2192 sample\u2081                                  \u2502\n\u2502  Trainer:   train(sample\u2081) \u2192 policy_v2                           \u2502\n\u2502  Generator: policy_v1 \u2192 sample\u2082  \u2190 still using v1!               \u2502\n\u2502  Trainer:   train(sample\u2082) \u2192 policy_v3                           \u2502\n\u2502                                                                  \u2502\n\u2502  Samples are \"stale\" - generated by older policy versions        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis **off-policy-ness** can work up to a degree, but must be limited. The generators\nneed fresh weights regularly to stay \"close enough\" to on-policy. Weight sync frequency\nbecomes a key hyperparameter trading off:\n\n- **Too slow**: Samples become too stale, training diverges\n- **Too fast**: Weight sync overhead dominates, negating async benefits\n\n### The Scale Problem\n\nFor LLM-based RL, the weights are **massive**. Back-of-envelope math\n(1 parameter \u2248 2 bytes in bf16):\n\n| Model | Weight Size |\n|-------|-------------|\n| Llama 3.1 70B | ~140 GB |\n| Llama 3.1 405B | ~810 GB |\n| DeepSeek V3 671B | ~1.3 TB |\n\nThese weights need to move from trainer \u2192 generators regularly. If we're\nnot careful, our \"async RL training workload\" just becomes a weight syncing\nworkload. Let's look at the bandwidth hierarchy to understand why this is\ntricky and what we can do about it.\n\"\"\")", "code_hash": "1129f2591acb6dea584177d1666eb658", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 2. The Bandwidth Hierarchy\n\nModern HPC clusters have multiple interconnects with vastly different bandwidths:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                              NODE A                                                      \u2502\n\u2502                                                                                                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                         ======  64 GB/s PCIe                                             \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  ------ 48 GB/s ------ \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518      PCIe        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n                                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                        \u2502                                                    \u2502\n                                                        \u2502              InfiniBand Switch                     \u2502\n                                                        \u2502                                                    \u2502\n                                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510      PCIe        \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 ------ 48 GB/s ------  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                           ======  64 GB/s PCIe                                           \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              NODE B                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nBandwidth encoding (line intensity):\n  ########  NVLink/NVSwitch   900 GB/s bidirectional (GPU \u2194 GPU, same node)\n  ========  PCIe Gen5 / RDMA  50-64 GB/s unidirectional (CPU\u2194GPU, CPU\u2194NIC, cross-node)\n  --------  CPU interconnect  48 GB/s (CPU \u2194 CPU, same node)\n```\n\n### A Note on Bandwidth Numbers\n\nBandwidth specs vary by hardware generation, cluster configuration, and vendor.\nWe'll use numbers from Meta's published Llama 3 training infrastructure\n([Building Meta's GenAI Infrastructure](https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/)):\n\n\u003E \"Both of these solutions interconnect **400 Gbps endpoints**... we have successfully\n\u003E used both RoCE and InfiniBand clusters for large, GenAI workloads (including our\n\u003E ongoing training of Llama 3 on our RoCE cluster) without any network bottlenecks.\"\n\n**Important**: \"400 Gbps\" in networking is **full-duplex** - meaning 400 Gbps transmit\nAND 400 Gbps receive simultaneously. For weight sync (unidirectional: trainer \u2192 generator),\nwe get the full 400 Gbps = **50 GB/s per NIC**.\n\nMeta's Grand Teton nodes have **8 RDMA NICs** (one per GPU, 1:1 mapping), giving\n400 GB/s aggregate unidirectional bandwidth per node. For more details on Grand Teton\nand Monarch's RDMA architecture, see the SIGCOMM 2024 paper:\n[RDMA over Ethernet for Distributed AI Training at Meta Scale](https://cs.stanford.edu/~keithw/sigcomm2024/sigcomm24-final246-acmpaginated.pdf).\n\n| Interconnect | Bandwidth | Notes |\n|--------------|-----------|-------|\n| **NVLink 4.0** | 900 GB/s bidirectional | ~450 GB/s per direction |\n| **RDMA (IB/RoCE)** | 400 Gbps = 50 GB/s | Per NIC, full-duplex |\n| **PCIe Gen5 x16** | 64 GB/s | Per direction |\n\n**Key observations:**\n\n1. **NVLink is fast but same-node only** - 450 GB/s, but can't cross the network\n2. **RDMA \u003E\u003E TCP** - 50 GB/s with zero-copy beats TCP significantly for cross-node\n3. **Multi-NIC scales** - 8 NICs \u00d7 50 GB/s = 400 GB/s, approaching NVLink speeds\n\n**Rule of thumb**: NVLink for same-node ops (gradients, activations).\nRDMA for cross-node communication (weight sync) - it's the only practical option.\n\n### Back-of-Envelope: Syncing Large Models\n\nLet's do some quick math. DeepSeek V3 has 671B parameters (~1.34 TB in bf16).\n\nThe key insight: **you're not shoving 1.3 TB through a single NIC**. The weights\nare distributed across many GPUs (via some combination of PP, EP, TP, FSDP),\nand each GPU has its own NIC. You get **aggregate bandwidth** across all NICs.\n\nThe actual sync time depends on **both sides**:\n- **Trainer's aggregate upload bandwidth** (sending weights out)\n- **Generator's aggregate download bandwidth** (receiving weights)\n\nThe bottleneck is whichever is smaller. And if multiple generators pull from\nthe same trainer simultaneously, the trainer's bandwidth is divided among them.\n\nWith Grand Teton's 8 NICs per node at 50 GB/s each (400 GB/s per node),\nthe math is simple: **Time = Shard Size / Bandwidth**.\n\nThe per-node shard size depends on how many nodes the model is spread across:\n- DeepSeek V3 (1.3 TB) across 8 nodes \u2192 ~160 GB per node\n- DeepSeek V3 (1.3 TB) across 16 nodes \u2192 ~80 GB per node\n\n| Per-node shard | Time to sync |\n|----------------|--------------|\n| ~160 GB (8 nodes) | 160 / 400 = **0.4 seconds** |\n| ~80 GB (16 nodes) | 80 / 400 = **0.2 seconds** |\n\nThe exact per-node shard size depends on your parallelism strategy (PP, EP, TP, etc.),\nbut the math works out: with modern RDMA hardware, you can sync even the largest\nmodels in **sub-second time**.\n\nCompare this to naive TCP: kernel copies, socket overhead, no zero-copy...\neasily 10x slower. **RDMA is the only way to make async RL practical at scale.**\n\"\"\")", "code_hash": "7a3b476e828f0fd0b4d4a1e42975ecd7", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 3. The Problem: Collectives Are Blocking\n\nMost people use RDMA via **collectives** through PyTorch distributed:\n\n```python\nimport torch.distributed as dist\n\ndist.init_process_group(backend=\"nccl\")\ndist.all_reduce(gradients, op=dist.ReduceOp.SUM)\ndist.broadcast(weights, src=0)\n```\n\nThis works great for training. But async RL has a different access pattern.\n\n### High Variance in Generation Times\n\nGenerators have wildly different completion times:\n- Some prompts \u2192 10 tokens (fast)\n- Other prompts \u2192 1000 tokens (slow)\n\nWith collectives, fast generators wait for slow ones:\n\n```\nGenerator 0: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\nGenerator 1: \u251c\u2500\u2500\u2500\u2500\u2500\u2500 gen (slow) \u2500\u2500\u2500\u2500\u2500\u2500\u2524\nGenerator 2: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\n                                      \u2193\n                          all_gather(weights)  # Everyone waits!\n```\n\n### The One-Sided Solution: RDMA\n\nWhat if the sender could write directly to the receiver's memory without coordination?\n\n```\nTwo-sided (send/recv):\n  Sender: \"I have data\"  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  Receiver: \"I'm ready\"\n  Sender: sends data     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  Receiver: receives data\n                         2 messages required\n\nOne-sided (RDMA):\n  Sender: writes directly to receiver's memory\n                         No coordination needed!\n```\n\nThis is what RDMA enables: **one-sided memory operations**.\nThe trainer doesn't even know when generators pull weights - this is truly async!\n\"\"\")", "code_hash": "dd98f583d07acf067de617193493bad2", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 4. The Magic Pointer Pattern\n\nOne natural question that arises is along the lines of, \"How do we actually represent one-sided puts/gets if not with NCCL collectives?\"\n\nHere's a key insight: to represent remote data, we only need a **tiny handle** -\nan `(addr, rkey, size)` tuple that says \"here's where my data lives.\"\n\nMonarch wraps this in `RDMABuffer`. Let's see how small it actually is:\n\"\"\")", "code_hash": "cb76c2f11c389956cc5404a2489a841e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "# Measure actual size of RDMABuffer handles\nimport pickle\n\ndef show_fallback_sizes():\n    \"\"\"Fallback: show expected sizes based on RDMABuffer structure.\"\"\"\n    print(\"(RDMA not available - showing expected handle sizes)\\n\")\n    print(\"RDMABuffer contains: addr (8B) + rkey (4B) + size (8B) + owner (~100B)\")\n    print(\"Total serialized size: ~150-200 bytes regardless of tensor size\\n\")\n\n    sizes = [(\"1 KB\", 1024), (\"1 MB\", 1024**2), (\"1 GB\", 1024**3)]\n    handle_bytes = 150  # approximate\n\n    for name, tensor_bytes in sizes:\n        ratio = tensor_bytes / handle_bytes\n        print(f\"{name:\u003C8} tensor \u2192 ~150 byte handle \u2192 {ratio:,.0f}x compression\")\n\n    print(\"\\n\u2192 Handle size is O(1) regardless of tensor size!\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback_sizes()\n    else:\n        class BufferSizeDemo(Actor):\n            \"\"\"Actor that creates RDMABuffers and measures their size.\"\"\"\n\n            @endpoint\n            def measure_buffer_sizes(self) -\u003E list:\n                import pickle as _pickle\n                results = []\n                sizes = [\n                    (\"1 KB\", 256),\n                    (\"1 MB\", 256 * 1024),\n                    (\"10 MB\", 256 * 1024 * 10),\n                ]\n\n                for name, numel in sizes:\n                    tensor = torch.randn(numel)\n                    tensor_bytes = tensor.numel() * tensor.element_size()\n\n                    byte_tensor = tensor.view(torch.uint8).flatten()\n                    buffer = RDMABuffer(byte_tensor)\n                    handle_bytes = len(_pickle.dumps(buffer))\n\n                    results.append((name, tensor_bytes, handle_bytes))\n\n                return results\n\n        proc = this_host().spawn_procs(per_host={\"procs\": 1})\n        demo = proc.spawn(\"buffer_demo\", BufferSizeDemo)\n\n        results = demo.measure_buffer_sizes.call_one().get()\n\n        print(\"RDMABuffer handle size vs actual tensor size:\\n\")\n        print(f\"{'Tensor Size':\u003C12} {'Actual Bytes':\u003C15} {'Handle Size':\u003C15} {'Ratio':\u003C10}\")\n        print(\"-\" * 55)\n\n        for name, tensor_bytes, handle_bytes in results:\n            ratio = tensor_bytes / handle_bytes\n            print(f\"{name:\u003C12} {tensor_bytes:\u003E12,} B   {handle_bytes:\u003E6} B        {ratio:\u003E8,.0f}x\")\n\n        print(\"\\n\u2192 Handle size is O(1) regardless of tensor size!\")\n\nexcept Exception as e:\n    print(f\"(RDMA setup failed: {e})\\n\")\n    show_fallback_sizes()", "code_hash": "3d6ad99e96a0aafd076b1cd1ded4f8b9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n### The Magic Pointer\n\nThis is the core pattern: **separate control plane from data plane**.\n\n- **Control plane** (actor messages): Send tiny handle (~100 bytes)\n- **Data plane** (RDMA): Bulk transfer of actual data (~10 GB)\n\nThink of `RDMABuffer` as a **magic pointer** - it's a pointer that works across machines:\n\n```\nTrainer                              Generator\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 weights     \u2502                     \u2502 local copy  \u2502\n\u2502 (10 GB)     \u2502                     \u2502 (empty)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                   \u2502\n       \u2502  1. Create RDMABuffer             \u2502\n       \u2502     (register memory, get handle) \u2502\n       \u2502                                   \u2502\n       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 2. Send handle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502  (~100 bytes via actor)\n       \u2502                                   \u2502\n       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500 3. RDMA read \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  (~10 GB via hardware)\n       \u2502        (no trainer involvement!)  \u2502\n```\n\nThe trainer doesn't even know when generators pull weights. True one-sided.\n\n### RDMABuffer in Action\n\n```python\nfrom monarch.rdma import RDMABuffer\n\n# Trainer side: register weights\nweights = torch.randn(1024, 1024, device=\"cuda\")\nbuffer = RDMABuffer(weights.view(torch.uint8).flatten())\n\n# Return buffer as part of an endpoint response\n@endpoint\ndef get_weight_handle(self) -\u003E RDMABuffer:\n    return self.buffer\n\n# Generator side: receive handle, pull directly into GPU\nhandle = trainer.get_weight_handle.call_one().get()  # Tiny message\ngpu_weights = model.weights.view(torch.uint8).flatten()\nhandle.read_into(gpu_weights).get()                   # Bulk RDMA \u2192 GPU\n```\n\n**Want to understand how RDMA works under the hood?** Check out **06b_weight_sync_deep_dive.py**\nfor ibverbs internals, queue pair setup, and why Monarch's actor model is such a natural fit\nfor managing RDMA connections. It's actors all the way down!\n\"\"\")", "code_hash": "3cd3093261f72b274838b78e1c26c649", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Live Demo: Trainer \u2192 Generator Weight Sync\n\nLet's see this in action with a simple example. A trainer holds weights,\na generator pulls them via RDMA.\n\"\"\")", "code_hash": "9b369b191c83a1c907ac9fc47f3166bc", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "# Simple trainer \u2192 generator weight sync demo\n\ndef show_fallback_demo():\n    \"\"\"Show what would happen with RDMA.\"\"\"\n    print(\"(RDMA not available - showing conceptual flow)\\n\")\n    print(\"1. Trainer creates weights (e.g., 4 MB tensor)\")\n    print(\"2. Trainer wraps weights in RDMABuffer \u2192 tiny handle (~150 bytes)\")\n    print(\"3. Trainer sends handle to Generator via actor message\")\n    print(\"4. Generator calls handle.read_into(local_buffer)\")\n    print(\"5. RDMA hardware transfers 4 MB directly, trainer not involved!\")\n    print(\"\\n\u2192 Zero-copy, one-sided, no serialization overhead\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback_demo()\n    else:\n        class Sender(Actor):\n            \"\"\"Sender that holds data and exposes an RDMA handle.\"\"\"\n\n            def __init__(self, size: int):\n                # Create some data to send\n                self.data = torch.randn(size, dtype=torch.float32)\n                # Register with RDMA\n                self.data_bytes = self.data.view(torch.uint8).flatten()\n                self.buffer = RDMABuffer(self.data_bytes)\n                print(f\"[Sender] Created data: {self.data.numel() * 4 / 1e6:.1f} MB\")\n\n            @endpoint\n            def get_handle(self) -\u003E RDMABuffer:\n                \"\"\"Return tiny handle (not the data itself!)\"\"\"\n                return self.buffer\n\n            @endpoint\n            def get_checksum(self) -\u003E float:\n                \"\"\"For verification: sum of data\"\"\"\n                return float(self.data.sum())\n\n        class Receiver(Actor):\n            \"\"\"Receiver that pulls data from sender via RDMA.\"\"\"\n\n            def __init__(self, size: int):\n                # Pre-allocate space for data\n                self.data = torch.zeros(size, dtype=torch.float32)\n                self.data_bytes = self.data.view(torch.uint8).flatten()\n                print(f\"[Receiver] Allocated buffer: {self.data.numel() * 4 / 1e6:.1f} MB\")\n\n            @endpoint\n            def pull_data(self, handle: RDMABuffer) -\u003E float:\n                \"\"\"Pull data via RDMA read, return checksum for verification.\"\"\"\n                # This is the magic: RDMA read directly into our buffer\n                handle.read_into(self.data_bytes).get()\n                return float(self.data.sum())\n\n        # Spawn sender and receiver\n        procs = this_host().spawn_procs(per_host={\"procs\": 2})\n\n        sender = procs.slice(procs=0).spawn(\"sender\", Sender, 1024 * 1024)  # 4 MB\n        receiver = procs.slice(procs=1).spawn(\"receiver\", Receiver, 1024 * 1024)\n\n        # Step 1: Get handle from sender (tiny message!)\n        handle = sender.get_handle.call_one().get()\n        print(f\"\\n[Orchestrator] Got handle from sender\")\n\n        # Step 2: Send handle to receiver, have it pull data\n        receiver_checksum = receiver.pull_data.call_one(handle).get()\n        sender_checksum = sender.get_checksum.call_one().get()\n\n        print(f\"[Orchestrator] Sender checksum: {sender_checksum:.2f}\")\n        print(f\"[Orchestrator] Receiver checksum: {receiver_checksum:.2f}\")\n        print(f\"[Orchestrator] Match: {abs(sender_checksum - receiver_checksum) \u003C 0.01}\")\n\nexcept Exception as e:\n    print(f\"(Demo failed: {e})\\n\")\n    show_fallback_demo()", "code_hash": "9c7090020db0a6d3770e0f81a71d9cb5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 5. CPU Staging Pattern\n\n### GPU-Native RDMA Works!\n\nFirst, let's be clear: **GPU-native RDMA works** and is fast:\n- GPUDirect RDMA: NIC reads directly from GPU memory\n- No CPU copy needed (when hardware supports it)\n- Great for synchronous transfers\n\n### Why CPU Staging for Async RL?\n\nThe issue isn't bandwidth - it's **timing**:\n\n```\nDirect GPU\u2192GPU RDMA:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Generator GPU is mid-inference                       \u2502\n\u2502 \u251c\u2500\u2500 layer 1 \u2500\u2500\u2524 [RDMA arrives, needs sync!]         \u2502\n\u2502               \u2193                                      \u2502\n\u2502         cudaDeviceSynchronize()  \u2190 Blocks inference! \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nWith CPU staging, nothing on the critical path blocks:\n\n```\nTrainer GPU \u2500\u2500\u25ba CPU staging buffer (RDMA registered)\n                      \u2502\n                      \u2502 [Sits here, ready anytime]\n                      \u2502\n                      \u25bc\nGenerator grabs when ready \u2500\u2500\u25ba Generator GPU\n```\n\nThe CPU buffer is a **temporal decoupling point**.\n\"\"\")", "code_hash": "a8e57a271297ac88d2492cc4df33416e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 6. Circular Weight Buffers\n\n### The Versioning Problem\n\nIn async RL, trainer updates weights continuously. Generators need to:\n1. **Grab the latest** weights (not stale ones)\n2. **Not block** waiting for updates\n3. **Avoid memory churn** (re-registering RDMA buffers is expensive)\n\n### Solution: Circular Buffer\n\n```\nTrainer writes:     v0    \u2192  v1  \u2192  v2  \u2192  v3  \u2192  v4  \u2192  v5  \u2192 ...\n                     \u2193        \u2193      \u2193\nBuffer slots:      [slot0] [slot1] [slot2]  (circular, reused)\n                     v3      v4      v5\n\nGenerator reads: \"Give me latest\" \u2192 v5\n```\n\nBenefits:\n- **Pre-registered RDMA buffers** - no memory registration on hot path\n- **Lock-free reads** - generators always get a consistent snapshot\n- **Bounded memory** - only N versions in flight\n\nThe key insight: register all slots at init time, then just write to them.\nNo allocation, no registration on the critical path.\n\n**Want to see a full implementation?** Check out **06b_weight_sync_deep_dive.py** for a\ncomplete `CircularWeightBuffer` class with versioning and RDMA integration.\n\"\"\")", "code_hash": "54a047ff55d24352a29de7b29354120f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 7. Weight Re-sharding\n\n### The Sharding Mismatch Problem\n\nTrainer and Generator often have **different tensor layouts**. Consider an example:\n\n| Role | Parallelism | Sharding |\n|------|-------------|----------|\n| Trainer | FSDP (8 GPUs) | `Shard(0)` - rows split across 8 GPUs |\n| Generator | TP (2 GPUs) | `Shard(1)` - columns split across 2 GPUs |\n\nTherefore we cannot always directly transfer weights - we need **re-sharding**.\n\nConsider a simple example where the trainer may be row-sharded and the generator may be column-sharded:\n\n```\nTrainer (row-sharded):          Generator (column-sharded):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GPU 0: rows 0-127\u2502            \u2502 GPU 0   \u2502 GPU 1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u2192      \u2502 cols    \u2502 cols    \u2502\n\u2502 GPU 1: rows 128+ \u2502            \u2502 0-511   \u2502 512+    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### Two Approaches\n\n**Gather Then Slice** (simple but wasteful):\nOne approach is to materialize the entire tensor, i.e. `gather`, transfer the full tensor, and then slice on the receiver side:\n1. Each receiver gathers ALL sender shards \u2192 full tensor\n2. Each receiver slices out its portion\n3. **Problem**: 2x redundant data transfer\n\n**Routed Transfer** (optimal):\nA more efficient approach is to only transfer the data that needs to be transferred:\n1. Pre-compute which sender chunks overlap with which receiver regions\n2. Send only the exact chunks needed\n3. **Benefit**: Minimal bandwidth, no redundancy\n\n```\nGATHER: G0 receives T0,T1,T2,T3 \u2192 discards T2,T3 (50% waste!)\nROUTED: G0 receives T0,T1 only \u2192 exactly what it needs\n```\n\nThe routed approach batches all needed transfers into one plan.\nPre-compute the plan once at handshake, execute it on each sync.\n\n**Want to see the overlap computation and benchmarks?** Check out **06b_weight_sync_deep_dive.py**\nfor the full DTensor re-sharding implementation with placement-aware routing.\n\"\"\")", "code_hash": "76823a65fe3bf897c64a5af8de3362fb", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 8. Putting It All Together\n\nThe full async RL weight sync pattern:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TRAINER                                  \u2502\n\u2502  1. Train step completes                                        \u2502\n\u2502  2. Copy weights to CPU staging buffer (non-blocking D2H)       \u2502\n\u2502  3. Publish to circular buffer with version tag                 \u2502\n\u2502  4. Continue training (no blocking!)                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              CIRCULAR BUFFER (CPU, RDMA-registered)             \u2502\n\u2502  [slot 0: v3] [slot 1: v4] [slot 2: v5]                        \u2502\n\u2502                                 \u2191 latest                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                     \u25bc                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   GENERATOR 0   \u2502   \u2502   GENERATOR 1   \u2502   \u2502   GENERATOR 2   \u2502\n\u2502                 \u2502   \u2502                 \u2502   \u2502                 \u2502\n\u2502 After gen done: \u2502   \u2502 After gen done: \u2502   \u2502 After gen done: \u2502\n\u2502 1. Get latest   \u2502   \u2502 1. Get latest   \u2502   \u2502 1. Get latest   \u2502\n\u2502    version      \u2502   \u2502    version      \u2502   \u2502    version      \u2502\n\u2502 2. RDMA read    \u2502   \u2502 2. RDMA read    \u2502   \u2502 2. RDMA read    \u2502\n\u2502    \u2192 GPU        \u2502   \u2502    \u2192 GPU        \u2502   \u2502    \u2192 GPU        \u2502\n\u2502 3. Re-shard if  \u2502   \u2502 3. Re-shard if  \u2502   \u2502 3. Re-shard if  \u2502\n\u2502    needed       \u2502   \u2502    needed       \u2502   \u2502    needed       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Key properties:**\n- Trainer never blocks waiting for generators\n- Generators pull directly to GPU when *they're* ready\n- Re-sharding happens locally on each generator\n- Circular buffer bounds memory, reuses RDMA registrations\n\"\"\")", "code_hash": "806222a0a76efaa0bba91baefc514224", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Live Demo: Async Weight Sync\n\nLet's see this in action! We'll simulate the core async RL pattern:\n\n- **1 Trainer**: Runs training steps, publishes new weights to a 3-slot circular buffer\n- **4 Generators**: Each independently syncs to latest weights, then generates\n\nAll 5 actors run **concurrently and independently**. The trainer never waits for generators,\nand each generator grabs weights whenever it's ready (at slightly different rates to show\nthe async behavior). To verify correctness, we set weights to `version` and check on read.\n\"\"\")", "code_hash": "2a2c4d6cd41bd5c6ea375b2fcbd9c264", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "import threading\n\ndef show_fallback():\n    print(\"(RDMA not available - showing conceptual flow)\\n\")\n    print(\"What would happen with RDMA:\")\n    print(\"  [Trainer] Publishes v0, v1, v2... to circular buffer\")\n    print(\"  [Generator] Syncs when ready, verifies weights match version\")\n    print(\"  Both run independently, no blocking!\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback()\n    else:\n        class Trainer(Actor):\n            \"\"\"Trainer with circular buffer for weight versioning.\"\"\"\n\n            def __init__(self, weight_size: int):\n                self.n_slots = 5\n                self.version = 0\n                self.slots = []\n                self.handles = []\n                for _ in range(self.n_slots):\n                    slot = torch.zeros(weight_size, dtype=torch.float32)\n                    self.slots.append(slot)\n                    self.handles.append(RDMABuffer(slot.view(torch.uint8).flatten()))\n                print(f\"[Trainer] Initialized {self.n_slots}-slot circular buffer\")\n\n            @endpoint\n            def get_latest(self) -\u003E tuple:\n                if self.version == 0:\n                    return None, -1\n                v = self.version - 1\n                return self.handles[v % self.n_slots], v\n\n            @endpoint\n            def train_step(self):\n                \"\"\"Single training step: publish new weights.\"\"\"\n                import sys\n                slot_idx = self.version % self.n_slots\n                self.slots[slot_idx].fill_(float(self.version))\n                self.version += 1\n                print(f\"[Trainer] Published v{self.version - 1}\")\n                sys.stdout.flush()\n                return self.version\n\n        class Generator(Actor):\n            \"\"\"Generator that syncs weights and generates.\"\"\"\n\n            def __init__(self, weight_size: int, trainer):\n                self.gen_id = current_rank().rank\n                self.trainer = trainer\n                self.weights = torch.zeros(weight_size, dtype=torch.float32)\n                self.weight_bytes = self.weights.view(torch.uint8).flatten()\n                self.current_version = -1\n                print(f\"[Gen {self.gen_id}] Initialized\")\n\n            @endpoint\n            def generate_step(self) -\u003E int:\n                \"\"\"Single generate step: sync if needed, then generate.\"\"\"\n                import sys\n                # Try to sync weights\n                handle, version = self.trainer.get_latest.call_one().get()\n                if handle is not None and version \u003E self.current_version:\n                    handle.read_into(self.weight_bytes).get()\n                    actual = int(self.weights[0].item())\n                    if actual \u003E= version:\n                        self.current_version = actual\n                        print(f\"[Gen {self.gen_id}] Synced to v{actual}\")\n                        sys.stdout.flush()\n                return self.current_version\n\n        # Spawn trainer and generators\n        n_generators = 4\n        trainer_proc = this_host().spawn_procs(per_host={\"procs\": 1})\n        generator_procs = this_host().spawn_procs(per_host={\"procs\": n_generators})\n\n        trainer = trainer_proc.spawn(\"trainer\", Trainer, weight_size=1024)\n        generators = generator_procs.spawn(\"generators\", Generator, weight_size=1024, trainer=trainer)\n\n        print(\"\\n--- Running async RL simulation ---\\n\")\n\n        # Results storage\n        _results = {\"trainer\": None, \"generators\": [None] * n_generators}\n\n        def run_trainer(n_steps, step_time):\n            import time\n            for _ in range(n_steps):\n                time.sleep(step_time)\n                _results[\"trainer\"] = trainer.train_step.call_one().get()\n\n        def run_generator(gen_actor, gen_idx, n_iters, gen_time):\n            import time\n            for _ in range(n_iters):\n                version = gen_actor.generate_step.call_one().get()\n                if version \u003E= 0:\n                    time.sleep(gen_time)\n                    print(f\"[Gen {gen_idx}] Generated (v{version})\")\n                else:\n                    time.sleep(0.05)\n            _results[\"generators\"][gen_idx] = version\n\n        # Create threads for trainer and each generator\n        threads = []\n\n        # Trainer thread\n        t = threading.Thread(target=run_trainer, args=(6, 1.0))  # 1 second per step\n        threads.append(t)\n\n        # Generator threads\n        for i in range(n_generators):\n            gen_actor = generators.slice(procs=i)\n            t = threading.Thread(target=run_generator, args=(gen_actor, i, 5, 0.25))\n            threads.append(t)\n\n        # Start all threads\n        for t in threads:\n            t.start()\n\n        # Wait for all to complete\n        for t in threads:\n            t.join()\n\n        print(f\"\\n--- Done! Trainer published {_results['trainer']} versions ---\")\n        print(f\"Generators ended on versions: {_results['generators']}\")\n        print(\"All pulled independently via RDMA, weights verified!\")\n\nexcept Exception as e:\n    import traceback\n    traceback.print_exc()\n    print(f\"(Demo failed: {e})\")\n    show_fallback()", "code_hash": "fc623739ac02a608e965716d9ee6d522", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 9. Going Further: TorchStore\n\nAll the patterns we've covered - RDMA memory registration, magic pointers, circular buffers,\npre-computed transfer plans - are building blocks. If you need a **production-ready solution**,\ncheck out [TorchStore](https://github.com/meta-pytorch/torchstore).\n\n### What is TorchStore?\n\nTorchStore is a **distributed, asynchronous key-value store for PyTorch tensors** built on\nMonarch's actor framework. It abstracts away the RDMA complexity while giving you:\n\n```python\nfrom torchstore import TorchStore\n\n# Store tensors with async API\nawait ts.put(\"model/layer1/weights\", tensor)\n\n# Retrieve with optional in-place and slice semantics\nawait ts.get(\"model/layer1/weights\", inplace_tensor=buffer)\n\n# Native PyTorch checkpoint support\nawait ts.put_state_dict(model.state_dict())\nloaded = await ts.get_state_dict()\n```\n\n### When to Use What\n\n| Scenario | Solution |\n|----------|----------|\n| Learning RDMA patterns | This notebook + 06b |\n| Custom RL weight sync | See 06b for `RDMABuffer` + `RDMAAction` patterns |\n| General tensor storage | Use TorchStore |\n| Checkpointing | Use TorchStore's `put_state_dict` |\n\"\"\")", "code_hash": "073a87de27a68088af5e59280149bddb", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Summary\n\n### Key Takeaways\n\n1. **Bandwidth hierarchy matters**: NVLink (900 GB/s) \u003E\u003E InfiniBand (50 GB/s)\n   - Keep frequent operations on NVLink, use RDMA for cross-node\n\n2. **Collectives block, RL needs async**: High variance in generation times makes\n   synchronous operations expensive\n\n3. **Magic pointer pattern**: Tiny handle over control plane, bulk data over data plane\n   - ~100 bytes to describe 10 GB transfer\n\n4. **CPU staging**: Temporal decoupling for async RL\n   - Nothing blocks on the critical path\n\n5. **Circular buffers**: Version weights without memory churn\n   - Pre-register RDMA buffers, reuse slots\n\n6. **Weight re-sharding**: Different layouts need overlap computation\n   - Routed approach avoids redundant transfers\n\n### Want More?\n\n- **06b_weight_sync_deep_dive.py** - ibverbs internals, benchmarks, full implementations\n- **07_async_rl_e2e.py** - Complete async RL system using these patterns\n\"\"\")", "code_hash": "8e80d8ee8fd8fec72619d8eed709ad75", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8e01abc14814a6848ee5704e220ac262", "console": [], "id": "MJUe", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "cfa8b7221506f6f53e461b2b4219ee21", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"rdma-weight-synchronization\"\u003ERDMA \u0026amp; Weight Synchronization\u003C/h1\u003E\n\u003Cspan class=\"paragraph\"\u003EThis notebook explores efficient weight synchronization for async RL systems.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EOutline:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003EWhy Weight Sync Matters\u003C/strong\u003E - On-policy vs off-policy, model scale\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EThe Bandwidth Hierarchy\u003C/strong\u003E - NVLink, InfiniBand, PCIe\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EThe Problem: Collectives Are Blocking\u003C/strong\u003E - Why RL needs something different\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EThe Magic Pointer Pattern\u003C/strong\u003E - Control plane vs data plane separation\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECPU Staging\u003C/strong\u003E - Decoupling trainer and generator timing\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECircular Weight Buffers\u003C/strong\u003E - Versioning without memory churn\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EWeight Re-sharding\u003C/strong\u003E - Handling different tensor layouts\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EPutting It All Together\u003C/strong\u003E - Live demo with concurrent loops\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWant to go deeper?\u003C/strong\u003E Check out \u003Cstrong\u003E06b_weight_sync_deep_dive.py\u003C/strong\u003E for ibverbs internals,\nmemory registration benchmarks, and full implementations. This notebook focuses on\nthe concepts and patterns you need to know for async RL.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "1129f2591acb6dea584177d1666eb658", "console": [], "id": "bkHC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"1-why-weight-sync-matters\"\u003E1. Why Weight Sync Matters\u003C/h2\u003E\n\u003Ch3 id=\"the-on-policy-problem\"\u003EThe On-Policy Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETraditional RL algorithms want to be \u003Cstrong\u003Eon-policy\u003C/strong\u003E: generate experience using the current\npolicy, then immediately use that experience to update the policy. This creates a tight loop:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EOn-Policy RL:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  generate(policy_v1) \u2192 train(samples) \u2192 policy_v2 \u2192 repeat       \u2502\n\u2502                                                                  \u2502\n\u2502  Experience from v1 is only valid for updating v1                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EAsync RL breaks this rule.\u003C/strong\u003E Generators run continuously while the trainer updates weights.\nBy the time a sample reaches the trainer, it was generated by an old policy version:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EAsync RL (off-policy):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator: policy_v1 \u2192 sample\u2081                                  \u2502\n\u2502  Trainer:   train(sample\u2081) \u2192 policy_v2                           \u2502\n\u2502  Generator: policy_v1 \u2192 sample\u2082  \u2190 still using v1!               \u2502\n\u2502  Trainer:   train(sample\u2082) \u2192 policy_v3                           \u2502\n\u2502                                                                  \u2502\n\u2502  Samples are \u0026quot;stale\u0026quot; - generated by older policy versions        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis \u003Cstrong\u003Eoff-policy-ness\u003C/strong\u003E can work up to a degree, but must be limited. The generators\nneed fresh weights regularly to stay \"close enough\" to on-policy. Weight sync frequency\nbecomes a key hyperparameter trading off:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EToo slow\u003C/strong\u003E: Samples become too stale, training diverges\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EToo fast\u003C/strong\u003E: Weight sync overhead dominates, negating async benefits\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"the-scale-problem\"\u003EThe Scale Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFor LLM-based RL, the weights are \u003Cstrong\u003Emassive\u003C/strong\u003E. Back-of-envelope math\n(1 parameter \u2248 2 bytes in bf16):\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EModel\u003C/th\u003E\n\u003Cth\u003EWeight Size\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELlama 3.1 70B\u003C/td\u003E\n\u003Ctd\u003E~140 GB\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELlama 3.1 405B\u003C/td\u003E\n\u003Ctd\u003E~810 GB\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EDeepSeek V3 671B\u003C/td\u003E\n\u003Ctd\u003E~1.3 TB\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThese weights need to move from trainer \u2192 generators regularly. If we're\nnot careful, our \"async RL training workload\" just becomes a weight syncing\nworkload. Let's look at the bandwidth hierarchy to understand why this is\ntricky and what we can do about it.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "7a3b476e828f0fd0b4d4a1e42975ecd7", "console": [], "id": "lEQa", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"2-the-bandwidth-hierarchy\"\u003E2. The Bandwidth Hierarchy\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EModern HPC clusters have multiple interconnects with vastly different bandwidths:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                              NODE A                                                      \u2502\n\u2502                                                                                                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                         ======  64 GB/s PCIe                                             \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  ------ 48 GB/s ------ \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518      PCIe        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n                                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                        \u2502                                                    \u2502\n                                                        \u2502              InfiniBand Switch                     \u2502\n                                                        \u2502                                                    \u2502\n                                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510      PCIe        \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 ------ 48 GB/s ------  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                           ======  64 GB/s PCIe                                           \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              NODE B                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nBandwidth encoding (line intensity):\n  ########  NVLink/NVSwitch   900 GB/s bidirectional (GPU \u2194 GPU, same node)\n  ========  PCIe Gen5 / RDMA  50-64 GB/s unidirectional (CPU\u2194GPU, CPU\u2194NIC, cross-node)\n  --------  CPU interconnect  48 GB/s (CPU \u2194 CPU, same node)\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"a-note-on-bandwidth-numbers\"\u003EA Note on Bandwidth Numbers\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EBandwidth specs vary by hardware generation, cluster configuration, and vendor.\nWe'll use numbers from Meta's published Llama 3 training infrastructure\n(\u003Ca href=\"https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/\" rel=\"noopener noreferrer\" target=\"_blank\"\u003EBuilding Meta's GenAI Infrastructure\u003C/a\u003E):\u003C/span\u003E\n\u003Cblockquote\u003E\n\u003Cspan class=\"paragraph\"\u003E\"Both of these solutions interconnect \u003Cstrong\u003E400 Gbps endpoints\u003C/strong\u003E... we have successfully\nused both RoCE and InfiniBand clusters for large, GenAI workloads (including our\nongoing training of Llama 3 on our RoCE cluster) without any network bottlenecks.\"\u003C/span\u003E\n\u003C/blockquote\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EImportant\u003C/strong\u003E: \"400 Gbps\" in networking is \u003Cstrong\u003Efull-duplex\u003C/strong\u003E - meaning 400 Gbps transmit\nAND 400 Gbps receive simultaneously. For weight sync (unidirectional: trainer \u2192 generator),\nwe get the full 400 Gbps = \u003Cstrong\u003E50 GB/s per NIC\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMeta's Grand Teton nodes have \u003Cstrong\u003E8 RDMA NICs\u003C/strong\u003E (one per GPU, 1:1 mapping), giving\n400 GB/s aggregate unidirectional bandwidth per node. For more details on Grand Teton\nand Monarch's RDMA architecture, see the SIGCOMM 2024 paper:\n\u003Ca href=\"https://cs.stanford.edu/~keithw/sigcomm2024/sigcomm24-final246-acmpaginated.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ERDMA over Ethernet for Distributed AI Training at Meta Scale\u003C/a\u003E.\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EInterconnect\u003C/th\u003E\n\u003Cth\u003EBandwidth\u003C/th\u003E\n\u003Cth\u003ENotes\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ENVLink 4.0\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E900 GB/s bidirectional\u003C/td\u003E\n\u003Ctd\u003E~450 GB/s per direction\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ERDMA (IB/RoCE)\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E400 Gbps = 50 GB/s\u003C/td\u003E\n\u003Ctd\u003EPer NIC, full-duplex\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003EPCIe Gen5 x16\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E64 GB/s\u003C/td\u003E\n\u003Ctd\u003EPer direction\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey observations:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003ENVLink is fast but same-node only\u003C/strong\u003E - 450 GB/s, but can't cross the network\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERDMA \u0026gt;\u0026gt; TCP\u003C/strong\u003E - 50 GB/s with zero-copy beats TCP significantly for cross-node\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EMulti-NIC scales\u003C/strong\u003E - 8 NICs \u00d7 50 GB/s = 400 GB/s, approaching NVLink speeds\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ERule of thumb\u003C/strong\u003E: NVLink for same-node ops (gradients, activations).\nRDMA for cross-node communication (weight sync) - it's the only practical option.\u003C/span\u003E\n\u003Ch3 id=\"back-of-envelope-syncing-large-models\"\u003EBack-of-Envelope: Syncing Large Models\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's do some quick math. DeepSeek V3 has 671B parameters (~1.34 TB in bf16).\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key insight: \u003Cstrong\u003Eyou're not shoving 1.3 TB through a single NIC\u003C/strong\u003E. The weights\nare distributed across many GPUs (via some combination of PP, EP, TP, FSDP),\nand each GPU has its own NIC. You get \u003Cstrong\u003Eaggregate bandwidth\u003C/strong\u003E across all NICs.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe actual sync time depends on \u003Cstrong\u003Eboth sides\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003ETrainer's aggregate upload bandwidth\u003C/strong\u003E (sending weights out)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EGenerator's aggregate download bandwidth\u003C/strong\u003E (receiving weights)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThe bottleneck is whichever is smaller. And if multiple generators pull from\nthe same trainer simultaneously, the trainer's bandwidth is divided among them.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWith Grand Teton's 8 NICs per node at 50 GB/s each (400 GB/s per node),\nthe math is simple: \u003Cstrong\u003ETime = Shard Size / Bandwidth\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe per-node shard size depends on how many nodes the model is spread across:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EDeepSeek V3 (1.3 TB) across 8 nodes \u2192 ~160 GB per node\u003C/li\u003E\n\u003Cli\u003EDeepSeek V3 (1.3 TB) across 16 nodes \u2192 ~80 GB per node\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EPer-node shard\u003C/th\u003E\n\u003Cth\u003ETime to sync\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E~160 GB (8 nodes)\u003C/td\u003E\n\u003Ctd\u003E160 / 400 = \u003Cstrong\u003E0.4 seconds\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E~80 GB (16 nodes)\u003C/td\u003E\n\u003Ctd\u003E80 / 400 = \u003Cstrong\u003E0.2 seconds\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThe exact per-node shard size depends on your parallelism strategy (PP, EP, TP, etc.),\nbut the math works out: with modern RDMA hardware, you can sync even the largest\nmodels in \u003Cstrong\u003Esub-second time\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ECompare this to naive TCP: kernel copies, socket overhead, no zero-copy...\neasily 10x slower. \u003Cstrong\u003ERDMA is the only way to make async RL practical at scale.\u003C/strong\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "dd98f583d07acf067de617193493bad2", "console": [], "id": "PKri", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"3-the-problem-collectives-are-blocking\"\u003E3. The Problem: Collectives Are Blocking\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EMost people use RDMA via \u003Cstrong\u003Ecollectives\u003C/strong\u003E through PyTorch distributed:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Etorch.distributed\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eas\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Edist\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Einit_process_group\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebackend\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;nccl\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eall_reduce\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egradients\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eop\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003EReduceOp\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003ESUM\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebroadcast\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Esrc\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis works great for training. But async RL has a different access pattern.\u003C/span\u003E\n\u003Ch3 id=\"high-variance-in-generation-times\"\u003EHigh Variance in Generation Times\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EGenerators have wildly different completion times:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ESome prompts \u2192 10 tokens (fast)\u003C/li\u003E\n\u003Cli\u003EOther prompts \u2192 1000 tokens (slow)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EWith collectives, fast generators wait for slow ones:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EGenerator 0: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\nGenerator 1: \u251c\u2500\u2500\u2500\u2500\u2500\u2500 gen (slow) \u2500\u2500\u2500\u2500\u2500\u2500\u2524\nGenerator 2: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\n                                      \u2193\n                          all_gather(weights)  # Everyone waits!\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"the-one-sided-solution-rdma\"\u003EThe One-Sided Solution: RDMA\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EWhat if the sender could write directly to the receiver's memory without coordination?\u003C/span\u003E\n\u003Cdiv class=\"language-teratermmacro codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"nv\"\u003ETwo\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Esided\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"k\"\u003Esend\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;I have data\u0026quot;\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EReceiver\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;I\u0026#39;m ready\u0026quot;\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Esends\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edata\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EReceiver\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edata\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Emessages\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Erequired\u003C/span\u003E\n\n\u003Cspan class=\"nv\"\u003EOne\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Esided\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ewrites\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edirectly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ereceiver\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u0026#39;s memory\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E                         No coordination needed!\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is what RDMA enables: \u003Cstrong\u003Eone-sided memory operations\u003C/strong\u003E.\nThe trainer doesn't even know when generators pull weights - this is truly async!\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cb76c2f11c389956cc5404a2489a841e", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"4-the-magic-pointer-pattern\"\u003E4. The Magic Pointer Pattern\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EOne natural question that arises is along the lines of, \"How do we actually represent one-sided puts/gets if not with NCCL collectives?\"\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EHere's a key insight: to represent remote data, we only need a \u003Cstrong\u003Etiny handle\u003C/strong\u003E -\nan \u003Ccode\u003E(addr, rkey, size)\u003C/code\u003E tuple that says \"here's where my data lives.\"\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch wraps this in \u003Ccode\u003ERDMABuffer\u003C/code\u003E. Let's see how small it actually is:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "3d6ad99e96a0aafd076b1cd1ded4f8b9", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-05_15:28_436\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "RDMABuffer handle size vs actual tensor size:\n\nTensor Size  Actual Bytes    Handle Size     Ratio     \n-------------------------------------------------------\n1 KB                1,024 B      437 B               2x\n1 MB            1,048,576 B      440 B           2,383x\n10 MB          10,485,760 B      441 B          23,777x\n\n\u2192 Handle size is O(1) regardless of tensor size!\n", "type": "stream"}], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3cd3093261f72b274838b78e1c26c649", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"the-magic-pointer\"\u003EThe Magic Pointer\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is the core pattern: \u003Cstrong\u003Eseparate control plane from data plane\u003C/strong\u003E.\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EControl plane\u003C/strong\u003E (actor messages): Send tiny handle (~100 bytes)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EData plane\u003C/strong\u003E (RDMA): Bulk transfer of actual data (~10 GB)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThink of \u003Ccode\u003ERDMABuffer\u003C/code\u003E as a \u003Cstrong\u003Emagic pointer\u003C/strong\u003E - it's a pointer that works across machines:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E                              \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elocal\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecopy\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mh\"\u003E10\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGB\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eempty\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECreate\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eregister\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ememory\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ESend\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"o\"\u003E~\u003C/span\u003E\u003Cspan class=\"mh\"\u003E100\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebytes\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Evia\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eactor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"o\"\u003E~\u003C/span\u003E\u003Cspan class=\"mh\"\u003E10\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGB\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Evia\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehardware\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Einvolvement\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe trainer doesn't even know when generators pull weights. True one-sided.\u003C/span\u003E\n\u003Ch3 id=\"rdmabuffer-in-action\"\u003ERDMABuffer in Action\u003C/h3\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch.rdma\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Trainer side: register weights\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erandn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Edevice\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;cuda\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Return buffer as part of an endpoint response\u003C/span\u003E\n\u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Generator side: receive handle, pull directly into GPU\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# Tiny message\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E                   \u003Cspan class=\"c1\"\u003E# Bulk RDMA \u2192 GPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWant to understand how RDMA works under the hood?\u003C/strong\u003E Check out \u003Cstrong\u003E06b_weight_sync_deep_dive.py\u003C/strong\u003E\nfor ibverbs internals, queue pair setup, and why Monarch's actor model is such a natural fit\nfor managing RDMA connections. It's actors all the way down!\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "9b369b191c83a1c907ac9fc47f3166bc", "console": [], "id": "RGSE", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"live-demo-trainer-generator-weight-sync\"\u003ELive Demo: Trainer \u2192 Generator Weight Sync\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's see this in action with a simple example. A trainer holds weights,\na generator pulls them via RDMA.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "9c7090020db0a6d3770e0f81a71d9cb5", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "[Receiver] Allocated buffer: 4.2 MB\n[Sender] Created data: 4.2 MB\n\n[Orchestrator] Got handle from sender\n[Orchestrator] Sender checksum: 38.53\n[Orchestrator] Receiver checksum: 38.53\n[Orchestrator] Match: True\n", "type": "stream"}], "id": "Kclp", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "a8e57a271297ac88d2492cc4df33416e", "console": [], "id": "emfo", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"5-cpu-staging-pattern\"\u003E5. CPU Staging Pattern\u003C/h2\u003E\n\u003Ch3 id=\"gpu-native-rdma-works\"\u003EGPU-Native RDMA Works!\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFirst, let's be clear: \u003Cstrong\u003EGPU-native RDMA works\u003C/strong\u003E and is fast:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EGPUDirect RDMA: NIC reads directly from GPU memory\u003C/li\u003E\n\u003Cli\u003ENo CPU copy needed (when hardware supports it)\u003C/li\u003E\n\u003Cli\u003EGreat for synchronous transfers\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"why-cpu-staging-for-async-rl\"\u003EWhy CPU Staging for Async RL?\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThe issue isn't bandwidth - it's \u003Cstrong\u003Etiming\u003C/strong\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EDirect GPU\u2192GPU RDMA:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Generator GPU is mid-inference                       \u2502\n\u2502 \u251c\u2500\u2500 layer 1 \u2500\u2500\u2524 [RDMA arrives, needs sync!]         \u2502\n\u2502               \u2193                                      \u2502\n\u2502         cudaDeviceSynchronize()  \u2190 Blocks inference! \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EWith CPU staging, nothing on the critical path blocks:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eregistered\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003ESits\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehere\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eready\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eanytime\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egrabs\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eready\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe CPU buffer is a \u003Cstrong\u003Etemporal decoupling point\u003C/strong\u003E.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "54a047ff55d24352a29de7b29354120f", "console": [], "id": "Hstk", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"6-circular-weight-buffers\"\u003E6. Circular Weight Buffers\u003C/h2\u003E\n\u003Ch3 id=\"the-versioning-problem\"\u003EThe Versioning Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EIn async RL, trainer updates weights continuously. Generators need to:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003EGrab the latest\u003C/strong\u003E weights (not stale ones)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ENot block\u003C/strong\u003E waiting for updates\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EAvoid memory churn\u003C/strong\u003E (re-registering RDMA buffers is expensive)\u003C/li\u003E\n\u003C/ol\u003E\n\u003Ch3 id=\"solution-circular-buffer\"\u003ESolution: Circular Buffer\u003C/h3\u003E\n\u003Cdiv class=\"language-tsql codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Ewrites\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev0\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev1\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev2\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E...\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EBuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Eslots\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot0\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot1\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot2\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecircular\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereused\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Ereads\u003C/span\u003E\u003Cspan class=\"err\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E\u0026quot;Give me latest\u0026quot;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EBenefits:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EPre-registered RDMA buffers\u003C/strong\u003E - no memory registration on hot path\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ELock-free reads\u003C/strong\u003E - generators always get a consistent snapshot\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EBounded memory\u003C/strong\u003E - only N versions in flight\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key insight: register all slots at init time, then just write to them.\nNo allocation, no registration on the critical path.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWant to see a full implementation?\u003C/strong\u003E Check out \u003Cstrong\u003E06b_weight_sync_deep_dive.py\u003C/strong\u003E for a\ncomplete \u003Ccode\u003ECircularWeightBuffer\u003C/code\u003E class with versioning and RDMA integration.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "76823a65fe3bf897c64a5af8de3362fb", "console": [], "id": "nWHF", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"7-weight-re-sharding\"\u003E7. Weight Re-sharding\u003C/h2\u003E\n\u003Ch3 id=\"the-sharding-mismatch-problem\"\u003EThe Sharding Mismatch Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETrainer and Generator often have \u003Cstrong\u003Edifferent tensor layouts\u003C/strong\u003E. Consider an example:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ERole\u003C/th\u003E\n\u003Cth\u003EParallelism\u003C/th\u003E\n\u003Cth\u003ESharding\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ETrainer\u003C/td\u003E\n\u003Ctd\u003EFSDP (8 GPUs)\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003EShard(0)\u003C/code\u003E - rows split across 8 GPUs\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGenerator\u003C/td\u003E\n\u003Ctd\u003ETP (2 GPUs)\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003EShard(1)\u003C/code\u003E - columns split across 2 GPUs\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003ETherefore we cannot always directly transfer weights - we need \u003Cstrong\u003Ere-sharding\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EConsider a simple example where the trainer may be row-sharded and the generator may be column-sharded:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003ETrainer (row-sharded):          Generator (column-sharded):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GPU 0: rows 0-127\u2502            \u2502 GPU 0   \u2502 GPU 1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u2192      \u2502 cols    \u2502 cols    \u2502\n\u2502 GPU 1: rows 128+ \u2502            \u2502 0-511   \u2502 512+    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"two-approaches\"\u003ETwo Approaches\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EGather Then Slice\u003C/strong\u003E (simple but wasteful):\nOne approach is to materialize the entire tensor, i.e. \u003Ccode\u003Egather\u003C/code\u003E, transfer the full tensor, and then slice on the receiver side:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EEach receiver gathers ALL sender shards \u2192 full tensor\u003C/li\u003E\n\u003Cli\u003EEach receiver slices out its portion\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EProblem\u003C/strong\u003E: 2x redundant data transfer\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ERouted Transfer\u003C/strong\u003E (optimal):\nA more efficient approach is to only transfer the data that needs to be transferred:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EPre-compute which sender chunks overlap with which receiver regions\u003C/li\u003E\n\u003Cli\u003ESend only the exact chunks needed\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EBenefit\u003C/strong\u003E: Minimal bandwidth, no redundancy\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cdiv class=\"language-actionscript3 codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003EGATHER\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ediscards\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E50\u003C/span\u003E\u003Cspan class=\"o\"\u003E%\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewaste\u003C/span\u003E\u003Cspan class=\"o\"\u003E!)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EROUTED\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eonly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eexactly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhat\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eit\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeds\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe routed approach batches all needed transfers into one plan.\nPre-compute the plan once at handshake, execute it on each sync.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWant to see the overlap computation and benchmarks?\u003C/strong\u003E Check out \u003Cstrong\u003E06b_weight_sync_deep_dive.py\u003C/strong\u003E\nfor the full DTensor re-sharding implementation with placement-aware routing.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "806222a0a76efaa0bba91baefc514224", "console": [], "id": "iLit", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"8-putting-it-all-together\"\u003E8. Putting It All Together\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe full async RL weight sync pattern:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"n\"\u003ETRAINER\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ETrain\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estep\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecompletes\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECopy\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Enon\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eblocking\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ED2H\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EPublish\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecircular\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etag\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E4.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EContinue\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etraining\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eblocking\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E                            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u003Cspan class=\"n\"\u003ECIRCULAR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EBUFFER\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eregistered\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E0\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E1\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E2\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2191\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey properties:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ETrainer never blocks waiting for generators\u003C/li\u003E\n\u003Cli\u003EGenerators pull directly to GPU when \u003Cem\u003Ethey're\u003C/em\u003E ready\u003C/li\u003E\n\u003Cli\u003ERe-sharding happens locally on each generator\u003C/li\u003E\n\u003Cli\u003ECircular buffer bounds memory, reuses RDMA registrations\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "2a2c4d6cd41bd5c6ea375b2fcbd9c264", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"live-demo-async-weight-sync\"\u003ELive Demo: Async Weight Sync\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's see this in action! We'll simulate the core async RL pattern:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003E1 Trainer\u003C/strong\u003E: Runs training steps, publishes new weights to a 3-slot circular buffer\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003E4 Generators\u003C/strong\u003E: Each independently syncs to latest weights, then generates\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EAll 5 actors run \u003Cstrong\u003Econcurrently and independently\u003C/strong\u003E. The trainer never waits for generators,\nand each generator grabs weights whenever it's ready (at slightly different rates to show\nthe async behavior). To verify correctness, we set weights to \u003Ccode\u003Eversion\u003C/code\u003E and check on read.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "fc623739ac02a608e965716d9ee6d522", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "\n--- Running async RL simulation ---\n\n[Gen 0] Initialized\n[Gen 2] Initialized\n[Gen 1] Initialized\n[Gen 3] Initialized\n[Trainer] Initialized 5-slot circular buffer\n[Trainer] Published v0\n[Trainer] Published v1\n[Trainer] Published v2\n[Gen 2] Synced to v0\n[Gen 3] Synced to v0\n[Gen 0] Synced to v0\n[Gen 1] Synced to v0\n[Gen 2] Generated (v0)\n[Gen 3] Generated (v0)\n[Gen 2] Synced to v2\n[Gen 3] Synced to v2\n[Gen 0] Generated (v0)\n[Gen 1] Generated (v0)\n[Gen 0] Synced to v2\n[Gen 1] Synced to v2\n[Trainer] Published v3\n[Gen 2] Generated (v2)\n[Gen 3] Generated (v2)\n[Gen 2] Synced to v3\n[Gen 3] Synced to v3\n[Gen 0] Generated (v2)\n[Gen 1] Generated (v2)\n[Gen 0] Synced to v3\n[Gen 1] Synced to v3\n[Gen 2] Generated (v3)\n[Gen 3] Generated (v3)\n[Gen 0] Generated (v3)\n[Gen 1] Generated (v3)\n[Gen 2] Generated (v3)\n[Gen 3] Generated (v3)\n[Gen 0] Generated (v3)\n[Gen 1] Generated (v3)\n[Gen 2] Generated (v3)\n[Gen 3] Generated (v3)\n[Trainer] Published v4\n[Gen 0] Generated (v3)\n[Gen 1] Generated (v3)\n[Trainer] Published v5\n\n--- Done! Trainer published 6 versions ---\nGenerators ended on versions: [3, 3, 3, 3]\nAll pulled independently via RDMA, weights verified!\n", "type": "stream"}], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "073a87de27a68088af5e59280149bddb", "console": [], "id": "qnkX", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"9-going-further-torchstore\"\u003E9. Going Further: TorchStore\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EAll the patterns we've covered - RDMA memory registration, magic pointers, circular buffers,\npre-computed transfer plans - are building blocks. If you need a \u003Cstrong\u003Eproduction-ready solution\u003C/strong\u003E,\ncheck out \u003Ca href=\"https://github.com/meta-pytorch/torchstore\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ETorchStore\u003C/a\u003E.\u003C/span\u003E\n\u003Ch3 id=\"what-is-torchstore\"\u003EWhat is TorchStore?\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETorchStore is a \u003Cstrong\u003Edistributed, asynchronous key-value store for PyTorch tensors\u003C/strong\u003E built on\nMonarch's actor framework. It abstracts away the RDMA complexity while giving you:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Etorchstore\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003ETorchStore\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Store tensors with async API\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eput\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;model/layer1/weights\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Retrieve with optional in-place and slice semantics\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;model/layer1/weights\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Einplace_tensor\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Native PyTorch checkpoint support\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eput_state_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estate_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eloaded\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_state_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"when-to-use-what\"\u003EWhen to Use What\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EScenario\u003C/th\u003E\n\u003Cth\u003ESolution\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELearning RDMA patterns\u003C/td\u003E\n\u003Ctd\u003EThis notebook + 06b\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ECustom RL weight sync\u003C/td\u003E\n\u003Ctd\u003ESee 06b for \u003Ccode\u003ERDMABuffer\u003C/code\u003E + \u003Ccode\u003ERDMAAction\u003C/code\u003E patterns\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGeneral tensor storage\u003C/td\u003E\n\u003Ctd\u003EUse TorchStore\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ECheckpointing\u003C/td\u003E\n\u003Ctd\u003EUse TorchStore's \u003Ccode\u003Eput_state_dict\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "8e80d8ee8fd8fec72619d8eed709ad75", "console": [], "id": "TqIu", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"summary\"\u003ESummary\u003C/h2\u003E\n\u003Ch3 id=\"key-takeaways\"\u003EKey Takeaways\u003C/h3\u003E\n\u003Col\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EBandwidth hierarchy matters\u003C/strong\u003E: NVLink (900 GB/s) \u0026gt;\u0026gt; InfiniBand (50 GB/s)\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EKeep frequent operations on NVLink, use RDMA for cross-node\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECollectives block, RL needs async\u003C/strong\u003E: High variance in generation times makes\n   synchronous operations expensive\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EMagic pointer pattern\u003C/strong\u003E: Tiny handle over control plane, bulk data over data plane\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E~100 bytes to describe 10 GB transfer\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECPU staging\u003C/strong\u003E: Temporal decoupling for async RL\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ENothing blocks on the critical path\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECircular buffers\u003C/strong\u003E: Version weights without memory churn\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EPre-register RDMA buffers, reuse slots\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWeight re-sharding\u003C/strong\u003E: Different layouts need overlap computation\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ERouted approach avoids redundant transfers\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003C/ol\u003E\n\u003Ch3 id=\"want-more\"\u003EWant More?\u003C/h3\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003E06b_weight_sync_deep_dive.py\u003C/strong\u003E - ibverbs internals, benchmarks, full implementations\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003E07_async_rl_e2e.py\u003C/strong\u003E - Complete async RL system using these patterns\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.19.7%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23%20Shared%20imports%20for%20the%20notebook%0A%20%20%20%20import%20time%0A%20%20%20%20import%20torch%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20this_host%2C%20current_rank%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%2C%20is_rdma_available%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20Actor%2C%0A%20%20%20%20%20%20%20%20RDMABuffer%2C%0A%20%20%20%20%20%20%20%20current_rank%2C%0A%20%20%20%20%20%20%20%20endpoint%2C%0A%20%20%20%20%20%20%20%20is_rdma_available%2C%0A%20%20%20%20%20%20%20%20this_host%2C%0A%20%20%20%20%20%20%20%20torch%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20RDMA%20%26%20Weight%20Synchronization%0A%0A%20%20%20%20This%20notebook%20explores%20efficient%20weight%20synchronization%20for%20async%20RL%20systems.%0A%0A%20%20%20%20**Outline%3A**%0A%0A%20%20%20%201.%20**Why%20Weight%20Sync%20Matters**%20-%20On-policy%20vs%20off-policy%2C%20model%20scale%0A%20%20%20%202.%20**The%20Bandwidth%20Hierarchy**%20-%20NVLink%2C%20InfiniBand%2C%20PCIe%0A%20%20%20%203.%20**The%20Problem%3A%20Collectives%20Are%20Blocking**%20-%20Why%20RL%20needs%20something%20different%0A%20%20%20%204.%20**The%20Magic%20Pointer%20Pattern**%20-%20Control%20plane%20vs%20data%20plane%20separation%0A%20%20%20%205.%20**CPU%20Staging**%20-%20Decoupling%20trainer%20and%20generator%20timing%0A%20%20%20%206.%20**Circular%20Weight%20Buffers**%20-%20Versioning%20without%20memory%20churn%0A%20%20%20%207.%20**Weight%20Re-sharding**%20-%20Handling%20different%20tensor%20layouts%0A%20%20%20%208.%20**Putting%20It%20All%20Together**%20-%20Live%20demo%20with%20concurrent%20loops%0A%0A%20%20%20%20**Want%20to%20go%20deeper%3F**%20Check%20out%20**06b_weight_sync_deep_dive.py**%20for%20ibverbs%20internals%2C%0A%20%20%20%20memory%20registration%20benchmarks%2C%20and%20full%20implementations.%20This%20notebook%20focuses%20on%0A%20%20%20%20the%20concepts%20and%20patterns%20you%20need%20to%20know%20for%20async%20RL.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%201.%20Why%20Weight%20Sync%20Matters%0A%0A%20%20%20%20%23%23%23%20The%20On-Policy%20Problem%0A%0A%20%20%20%20Traditional%20RL%20algorithms%20want%20to%20be%20**on-policy**%3A%20generate%20experience%20using%20the%20current%0A%20%20%20%20policy%2C%20then%20immediately%20use%20that%20experience%20to%20update%20the%20policy.%20This%20creates%20a%20tight%20loop%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20On-Policy%20RL%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20generate(policy_v1)%20%E2%86%92%20train(samples)%20%E2%86%92%20policy_v2%20%E2%86%92%20repeat%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Experience%20from%20v1%20is%20only%20valid%20for%20updating%20v1%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Async%20RL%20breaks%20this%20rule.**%20Generators%20run%20continuously%20while%20the%20trainer%20updates%20weights.%0A%20%20%20%20By%20the%20time%20a%20sample%20reaches%20the%20trainer%2C%20it%20was%20generated%20by%20an%20old%20policy%20version%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Async%20RL%20(off-policy)%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20Generator%3A%20policy_v1%20%E2%86%92%20sample%E2%82%81%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Trainer%3A%20%20%20train(sample%E2%82%81)%20%E2%86%92%20policy_v2%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Generator%3A%20policy_v1%20%E2%86%92%20sample%E2%82%82%20%20%E2%86%90%20still%20using%20v1!%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Trainer%3A%20%20%20train(sample%E2%82%82)%20%E2%86%92%20policy_v3%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Samples%20are%20%22stale%22%20-%20generated%20by%20older%20policy%20versions%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20**off-policy-ness**%20can%20work%20up%20to%20a%20degree%2C%20but%20must%20be%20limited.%20The%20generators%0A%20%20%20%20need%20fresh%20weights%20regularly%20to%20stay%20%22close%20enough%22%20to%20on-policy.%20Weight%20sync%20frequency%0A%20%20%20%20becomes%20a%20key%20hyperparameter%20trading%20off%3A%0A%0A%20%20%20%20-%20**Too%20slow**%3A%20Samples%20become%20too%20stale%2C%20training%20diverges%0A%20%20%20%20-%20**Too%20fast**%3A%20Weight%20sync%20overhead%20dominates%2C%20negating%20async%20benefits%0A%0A%20%20%20%20%23%23%23%20The%20Scale%20Problem%0A%0A%20%20%20%20For%20LLM-based%20RL%2C%20the%20weights%20are%20**massive**.%20Back-of-envelope%20math%0A%20%20%20%20(1%20parameter%20%E2%89%88%202%20bytes%20in%20bf16)%3A%0A%0A%20%20%20%20%7C%20Model%20%7C%20Weight%20Size%20%7C%0A%20%20%20%20%7C-------%7C-------------%7C%0A%20%20%20%20%7C%20Llama%203.1%2070B%20%7C%20~140%20GB%20%7C%0A%20%20%20%20%7C%20Llama%203.1%20405B%20%7C%20~810%20GB%20%7C%0A%20%20%20%20%7C%20DeepSeek%20V3%20671B%20%7C%20~1.3%20TB%20%7C%0A%0A%20%20%20%20These%20weights%20need%20to%20move%20from%20trainer%20%E2%86%92%20generators%20regularly.%20If%20we're%0A%20%20%20%20not%20careful%2C%20our%20%22async%20RL%20training%20workload%22%20just%20becomes%20a%20weight%20syncing%0A%20%20%20%20workload.%20Let's%20look%20at%20the%20bandwidth%20hierarchy%20to%20understand%20why%20this%20is%0A%20%20%20%20tricky%20and%20what%20we%20can%20do%20about%20it.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%202.%20The%20Bandwidth%20Hierarchy%0A%0A%20%20%20%20Modern%20HPC%20clusters%20have%20multiple%20interconnects%20with%20vastly%20different%20bandwidths%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NODE%20A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NVSwitch%20%2F%20NVLink%20Fabric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s%20NVLink%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2064%20GB%2Fs%20PCIe%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20------%2048%20GB%2Fs%20------%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20CPU%200%20%20%E2%94%82%20%20%20%20%20CPU%20interconnect%20%20%20%E2%94%82%20%20CPU%201%20%20%E2%94%82%20%3D%3D%3D%3D%3D%3D%2064%20GB%2Fs%20%E2%95%90%E2%95%90%E2%94%82%20NIC%200%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20NIC%201%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20PCIe%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%2064%20GB%2Fs%20PCIe%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2050%20GB%2Fs%20%20%20%3D%3D%3D%3D%3D%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20IB%20NDR400%20%20%20%20%20%20%20%20%20IB%20NDR400%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20InfiniBand%20Switch%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2050%20GB%2Fs%20%20%20%3D%3D%3D%3D%3D%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20IB%20NDR400%20%20%20%20%20%20%20%20%20IB%20NDR400%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%2064%20GB%2Fs%20PCIe%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20PCIe%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20CPU%200%20%20%E2%94%82%20%20%20%20%20CPU%20interconnect%20%20%20%E2%94%82%20%20CPU%201%20%20%E2%94%82%20%3D%3D%3D%3D%3D%3D%2064%20GB%2Fs%20%E2%95%90%E2%95%90%E2%94%82%20NIC%200%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20NIC%201%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20------%2048%20GB%2Fs%20------%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2064%20GB%2Fs%20PCIe%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%20%20900%20GB%2Fs%20NVLink%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%E2%94%82GPU%200%20%E2%94%82%20%E2%94%82GPU%201%20%E2%94%82%20%E2%94%82GPU%202%20%E2%94%82%20%E2%94%82GPU%203%20%E2%94%82%20%E2%94%82GPU%204%20%E2%94%82%20%E2%94%82GPU%205%20%E2%94%82%20%E2%94%82GPU%206%20%E2%94%82%20%E2%94%82GPU%207%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NVSwitch%20%2F%20NVLink%20Fabric%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NODE%20B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%0A%20%20%20%20Bandwidth%20encoding%20(line%20intensity)%3A%0A%20%20%20%20%20%20%23%23%23%23%23%23%23%23%20%20NVLink%2FNVSwitch%20%20%20900%20GB%2Fs%20bidirectional%20(GPU%20%E2%86%94%20GPU%2C%20same%20node)%0A%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%3D%3D%20%20PCIe%20Gen5%20%2F%20RDMA%20%2050-64%20GB%2Fs%20unidirectional%20(CPU%E2%86%94GPU%2C%20CPU%E2%86%94NIC%2C%20cross-node)%0A%20%20%20%20%20%20--------%20%20CPU%20interconnect%20%2048%20GB%2Fs%20(CPU%20%E2%86%94%20CPU%2C%20same%20node)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20A%20Note%20on%20Bandwidth%20Numbers%0A%0A%20%20%20%20Bandwidth%20specs%20vary%20by%20hardware%20generation%2C%20cluster%20configuration%2C%20and%20vendor.%0A%20%20%20%20We'll%20use%20numbers%20from%20Meta's%20published%20Llama%203%20training%20infrastructure%0A%20%20%20%20(%5BBuilding%20Meta's%20GenAI%20Infrastructure%5D(https%3A%2F%2Fengineering.fb.com%2F2024%2F03%2F12%2Fdata-center-engineering%2Fbuilding-metas-genai-infrastructure%2F))%3A%0A%0A%20%20%20%20%3E%20%22Both%20of%20these%20solutions%20interconnect%20**400%20Gbps%20endpoints**...%20we%20have%20successfully%0A%20%20%20%20%3E%20used%20both%20RoCE%20and%20InfiniBand%20clusters%20for%20large%2C%20GenAI%20workloads%20(including%20our%0A%20%20%20%20%3E%20ongoing%20training%20of%20Llama%203%20on%20our%20RoCE%20cluster)%20without%20any%20network%20bottlenecks.%22%0A%0A%20%20%20%20**Important**%3A%20%22400%20Gbps%22%20in%20networking%20is%20**full-duplex**%20-%20meaning%20400%20Gbps%20transmit%0A%20%20%20%20AND%20400%20Gbps%20receive%20simultaneously.%20For%20weight%20sync%20(unidirectional%3A%20trainer%20%E2%86%92%20generator)%2C%0A%20%20%20%20we%20get%20the%20full%20400%20Gbps%20%3D%20**50%20GB%2Fs%20per%20NIC**.%0A%0A%20%20%20%20Meta's%20Grand%20Teton%20nodes%20have%20**8%20RDMA%20NICs**%20(one%20per%20GPU%2C%201%3A1%20mapping)%2C%20giving%0A%20%20%20%20400%20GB%2Fs%20aggregate%20unidirectional%20bandwidth%20per%20node.%20For%20more%20details%20on%20Grand%20Teton%0A%20%20%20%20and%20Monarch's%20RDMA%20architecture%2C%20see%20the%20SIGCOMM%202024%20paper%3A%0A%20%20%20%20%5BRDMA%20over%20Ethernet%20for%20Distributed%20AI%20Training%20at%20Meta%20Scale%5D(https%3A%2F%2Fcs.stanford.edu%2F~keithw%2Fsigcomm2024%2Fsigcomm24-final246-acmpaginated.pdf).%0A%0A%20%20%20%20%7C%20Interconnect%20%7C%20Bandwidth%20%7C%20Notes%20%7C%0A%20%20%20%20%7C--------------%7C-----------%7C-------%7C%0A%20%20%20%20%7C%20**NVLink%204.0**%20%7C%20900%20GB%2Fs%20bidirectional%20%7C%20~450%20GB%2Fs%20per%20direction%20%7C%0A%20%20%20%20%7C%20**RDMA%20(IB%2FRoCE)**%20%7C%20400%20Gbps%20%3D%2050%20GB%2Fs%20%7C%20Per%20NIC%2C%20full-duplex%20%7C%0A%20%20%20%20%7C%20**PCIe%20Gen5%20x16**%20%7C%2064%20GB%2Fs%20%7C%20Per%20direction%20%7C%0A%0A%20%20%20%20**Key%20observations%3A**%0A%0A%20%20%20%201.%20**NVLink%20is%20fast%20but%20same-node%20only**%20-%20450%20GB%2Fs%2C%20but%20can't%20cross%20the%20network%0A%20%20%20%202.%20**RDMA%20%3E%3E%20TCP**%20-%2050%20GB%2Fs%20with%20zero-copy%20beats%20TCP%20significantly%20for%20cross-node%0A%20%20%20%203.%20**Multi-NIC%20scales**%20-%208%20NICs%20%C3%97%2050%20GB%2Fs%20%3D%20400%20GB%2Fs%2C%20approaching%20NVLink%20speeds%0A%0A%20%20%20%20**Rule%20of%20thumb**%3A%20NVLink%20for%20same-node%20ops%20(gradients%2C%20activations).%0A%20%20%20%20RDMA%20for%20cross-node%20communication%20(weight%20sync)%20-%20it's%20the%20only%20practical%20option.%0A%0A%20%20%20%20%23%23%23%20Back-of-Envelope%3A%20Syncing%20Large%20Models%0A%0A%20%20%20%20Let's%20do%20some%20quick%20math.%20DeepSeek%20V3%20has%20671B%20parameters%20(~1.34%20TB%20in%20bf16).%0A%0A%20%20%20%20The%20key%20insight%3A%20**you're%20not%20shoving%201.3%20TB%20through%20a%20single%20NIC**.%20The%20weights%0A%20%20%20%20are%20distributed%20across%20many%20GPUs%20(via%20some%20combination%20of%20PP%2C%20EP%2C%20TP%2C%20FSDP)%2C%0A%20%20%20%20and%20each%20GPU%20has%20its%20own%20NIC.%20You%20get%20**aggregate%20bandwidth**%20across%20all%20NICs.%0A%0A%20%20%20%20The%20actual%20sync%20time%20depends%20on%20**both%20sides**%3A%0A%20%20%20%20-%20**Trainer's%20aggregate%20upload%20bandwidth**%20(sending%20weights%20out)%0A%20%20%20%20-%20**Generator's%20aggregate%20download%20bandwidth**%20(receiving%20weights)%0A%0A%20%20%20%20The%20bottleneck%20is%20whichever%20is%20smaller.%20And%20if%20multiple%20generators%20pull%20from%0A%20%20%20%20the%20same%20trainer%20simultaneously%2C%20the%20trainer's%20bandwidth%20is%20divided%20among%20them.%0A%0A%20%20%20%20With%20Grand%20Teton's%208%20NICs%20per%20node%20at%2050%20GB%2Fs%20each%20(400%20GB%2Fs%20per%20node)%2C%0A%20%20%20%20the%20math%20is%20simple%3A%20**Time%20%3D%20Shard%20Size%20%2F%20Bandwidth**.%0A%0A%20%20%20%20The%20per-node%20shard%20size%20depends%20on%20how%20many%20nodes%20the%20model%20is%20spread%20across%3A%0A%20%20%20%20-%20DeepSeek%20V3%20(1.3%20TB)%20across%208%20nodes%20%E2%86%92%20~160%20GB%20per%20node%0A%20%20%20%20-%20DeepSeek%20V3%20(1.3%20TB)%20across%2016%20nodes%20%E2%86%92%20~80%20GB%20per%20node%0A%0A%20%20%20%20%7C%20Per-node%20shard%20%7C%20Time%20to%20sync%20%7C%0A%20%20%20%20%7C----------------%7C--------------%7C%0A%20%20%20%20%7C%20~160%20GB%20(8%20nodes)%20%7C%20160%20%2F%20400%20%3D%20**0.4%20seconds**%20%7C%0A%20%20%20%20%7C%20~80%20GB%20(16%20nodes)%20%7C%2080%20%2F%20400%20%3D%20**0.2%20seconds**%20%7C%0A%0A%20%20%20%20The%20exact%20per-node%20shard%20size%20depends%20on%20your%20parallelism%20strategy%20(PP%2C%20EP%2C%20TP%2C%20etc.)%2C%0A%20%20%20%20but%20the%20math%20works%20out%3A%20with%20modern%20RDMA%20hardware%2C%20you%20can%20sync%20even%20the%20largest%0A%20%20%20%20models%20in%20**sub-second%20time**.%0A%0A%20%20%20%20Compare%20this%20to%20naive%20TCP%3A%20kernel%20copies%2C%20socket%20overhead%2C%20no%20zero-copy...%0A%20%20%20%20easily%2010x%20slower.%20**RDMA%20is%20the%20only%20way%20to%20make%20async%20RL%20practical%20at%20scale.**%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%203.%20The%20Problem%3A%20Collectives%20Are%20Blocking%0A%0A%20%20%20%20Most%20people%20use%20RDMA%20via%20**collectives**%20through%20PyTorch%20distributed%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20import%20torch.distributed%20as%20dist%0A%0A%20%20%20%20dist.init_process_group(backend%3D%22nccl%22)%0A%20%20%20%20dist.all_reduce(gradients%2C%20op%3Ddist.ReduceOp.SUM)%0A%20%20%20%20dist.broadcast(weights%2C%20src%3D0)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20works%20great%20for%20training.%20But%20async%20RL%20has%20a%20different%20access%20pattern.%0A%0A%20%20%20%20%23%23%23%20High%20Variance%20in%20Generation%20Times%0A%0A%20%20%20%20Generators%20have%20wildly%20different%20completion%20times%3A%0A%20%20%20%20-%20Some%20prompts%20%E2%86%92%2010%20tokens%20(fast)%0A%20%20%20%20-%20Other%20prompts%20%E2%86%92%201000%20tokens%20(slow)%0A%0A%20%20%20%20With%20collectives%2C%20fast%20generators%20wait%20for%20slow%20ones%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Generator%200%3A%20%E2%94%9C%E2%94%80%E2%94%80%20gen%20(fast)%20%E2%94%80%E2%94%80%E2%94%A4%20%20%E2%9A%A0%EF%B8%8F%20WAITING...%0A%20%20%20%20Generator%201%3A%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%20gen%20(slow)%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20Generator%202%3A%20%E2%94%9C%E2%94%80%E2%94%80%20gen%20(fast)%20%E2%94%80%E2%94%80%E2%94%A4%20%20%E2%9A%A0%EF%B8%8F%20WAITING...%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20all_gather(weights)%20%20%23%20Everyone%20waits!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20The%20One-Sided%20Solution%3A%20RDMA%0A%0A%20%20%20%20What%20if%20the%20sender%20could%20write%20directly%20to%20the%20receiver's%20memory%20without%20coordination%3F%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Two-sided%20(send%2Frecv)%3A%0A%20%20%20%20%20%20Sender%3A%20%22I%20have%20data%22%20%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20Receiver%3A%20%22I'm%20ready%22%0A%20%20%20%20%20%20Sender%3A%20sends%20data%20%20%20%20%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20Receiver%3A%20receives%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%202%20messages%20required%0A%0A%20%20%20%20One-sided%20(RDMA)%3A%0A%20%20%20%20%20%20Sender%3A%20writes%20directly%20to%20receiver's%20memory%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20No%20coordination%20needed!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20what%20RDMA%20enables%3A%20**one-sided%20memory%20operations**.%0A%20%20%20%20The%20trainer%20doesn't%20even%20know%20when%20generators%20pull%20weights%20-%20this%20is%20truly%20async!%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%204.%20The%20Magic%20Pointer%20Pattern%0A%0A%20%20%20%20One%20natural%20question%20that%20arises%20is%20along%20the%20lines%20of%2C%20%22How%20do%20we%20actually%20represent%20one-sided%20puts%2Fgets%20if%20not%20with%20NCCL%20collectives%3F%22%0A%0A%20%20%20%20Here's%20a%20key%20insight%3A%20to%20represent%20remote%20data%2C%20we%20only%20need%20a%20**tiny%20handle**%20-%0A%20%20%20%20an%20%60(addr%2C%20rkey%2C%20size)%60%20tuple%20that%20says%20%22here's%20where%20my%20data%20lives.%22%0A%0A%20%20%20%20Monarch%20wraps%20this%20in%20%60RDMABuffer%60.%20Let's%20see%20how%20small%20it%20actually%20is%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20endpoint%2C%20is_rdma_available%2C%20this_host%2C%20torch)%3A%0A%20%20%20%20%23%20Measure%20actual%20size%20of%20RDMABuffer%20handles%0A%20%20%20%20import%20pickle%0A%0A%20%20%20%20def%20show_fallback_sizes()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Fallback%3A%20show%20expected%20sizes%20based%20on%20RDMABuffer%20structure.%22%22%22%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20expected%20handle%20sizes)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%22RDMABuffer%20contains%3A%20addr%20(8B)%20%2B%20rkey%20(4B)%20%2B%20size%20(8B)%20%2B%20owner%20(~100B)%22)%0A%20%20%20%20%20%20%20%20print(%22Total%20serialized%20size%3A%20~150-200%20bytes%20regardless%20of%20tensor%20size%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20sizes%20%3D%20%5B(%221%20KB%22%2C%201024)%2C%20(%221%20MB%22%2C%201024**2)%2C%20(%221%20GB%22%2C%201024**3)%5D%0A%20%20%20%20%20%20%20%20handle_bytes%20%3D%20150%20%20%23%20approximate%0A%0A%20%20%20%20%20%20%20%20for%20name%2C%20tensor_bytes%20in%20sizes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20ratio%20%3D%20tensor_bytes%20%2F%20handle_bytes%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bname%3A%3C8%7D%20tensor%20%E2%86%92%20~150%20byte%20handle%20%E2%86%92%20%7Bratio%3A%2C.0f%7Dx%20compression%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Handle%20size%20is%20O(1)%20regardless%20of%20tensor%20size!%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback_sizes()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20BufferSizeDemo(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Actor%20that%20creates%20RDMABuffers%20and%20measures%20their%20size.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20measure_buffer_sizes(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20pickle%20as%20_pickle%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20results%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sizes%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%221%20KB%22%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%221%20MB%22%2C%20256%20*%201024)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%2210%20MB%22%2C%20256%20*%201024%20*%2010)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20numel%20in%20sizes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tensor%20%3D%20torch.randn(numel)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tensor_bytes%20%3D%20tensor.numel()%20*%20tensor.element_size()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_tensor%20%3D%20tensor.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20buffer%20%3D%20RDMABuffer(byte_tensor)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle_bytes%20%3D%20len(_pickle.dumps(buffer))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20results.append((name%2C%20tensor_bytes%2C%20handle_bytes))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20results%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20proc%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20%20%20%20%20demo%20%3D%20proc.spawn(%22buffer_demo%22%2C%20BufferSizeDemo)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20results%20%3D%20demo.measure_buffer_sizes.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22RDMABuffer%20handle%20size%20vs%20actual%20tensor%20size%3A%5Cn%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7B'Tensor%20Size'%3A%3C12%7D%20%7B'Actual%20Bytes'%3A%3C15%7D%20%7B'Handle%20Size'%3A%3C15%7D%20%7B'Ratio'%3A%3C10%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22-%22%20*%2055)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20tensor_bytes%2C%20handle_bytes%20in%20results%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ratio%20%3D%20tensor_bytes%20%2F%20handle_bytes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bname%3A%3C12%7D%20%7Btensor_bytes%3A%3E12%2C%7D%20B%20%20%20%7Bhandle_bytes%3A%3E6%7D%20B%20%20%20%20%20%20%20%20%7Bratio%3A%3E8%2C.0f%7Dx%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Handle%20size%20is%20O(1)%20regardless%20of%20tensor%20size!%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22(RDMA%20setup%20failed%3A%20%7Be%7D)%5Cn%22)%0A%20%20%20%20%20%20%20%20show_fallback_sizes()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20The%20Magic%20Pointer%0A%0A%20%20%20%20This%20is%20the%20core%20pattern%3A%20**separate%20control%20plane%20from%20data%20plane**.%0A%0A%20%20%20%20-%20**Control%20plane**%20(actor%20messages)%3A%20Send%20tiny%20handle%20(~100%20bytes)%0A%20%20%20%20-%20**Data%20plane**%20(RDMA)%3A%20Bulk%20transfer%20of%20actual%20data%20(~10%20GB)%0A%0A%20%20%20%20Think%20of%20%60RDMABuffer%60%20as%20a%20**magic%20pointer**%20-%20it's%20a%20pointer%20that%20works%20across%20machines%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20Generator%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20weights%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20local%20copy%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20(10%20GB)%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20(empty)%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%201.%20Create%20RDMABuffer%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20(register%20memory%2C%20get%20handle)%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%202.%20Send%20handle%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%E2%94%82%20%20(~100%20bytes%20via%20actor)%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%E2%97%84%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%203.%20RDMA%20read%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20(~10%20GB%20via%20hardware)%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20(no%20trainer%20involvement!)%20%20%E2%94%82%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20trainer%20doesn't%20even%20know%20when%20generators%20pull%20weights.%20True%20one-sided.%0A%0A%20%20%20%20%23%23%23%20RDMABuffer%20in%20Action%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%0A%0A%20%20%20%20%23%20Trainer%20side%3A%20register%20weights%0A%20%20%20%20weights%20%3D%20torch.randn(1024%2C%201024%2C%20device%3D%22cuda%22)%0A%20%20%20%20buffer%20%3D%20RDMABuffer(weights.view(torch.uint8).flatten())%0A%0A%20%20%20%20%23%20Return%20buffer%20as%20part%20of%20an%20endpoint%20response%0A%20%20%20%20%40endpoint%0A%20%20%20%20def%20get_weight_handle(self)%20-%3E%20RDMABuffer%3A%0A%20%20%20%20%20%20%20%20return%20self.buffer%0A%0A%20%20%20%20%23%20Generator%20side%3A%20receive%20handle%2C%20pull%20directly%20into%20GPU%0A%20%20%20%20handle%20%3D%20trainer.get_weight_handle.call_one().get()%20%20%23%20Tiny%20message%0A%20%20%20%20gpu_weights%20%3D%20model.weights.view(torch.uint8).flatten()%0A%20%20%20%20handle.read_into(gpu_weights).get()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Bulk%20RDMA%20%E2%86%92%20GPU%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Want%20to%20understand%20how%20RDMA%20works%20under%20the%20hood%3F**%20Check%20out%20**06b_weight_sync_deep_dive.py**%0A%20%20%20%20for%20ibverbs%20internals%2C%20queue%20pair%20setup%2C%20and%20why%20Monarch's%20actor%20model%20is%20such%20a%20natural%20fit%0A%20%20%20%20for%20managing%20RDMA%20connections.%20It's%20actors%20all%20the%20way%20down!%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Live%20Demo%3A%20Trainer%20%E2%86%92%20Generator%20Weight%20Sync%0A%0A%20%20%20%20Let's%20see%20this%20in%20action%20with%20a%20simple%20example.%20A%20trainer%20holds%20weights%2C%0A%20%20%20%20a%20generator%20pulls%20them%20via%20RDMA.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20endpoint%2C%20is_rdma_available%2C%20this_host%2C%20torch)%3A%0A%20%20%20%20%23%20Simple%20trainer%20%E2%86%92%20generator%20weight%20sync%20demo%0A%0A%20%20%20%20def%20show_fallback_demo()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Show%20what%20would%20happen%20with%20RDMA.%22%22%22%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20conceptual%20flow)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%221.%20Trainer%20creates%20weights%20(e.g.%2C%204%20MB%20tensor)%22)%0A%20%20%20%20%20%20%20%20print(%222.%20Trainer%20wraps%20weights%20in%20RDMABuffer%20%E2%86%92%20tiny%20handle%20(~150%20bytes)%22)%0A%20%20%20%20%20%20%20%20print(%223.%20Trainer%20sends%20handle%20to%20Generator%20via%20actor%20message%22)%0A%20%20%20%20%20%20%20%20print(%224.%20Generator%20calls%20handle.read_into(local_buffer)%22)%0A%20%20%20%20%20%20%20%20print(%225.%20RDMA%20hardware%20transfers%204%20MB%20directly%2C%20trainer%20not%20involved!%22)%0A%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Zero-copy%2C%20one-sided%2C%20no%20serialization%20overhead%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback_demo()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Sender(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Sender%20that%20holds%20data%20and%20exposes%20an%20RDMA%20handle.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20some%20data%20to%20send%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data%20%3D%20torch.randn(size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20with%20RDMA%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data_bytes%20%3D%20self.data.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%20%3D%20RDMABuffer(self.data_bytes)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BSender%5D%20Created%20data%3A%20%7Bself.data.numel()%20*%204%20%2F%201e6%3A.1f%7D%20MB%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20get_handle(self)%20-%3E%20RDMABuffer%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Return%20tiny%20handle%20(not%20the%20data%20itself!)%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.buffer%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20get_checksum(self)%20-%3E%20float%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22For%20verification%3A%20sum%20of%20data%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20float(self.data.sum())%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Receiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Receiver%20that%20pulls%20data%20from%20sender%20via%20RDMA.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Pre-allocate%20space%20for%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data%20%3D%20torch.zeros(size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data_bytes%20%3D%20self.data.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BReceiver%5D%20Allocated%20buffer%3A%20%7Bself.data.numel()%20*%204%20%2F%201e6%3A.1f%7D%20MB%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20pull_data(self%2C%20handle%3A%20RDMABuffer)%20-%3E%20float%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Pull%20data%20via%20RDMA%20read%2C%20return%20checksum%20for%20verification.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20is%20the%20magic%3A%20RDMA%20read%20directly%20into%20our%20buffer%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(self.data_bytes).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20float(self.data.sum())%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Spawn%20sender%20and%20receiver%0A%20%20%20%20%20%20%20%20%20%20%20%20procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%202%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20sender%20%3D%20procs.slice(procs%3D0).spawn(%22sender%22%2C%20Sender%2C%201024%20*%201024)%20%20%23%204%20MB%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver%20%3D%20procs.slice(procs%3D1).spawn(%22receiver%22%2C%20Receiver%2C%201024%20*%201024)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Step%201%3A%20Get%20handle%20from%20sender%20(tiny%20message!)%0A%20%20%20%20%20%20%20%20%20%20%20%20handle%20%3D%20sender.get_handle.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5Cn%5BOrchestrator%5D%20Got%20handle%20from%20sender%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Step%202%3A%20Send%20handle%20to%20receiver%2C%20have%20it%20pull%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_checksum%20%3D%20receiver.pull_data.call_one(handle).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_checksum%20%3D%20sender.get_checksum.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BOrchestrator%5D%20Sender%20checksum%3A%20%7Bsender_checksum%3A.2f%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BOrchestrator%5D%20Receiver%20checksum%3A%20%7Breceiver_checksum%3A.2f%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BOrchestrator%5D%20Match%3A%20%7Babs(sender_checksum%20-%20receiver_checksum)%20%3C%200.01%7D%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22(Demo%20failed%3A%20%7Be%7D)%5Cn%22)%0A%20%20%20%20%20%20%20%20show_fallback_demo()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%205.%20CPU%20Staging%20Pattern%0A%0A%20%20%20%20%23%23%23%20GPU-Native%20RDMA%20Works!%0A%0A%20%20%20%20First%2C%20let's%20be%20clear%3A%20**GPU-native%20RDMA%20works**%20and%20is%20fast%3A%0A%20%20%20%20-%20GPUDirect%20RDMA%3A%20NIC%20reads%20directly%20from%20GPU%20memory%0A%20%20%20%20-%20No%20CPU%20copy%20needed%20(when%20hardware%20supports%20it)%0A%20%20%20%20-%20Great%20for%20synchronous%20transfers%0A%0A%20%20%20%20%23%23%23%20Why%20CPU%20Staging%20for%20Async%20RL%3F%0A%0A%20%20%20%20The%20issue%20isn't%20bandwidth%20-%20it's%20**timing**%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Direct%20GPU%E2%86%92GPU%20RDMA%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20Generator%20GPU%20is%20mid-inference%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%E2%94%9C%E2%94%80%E2%94%80%20layer%201%20%E2%94%80%E2%94%80%E2%94%A4%20%5BRDMA%20arrives%2C%20needs%20sync!%5D%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20cudaDeviceSynchronize()%20%20%E2%86%90%20Blocks%20inference!%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20With%20CPU%20staging%2C%20nothing%20on%20the%20critical%20path%20blocks%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20GPU%20%E2%94%80%E2%94%80%E2%96%BA%20CPU%20staging%20buffer%20(RDMA%20registered)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%5BSits%20here%2C%20ready%20anytime%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20Generator%20grabs%20when%20ready%20%E2%94%80%E2%94%80%E2%96%BA%20Generator%20GPU%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20CPU%20buffer%20is%20a%20**temporal%20decoupling%20point**.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%206.%20Circular%20Weight%20Buffers%0A%0A%20%20%20%20%23%23%23%20The%20Versioning%20Problem%0A%0A%20%20%20%20In%20async%20RL%2C%20trainer%20updates%20weights%20continuously.%20Generators%20need%20to%3A%0A%20%20%20%201.%20**Grab%20the%20latest**%20weights%20(not%20stale%20ones)%0A%20%20%20%202.%20**Not%20block**%20waiting%20for%20updates%0A%20%20%20%203.%20**Avoid%20memory%20churn**%20(re-registering%20RDMA%20buffers%20is%20expensive)%0A%0A%20%20%20%20%23%23%23%20Solution%3A%20Circular%20Buffer%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20writes%3A%20%20%20%20%20v0%20%20%20%20%E2%86%92%20%20v1%20%20%E2%86%92%20%20v2%20%20%E2%86%92%20%20v3%20%20%E2%86%92%20%20v4%20%20%E2%86%92%20%20v5%20%20%E2%86%92%20...%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%E2%86%93%0A%20%20%20%20Buffer%20slots%3A%20%20%20%20%20%20%5Bslot0%5D%20%5Bslot1%5D%20%5Bslot2%5D%20%20(circular%2C%20reused)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v3%20%20%20%20%20%20v4%20%20%20%20%20%20v5%0A%0A%20%20%20%20Generator%20reads%3A%20%22Give%20me%20latest%22%20%E2%86%92%20v5%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Benefits%3A%0A%20%20%20%20-%20**Pre-registered%20RDMA%20buffers**%20-%20no%20memory%20registration%20on%20hot%20path%0A%20%20%20%20-%20**Lock-free%20reads**%20-%20generators%20always%20get%20a%20consistent%20snapshot%0A%20%20%20%20-%20**Bounded%20memory**%20-%20only%20N%20versions%20in%20flight%0A%0A%20%20%20%20The%20key%20insight%3A%20register%20all%20slots%20at%20init%20time%2C%20then%20just%20write%20to%20them.%0A%20%20%20%20No%20allocation%2C%20no%20registration%20on%20the%20critical%20path.%0A%0A%20%20%20%20**Want%20to%20see%20a%20full%20implementation%3F**%20Check%20out%20**06b_weight_sync_deep_dive.py**%20for%20a%0A%20%20%20%20complete%20%60CircularWeightBuffer%60%20class%20with%20versioning%20and%20RDMA%20integration.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%207.%20Weight%20Re-sharding%0A%0A%20%20%20%20%23%23%23%20The%20Sharding%20Mismatch%20Problem%0A%0A%20%20%20%20Trainer%20and%20Generator%20often%20have%20**different%20tensor%20layouts**.%20Consider%20an%20example%3A%0A%0A%20%20%20%20%7C%20Role%20%7C%20Parallelism%20%7C%20Sharding%20%7C%0A%20%20%20%20%7C------%7C-------------%7C----------%7C%0A%20%20%20%20%7C%20Trainer%20%7C%20FSDP%20(8%20GPUs)%20%7C%20%60Shard(0)%60%20-%20rows%20split%20across%208%20GPUs%20%7C%0A%20%20%20%20%7C%20Generator%20%7C%20TP%20(2%20GPUs)%20%7C%20%60Shard(1)%60%20-%20columns%20split%20across%202%20GPUs%20%7C%0A%0A%20%20%20%20Therefore%20we%20cannot%20always%20directly%20transfer%20weights%20-%20we%20need%20**re-sharding**.%0A%0A%20%20%20%20Consider%20a%20simple%20example%20where%20the%20trainer%20may%20be%20row-sharded%20and%20the%20generator%20may%20be%20column-sharded%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20(row-sharded)%3A%20%20%20%20%20%20%20%20%20%20Generator%20(column-sharded)%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20GPU%200%3A%20rows%200-127%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20GPU%200%20%20%20%E2%94%82%20GPU%201%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20%20%20%20%E2%86%92%20%20%20%20%20%20%E2%94%82%20cols%20%20%20%20%E2%94%82%20cols%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20GPU%201%3A%20rows%20128%2B%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%200-511%20%20%20%E2%94%82%20512%2B%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20Two%20Approaches%0A%0A%20%20%20%20**Gather%20Then%20Slice**%20(simple%20but%20wasteful)%3A%0A%20%20%20%20One%20approach%20is%20to%20materialize%20the%20entire%20tensor%2C%20i.e.%20%60gather%60%2C%20transfer%20the%20full%20tensor%2C%20and%20then%20slice%20on%20the%20receiver%20side%3A%0A%20%20%20%201.%20Each%20receiver%20gathers%20ALL%20sender%20shards%20%E2%86%92%20full%20tensor%0A%20%20%20%202.%20Each%20receiver%20slices%20out%20its%20portion%0A%20%20%20%203.%20**Problem**%3A%202x%20redundant%20data%20transfer%0A%0A%20%20%20%20**Routed%20Transfer**%20(optimal)%3A%0A%20%20%20%20A%20more%20efficient%20approach%20is%20to%20only%20transfer%20the%20data%20that%20needs%20to%20be%20transferred%3A%0A%20%20%20%201.%20Pre-compute%20which%20sender%20chunks%20overlap%20with%20which%20receiver%20regions%0A%20%20%20%202.%20Send%20only%20the%20exact%20chunks%20needed%0A%20%20%20%203.%20**Benefit**%3A%20Minimal%20bandwidth%2C%20no%20redundancy%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20GATHER%3A%20G0%20receives%20T0%2CT1%2CT2%2CT3%20%E2%86%92%20discards%20T2%2CT3%20(50%25%20waste!)%0A%20%20%20%20ROUTED%3A%20G0%20receives%20T0%2CT1%20only%20%E2%86%92%20exactly%20what%20it%20needs%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20routed%20approach%20batches%20all%20needed%20transfers%20into%20one%20plan.%0A%20%20%20%20Pre-compute%20the%20plan%20once%20at%20handshake%2C%20execute%20it%20on%20each%20sync.%0A%0A%20%20%20%20**Want%20to%20see%20the%20overlap%20computation%20and%20benchmarks%3F**%20Check%20out%20**06b_weight_sync_deep_dive.py**%0A%20%20%20%20for%20the%20full%20DTensor%20re-sharding%20implementation%20with%20placement-aware%20routing.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%208.%20Putting%20It%20All%20Together%0A%0A%20%20%20%20The%20full%20async%20RL%20weight%20sync%20pattern%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20TRAINER%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%201.%20Train%20step%20completes%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%202.%20Copy%20weights%20to%20CPU%20staging%20buffer%20(non-blocking%20D2H)%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%203.%20Publish%20to%20circular%20buffer%20with%20version%20tag%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%204.%20Continue%20training%20(no%20blocking!)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20CIRCULAR%20BUFFER%20(CPU%2C%20RDMA-registered)%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%5Bslot%200%3A%20v3%5D%20%5Bslot%201%3A%20v4%5D%20%5Bslot%202%3A%20v5%5D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%91%20latest%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20GENERATOR%200%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20GENERATOR%201%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20GENERATOR%202%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%0A%20%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Key%20properties%3A**%0A%20%20%20%20-%20Trainer%20never%20blocks%20waiting%20for%20generators%0A%20%20%20%20-%20Generators%20pull%20directly%20to%20GPU%20when%20*they're*%20ready%0A%20%20%20%20-%20Re-sharding%20happens%20locally%20on%20each%20generator%0A%20%20%20%20-%20Circular%20buffer%20bounds%20memory%2C%20reuses%20RDMA%20registrations%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Live%20Demo%3A%20Async%20Weight%20Sync%0A%0A%20%20%20%20Let's%20see%20this%20in%20action!%20We'll%20simulate%20the%20core%20async%20RL%20pattern%3A%0A%0A%20%20%20%20-%20**1%20Trainer**%3A%20Runs%20training%20steps%2C%20publishes%20new%20weights%20to%20a%203-slot%20circular%20buffer%0A%20%20%20%20-%20**4%20Generators**%3A%20Each%20independently%20syncs%20to%20latest%20weights%2C%20then%20generates%0A%0A%20%20%20%20All%205%20actors%20run%20**concurrently%20and%20independently**.%20The%20trainer%20never%20waits%20for%20generators%2C%0A%20%20%20%20and%20each%20generator%20grabs%20weights%20whenever%20it's%20ready%20(at%20slightly%20different%20rates%20to%20show%0A%20%20%20%20the%20async%20behavior).%20To%20verify%20correctness%2C%20we%20set%20weights%20to%20%60version%60%20and%20check%20on%20read.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Actor%2C%0A%20%20%20%20RDMABuffer%2C%0A%20%20%20%20current_rank%2C%0A%20%20%20%20endpoint%2C%0A%20%20%20%20is_rdma_available%2C%0A%20%20%20%20this_host%2C%0A%20%20%20%20torch%2C%0A)%3A%0A%20%20%20%20import%20threading%0A%0A%20%20%20%20def%20show_fallback()%3A%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20conceptual%20flow)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%22What%20would%20happen%20with%20RDMA%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%5BTrainer%5D%20Publishes%20v0%2C%20v1%2C%20v2...%20to%20circular%20buffer%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%5BGenerator%5D%20Syncs%20when%20ready%2C%20verifies%20weights%20match%20version%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20Both%20run%20independently%2C%20no%20blocking!%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Trainer(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Trainer%20with%20circular%20buffer%20for%20weight%20versioning.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20weight_size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.n_slots%20%3D%205%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.version%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(self.n_slots)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot%20%3D%20torch.zeros(weight_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots.append(slot)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles.append(RDMABuffer(slot.view(torch.uint8).flatten()))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%5D%20Initialized%20%7Bself.n_slots%7D-slot%20circular%20buffer%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20get_latest(self)%20-%3E%20tuple%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20self.version%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20None%2C%20-1%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v%20%3D%20self.version%20-%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.handles%5Bv%20%25%20self.n_slots%5D%2C%20v%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20train_step(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Single%20training%20step%3A%20publish%20new%20weights.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20sys%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20self.version%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots%5Bslot_idx%5D.fill_(float(self.version))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.version%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%5D%20Published%20v%7Bself.version%20-%201%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sys.stdout.flush()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.version%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Generator(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Generator%20that%20syncs%20weights%20and%20generates.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20weight_size%3A%20int%2C%20trainer)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.gen_id%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.trainer%20%3D%20trainer%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.weights%20%3D%20torch.zeros(weight_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.weight_bytes%20%3D%20self.weights.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.current_version%20%3D%20-1%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGen%20%7Bself.gen_id%7D%5D%20Initialized%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20generate_step(self)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Single%20generate%20step%3A%20sync%20if%20needed%2C%20then%20generate.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20sys%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Try%20to%20sync%20weights%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle%2C%20version%20%3D%20self.trainer.get_latest.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20handle%20is%20not%20None%20and%20version%20%3E%20self.current_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(self.weight_bytes).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actual%20%3D%20int(self.weights%5B0%5D.item())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20actual%20%3E%3D%20version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.current_version%20%3D%20actual%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGen%20%7Bself.gen_id%7D%5D%20Synced%20to%20v%7Bactual%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sys.stdout.flush()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.current_version%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Spawn%20trainer%20and%20generators%0A%20%20%20%20%20%20%20%20%20%20%20%20n_generators%20%3D%204%0A%20%20%20%20%20%20%20%20%20%20%20%20trainer_proc%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20%20%20%20%20generator_procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%20n_generators%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20trainer%20%3D%20trainer_proc.spawn(%22trainer%22%2C%20Trainer%2C%20weight_size%3D1024)%0A%20%20%20%20%20%20%20%20%20%20%20%20generators%20%3D%20generator_procs.spawn(%22generators%22%2C%20Generator%2C%20weight_size%3D1024%2C%20trainer%3Dtrainer)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn---%20Running%20async%20RL%20simulation%20---%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Results%20storage%0A%20%20%20%20%20%20%20%20%20%20%20%20_results%20%3D%20%7B%22trainer%22%3A%20None%2C%20%22generators%22%3A%20%5BNone%5D%20*%20n_generators%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20def%20run_trainer(n_steps%2C%20step_time)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20time%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(n_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(step_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20_results%5B%22trainer%22%5D%20%3D%20trainer.train_step.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20def%20run_generator(gen_actor%2C%20gen_idx%2C%20n_iters%2C%20gen_time)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20time%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(n_iters)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20version%20%3D%20gen_actor.generate_step.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3E%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(gen_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGen%20%7Bgen_idx%7D%5D%20Generated%20(v%7Bversion%7D)%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(0.05)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20_results%5B%22generators%22%5D%5Bgen_idx%5D%20%3D%20version%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20threads%20for%20trainer%20and%20each%20generator%0A%20%20%20%20%20%20%20%20%20%20%20%20threads%20%3D%20%5B%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Trainer%20thread%0A%20%20%20%20%20%20%20%20%20%20%20%20t%20%3D%20threading.Thread(target%3Drun_trainer%2C%20args%3D(6%2C%201.0))%20%20%23%201%20second%20per%20step%0A%20%20%20%20%20%20%20%20%20%20%20%20threads.append(t)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Generator%20threads%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%20in%20range(n_generators)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gen_actor%20%3D%20generators.slice(procs%3Di)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20t%20%3D%20threading.Thread(target%3Drun_generator%2C%20args%3D(gen_actor%2C%20i%2C%205%2C%200.25))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threads.append(t)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Start%20all%20threads%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20t%20in%20threads%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20t.start()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Wait%20for%20all%20to%20complete%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20t%20in%20threads%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20t.join()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5Cn---%20Done!%20Trainer%20published%20%7B_results%5B'trainer'%5D%7D%20versions%20---%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Generators%20ended%20on%20versions%3A%20%7B_results%5B'generators'%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22All%20pulled%20independently%20via%20RDMA%2C%20weights%20verified!%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20import%20traceback%0A%20%20%20%20%20%20%20%20traceback.print_exc()%0A%20%20%20%20%20%20%20%20print(f%22(Demo%20failed%3A%20%7Be%7D)%22)%0A%20%20%20%20%20%20%20%20show_fallback()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%209.%20Going%20Further%3A%20TorchStore%0A%0A%20%20%20%20All%20the%20patterns%20we've%20covered%20-%20RDMA%20memory%20registration%2C%20magic%20pointers%2C%20circular%20buffers%2C%0A%20%20%20%20pre-computed%20transfer%20plans%20-%20are%20building%20blocks.%20If%20you%20need%20a%20**production-ready%20solution**%2C%0A%20%20%20%20check%20out%20%5BTorchStore%5D(https%3A%2F%2Fgithub.com%2Fmeta-pytorch%2Ftorchstore).%0A%0A%20%20%20%20%23%23%23%20What%20is%20TorchStore%3F%0A%0A%20%20%20%20TorchStore%20is%20a%20**distributed%2C%20asynchronous%20key-value%20store%20for%20PyTorch%20tensors**%20built%20on%0A%20%20%20%20Monarch's%20actor%20framework.%20It%20abstracts%20away%20the%20RDMA%20complexity%20while%20giving%20you%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20torchstore%20import%20TorchStore%0A%0A%20%20%20%20%23%20Store%20tensors%20with%20async%20API%0A%20%20%20%20await%20ts.put(%22model%2Flayer1%2Fweights%22%2C%20tensor)%0A%0A%20%20%20%20%23%20Retrieve%20with%20optional%20in-place%20and%20slice%20semantics%0A%20%20%20%20await%20ts.get(%22model%2Flayer1%2Fweights%22%2C%20inplace_tensor%3Dbuffer)%0A%0A%20%20%20%20%23%20Native%20PyTorch%20checkpoint%20support%0A%20%20%20%20await%20ts.put_state_dict(model.state_dict())%0A%20%20%20%20loaded%20%3D%20await%20ts.get_state_dict()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20When%20to%20Use%20What%0A%0A%20%20%20%20%7C%20Scenario%20%7C%20Solution%20%7C%0A%20%20%20%20%7C----------%7C----------%7C%0A%20%20%20%20%7C%20Learning%20RDMA%20patterns%20%7C%20This%20notebook%20%2B%2006b%20%7C%0A%20%20%20%20%7C%20Custom%20RL%20weight%20sync%20%7C%20See%2006b%20for%20%60RDMABuffer%60%20%2B%20%60RDMAAction%60%20patterns%20%7C%0A%20%20%20%20%7C%20General%20tensor%20storage%20%7C%20Use%20TorchStore%20%7C%0A%20%20%20%20%7C%20Checkpointing%20%7C%20Use%20TorchStore's%20%60put_state_dict%60%20%7C%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20%23%23%23%20Key%20Takeaways%0A%0A%20%20%20%201.%20**Bandwidth%20hierarchy%20matters**%3A%20NVLink%20(900%20GB%2Fs)%20%3E%3E%20InfiniBand%20(50%20GB%2Fs)%0A%20%20%20%20%20%20%20-%20Keep%20frequent%20operations%20on%20NVLink%2C%20use%20RDMA%20for%20cross-node%0A%0A%20%20%20%202.%20**Collectives%20block%2C%20RL%20needs%20async**%3A%20High%20variance%20in%20generation%20times%20makes%0A%20%20%20%20%20%20%20synchronous%20operations%20expensive%0A%0A%20%20%20%203.%20**Magic%20pointer%20pattern**%3A%20Tiny%20handle%20over%20control%20plane%2C%20bulk%20data%20over%20data%20plane%0A%20%20%20%20%20%20%20-%20~100%20bytes%20to%20describe%2010%20GB%20transfer%0A%0A%20%20%20%204.%20**CPU%20staging**%3A%20Temporal%20decoupling%20for%20async%20RL%0A%20%20%20%20%20%20%20-%20Nothing%20blocks%20on%20the%20critical%20path%0A%0A%20%20%20%205.%20**Circular%20buffers**%3A%20Version%20weights%20without%20memory%20churn%0A%20%20%20%20%20%20%20-%20Pre-register%20RDMA%20buffers%2C%20reuse%20slots%0A%0A%20%20%20%206.%20**Weight%20re-sharding**%3A%20Different%20layouts%20need%20overlap%20computation%0A%20%20%20%20%20%20%20-%20Routed%20approach%20avoids%20redundant%20transfers%0A%0A%20%20%20%20%23%23%23%20Want%20More%3F%0A%0A%20%20%20%20-%20**06b_weight_sync_deep_dive.py**%20-%20ibverbs%20internals%2C%20benchmarks%2C%20full%20implementations%0A%20%20%20%20-%20**07_async_rl_e2e.py**%20-%20Complete%20async%20RL%20system%20using%20these%20patterns%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">7a30acef511a55fc57efa4a8898c3af9</marimo-code-hash>
</body>
</html>
