<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>06_rdma_weight_sync.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>06 rdma weight sync</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-DGasP9Lh.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/preload-helper-DItdS47A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-BGmjiNul.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/compiler-runtime-DeeZ7FnK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/badge-Ce8wRjuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEventListener-DIUKKfEy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/button-YC1gW_kJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-dom-C9fstfnp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Combination-CMPwuAmi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/menu-items-CJhvWPOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-uzvC4uAK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createLucideIcon-CnW3RofX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/check-DdfN0k2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/select-V5IdpNiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-CEc2ajau.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/use-toast-rmUWldD_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEvent-DO6uJBas.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/zod-Cg4WLWh2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utils-DXvhzCGS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Deferred-CrO5-0RA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/config-CIrPQIbt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/uuid-DercMavo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/DeferredRequestRegistry-CO2AyNfd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/requests-BsVD4CdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useLifecycle-D35CBukS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNonce-_Aax6sXd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useTheme-DUdVAZI8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createReducer-Dnna-AUO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BIKFl48f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-B0VqT_4z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-TiFCI16_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Cayq-K1c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BYyu59D8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/stex-CtmkcLz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toDate-CgbKQM5E.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/database-zap-B9y7063w.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-BpZ7g6ok.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spinner-DaIKav-i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chevron-right-DwagBitu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dropdown-menu-B-6unW-7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/kbd-C3JY7O_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/renderShortcut-DEwfrKeS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/multi-map-C8GlnP-4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-BrGyZf9c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-dialog-DwQffb13.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dialog-CxGKN4C_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CdxIjAOP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/label-Be1daUcS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDebounce-D5NcotGm.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/textarea-DBO30D7K.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/numbers-iQunIAXf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/SSRProvider-CEHRCdjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/context-JwD-oSsl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNumberFormatter-c6GXymzg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/usePress-Bup4EGrp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/input-pAun1m1X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/links-DHZUhGz-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/popover-Gz-GJzym.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/switch-8sn_4qbh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-C8uQmBAN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/mode-DX8pdI-l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAsyncData-C4XRy1BE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/errors-2SszdW9t.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/error-banner-DUzsIXtq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-Bv2DBpIS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-CQ15EONK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/plus-BD5o34_i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-cw-CQd-1kjx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/trash-2-CyqGun26.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/triangle-alert-B65rDESJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ai-model-dropdown-71lgLrLy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-D_rSvXvJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/precisionRound-BMPhtTJQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-C92Rrpmf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/vega-loader.browser-CRZ52CKf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-BGrCWNss.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ErrorBoundary-ChCiwl15.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useInstallPackage-Bdnnp5fe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ImperativeModal-CUbWEBci.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cell-link-Bw5bzt4a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/datasource-B0OJBphG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/state-BfXVTTtD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/MarimoErrorOutput-5rudBbo3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-icon-BhONVREY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/html-to-image-DjukyIj4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/focus-D51fcwZX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/LazyAnyLanguageCodeMirror-yzHjsVJt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-5FQGJX7Z-CVUXBqX6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/katex-Dc8yG8NU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DhMlG2dP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/command-DhzFN2CJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-BhCZMKuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useRunCells-24p6hn99.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/purify.es-DNVQZNFu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/RenderHTML-CQZqVk1Z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useIframeCapabilities-DuIDx9mD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/formats-W1SWxSE3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/en-US-pRRbZZHE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isValid-DcYggVWP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dates-Dhn1r-h6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/maps-t9yNKYA8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/extends-B2LJnKU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/emotion-is-prop-valid.esm-DD4AwVTU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDateFormatter-CS4kbWl2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-DZR6ewbN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-CknFTI_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-Cs1JbsV6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/play-BPIh-ZEU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-components-CGlO4yUw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-display-B4mGvJ0X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeleteCell-5uYlTcQZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/icons-BhEXrzsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/process-output-CagdHMzs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/blob-CuXvdYPX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/objectWithoutPropertiesLoose-DaPAPabU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/esm-DpMp6qko.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/add-cell-with-ai-pVFp5LZG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chart-no-axes-column-W42b2ZIs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-function-CqXXKtIq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spec-D1kBp3jX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/column-preview-CxMrs0B_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toggle-jWKnIArU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/globals-DKH14XH0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/share-CbPtIlnM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-resizable-panels.browser.esm-Ctj_10o2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utilities.esm-CIPARd6-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/floating-outline-DcxjrFFt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAddCell-BmeZUK02.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/eye-off-BhExYOph.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/readonly-python-code-DyP9LVLc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-video-camera-DW3v07j2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-DuQOSW7G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-ccw-DLEiQDS3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/form-DUA_Rz_a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/field-BEg1eC0P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useBoolean-B1Xeh6vA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeepCompareMemoize-ZPd9PxYl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-CS34eOZi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/prop-types-BiQYf0aU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/es-D8BOePqo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/code-xml-XLwHyDBr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-B9SUL40m.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/house-DhFkiXz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/settings-DOXWMfVd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-C8Tw_XXG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/bundle.esm-2AjO7UK5.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-CikhHYAB.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "06_rdma_weight_sync.py",
            "mode": "read",
            "version": "0.19.7",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(r\"\"\"\n# RDMA \u0026 Weight Synchronization\n\nThis notebook explores efficient weight synchronization for async RL systems.\n\n**Outline:**\n\n1. **Why Weight Sync Matters** - On-policy vs off-policy, model scale\n2. **The Bandwidth Hierarchy** - NVLink, InfiniBand, PCIe\n3. **The Problem: Collectives Are Blocking** - Why RL needs something different\n4. **How RDMA Works** - ibverbs, one-sided operations\n5. **The Magic Pointer Pattern** - Control plane vs data plane separation\n6. **CPU Staging** - Decoupling trainer and generator timing\n7. **Circular Weight Buffers** - Versioning without memory churn\n8. **Weight Re-sharding** - Handling different tensor layouts\n9. **Putting It All Together** - The complete pattern\n\"\"\")", "code_hash": "253c975dac02c4eecec395f5a6f11359", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 1. Why Weight Sync Matters\n\n### The On-Policy Problem\n\nTraditional RL algorithms want to be **on-policy**: generate experience using the current\npolicy, then immediately use that experience to update the policy. This creates a tight loop:\n\n```\nOn-Policy RL:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  generate(policy_v1) \u2192 train(samples) \u2192 policy_v2 \u2192 repeat       \u2502\n\u2502                                                                  \u2502\n\u2502  Experience from v1 is only valid for updating v1                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Async RL breaks this rule.** Generators run continuously while the trainer updates weights.\nBy the time a sample reaches the trainer, it was generated by an old policy version:\n\n```\nAsync RL (off-policy):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator: policy_v1 \u2192 sample\u2081                                  \u2502\n\u2502  Trainer:   train(sample\u2081) \u2192 policy_v2                           \u2502\n\u2502  Generator: policy_v1 \u2192 sample\u2082  \u2190 still using v1!               \u2502\n\u2502  Trainer:   train(sample\u2082) \u2192 policy_v3                           \u2502\n\u2502                                                                  \u2502\n\u2502  Samples are \"stale\" - generated by older policy versions        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis **off-policy-ness** can work up to a degree, but must be limited. The generators\nneed fresh weights regularly to stay \"close enough\" to on-policy. Weight sync frequency\nbecomes a key hyperparameter trading off:\n\n- **Too slow**: Samples become too stale, training diverges\n- **Too fast**: Weight sync overhead dominates, negating async benefits\n\n### The Scale Problem\n\nFor LLM-based RL, the weights are **massive**. Let's calculate:\n\"\"\")", "code_hash": "adcd7c1a7fe508413fb842b361890260", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "# Calculate model sizes\n_models = [\n    (\"Llama 3.2 3B\", 3),\n    (\"Qwen 2.5 7B\", 7),\n    (\"Llama 3.1 70B\", 70),\n    (\"Llama 3.1 405B\", 405),\n    (\"DeepSeek V3 671B\", 671),\n]\n\nprint(\"Model Weight Sizes (bf16 precision):\\n\")\nprint(f\"{'Model':\u003C20} {'Weight Size'}\")\nprint(\"-\" * 35)\n\nfor _name, _params_b in _models:\n    _size_gb = _params_b * 2  # bf16 = 2 bytes per param\n\n    if _size_gb \u003E= 1000:\n        _size_str = f\"{_size_gb/1000:.1f} TB\"\n    else:\n        _size_str = f\"{_size_gb:.0f} GB\"\n\n    print(f\"{_name:\u003C20} {_size_str}\")\n\nprint(\"\\n\u2192 These weights need to move from trainer \u2192 generators\")\nprint(\"\u2192 For large models, this means crossing the network fabric\")\n\nmo.md(r\"\"\"\n### Why This Forces Cross-Node Transfer\n\nThe numbers speak for themselves:\n\n- A **70B model** has 140 GB of weights\n- A **405B model** has 810 GB of weights\n- **DeepSeek V3** has 1.3 TB of weights\n\nThese models are sharded across many GPUs, often spanning multiple nodes.\nWeight sync can't rely on NVLink alone - it must cross InfiniBand/RoCE.\n\nThis is why we need RDMA.\n\"\"\")", "code_hash": "74c70cf0623f5d30c14182baa0290a25", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 2. The Bandwidth Hierarchy\n\nModern HPC clusters have multiple interconnects with vastly different bandwidths:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                              NODE A                                                      \u2502\n\u2502                                                                                                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                         ======  64 GB/s PCIe                                             \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  ------ 48 GB/s ------ \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518      PCIe        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n                                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                        \u2502                                                    \u2502\n                                                        \u2502              InfiniBand Switch                     \u2502\n                                                        \u2502                                                    \u2502\n                                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510      PCIe        \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 ------ 48 GB/s ------  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                           ======  64 GB/s PCIe                                           \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              NODE B                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nBandwidth encoding (line intensity):\n  ########  NVLink/NVSwitch   900 GB/s   (GPU \u2194 GPU, same node)\n  ========  PCIe Gen5 / IB     50-64 GB/s (CPU\u2194GPU, CPU\u2194NIC, cross-node)\n  --------  CPU interconnect   48 GB/s   (CPU \u2194 CPU, same node)\n```\n\nRDMA can transfer between any registered memory (CPU or GPU) via the NICs.\n\n| Interconnect | Bandwidth | Latency | Use Case |\n|--------------|-----------|---------|----------|\n| **NVLink/NVSwitch** | 900 GB/s | ~1 \u03bcs | Same-node GPU\u2194GPU |\n| **InfiniBand NDR400** | 50 GB/s | ~1-2 \u03bcs | Cross-node RDMA |\n| **PCIe Gen5 x16** | 64 GB/s | ~1-2 \u03bcs | CPU\u2194GPU, CPU\u2194NIC |\n| **CPU interconnect** | 48 GB/s | ~100 ns | CPU\u2194CPU (same node) |\n\n**Key observations:**\n\n1. **NVLink dominates** - 900 GB/s is ~18x faster than cross-node RDMA. Same-node GPU\u2194GPU\n   communication is nearly free compared to crossing the network.\n\n2. **RDMA \u003E\u003E Ethernet** - InfiniBand/RoCE at 50 GB/s is ~4x faster than 100GbE (12.5 GB/s),\n   plus kernel bypass and lower latency. Worth the complexity for HPC workloads.\n\n3. **PCIe is faster than you'd think** - At 64 GB/s, CPU\u2194GPU transfers aren't the bottleneck\n   people often assume. The real cost is synchronization, not bandwidth.\n\n**Rule of thumb**: Place the most bandwidth-intensive, frequent operations on NVLink\n(gradients, activations). Use RDMA for cross-node communication (weight sync, sharding).\nPCIe is fine for occasional CPU\u2194GPU transfers.\n\nWe'll focus primarily on **NVLink** and **RDMA** for this notebook. Most people use these\nvia **collectives**, exposed through PyTorch distributed:\n\n```python\nimport torch.distributed as dist\n\n# Initialize process group - NCCL uses NVLink (same-node) and RDMA (cross-node)\ndist.init_process_group(backend=\"nccl\")\n\n# All-reduce: average gradients across all GPUs\ndist.all_reduce(gradients, op=dist.ReduceOp.SUM)\ngradients /= world_size\n\n# All-gather: collect tensors from all ranks\ngathered = [torch.empty_like(tensor) for _ in range(world_size)]\ndist.all_gather(gathered, tensor)\n\n# Broadcast: send from rank 0 to all others\ndist.broadcast(weights, src=0)\n```\n\nThis works great for training. But for RL weight sync, we need something different...\n\"\"\")", "code_hash": "cec1b0c381d3e84ce5137584cc45ab54", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "import torch", "code_hash": "e2ddceb8064dfb2235ad898d34eee19a", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 3. The Problem: Collectives Are Blocking\n\nCollectives work great for training - everyone computes gradients, then synchronizes.\nBut async RL has a different access pattern.\n\n### High Variance in Generation Times\n\nGenerators have wildly different completion times:\n- Some prompts \u2192 10 tokens (fast)\n- Other prompts \u2192 1000 tokens (slow)\n\nWith collectives, fast generators wait for slow ones:\n\n```\nGenerator 0: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\nGenerator 1: \u251c\u2500\u2500\u2500\u2500\u2500\u2500 gen (slow) \u2500\u2500\u2500\u2500\u2500\u2500\u2524\nGenerator 2: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\n                                      \u2193\n                          all_gather(weights)  # Everyone waits!\n```\n\n### What About send/recv?\n\nPyTorch distributed does have point-to-point primitives:\n\n```python\n# Sender side\ndist.send(tensor, dst=receiver_rank)\n\n# Receiver side\ndist.recv(tensor, src=sender_rank)\n```\n\nBut this is **two-sided** - both sender and receiver must coordinate:\n- Receiver must call `recv()` before sender's `send()` completes\n- Trainer would need to wait until generators are ready to receive\n- Still blocking on coordination!\n\n### The One-Sided Solution: RDMA\n\nWhat if the sender could write directly to the receiver's memory without coordination?\n\n```\nTwo-sided (send/recv):\n  Sender: \"I have data\"  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  Receiver: \"I'm ready\"\n  Sender: sends data     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  Receiver: receives data\n                         2 messages required\n\nOne-sided (RDMA):\n  Sender: writes directly to receiver's memory\n                         No coordination needed!\n```\n\nThis is what RDMA enables: **one-sided memory operations**.\n\"\"\")", "code_hash": "3635469f9ef34cc32298f48cd8a8e002", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 4. How RDMA Works (ibverbs)\n\nRDMA (Remote Direct Memory Access) lets one machine read/write another machine's memory\ndirectly, bypassing the kernel and CPU on both sides.\n\n### The ibverbs Stack\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Application (PyTorch, Monarch, etc.)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  libibverbs  (userspace RDMA API)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Provider driver (mlx5, efa, rxe, etc.)                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Hardware (InfiniBand NIC, RoCE NIC, etc.)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nWe'll focus on **InfiniBand** and **RoCE** (RDMA over Converged Ethernet).\nOther transports like AWS EFA exist but we won't cover them here.\n\n### Key RDMA Operations\n\n| Operation | Description |\n|-----------|-------------|\n| `RDMA_WRITE` | Write to remote memory (one-sided) |\n| `RDMA_READ` | Read from remote memory (one-sided) |\n| `SEND/RECV` | Two-sided messaging (like TCP) |\n\nThe magic is in `RDMA_WRITE` and `RDMA_READ` - they're **one-sided**:\n- Remote CPU is not involved\n- Remote application doesn't need to call anything\n- NIC handles everything in hardware\n\n### Memory Registration\n\nBefore RDMA, memory must be **registered** with the NIC:\n\n```python\n# Conceptually (actual ibverbs API is in C)\nmr = rdma_register_memory(buffer, size)\n# Returns:\n#   - lkey: local access key (for local operations)\n#   - rkey: remote access key (share with remote peer)\n#   - addr: physical/virtual address\n```\n\nThe `(addr, rkey)` pair is a **remote-accessible pointer**. Share it with a peer,\nand they can read/write your memory directly.\n\n### Queue Pair Setup\n\nBefore any RDMA operations, you need to establish a **Queue Pair (QP)** between\nsender and receiver. This is a one-time connection setup:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Sender    \u2502                           \u2502  Receiver   \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Create QP  \u2502 \u2500\u2500\u2500 exchange QP info \u2500\u2500\u2500\u25ba \u2502  Create QP  \u2502\n\u2502  (qp_num,   \u2502 \u25c4\u2500\u2500 (qp_num, lid, gid) \u2500\u2500 \u2502             \u2502\n\u2502   lid, gid) \u2502                           \u2502             \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Move QP to \u2502                           \u2502  Move QP to \u2502\n\u2502  RTR \u2192 RTS  \u2502                           \u2502  RTR \u2192 RTS  \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Now ready  \u2502 \u2550\u2550\u2550 RDMA operations \u2550\u2550\u2550\u2550\u25ba \u2502  Now ready  \u2502\n\u2502  for RDMA!  \u2502                           \u2502  for RDMA!  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis is where **Monarch actors** shine. Because you can spawn arbitrary actors,\nyou can create **RDMA Manager actors** that:\n- Initialize QPs on their respective hosts\n- Exchange QP info via actor messages\n- Manage the connection lifecycle\n\n```python\n# Monarch pattern: RDMA managers as actors\nclass RDMAManager(Actor):\n    def __init__(self):\n        self.qp = create_queue_pair()\n        self.qp_info = get_qp_info(self.qp)  # (qp_num, lid, gid)\n\n    @endpoint\n    def get_qp_info(self) -\u003E QpInfo:\n        return self.qp_info\n\n    @endpoint\n    def connect(self, remote_qp_info: QpInfo):\n        # Transition QP: INIT \u2192 RTR \u2192 RTS\n        connect_qp(self.qp, remote_qp_info)\n\n# Setup: exchange QP info via actor messages, then RDMA is ready\ntrainer_info = trainer_rdma.get_qp_info.call_one().get()\ngenerator_rdma.connect.call_one(trainer_info).get()\n```\n\nThe actor abstraction makes RDMA connection management natural and composable.\n\n### Monarch Using Monarch: RdmaController\n\nHere's the cool part: **Monarch uses itself** to manage RDMA infrastructure. Looking at\nthe actual Python code in `monarch/_src/rdma/rdma.py`:\n\n```python\n# From Monarch's RDMA implementation\nfrom monarch._src.actor.proc_mesh import get_or_spawn_controller\n\nclass RdmaController(Actor):\n    '''Singleton controller that coordinates RDMA initialization.'''\n\n    def __init__(self):\n        # Track which proc meshes have RDMA initialized\n        self._manager_futures: dict[ProcMesh, Future[RdmaManager]] = {}\n\n    @endpoint\n    async def init_rdma_on_mesh(self, proc_mesh: ProcMesh) -\u003E None:\n        '''Lazily initialize RDMA on a proc mesh.'''\n        if proc_mesh not in self._manager_futures:\n            self._manager_futures[proc_mesh] = Future(\n                coro=RdmaManager.create(proc_mesh)\n            )\n        await self._manager_futures[proc_mesh]\n\n# Cached initialization - only runs once per process\n@functools.cache\ndef _ensure_init_rdma_manager():\n    async def task():\n        controller = await get_or_spawn_controller(\"rdma_controller\", RdmaController)\n        await controller.init_rdma_on_mesh.call_one(current_proc_mesh())\n    return spawn_task(task())\n```\n\nThis is **Monarch building Monarch** - the RDMA subsystem uses the same patterns:\n\n- `get_or_spawn_controller(\"rdma_controller\", RdmaController)` ensures one global controller\n- The controller lazily initializes RDMA managers per proc mesh\n- `@functools.cache` ensures we only bootstrap once per process\n- Under the hood, the actual RDMA operations are in Rust (`RdmaManagerActor`)\n\nIt's actors all the way down.\n\n### Why This Matters for Weight Sync\n\nRemember: CPU memory AND GPU memory can both be registered for RDMA.\n\n```\nTrainer:\n  1. Register weight buffer with RDMA NIC\n  2. Get (addr, rkey) handle\n  3. Share handle with generators (tiny message)\n\nGenerator:\n  1. Receive handle\n  2. RDMA_READ directly from trainer's memory\n  3. No coordination with trainer needed!\n```\n\nThe trainer doesn't even know when generators pull weights. True one-sided.\n\"\"\")", "code_hash": "0a71e903f733748118150942a35efc3d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 5. The Magic Pointer Pattern\n\nNow here's the key insight from our RDMA discussion: to represent remote data,\nwe only need a **tiny handle** - the `(addr, rkey, size)` tuple.\n\nMonarch wraps this in `RDMABuffer`. Let's see how small it actually is:\n\"\"\")", "code_hash": "e4350ebea9f184ec46ac1d92959c648c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "# Central imports for all RDMA examples in this notebook\nimport time\nfrom monarch.actor import Actor, endpoint, this_host, current_rank\nfrom monarch.rdma import RDMABuffer, RDMAAction, is_rdma_available", "code_hash": "93cd1380c225976a61d1164279118d8e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "# Measure actual size of RDMABuffer handles\nimport pickle\n\ndef show_fallback():\n    \"\"\"Fallback: show expected sizes based on RDMABuffer structure.\"\"\"\n    print(\"(RDMA not available - showing expected handle sizes)\\n\")\n    print(\"RDMABuffer contains: addr (8B) + rkey (4B) + size (8B) + owner (~100B)\")\n    print(\"Total serialized size: ~150-200 bytes regardless of tensor size\\n\")\n\n    sizes = [(\"1 KB\", 1024), (\"1 MB\", 1024**2), (\"1 GB\", 1024**3)]\n    handle_bytes = 150  # approximate\n\n    for name, tensor_bytes in sizes:\n        ratio = tensor_bytes / handle_bytes\n        print(f\"{name:\u003C8} tensor \u2192 ~150 byte handle \u2192 {ratio:,.0f}x compression\")\n\n    print(\"\\n\u2192 Handle size is O(1) regardless of tensor size!\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback()\n    else:\n        class BufferSizeDemo(Actor):\n            \"\"\"Actor that creates RDMABuffers and measures their size.\"\"\"\n\n            @endpoint\n            def measure_buffer_sizes(self) -\u003E list:\n                import pickle as _pickle\n                results = []\n                sizes = [\n                    (\"1 KB\", 256),\n                    (\"1 MB\", 256 * 1024),\n                    (\"10 MB\", 256 * 1024 * 10),\n                ]\n\n                for name, numel in sizes:\n                    tensor = torch.randn(numel)\n                    tensor_bytes = tensor.numel() * tensor.element_size()\n\n                    byte_tensor = tensor.view(torch.uint8).flatten()\n                    buffer = RDMABuffer(byte_tensor)\n                    handle_bytes = len(_pickle.dumps(buffer))\n\n                    results.append((name, tensor_bytes, handle_bytes))\n\n                return results\n\n        host = this_host()\n        proc = host.spawn_procs({\"procs\": 1})\n        demo = proc.spawn(\"buffer_demo\", BufferSizeDemo)\n\n        results = demo.measure_buffer_sizes.call_one().get()\n\n        print(\"RDMABuffer handle size vs actual tensor size:\\n\")\n        print(f\"{'Tensor Size':\u003C12} {'Actual Bytes':\u003C15} {'Handle Size':\u003C15} {'Ratio':\u003C10}\")\n        print(\"-\" * 55)\n\n        for name, tensor_bytes, handle_bytes in results:\n            ratio = tensor_bytes / handle_bytes\n            print(f\"{name:\u003C12} {tensor_bytes:\u003E12,} B   {handle_bytes:\u003E6} B        {ratio:\u003E8,.0f}x\")\n\n        print(\"\\n\u2192 Handle size is O(1) regardless of tensor size!\")\n\nexcept Exception as e:\n    print(f\"(RDMA setup failed: {e})\\n\")\n    show_fallback()", "code_hash": "33f52127ad06527402c41752fe53ec8f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(r\"\"\"\n### The Magic Pointer\n\nThis is the core pattern: **separate control plane from data plane**.\n\n- **Control plane** (actor messages): Send tiny handle (~100 bytes)\n- **Data plane** (RDMA): Bulk transfer of actual data (~10 GB)\n\nThink of `RDMABuffer` as a **magic pointer** - it's a pointer that works across machines:\n\n```\nTrainer                              Generator\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 weights     \u2502                     \u2502 local copy  \u2502\n\u2502 (10 GB)     \u2502                     \u2502 (empty)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                   \u2502\n       \u2502  1. Create RDMABuffer             \u2502\n       \u2502     (register memory, get handle) \u2502\n       \u2502                                   \u2502\n       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 2. Send handle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502  (~100 bytes via actor)\n       \u2502                                   \u2502\n       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500 3. RDMA read \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  (~10 GB via hardware)\n       \u2502        (no trainer involvement!)  \u2502\n```\n\nThe trainer doesn't even know when generators pull weights. True one-sided.\n\n### RDMABuffer in Action\n\nFrom `monarch.rdma`:\n\n```python\nfrom monarch.rdma import RDMABuffer\n\n# Trainer side: register weights\nweights = torch.randn(1024, 1024, device=\"cuda\")\nbuffer = RDMABuffer(weights.view(torch.uint8).flatten())\n\n# Return buffer as part of an endpoint response\n# This is a TINY message - just the handle!\n@endpoint\ndef get_weight_handle(self) -\u003E RDMABuffer:\n    return self.buffer\n\n# Generator side: receive handle, pull directly into GPU\nhandle = trainer.get_weight_handle.call_one().get()  # Tiny message\ngpu_weights = model.weights.view(torch.uint8).flatten()\nhandle.read_into(gpu_weights).get()                   # Bulk RDMA \u2192 GPU\n```\n\nSee the [GRPO Actor example](https://meta-pytorch.org/monarch/generated/examples/grpo_actor.html)\nfor a minimal implementation showing RDMA data flow. We'll build a more complete\nversion in the following sections.\n\"\"\")", "code_hash": "70a1235b5a21ad6ce9e6c68db0e1da21", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "mo.md(r\"\"\"\n### The Cost of Memory Registration\n\nRDMA memory registration is **expensive**:\n- Pins physical pages (prevents swapping)\n- Creates IOMMU/DMA mappings in the NIC\n- Can take milliseconds for large buffers\n\nBut here's the good news: **Monarch caches all memory region registrations.** Once a buffer\nis registered, subsequent uses hit the cache, making it essentially free in steady state.\n\nLet's see this in action with 3 approaches:\n\"\"\")", "code_hash": "289e5d25880fe95c9cc9cfaa728a34fb", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "mo.md(r\"\"\"\n#### Approach 1: Naive\n\nCreate new RDMABuffer on each transfer - registration happens on first use:\n\"\"\")", "code_hash": "6e195070f991709a57a7bf019f11e5f5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "class NaiveSender(Actor):\n    \"\"\"Creates new RDMABuffer handles every transfer. Expensive!\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = [torch.zeros(size, dtype=torch.float32) for size in layer_sizes]\n        for i, layer in enumerate(self.layers):\n            layer.fill_(float(i + 1))\n\n    @endpoint\n    def get_fresh_handles(self) -\u003E list:\n        handles = []\n        for size, layer in zip(self.layer_sizes, self.layers):\n            byte_view = layer.view(torch.uint8).flatten()\n            handles.append((size, RDMABuffer(byte_view)))\n        return handles\n\n\nclass NaiveReceiver(Actor):\n    \"\"\"Receives from naive sender - pays MR cost every step.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = [torch.zeros(size, dtype=torch.float32) for size in layer_sizes]\n        self.rank = current_rank().rank\n\n    @endpoint\n    def receive_step(self, sender: NaiveSender) -\u003E dict:\n        start = time.perf_counter()\n        handles = sender.get_fresh_handles.call_one().get()\n        for i, (size, handle) in enumerate(handles):\n            byte_view = self.layers[i].view(torch.uint8).flatten()\n            handle.read_into(byte_view).get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\nprint(\"NaiveSender: Re-registers all parameters on every call\")", "code_hash": "cb0763f4294eadb91b3e3d6ecb7660ee", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "mo.md(r\"\"\"\n#### Approach 2: Contiguous Buffer\n\nAllocate one buffer, register at init time:\n\"\"\")", "code_hash": "8ea12b5c5327cddc0ab2a40368431518", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "class ContiguousSender(Actor):\n    \"\"\"One buffer, one MR, registered at startup.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        total_size = sum(layer_sizes)\n\n        # One contiguous buffer\n        self.buffer = torch.zeros(total_size, dtype=torch.float32)\n        offset = 0\n        for i, size in enumerate(layer_sizes):\n            self.buffer[offset : offset + size].fill_(float(i + 1))\n            offset += size\n\n        # Register ONCE at startup\n        byte_view = self.buffer.view(torch.uint8).flatten()\n        self.handle = RDMABuffer(byte_view)\n\n    @endpoint\n    def get_handle(self) -\u003E tuple:\n        return (len(self.buffer), self.handle)  # Same handle every time!\n\n\nclass ContiguousReceiver(Actor):\n    \"\"\"Receives from contiguous sender - fast after first step.\"\"\"\n\n    def __init__(self, total_size: int):\n        self.buffer = torch.zeros(total_size, dtype=torch.float32)\n        self.rank = current_rank().rank\n\n    @endpoint\n    def receive_step(self, sender: ContiguousSender) -\u003E dict:\n        start = time.perf_counter()\n        size, handle = sender.get_handle.call_one().get()\n        byte_view = self.buffer.view(torch.uint8).flatten()\n        handle.read_into(byte_view).get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\nprint(\"ContiguousSender: Registers once, reuses same handle\")", "code_hash": "b20940a01eb850b248043c377b34e75c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "mo.md(r\"\"\"\n#### Approach 3: Scattered + RDMAAction\n\nRegister each buffer at init, build transfer plan once via handshake:\n\n\n**What is RDMAAction?**\n\nThink of `RDMAAction` as a **transfer plan**. You\ndescribe all the reads/writes you want\nto do, then `submit()` executes the whole plan at once:\n\n```python\n# Build the plan once\naction = RDMAAction()\naction.read_into(handle1, local_buffer1)\naction.read_into(handle2, local_buffer2)\naction.read_into(handle3, local_buffer3)\n\n# Execute whenever you want - just one call\naction.submit().get()\n```\n\nThis is useful when you have many scattered buffers (like model parameters) and want to batch them into a single logical operation.\n\"\"\")", "code_hash": "084714f2ffb4ab350d8eb1663c8d1346", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "class ScatteredSender(Actor):\n    \"\"\"Multiple buffers, each registered once at startup.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = []\n        self.handles = []\n\n        for i, size in enumerate(layer_sizes):\n            layer = torch.zeros(size, dtype=torch.float32)\n            layer.fill_(float(i + 1))\n            self.layers.append(layer)\n            # Register ONCE at startup\n            byte_view = layer.view(torch.uint8).flatten()\n            self.handles.append(RDMABuffer(byte_view))\n\n    @endpoint\n    def get_handles(self) -\u003E list:\n        return [(size, handle) for size, handle in zip(self.layer_sizes, self.handles)]\n\nclass ScatteredReceiver(Actor):\n    \"\"\"Receives from scattered sender with RDMAAction batching.\"\"\"\n\n    def __init__(self, layer_sizes: list):\n        self.layer_sizes = layer_sizes\n        self.layers = [torch.zeros(size, dtype=torch.float32) for size in layer_sizes]\n        self.rank = current_rank().rank\n        self.action = None  # Built on handshake\n\n    @endpoint\n    def handshake(self, sender: ScatteredSender):\n        \"\"\"Call once to build the RDMAAction transfer plan.\"\"\"\n        handles = sender.get_handles.call_one().get()\n        self.action = RDMAAction()\n        for i, (size, handle) in enumerate(handles):\n            byte_view = self.layers[i].view(torch.uint8).flatten()\n            self.action.read_into(handle, byte_view)\n        return \"Transfer plan ready\"\n\n    @endpoint\n    def receive_step(self) -\u003E dict:\n        \"\"\"Execute the cached transfer plan.\"\"\"\n        start = time.perf_counter()\n        self.action.submit().get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\nprint(\"ScatteredSender: Registers each layer once\")\nprint(\"ScatteredReceiver: handshake() builds plan, receive_step() executes it\")", "code_hash": "cf2558bd29e83f53df64e3e26f3b7b6d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "mo.md(r\"\"\"\n**Pattern recap:**\n\n- **Naive**: Create RDMABuffer in the transfer endpoint\n- **Contiguous**: Register one big buffer in `__init__`\n- **Scattered + RDMAAction**: Register multiple buffers in `__init__`, build transfer plan in `handshake()`\n\nLet's benchmark to see the difference:\n\"\"\")", "code_hash": "bc36214cf2b8bb000ba1be74598e2f61", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "def run_benchmark():\n    \"\"\"Compare the three approaches over multiple steps.\"\"\"\n    layer_sizes = [1000, 5000, 2000]  # 8000 floats total\n    total_size = sum(layer_sizes)\n    num_steps = 5\n\n    host = this_host()\n    sender_procs = host.spawn_procs({\"procs\": 1})\n    receiver_procs = host.spawn_procs({\"procs\": 1})\n\n    print(\"=== RDMA Registration Benchmark ===\")\n    print(f\"Transferring {total_size} floats ({total_size * 4 / 1024:.1f} KB) x {num_steps} steps\\n\")\n\n    results = {}\n\n    # Naive approach\n    naive_sender = sender_procs.spawn(\"naive_s\", NaiveSender, layer_sizes)\n    naive_receiver = receiver_procs.spawn(\"naive_r\", NaiveReceiver, layer_sizes)\n    times = []\n    for step in range(num_steps):\n        r = naive_receiver.receive_step.call_one(naive_sender).get()\n        times.append(r[\"elapsed_ms\"])\n    results[\"Naive\"] = times\n    print(f\"Naive (re-register each step):\")\n    for i, t in enumerate(times):\n        print(f\"  Step {i+1}: {t:.2f}ms\")\n    print(f\"  Average: {sum(times)/len(times):.2f}ms\\n\")\n\n    # Contiguous approach\n    cont_sender = sender_procs.spawn(\"cont_s\", ContiguousSender, layer_sizes)\n    cont_receiver = receiver_procs.spawn(\"cont_r\", ContiguousReceiver, total_size)\n    times = []\n    for step in range(num_steps):\n        r = cont_receiver.receive_step.call_one(cont_sender).get()\n        times.append(r[\"elapsed_ms\"])\n    results[\"Contiguous\"] = times\n    print(f\"Contiguous (register once):\")\n    for i, t in enumerate(times):\n        print(f\"  Step {i+1}: {t:.2f}ms\")\n    print(f\"  Average: {sum(times)/len(times):.2f}ms\\n\")\n\n    # Scattered + RDMAAction approach\n    scat_sender = sender_procs.spawn(\"scat_s\", ScatteredSender, layer_sizes)\n    scat_receiver = receiver_procs.spawn(\"scat_r\", ScatteredReceiver, layer_sizes)\n    scat_receiver.handshake.call_one(scat_sender).get()  # Build transfer plan once\n    times = []\n    for step in range(num_steps):\n        r = scat_receiver.receive_step.call_one().get()  # Just execute cached plan\n        times.append(r[\"elapsed_ms\"])\n    results[\"Scattered\"] = times\n    print(f\"Scattered + RDMAAction (register once, batch):\")\n    for i, t in enumerate(times):\n        print(f\"  Step {i+1}: {t:.2f}ms\")\n    print(f\"  Average: {sum(times)/len(times):.2f}ms\\n\")\n\n    print(\"=== What's Happening ===\")\n    print(\"Naive step 1: Cold MR registration (~2000ms)\")\n    print(\"Naive steps 2+: Cache hit, MR already registered (~10ms)\")\n    print(\"Contiguous/Scattered: Registration happened at spawn time, not during benchmark\")\n\n    return results\n\nbenchmark_results = run_benchmark()", "code_hash": "df277977136dfc231595fcc694a54d3d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}, {"code": "mo.md(r\"\"\"\n**What the benchmark shows:**\n\n- **Naive**: First call is ~2000ms (cold registration), subsequent calls ~10ms (cache hit)\n- **Contiguous/Scattered**: All calls are fast (~4-9ms) because registration happened\n  at spawn time, before the timing loop started\n\n*Note: RDMAAction (~9ms) is slower than Contiguous (~4ms) due to Python overhead.\nMoving the batching logic to Rust is a planned optimization.*\n\"\"\")", "code_hash": "cb64b2d65765fb608f01d2e9c51384c0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ulZA", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Two Weight Sync Patterns\n\nWith RDMABuffer as our building block, there are two main approaches:\n\n| Pattern | How it works | Trade-offs |\n|---------|--------------|------------|\n| **CPU Staging** | GPU \u2192 CPU buffer \u2192 RDMA \u2192 CPU \u2192 GPU | One MR, simple, but copies |\n| **Direct GPU** | GPU \u2192 RDMA \u2192 GPU (GPUDirect) | No copies, but one MR per param |\n\n**Pattern 1: CPU Staging (Contiguous Buffer)**\n\nPack all parameters into one contiguous CPU buffer, register once:\n\n```python\nclass Trainer(Actor):\n    def __init__(self):\n        # Calculate total size for all parameters\n        total_bytes = sum(p.numel() * p.element_size() for p in model.parameters())\n\n        # Allocate ONE contiguous buffer, register ONCE\n        self.staging_buffer = torch.empty(total_bytes, dtype=torch.uint8)\n        self.handle = RDMABuffer(self.staging_buffer)\n\n        # Track where each param lives in the buffer\n        self.param_offsets = compute_offsets(model)\n\n    def pack_weights(self):\n        '''Copy all params into contiguous buffer.'''\n        for name, param in model.named_parameters():\n            offset = self.param_offsets[name]\n            self.staging_buffer[offset:offset+size].copy_(param.view(torch.uint8))\n\n    @endpoint\n    def get_weight_handle(self) -\u003E RDMABuffer:\n        self.pack_weights()\n        return self.handle  # Same handle, new data\n```\n\n**Pattern 2: Direct GPU MRs**\n\nRegister each GPU parameter directly, no CPU copies:\n\n```python\nclass Trainer(Actor):\n    def __init__(self):\n        # Register each param ONCE at startup\n        self.handles = {}\n        for name, param in model.named_parameters():\n            byte_view = param.data.view(torch.uint8).flatten()\n            self.handles[name] = RDMABuffer(byte_view)\n\n    @endpoint\n    def get_param_handles(self) -\u003E dict[str, RDMABuffer]:\n        # Handles are reused - data updates in place\n        return self.handles\n```\n\nBoth patterns amortize MR registration cost across training iterations.\nLet's look at CPU staging in more detail (it's more common in async RL).\n\"\"\")", "code_hash": "b95b07f45da7a3e33ec1b3389ffa3e1d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 6. CPU Staging Pattern\n\n### GPU-Native RDMA Works!\n\nFirst, let's be clear: **GPU-native RDMA works** and is fast:\n- GPUDirect RDMA: NIC reads directly from GPU memory\n- No CPU copy needed (when hardware supports it)\n- Great for synchronous transfers\n\n### Why CPU Staging for Async RL?\n\nThe issue isn't bandwidth - it's **timing**:\n\n```\nDirect GPU\u2192GPU RDMA:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Generator GPU is mid-inference                       \u2502\n\u2502 \u251c\u2500\u2500 layer 1 \u2500\u2500\u2524 [RDMA arrives, needs sync!]         \u2502\n\u2502               \u2193                                      \u2502\n\u2502         cudaDeviceSynchronize()  \u2190 Blocks inference! \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nWith CPU staging, nothing on the critical path blocks:\n\n```\nTrainer GPU \u2500\u2500\u25ba CPU staging buffer (RDMA registered)\n                      \u2502\n                      \u2502 [Sits here, ready anytime]\n                      \u2502\n                      \u25bc\nGenerator grabs when ready \u2500\u2500\u25ba Generator GPU\n```\n\nThe CPU buffer is a **temporal decoupling point**.\n\"\"\")", "code_hash": "95ddd9de3d438a8eef2049b1c18a7d8c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Pvdt", "name": "_"}, {"code": "def demonstrate_cpu_staging():\n    \"\"\"Demonstrate the CPU staging pattern.\"\"\"\n    if not torch.cuda.is_available():\n        print(\"CUDA not available - showing conceptual flow\")\n        return\n\n    # Trainer side: GPU weights \u2192 CPU staging buffer (RDMA registered)\n    trainer_weights = torch.randn(1000, 1000, device=\"cuda:0\")\n\n    # Pin memory for efficient transfers and RDMA registration\n    cpu_staging = torch.empty_like(trainer_weights, device=\"cpu\").pin_memory()\n\n    # D2H: Trainer dumps to CPU (async, non-blocking for trainer)\n    cpu_staging.copy_(trainer_weights, non_blocking=True)\n    torch.cuda.synchronize()  # Just for timing demo\n\n    print(\"Trainer: Weights copied to CPU staging buffer (RDMA registered)\")\n    print(f\"  GPU memory: {trainer_weights.device}\")\n    print(f\"  CPU staging: pinned={cpu_staging.is_pinned()}\")\n\n    # Generator side: RDMA pulls from trainer's CPU \u2192 directly to generator's GPU\n    # (In this demo we simulate the RDMA transfer with a local copy)\n    generator_gpu_weights = torch.empty_like(cpu_staging, device=\"cuda:0\")\n    generator_gpu_weights.copy_(cpu_staging, non_blocking=True)  # Simulates RDMA \u2192 GPU\n    torch.cuda.synchronize()\n\n    print(\"Generator: Weights loaded directly to GPU (via RDMA)\")\n    print(f\"  Weights match: {torch.allclose(trainer_weights, generator_gpu_weights)}\")\n\ndemonstrate_cpu_staging()", "code_hash": "dd06d4354b46dece7fc2c1062c403486", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZBYS", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 7. Circular Weight Buffers\n\n### The Versioning Problem\n\nIn async RL, trainer updates weights continuously. Generators need to:\n1. **Grab the latest** weights (not stale ones)\n2. **Not block** waiting for updates\n3. **Avoid memory churn** (re-registering RDMA buffers is expensive)\n\n### Solution: Circular Buffer\n\n```\nTrainer writes:     v0 \u2192 v1 \u2192 v2 \u2192 v3 \u2192 v4 \u2192 v5 \u2192 ...\n                     \u2193    \u2193    \u2193\nBuffer slots:      [slot0][slot1][slot2]  (circular, reused)\n                     v3    v4    v5\n\nGenerator reads: \"Give me latest\" \u2192 v5\n```\n\nBenefits:\n- **Pre-registered RDMA buffers** - no memory registration on hot path\n- **Lock-free reads** - generators always get a consistent snapshot\n- **Bounded memory** - only N versions in flight\n\"\"\")", "code_hash": "309c675f1f544527fcf5a1fb0f8ee398", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aLJB", "name": "_"}, {"code": "from threading import Lock as _Lock\nfrom typing import Tuple as _Tuple, Optional as _Opt\n\nclass CircularWeightBuffer:\n    \"\"\"Circular buffer for versioned weight storage.\n\n    In production, this would be used inside a Monarch actor and slots\n    would be registered with RDMABuffer at init time.\n    \"\"\"\n\n    def __init__(self, template_tensor: torch.Tensor, n_slots: int = 3):\n        self.n_slots = n_slots\n        self.slots = [\n            torch.empty_like(template_tensor).pin_memory()\n            if template_tensor.device.type == \"cpu\"\n            else torch.empty_like(template_tensor, device=\"cpu\").pin_memory()\n            for _ in range(n_slots)\n        ]\n        self.latest_version = 0\n        self._lock = _Lock()\n\n        # In production (inside a Monarch actor):\n        # self.rdma_handles = [RDMABuffer(slot.view(torch.uint8).flatten()) for slot in self.slots]\n        # This pre-registers all slots with RDMA at init time (amortizes MR cost)\n\n    def publish(self, weights: torch.Tensor) -\u003E int:\n        \"\"\"Trainer publishes new weights. Returns version number.\"\"\"\n        with self._lock:\n            slot_idx = self.latest_version % self.n_slots\n            self.slots[slot_idx].copy_(weights)\n            self.latest_version += 1\n            return self.latest_version - 1\n\n    def get_latest(self) -\u003E _Tuple[torch.Tensor, int]:\n        \"\"\"Generator gets latest weights. Non-blocking.\"\"\"\n        with self._lock:\n            if self.latest_version == 0:\n                raise RuntimeError(\"No weights published yet\")\n            slot_idx = (self.latest_version - 1) % self.n_slots\n            version = self.latest_version - 1\n            return self.slots[slot_idx].clone(), version\n\n    def get_version(self, version: int) -\u003E _Opt[torch.Tensor]:\n        \"\"\"Get specific version if still available.\"\"\"\n        with self._lock:\n            oldest_available = max(0, self.latest_version - self.n_slots)\n            if version \u003C oldest_available or version \u003E= self.latest_version:\n                return None\n            slot_idx = version % self.n_slots\n            return self.slots[slot_idx].clone()\n\n# Demo\n_template = torch.randn(100, 100)\nweight_buffer = CircularWeightBuffer(_template, n_slots=3)\n\n# Trainer publishes versions\nfor _v in range(5):\n    _new_weights = torch.randn(100, 100) * (_v + 1)\n    published_v = weight_buffer.publish(_new_weights)\n    print(f\"Published version {published_v}\")\n\n# Generator grabs latest\nlatest_weights, latest_version = weight_buffer.get_latest()\nprint(f\"\\nGenerator got version {latest_version}, weights mean: {latest_weights.mean():.2f}\")\n\n# Try to get old version (might be evicted)\nold_weights = weight_buffer.get_version(1)\nprint(f\"Version 1 available: {old_weights is not None}\")\n\nprint(\"\\nIn production: RDMABuffer handles would be pre-registered at init time\")\nprint(\"Generators would call get_latest_handle() to get RDMA handle + version\")", "code_hash": "d6d5d71e57550b8cb9c32b20239ef5bc", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nHfw", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 8. Weight Re-sharding\n\n### The Sharding Mismatch Problem\n\nTrainer and Generator often have **different tensor layouts**:\n\n| Role | Parallelism | Sharding |\n|------|-------------|----------|\n| Trainer | FSDP (8 GPUs) | `Shard(0)` - rows split across 8 GPUs |\n| Generator | TP (2 GPUs) | `Shard(1)` - columns split across 2 GPUs |\n\nDirect weight transfer doesn't work - we need **re-sharding**.\n\n```\nTrainer (row-sharded):          Generator (column-sharded):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GPU 0: rows 0-127\u2502            \u2502 GPU 0   \u2502 GPU 1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u2192      \u2502 cols    \u2502 cols    \u2502\n\u2502 GPU 1: rows 128+ \u2502            \u2502 0-511   \u2502 512+    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\"\"\")", "code_hash": "410bc4300bcb24d7481c1df0d3cc170f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "xXTn", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Approach 1: Gather Then Slice\n\nSimple but inefficient:\n\n```\n1. Each receiver gathers ALL sender shards \u2192 full tensor\n2. Each receiver slices out its portion\n```\n\n**Pros**: Simple, works with any sharding\n**Cons**: 2x redundant data transfer (each receiver gets everything)\n\n### Approach 2: Routed/Direct Transfer\n\nOptimal but complex:\n\n```\n1. Pre-compute which sender chunks overlap with which receiver regions\n2. Send only the exact chunks needed\n3. Receivers place chunks directly in correct positions\n```\n\n**Pros**: Minimal bandwidth (no redundancy)\n**Cons**: Complex overlap computation\n\"\"\")", "code_hash": "cf55cb42141c833974d8ecb1b6877238", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "AjVT", "name": "_"}, {"code": "from dataclasses import dataclass\nfrom typing import List, Tuple\n\n@dataclass\nclass ShardMetadata:\n    \"\"\"Metadata describing a tensor shard.\"\"\"\n    rank: int\n    global_shape: Tuple[int, ...]\n    offset: Tuple[int, ...]  # Start position in global tensor\n    local_shape: Tuple[int, ...]  # Shape of this shard\n\ndef compute_shard_metadata(\n    global_shape: Tuple[int, int],\n    num_ranks: int,\n    shard_dim: int,\n) -\u003E List[ShardMetadata]:\n    \"\"\"Compute shard metadata for a given sharding.\"\"\"\n    shards = []\n    dim_size = global_shape[shard_dim]\n    shard_size = dim_size // num_ranks\n\n    for rank in range(num_ranks):\n        offset = [0, 0]\n        local_shape = list(global_shape)\n\n        offset[shard_dim] = rank * shard_size\n        local_shape[shard_dim] = shard_size\n\n        shards.append(ShardMetadata(\n            rank=rank,\n            global_shape=global_shape,\n            offset=tuple(offset),\n            local_shape=tuple(local_shape),\n        ))\n\n    return shards\n\n# Demo: Trainer has row-sharding, Generator has column-sharding\n_global_shape = (1024, 1024)\n\ntrainer_shards = compute_shard_metadata(_global_shape, num_ranks=4, shard_dim=0)\ngenerator_shards = compute_shard_metadata(_global_shape, num_ranks=2, shard_dim=1)\n\nprint(\"Trainer shards (row-wise, 4 GPUs):\")\nfor s in trainer_shards:\n    print(f\"  Rank {s.rank}: offset={s.offset}, shape={s.local_shape}\")\n\nprint(\"\\nGenerator shards (column-wise, 2 GPUs):\")\nfor s in generator_shards:\n    print(f\"  Rank {s.rank}: offset={s.offset}, shape={s.local_shape}\")", "code_hash": "01a93cde7e5ea82b6a4aa8a7a8c4acf8", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "pHFh", "name": "_"}, {"code": "@dataclass\nclass TransferChunk:\n    \"\"\"A chunk to transfer from sender to receiver.\"\"\"\n    sender_rank: int\n    receiver_rank: int\n    sender_offset: Tuple[int, int]  # Where to read from sender\n    receiver_offset: Tuple[int, int]  # Where to write in receiver\n    shape: Tuple[int, int]  # Shape of the chunk\n\ndef compute_overlap(\n    sender: ShardMetadata,\n    receiver: ShardMetadata,\n) -\u003E TransferChunk | None:\n    \"\"\"Compute overlap between sender and receiver shards.\"\"\"\n    # Find intersection in global coordinates\n    s_start = sender.offset\n    s_end = (s_start[0] + sender.local_shape[0], s_start[1] + sender.local_shape[1])\n\n    r_start = receiver.offset\n    r_end = (r_start[0] + receiver.local_shape[0], r_start[1] + receiver.local_shape[1])\n\n    # Compute intersection\n    inter_start = (max(s_start[0], r_start[0]), max(s_start[1], r_start[1]))\n    inter_end = (min(s_end[0], r_end[0]), min(s_end[1], r_end[1]))\n\n    # Check if there's actual overlap\n    if inter_start[0] \u003E= inter_end[0] or inter_start[1] \u003E= inter_end[1]:\n        return None\n\n    shape = (inter_end[0] - inter_start[0], inter_end[1] - inter_start[1])\n\n    # Convert to local coordinates\n    sender_local = (inter_start[0] - s_start[0], inter_start[1] - s_start[1])\n    receiver_local = (inter_start[0] - r_start[0], inter_start[1] - r_start[1])\n\n    return TransferChunk(\n        sender_rank=sender.rank,\n        receiver_rank=receiver.rank,\n        sender_offset=sender_local,\n        receiver_offset=receiver_local,\n        shape=shape,\n    )\n\ndef compute_transfer_plan(\n    sender_shards: List[ShardMetadata],\n    receiver_shards: List[ShardMetadata],\n) -\u003E List[TransferChunk]:\n    \"\"\"Compute all transfers needed for re-sharding.\"\"\"\n    transfers = []\n    for sender in sender_shards:\n        for receiver in receiver_shards:\n            chunk = compute_overlap(sender, receiver)\n            if chunk is not None:\n                transfers.append(chunk)\n    return transfers\n\n# Compute transfer plan\ntransfer_plan = compute_transfer_plan(trainer_shards, generator_shards)\n\nprint(f\"Transfer plan: {len(transfer_plan)} chunks needed\\n\")\nfor chunk in transfer_plan:\n    print(f\"Sender {chunk.sender_rank} \u2192 Receiver {chunk.receiver_rank}\")\n    print(f\"  Read from sender offset {chunk.sender_offset}, shape {chunk.shape}\")\n    print(f\"  Write to receiver offset {chunk.receiver_offset}\")\n    print()", "code_hash": "dd9ef142fcda82825b003d755d4b8bc5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "NCOB", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Live Benchmark: Gather vs Routed\n\nLet's benchmark the two approaches with **3 layers sharded differently**:\n\n| Layer | Shape | Trainer Sharding | Generator Sharding | Routing Opportunity |\n|-------|-------|------------------|-------------------|---------------------|\n| 0 | 1024\u00d71024 | Row-sharded (4-way) | Row-sharded (2-way) | Yes! Same dim |\n| 1 | 512\u00d72048 | Col-sharded (4-way) | Col-sharded (2-way) | Yes! Same dim |\n| 2 | 256\u00d7256 | Replicated | Replicated | No sharding |\n\n```\nExample: Layer 0 (1024\u00d71024) - Both row-sharded, different granularity\n\nTRAINER (4-way row shard)                       GENERATOR (2-way row shard)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 T0: rows 0-255    [256\u00d71024] \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502 G0: rows 0-511    [512\u00d71024]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502      \u2502     \u2191                           \u2502\n\u2502 T1: rows 256-511  [256\u00d71024] \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2502     T0 + T1 only                \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502      \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 T2: rows 512-767  [256\u00d71024] \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2502 G1: rows 512-1023 [512\u00d71024]    \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524         \u2502      \u2502     \u2191                           \u2502\n\u2502 T3: rows 768-1023 [256\u00d71024] \u2502 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502     T2 + T3 only                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nGATHER APPROACH:                                ROUTED APPROACH:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                    \u2502          \u2502                                    \u2502\n\u2502  G0 receives:                      \u2502          \u2502  G0 receives:                      \u2502\n\u2502    T0 \u2192 full 256\u00d71024 \u2713 needed     \u2502          \u2502    T0 \u2192 full 256\u00d71024 \u2713            \u2502\n\u2502    T1 \u2192 full 256\u00d71024 \u2713 needed     \u2502          \u2502    T1 \u2192 full 256\u00d71024 \u2713            \u2502\n\u2502    T2 \u2192 full 256\u00d71024 \u2717 WASTED     \u2502          \u2502    (skips T2, T3 - no overlap!)    \u2502\n\u2502    T3 \u2192 full 256\u00d71024 \u2717 WASTED     \u2502          \u2502                                    \u2502\n\u2502                                    \u2502          \u2502                                    \u2502\n\u2502  G0 transfers: 4 shards            \u2502          \u2502  G0 transfers: 2 shards            \u2502\n\u2502  G1 transfers: 4 shards            \u2502          \u2502  G1 transfers: 2 shards            \u2502\n\u2502  Total: 8 transfers                \u2502          \u2502  Total: 4 transfers                \u2502\n\u2502  50% wasted bandwidth!             \u2502          \u2502  0% wasted bandwidth!              \u2502\n\u2502                                    \u2502          \u2502                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis exercises the re-sharding logic across different patterns. We'll use RDMAAction\nto batch all the transfers and compare:\n\n- **Gather**: Each receiver gets ALL data from ALL senders, then slices locally\n- **Routed**: Each receiver only gets data it actually needs (based on overlap)\n\"\"\")", "code_hash": "f26af2d921295d23ea615b4e023bb94d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aqbW", "name": "_"}, {"code": "import os\nfrom torch.distributed._tensor import DTensor, Shard, Replicate, init_device_mesh\n\n# Configuration\nNUM_TRAINER_RANKS = 4\nNUM_GENERATOR_RANKS = 2\n\n# Layer configs: (global_shape, trainer_placement, generator_placement)\n# The placements define how each side shards the tensor\nLAYER_CONFIGS = [\n    # Layer 0: 1024x1024, both row-sharded (Shard(0)) but different granularity\n    {\"shape\": (1024, 1024), \"trainer_place\": Shard(0), \"gen_place\": Shard(0)},\n    # Layer 1: 512x2048, both col-sharded (Shard(1)) but different granularity\n    {\"shape\": (512, 2048), \"trainer_place\": Shard(1), \"gen_place\": Shard(1)},\n    # Layer 2: 256x256, replicated on both sides\n    {\"shape\": (256, 256), \"trainer_place\": Replicate(), \"gen_place\": Replicate()},\n]\n\ndef placement_to_shard_dim(placement) -\u003E int | None:\n    \"\"\"Extract shard dimension from DTensor placement.\"\"\"\n    if isinstance(placement, Shard):\n        return placement.dim\n    return None  # Replicate or other\n\ndef compute_layer_transfer_plan(layer_cfg, trainer_ranks, gen_ranks, gen_rank):\n    \"\"\"Use DTensor placement metadata to compute transfer plan for one layer.\"\"\"\n    trainer_dim = placement_to_shard_dim(layer_cfg[\"trainer_place\"])\n    gen_dim = placement_to_shard_dim(layer_cfg[\"gen_place\"])\n\n    if trainer_dim is None:\n        # Replicated on trainer side - just need one trainer\n        return [(0, None)]  # (trainer_rank, chunk_info)\n\n    if gen_dim is None:\n        # Replicated on generator side - need all trainers to reconstruct\n        return [(t, None) for t in range(trainer_ranks)]\n\n    # Both sharded - use compute_transfer_plan to find overlaps\n    trainer_shards = compute_shard_metadata(layer_cfg[\"shape\"], trainer_ranks, trainer_dim)\n    gen_shards = compute_shard_metadata(layer_cfg[\"shape\"], gen_ranks, gen_dim)\n\n    # Get this generator's shard metadata\n    my_shard = gen_shards[gen_rank]\n\n    # Find which trainers have overlapping data\n    overlapping = []\n    for t_shard in trainer_shards:\n        # Check if there's any overlap\n        t_start = t_shard.offset[trainer_dim]\n        t_end = t_start + t_shard.local_shape[trainer_dim]\n        g_start = my_shard.offset[gen_dim] if gen_dim == trainer_dim else 0\n        g_end = (my_shard.offset[gen_dim] + my_shard.local_shape[gen_dim]\n                 if gen_dim == trainer_dim else layer_cfg[\"shape\"][trainer_dim])\n\n        if t_end \u003E g_start and t_start \u003C g_end:\n            overlapping.append((t_shard.rank, t_shard))\n\n    return overlapping\n\nclass DTensorTrainer(Actor):\n    \"\"\"Trainer with DTensor shards - uses placement metadata for resharding.\"\"\"\n\n    def __init__(self):\n        self.rank = current_rank().rank\n        self.dtensors = []\n        self.handles = []\n        self.device_mesh = None\n\n    @endpoint\n    def setup_distributed(self):\n        \"\"\"Initialize distributed and create DTensors with proper placements.\"\"\"\n        world_size = int(os.environ.get(\"WORLD_SIZE\", \"1\"))\n\n        if not torch.distributed.is_initialized():\n            torch.distributed.init_process_group(backend=\"gloo\")\n\n        self.device_mesh = init_device_mesh(\"cpu\", (world_size,))\n\n        # Create DTensors based on layer configs\n        for i, cfg in enumerate(LAYER_CONFIGS):\n            placement = cfg[\"trainer_place\"]\n            shard_dim = placement_to_shard_dim(placement)\n\n            if shard_dim is not None:\n                # Sharded: compute local shape\n                local_shape = list(cfg[\"shape\"])\n                local_shape[shard_dim] = cfg[\"shape\"][shard_dim] // world_size\n                local_shape = tuple(local_shape)\n            else:\n                # Replicated: full shape\n                local_shape = cfg[\"shape\"]\n\n            local_tensor = torch.zeros(local_shape, dtype=torch.float32)\n            local_tensor.fill_(float(i * 10 + self.rank))\n\n            dt = DTensor.from_local(local_tensor, self.device_mesh, [placement], run_check=False)\n            self.dtensors.append(dt)\n            self.handles.append(RDMABuffer(local_tensor.view(torch.uint8).flatten()))\n\n        shapes = [tuple(dt.to_local().shape) for dt in self.dtensors]\n        placements = [str(cfg[\"trainer_place\"]) for cfg in LAYER_CONFIGS]\n        print(f\"Trainer {self.rank}: shapes={shapes}, placements={placements}\")\n        return shapes\n\n    @endpoint\n    def get_layer_handle(self, layer_idx: int):\n        \"\"\"Return (shape, handle) for a layer's local shard.\"\"\"\n        return (tuple(self.dtensors[layer_idx].to_local().shape), self.handles[layer_idx])\n\n    @endpoint\n    def destroy(self):\n        if torch.distributed.is_initialized():\n            torch.distributed.destroy_process_group()\n\nclass DTensorGenerator(Actor):\n    \"\"\"Generator that uses DTensor placement metadata for smart resharding.\"\"\"\n\n    def __init__(self):\n        self.rank = current_rank().rank\n        self.action = None\n        self.recv_buffers = []\n        self.device_mesh = None\n\n    @endpoint\n    def setup_distributed(self):\n        world_size = int(os.environ.get(\"WORLD_SIZE\", \"1\"))\n        if not torch.distributed.is_initialized():\n            torch.distributed.init_process_group(backend=\"gloo\")\n        self.device_mesh = init_device_mesh(\"cpu\", (world_size,))\n        print(f\"Generator {self.rank}: distributed initialized\")\n        return world_size\n\n    @endpoint\n    def handshake_gather(self, trainers):\n        \"\"\"Gather approach: fetch ALL shards (ignores placement metadata).\"\"\"\n        total = len(trainers) * len(LAYER_CONFIGS)\n        return f\"Gather: {total} transfers (all trainers \u00d7 all layers)\"\n\n    @endpoint\n    def handshake_routed(self, trainers):\n        \"\"\"Routed approach: use DTensor placements to compute minimal transfers.\"\"\"\n        self.action = RDMAAction()\n        self.recv_buffers = []\n        total_transfers = 0\n\n        for layer_idx, cfg in enumerate(LAYER_CONFIGS):\n            # Use placement metadata to compute which trainers we need\n            overlapping = compute_layer_transfer_plan(\n                cfg, NUM_TRAINER_RANKS, NUM_GENERATOR_RANKS, self.rank\n            )\n\n            for t_rank, _ in overlapping:\n                shape, handle = trainers[t_rank].get_layer_handle.call_one(layer_idx).get()\n                buf = torch.zeros(shape, dtype=torch.float32)\n                self.recv_buffers.append(buf)\n                self.action.read_into(handle, buf.view(torch.uint8).flatten())\n                total_transfers += 1\n\n        return f\"Routed: {total_transfers} transfers (placement-aware)\"\n\n    @endpoint\n    def receive_routed(self) -\u003E dict:\n        start = time.perf_counter()\n        self.action.submit().get()\n        elapsed_ms = (time.perf_counter() - start) * 1000\n        return {\"elapsed_ms\": elapsed_ms}\n\n    @endpoint\n    def destroy(self):\n        if torch.distributed.is_initialized():\n            torch.distributed.destroy_process_group()\n\nprint(\"DTensor actors defined (using placement metadata for routing)\")", "code_hash": "7124722cbde534cdb102f483afec2d65", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TRpd", "name": "_"}, {"code": "from monarch.spmd import setup_torch_elastic_env\n\n# Spawn trainer mesh (4 procs, one actor per proc)\n_trainer_procs = this_host().spawn_procs(per_host={\"procs\": NUM_TRAINER_RANKS})\nsetup_torch_elastic_env(_trainer_procs)  # Sets WORLD_SIZE, RANK, MASTER_ADDR, etc.\n_trainers = _trainer_procs.spawn(\"trainers\", DTensorTrainer)\n\n# Spawn generator mesh (2 procs)\n_gen_procs = this_host().spawn_procs(per_host={\"procs\": NUM_GENERATOR_RANKS})\nsetup_torch_elastic_env(_gen_procs)\n_generators = _gen_procs.spawn(\"generators\", DTensorGenerator)\n\nprint(\"\\n=== DTensor Reshard Benchmark ===\")\nprint(f\"Trainer mesh: {NUM_TRAINER_RANKS} ranks, Generator mesh: {NUM_GENERATOR_RANKS} ranks\")\nprint(\"Layer configs:\")\nfor i, cfg in enumerate(LAYER_CONFIGS):\n    print(f\"  Layer {i}: {cfg['shape']}, trainer={cfg['trainer_place']}, gen={cfg['gen_place']}\")\n\n# Initialize distributed on trainers and generators (separate process groups)\nprint(\"\\nSetting up distributed...\")\n_trainer_shapes = _trainers.setup_distributed.call().get()\n_gen_world = _generators.setup_distributed.call().get()\nprint(f\"  Trainer shapes: {[s for _, s in _trainer_shapes]}\")\nprint(f\"  Generator world sizes: {[w for _, w in _gen_world]}\")\n\n# Get list of individual trainer actors for the generators to call\n_trainer_list = [_trainers.slice(procs=i) for i in range(NUM_TRAINER_RANKS)]\n\n# Handshake to build transfer plans (uses DTensor placement metadata!)\nprint(\"\\nBuilding transfer plans (using placement metadata)...\")\n_results = _generators.handshake_routed.call(_trainer_list).get()\nfor _i, _r in enumerate(_results):\n    print(f\"  Generator {_i}: {_r}\")\n\n# Run benchmark\nprint(\"\\nRunning transfers...\")\n_times = []\nfor _step in range(3):\n    _step_start = time.perf_counter()\n    _results = _generators.receive_routed.call().get()\n    _step_ms = (time.perf_counter() - _step_start) * 1000\n    _times.append(_step_ms)\n    print(f\"  Step {_step + 1}: {_step_ms:.1f}ms\")\n\n_avg = sum(_times) / len(_times)\nprint(f\"  Average: {_avg:.1f}ms\")\n\n# Cleanup distributed process groups\n_trainers.destroy.call().get()\n_generators.destroy.call().get()\nprint(\"\\nDistributed cleanup complete\")", "code_hash": "b33f716dfcd3b58035412e825f1f7060", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TXez", "name": "_"}, {"code": "mo.md(r\"\"\"\n**What the benchmark shows:**\n\n- **Gather**: Each receiver talks to ALL trainers and receives ALL their data, then discards\n  what it doesn't need. With 4 trainers and 2 generators, that's 8 transfers per layer.\n- **Routed**: Each receiver only talks to trainers with overlapping data. For same-dimension\n  sharding (trainer 4-way, generator 2-way), each generator only needs 2 of the 4 shards.\n  That's 4 transfers per layer - **50% fewer connections**.\n\nFor large models where weight sync is a bottleneck, the routed approach can save\nsignificant bandwidth. The handshake pattern amortizes the overlap computation cost.\n\nThe key insight: **RDMAAction lets you batch all the routed transfers into one plan**,\nso you get the efficiency of smart routing with the simplicity of a single `submit()` call.\n\"\"\")", "code_hash": "150a68bfdccb5ee2c66b01b6ea038293", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "dNNg", "name": "_"}, {"code": "mo.md(r\"\"\"\n### The DTensor Dream (and Reality)\n\nIf trainer and generator both used **DTensor** with the same sharding spec, re-sharding\nwould be automatic - the framework handles overlap computation and transfers.\n\n```python\n# Ideal world: DTensor handles it\ntrainer_weights: DTensor  # Shard(0) across 8 GPUs\ngenerator_weights: DTensor  # Shard(1) across 2 GPUs\n\n# Re-sharding is just redistribution\ngenerator_weights = trainer_weights.redistribute(generator_placement)\n```\n\n**In practice, it's harder**:\n- vLLM does its own sharding and weight fusing (not DTensor-compatible)\n- Training frameworks (FSDP, etc.) have different abstractions\n- You often need custom overlap computation like we showed above\n\nThe routed approach (compute overlaps, send only needed chunks) is 2x faster than\nnaive gather-then-slice, but requires this manual coordination.\n\n**For cross-node RDMA transfers**, the key insight remains: pre-compute the transfer\nplan once, then each sync just executes the planned RDMA operations with RDMAAction.\n\"\"\")", "code_hash": "451e5f375cd885f5faa4be78edff6345", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "yCnT", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 9. Putting It All Together\n\nThe full async RL weight sync pattern:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TRAINER                                  \u2502\n\u2502  1. Train step completes                                        \u2502\n\u2502  2. Copy weights to CPU staging buffer (non-blocking D2H)       \u2502\n\u2502  3. Publish to circular buffer with version tag                 \u2502\n\u2502  4. Continue training (no blocking!)                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              CIRCULAR BUFFER (CPU, RDMA-registered)             \u2502\n\u2502  [slot 0: v3] [slot 1: v4] [slot 2: v5]                        \u2502\n\u2502                                 \u2191 latest                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                     \u25bc                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   GENERATOR 0   \u2502   \u2502   GENERATOR 1   \u2502   \u2502   GENERATOR 2   \u2502\n\u2502                 \u2502   \u2502                 \u2502   \u2502                 \u2502\n\u2502 After gen done: \u2502   \u2502 After gen done: \u2502   \u2502 After gen done: \u2502\n\u2502 1. Get latest   \u2502   \u2502 1. Get latest   \u2502   \u2502 1. Get latest   \u2502\n\u2502    version      \u2502   \u2502    version      \u2502   \u2502    version      \u2502\n\u2502 2. RDMA read    \u2502   \u2502 2. RDMA read    \u2502   \u2502 2. RDMA read    \u2502\n\u2502    \u2192 GPU        \u2502   \u2502    \u2192 GPU        \u2502   \u2502    \u2192 GPU        \u2502\n\u2502 3. Re-shard if  \u2502   \u2502 3. Re-shard if  \u2502   \u2502 3. Re-shard if  \u2502\n\u2502    needed       \u2502   \u2502    needed       \u2502   \u2502    needed       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Key properties:**\n- Trainer never blocks waiting for generators\n- Generators pull directly to GPU when *they're* ready\n- Re-sharding happens locally on each generator\n- Circular buffer bounds memory, reuses RDMA registrations\n\"\"\")", "code_hash": "4ee241f55b0f0e4b6423165320d8eb6f", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "wlCL", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Code Pattern\n\n```python\n# Trainer side\nclass Trainer(Actor):\n    def __init__(self):\n        self.weight_buffer = CircularWeightBuffer(\n            template=self.model.state_dict_tensor(),\n            n_slots=3,\n        )\n\n    @endpoint\n    def get_weight_handle(self) -\u003E Tuple[RDMABuffer, int]:\n        '''Return handle to latest weights and version.'''\n        slot_idx = (self.weight_buffer.latest_version - 1) % 3\n        handle = self.weight_buffer.rdma_handles[slot_idx]\n        version = self.weight_buffer.latest_version - 1\n        return handle, version\n\n    async def train_loop(self):\n        while True:\n            loss = self.train_step()\n            if self.step % sync_interval == 0:\n                # Non-blocking publish\n                self.weight_buffer.publish(self.model.weights)\n\n# Generator side\nclass Generator(Actor):\n    def __init__(self, trainer_ref):\n        self.trainer = trainer_ref\n        self.current_version = -1\n\n    async def maybe_sync_weights(self):\n        handle, version = await self.trainer.get_weight_handle.call_one().get()\n        if version \u003E self.current_version:\n            # Pull via RDMA directly into GPU memory\n            gpu_weights = self.model.weights.view(torch.uint8).flatten()\n            await handle.read_into(gpu_weights)\n            self.current_version = version\n\n    async def generate_loop(self):\n        while True:\n            await self.maybe_sync_weights()\n            output = self.generate(prompt)\n            self.submit_to_buffer(output)\n```\n\"\"\")", "code_hash": "26dba11147530b7414a96869242e3902", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "kqZH", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 10. Going Further: TorchStore\n\nAll the patterns we've covered - RDMA memory registration, magic pointers, circular buffers,\npre-computed transfer plans - are building blocks. If you need a **production-ready solution**,\ncheck out [TorchStore](https://github.com/meta-pytorch/torchstore).\n\n### What is TorchStore?\n\nTorchStore is a **distributed, asynchronous key-value store for PyTorch tensors** built on\nMonarch's actor framework. It abstracts away the RDMA complexity while giving you:\n\n```python\nfrom torchstore import TorchStore\n\n# Store tensors with async API\nawait ts.put(\"model/layer1/weights\", tensor)\n\n# Retrieve with optional in-place and slice semantics\nawait ts.get(\"model/layer1/weights\", inplace_tensor=buffer)\n\n# Native PyTorch checkpoint support\nawait ts.put_state_dict(model.state_dict())\nloaded = await ts.get_state_dict()\n```\n\n### RDMA Under the Hood\n\nTorchStore implements the patterns we've discussed:\n\n- **Transport abstraction** with automatic RDMA detection:\n  1. TorchComms RDMA (highest performance)\n  2. Monarch RDMA (fallback)\n  3. Monarch RPC (no RDMA available)\n\n- **Memory region management**: Pre-registers buffers, handles cleanup\n\n- **DTensor support**: Efficiently stores/retrieves tensor shards across ranks\n\n- **Tensor slicing**: Fetch arbitrary slices without retrieving the whole tensor\n\nThe key insight: **TorchStore lets you think in key-value semantics while getting RDMA\nperformance**. No manual buffer management, no handle passing, no overlap computation.\n\n### When to Use What\n\n| Scenario | Solution |\n|----------|----------|\n| Learning RDMA patterns | This notebook's examples |\n| Custom RL weight sync | Build on `RDMABuffer` + `RDMAAction` |\n| General tensor storage | Use TorchStore |\n| Checkpointing | Use TorchStore's `put_state_dict` |\n\"\"\")", "code_hash": "3133bc88ab2a0a882aaa3a0475a44017", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "wAgl", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Summary\n\n### Key Takeaways\n\n1. **Bandwidth hierarchy matters**: NVLink (450 GB/s) \u003E\u003E InfiniBand (50-100 GB/s) \u003E\u003E PCIe\n   - Know your hardware, optimize for the right interconnect\n\n2. **Collectives vs P2P**: Collectives are synchronized; RL needs async P2P\n   - High variance in generation times makes blocking expensive\n\n3. **Magic pointer pattern**: Tiny handle over control plane, bulk data over data plane\n   - ~100 bytes to describe 10 GB transfer\n\n4. **CPU staging**: Temporal decoupling for async RL\n   - GPU-native RDMA works for sync cases\n   - CPU staging ensures nothing blocks on the critical path\n\n5. **Circular buffers**: Version weights without memory churn\n   - Pre-register RDMA buffers, reuse slots\n   - Generators grab latest, never stale\n\n6. **Weight re-sharding**: Different layouts need overlap computation\n   - Routed approach is 2x faster than gather\n   - Pre-compute transfer plan, minimize redundant data\n\n### Next Steps\n\nSee **07_async_rl_e2e.py** for a complete async RL system that uses these patterns.\n\"\"\")", "code_hash": "a3abb4c511005ddfec0279d1c84e6846", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "rEll", "name": "_"}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "253c975dac02c4eecec395f5a6f11359", "console": [], "id": "MJUe", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"rdma-weight-synchronization\"\u003ERDMA \u0026amp; Weight Synchronization\u003C/h1\u003E\n\u003Cspan class=\"paragraph\"\u003EThis notebook explores efficient weight synchronization for async RL systems.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EOutline:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003EWhy Weight Sync Matters\u003C/strong\u003E - On-policy vs off-policy, model scale\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EThe Bandwidth Hierarchy\u003C/strong\u003E - NVLink, InfiniBand, PCIe\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EThe Problem: Collectives Are Blocking\u003C/strong\u003E - Why RL needs something different\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EHow RDMA Works\u003C/strong\u003E - ibverbs, one-sided operations\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EThe Magic Pointer Pattern\u003C/strong\u003E - Control plane vs data plane separation\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECPU Staging\u003C/strong\u003E - Decoupling trainer and generator timing\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECircular Weight Buffers\u003C/strong\u003E - Versioning without memory churn\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EWeight Re-sharding\u003C/strong\u003E - Handling different tensor layouts\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EPutting It All Together\u003C/strong\u003E - The complete pattern\u003C/li\u003E\n\u003C/ol\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "adcd7c1a7fe508413fb842b361890260", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"1-why-weight-sync-matters\"\u003E1. Why Weight Sync Matters\u003C/h2\u003E\n\u003Ch3 id=\"the-on-policy-problem\"\u003EThe On-Policy Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETraditional RL algorithms want to be \u003Cstrong\u003Eon-policy\u003C/strong\u003E: generate experience using the current\npolicy, then immediately use that experience to update the policy. This creates a tight loop:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EOn-Policy RL:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  generate(policy_v1) \u2192 train(samples) \u2192 policy_v2 \u2192 repeat       \u2502\n\u2502                                                                  \u2502\n\u2502  Experience from v1 is only valid for updating v1                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EAsync RL breaks this rule.\u003C/strong\u003E Generators run continuously while the trainer updates weights.\nBy the time a sample reaches the trainer, it was generated by an old policy version:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EAsync RL (off-policy):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator: policy_v1 \u2192 sample\u2081                                  \u2502\n\u2502  Trainer:   train(sample\u2081) \u2192 policy_v2                           \u2502\n\u2502  Generator: policy_v1 \u2192 sample\u2082  \u2190 still using v1!               \u2502\n\u2502  Trainer:   train(sample\u2082) \u2192 policy_v3                           \u2502\n\u2502                                                                  \u2502\n\u2502  Samples are \u0026quot;stale\u0026quot; - generated by older policy versions        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis \u003Cstrong\u003Eoff-policy-ness\u003C/strong\u003E can work up to a degree, but must be limited. The generators\nneed fresh weights regularly to stay \"close enough\" to on-policy. Weight sync frequency\nbecomes a key hyperparameter trading off:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EToo slow\u003C/strong\u003E: Samples become too stale, training diverges\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EToo fast\u003C/strong\u003E: Weight sync overhead dominates, negating async benefits\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"the-scale-problem\"\u003EThe Scale Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFor LLM-based RL, the weights are \u003Cstrong\u003Emassive\u003C/strong\u003E. Let's calculate:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "74c70cf0623f5d30c14182baa0290a25", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Model Weight Sizes (bf16 precision):\n\nModel                Weight Size\n-----------------------------------\nLlama 3.2 3B         6 GB\nQwen 2.5 7B          14 GB\nLlama 3.1 70B        140 GB\nLlama 3.1 405B       810 GB\nDeepSeek V3 671B     1.3 TB\n\n\u2192 These weights need to move from trainer \u2192 generators\n\u2192 For large models, this means crossing the network fabric\n", "type": "stream"}], "id": "bkHC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"why-this-forces-cross-node-transfer\"\u003EWhy This Forces Cross-Node Transfer\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThe numbers speak for themselves:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EA \u003Cstrong\u003E70B model\u003C/strong\u003E has 140 GB of weights\u003C/li\u003E\n\u003Cli\u003EA \u003Cstrong\u003E405B model\u003C/strong\u003E has 810 GB of weights\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EDeepSeek V3\u003C/strong\u003E has 1.3 TB of weights\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThese models are sharded across many GPUs, often spanning multiple nodes.\nWeight sync can't rely on NVLink alone - it must cross InfiniBand/RoCE.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is why we need RDMA.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cec1b0c381d3e84ce5137584cc45ab54", "console": [], "id": "lEQa", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"2-the-bandwidth-hierarchy\"\u003E2. The Bandwidth Hierarchy\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EModern HPC clusters have multiple interconnects with vastly different bandwidths:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                              NODE A                                                      \u2502\n\u2502                                                                                                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                         ======  64 GB/s PCIe                                             \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  ------ 48 GB/s ------ \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518      PCIe        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n                                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                        \u2502                                                    \u2502\n                                                        \u2502              InfiniBand Switch                     \u2502\n                                                        \u2502                                                    \u2502\n                                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                    IB NDR400         IB NDR400\n                                                                         \u2502                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510      PCIe        \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502     CPU interconnect   \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 ------ 48 GB/s ------  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                           ======  64 GB/s PCIe                                           \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              NODE B                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nBandwidth encoding (line intensity):\n  ########  NVLink/NVSwitch   900 GB/s   (GPU \u2194 GPU, same node)\n  ========  PCIe Gen5 / IB     50-64 GB/s (CPU\u2194GPU, CPU\u2194NIC, cross-node)\n  --------  CPU interconnect   48 GB/s   (CPU \u2194 CPU, same node)\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003ERDMA can transfer between any registered memory (CPU or GPU) via the NICs.\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EInterconnect\u003C/th\u003E\n\u003Cth\u003EBandwidth\u003C/th\u003E\n\u003Cth\u003ELatency\u003C/th\u003E\n\u003Cth\u003EUse Case\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ENVLink/NVSwitch\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E900 GB/s\u003C/td\u003E\n\u003Ctd\u003E~1 \u03bcs\u003C/td\u003E\n\u003Ctd\u003ESame-node GPU\u2194GPU\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003EInfiniBand NDR400\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E50 GB/s\u003C/td\u003E\n\u003Ctd\u003E~1-2 \u03bcs\u003C/td\u003E\n\u003Ctd\u003ECross-node RDMA\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003EPCIe Gen5 x16\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E64 GB/s\u003C/td\u003E\n\u003Ctd\u003E~1-2 \u03bcs\u003C/td\u003E\n\u003Ctd\u003ECPU\u2194GPU, CPU\u2194NIC\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ECPU interconnect\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E48 GB/s\u003C/td\u003E\n\u003Ctd\u003E~100 ns\u003C/td\u003E\n\u003Ctd\u003ECPU\u2194CPU (same node)\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey observations:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003ENVLink dominates\u003C/strong\u003E - 900 GB/s is ~18x faster than cross-node RDMA. Same-node GPU\u2194GPU\n   communication is nearly free compared to crossing the network.\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERDMA \u0026gt;\u0026gt; Ethernet\u003C/strong\u003E - InfiniBand/RoCE at 50 GB/s is ~4x faster than 100GbE (12.5 GB/s),\n   plus kernel bypass and lower latency. Worth the complexity for HPC workloads.\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EPCIe is faster than you'd think\u003C/strong\u003E - At 64 GB/s, CPU\u2194GPU transfers aren't the bottleneck\n   people often assume. The real cost is synchronization, not bandwidth.\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ERule of thumb\u003C/strong\u003E: Place the most bandwidth-intensive, frequent operations on NVLink\n(gradients, activations). Use RDMA for cross-node communication (weight sync, sharding).\nPCIe is fine for occasional CPU\u2194GPU transfers.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWe'll focus primarily on \u003Cstrong\u003ENVLink\u003C/strong\u003E and \u003Cstrong\u003ERDMA\u003C/strong\u003E for this notebook. Most people use these\nvia \u003Cstrong\u003Ecollectives\u003C/strong\u003E, exposed through PyTorch distributed:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Etorch.distributed\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eas\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Edist\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Initialize process group - NCCL uses NVLink (same-node) and RDMA (cross-node)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Einit_process_group\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebackend\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;nccl\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# All-reduce: average gradients across all GPUs\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eall_reduce\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egradients\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eop\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003EReduceOp\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003ESUM\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egradients\u003C/span\u003E \u003Cspan class=\"o\"\u003E/=\u003C/span\u003E \u003Cspan class=\"n\"\u003Eworld_size\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# All-gather: collect tensors from all ranks\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egathered\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eempty_like\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003E_\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"nb\"\u003Erange\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eworld_size\u003C/span\u003E\u003Cspan class=\"p\"\u003E)]\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eall_gather\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egathered\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Broadcast: send from rank 0 to all others\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebroadcast\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Esrc\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis works great for training. But for RL weight sync, we need something different...\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e2ddceb8064dfb2235ad898d34eee19a", "console": [], "id": "PKri", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3635469f9ef34cc32298f48cd8a8e002", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"3-the-problem-collectives-are-blocking\"\u003E3. The Problem: Collectives Are Blocking\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ECollectives work great for training - everyone computes gradients, then synchronizes.\nBut async RL has a different access pattern.\u003C/span\u003E\n\u003Ch3 id=\"high-variance-in-generation-times\"\u003EHigh Variance in Generation Times\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EGenerators have wildly different completion times:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ESome prompts \u2192 10 tokens (fast)\u003C/li\u003E\n\u003Cli\u003EOther prompts \u2192 1000 tokens (slow)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EWith collectives, fast generators wait for slow ones:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EGenerator 0: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\nGenerator 1: \u251c\u2500\u2500\u2500\u2500\u2500\u2500 gen (slow) \u2500\u2500\u2500\u2500\u2500\u2500\u2524\nGenerator 2: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\n                                      \u2193\n                          all_gather(weights)  # Everyone waits!\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"what-about-sendrecv\"\u003EWhat About send/recv?\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EPyTorch distributed does have point-to-point primitives:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Sender side\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Esend\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Edst\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceiver_rank\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Receiver side\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Esrc\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Esender_rank\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EBut this is \u003Cstrong\u003Etwo-sided\u003C/strong\u003E - both sender and receiver must coordinate:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EReceiver must call \u003Ccode\u003Erecv()\u003C/code\u003E before sender's \u003Ccode\u003Esend()\u003C/code\u003E completes\u003C/li\u003E\n\u003Cli\u003ETrainer would need to wait until generators are ready to receive\u003C/li\u003E\n\u003Cli\u003EStill blocking on coordination!\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"the-one-sided-solution-rdma\"\u003EThe One-Sided Solution: RDMA\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EWhat if the sender could write directly to the receiver's memory without coordination?\u003C/span\u003E\n\u003Cdiv class=\"language-teratermmacro codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"nv\"\u003ETwo\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Esided\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"k\"\u003Esend\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;I have data\u0026quot;\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EReceiver\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;I\u0026#39;m ready\u0026quot;\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Esends\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edata\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EReceiver\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edata\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Emessages\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Erequired\u003C/span\u003E\n\n\u003Cspan class=\"nv\"\u003EOne\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Esided\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ewrites\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edirectly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ereceiver\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u0026#39;s memory\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E                         No coordination needed!\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is what RDMA enables: \u003Cstrong\u003Eone-sided memory operations\u003C/strong\u003E.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "0a71e903f733748118150942a35efc3d", "console": [], "id": "SFPL", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"4-how-rdma-works-ibverbs\"\u003E4. How RDMA Works (ibverbs)\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ERDMA (Remote Direct Memory Access) lets one machine read/write another machine's memory\ndirectly, bypassing the kernel and CPU on both sides.\u003C/span\u003E\n\u003Ch3 id=\"the-ibverbs-stack\"\u003EThe ibverbs Stack\u003C/h3\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Application (PyTorch, Monarch, etc.)                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  libibverbs  (userspace RDMA API)                       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Provider driver (mlx5, efa, rxe, etc.)                 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Hardware (InfiniBand NIC, RoCE NIC, etc.)              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EWe'll focus on \u003Cstrong\u003EInfiniBand\u003C/strong\u003E and \u003Cstrong\u003ERoCE\u003C/strong\u003E (RDMA over Converged Ethernet).\nOther transports like AWS EFA exist but we won't cover them here.\u003C/span\u003E\n\u003Ch3 id=\"key-rdma-operations\"\u003EKey RDMA Operations\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EOperation\u003C/th\u003E\n\u003Cth\u003EDescription\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003ERDMA_WRITE\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003EWrite to remote memory (one-sided)\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003ERDMA_READ\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003ERead from remote memory (one-sided)\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Ccode\u003ESEND/RECV\u003C/code\u003E\u003C/td\u003E\n\u003Ctd\u003ETwo-sided messaging (like TCP)\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThe magic is in \u003Ccode\u003ERDMA_WRITE\u003C/code\u003E and \u003Ccode\u003ERDMA_READ\u003C/code\u003E - they're \u003Cstrong\u003Eone-sided\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ERemote CPU is not involved\u003C/li\u003E\n\u003Cli\u003ERemote application doesn't need to call anything\u003C/li\u003E\n\u003Cli\u003ENIC handles everything in hardware\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"memory-registration\"\u003EMemory Registration\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EBefore RDMA, memory must be \u003Cstrong\u003Eregistered\u003C/strong\u003E with the NIC:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Conceptually (actual ibverbs API is in C)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Emr\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Erdma_register_memory\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Esize\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E# Returns:\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E#   - lkey: local access key (for local operations)\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E#   - rkey: remote access key (share with remote peer)\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E#   - addr: physical/virtual address\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe \u003Ccode\u003E(addr, rkey)\u003C/code\u003E pair is a \u003Cstrong\u003Eremote-accessible pointer\u003C/strong\u003E. Share it with a peer,\nand they can read/write your memory directly.\u003C/span\u003E\n\u003Ch3 id=\"queue-pair-setup\"\u003EQueue Pair Setup\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EBefore any RDMA operations, you need to establish a \u003Cstrong\u003EQueue Pair (QP)\u003C/strong\u003E between\nsender and receiver. This is a one-time connection setup:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                           \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Sender    \u2502                           \u2502  Receiver   \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Create QP  \u2502 \u2500\u2500\u2500 exchange QP info \u2500\u2500\u2500\u25ba \u2502  Create QP  \u2502\n\u2502  (qp_num,   \u2502 \u25c4\u2500\u2500 (qp_num, lid, gid) \u2500\u2500 \u2502             \u2502\n\u2502   lid, gid) \u2502                           \u2502             \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Move QP to \u2502                           \u2502  Move QP to \u2502\n\u2502  RTR \u2192 RTS  \u2502                           \u2502  RTR \u2192 RTS  \u2502\n\u2502             \u2502                           \u2502             \u2502\n\u2502  Now ready  \u2502 \u2550\u2550\u2550 RDMA operations \u2550\u2550\u2550\u2550\u25ba \u2502  Now ready  \u2502\n\u2502  for RDMA!  \u2502                           \u2502  for RDMA!  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is where \u003Cstrong\u003EMonarch actors\u003C/strong\u003E shine. Because you can spawn arbitrary actors,\nyou can create \u003Cstrong\u003ERDMA Manager actors\u003C/strong\u003E that:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EInitialize QPs on their respective hosts\u003C/li\u003E\n\u003Cli\u003EExchange QP info via actor messages\u003C/li\u003E\n\u003Cli\u003EManage the connection lifecycle\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Monarch pattern: RDMA managers as actors\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ERDMAManager\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ecreate_queue_pair\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp_info\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Eget_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# (qp_num, lid, gid)\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003EQpInfo\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp_info\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Econnect\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eremote_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"n\"\u003EQpInfo\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Transition QP: INIT \u2192 RTR \u2192 RTS\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Econnect_qp\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eqp\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eremote_qp_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Setup: exchange QP info via actor messages, then RDMA is ready\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Etrainer_info\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_rdma\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_qp_info\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerator_rdma\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Econnect\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer_info\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe actor abstraction makes RDMA connection management natural and composable.\u003C/span\u003E\n\u003Ch3 id=\"monarch-using-monarch-rdmacontroller\"\u003EMonarch Using Monarch: RdmaController\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EHere's the cool part: \u003Cstrong\u003EMonarch uses itself\u003C/strong\u003E to manage RDMA infrastructure. Looking at\nthe actual Python code in \u003Ccode\u003Emonarch/_src/rdma/rdma.py\u003C/code\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# From Monarch\u0026#39;s RDMA implementation\u003C/span\u003E\n\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch._src.actor.proc_mesh\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003Eget_or_spawn_controller\u003C/span\u003E\n\n\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ERdmaController\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"sd\"\u003E\u0026#39;\u0026#39;\u0026#39;Singleton controller that coordinates RDMA initialization.\u0026#39;\u0026#39;\u0026#39;\u003C/span\u003E\n\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Track which proc meshes have RDMA initialized\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"nb\"\u003Edict\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003EProcMesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003EFuture\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003ERdmaManager\u003C/span\u003E\u003Cspan class=\"p\"\u003E]]\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"p\"\u003E{}\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Einit_rdma_on_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"n\"\u003EProcMesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"kc\"\u003ENone\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"sd\"\u003E\u0026#39;\u0026#39;\u0026#39;Lazily initialize RDMA on a proc mesh.\u0026#39;\u0026#39;\u0026#39;\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eif\u003C/span\u003E \u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E \u003Cspan class=\"ow\"\u003Enot\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n            \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003EFuture\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\n                \u003Cspan class=\"n\"\u003Ecoro\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003ERdmaManager\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecreate\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n            \u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003E_manager_futures\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eproc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Cached initialization - only runs once per process\u003C/span\u003E\n\u003Cspan class=\"nd\"\u003E@functools\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecache\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003E_ensure_init_rdma_manager\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Etask\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Econtroller\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Eget_or_spawn_controller\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;rdma_controller\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003ERdmaController\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Econtroller\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Einit_rdma_on_mesh\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecurrent_proc_mesh\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"n\"\u003Espawn_task\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etask\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is \u003Cstrong\u003EMonarch building Monarch\u003C/strong\u003E - the RDMA subsystem uses the same patterns:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Ccode\u003Eget_or_spawn_controller(\"rdma_controller\", RdmaController)\u003C/code\u003E ensures one global controller\u003C/li\u003E\n\u003Cli\u003EThe controller lazily initializes RDMA managers per proc mesh\u003C/li\u003E\n\u003Cli\u003E\u003Ccode\u003E@functools.cache\u003C/code\u003E ensures we only bootstrap once per process\u003C/li\u003E\n\u003Cli\u003EUnder the hood, the actual RDMA operations are in Rust (\u003Ccode\u003ERdmaManagerActor\u003C/code\u003E)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EIt's actors all the way down.\u003C/span\u003E\n\u003Ch3 id=\"why-this-matters-for-weight-sync\"\u003EWhy This Matters for Weight Sync\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ERemember: CPU memory AND GPU memory can both be registered for RDMA.\u003C/span\u003E\n\u003Cdiv class=\"language-actionscript3 codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERegister\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweight\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ENIC\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eaddr\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erkey\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EShare\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egenerators\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etiny\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Emessage\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EReceive\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA_READ\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Edirectly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u0026#39;\u003C/span\u003E\u003Cspan class=\"n\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ememory\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ENo\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecoordination\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe trainer doesn't even know when generators pull weights. True one-sided.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e4350ebea9f184ec46ac1d92959c648c", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"5-the-magic-pointer-pattern\"\u003E5. The Magic Pointer Pattern\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ENow here's the key insight from our RDMA discussion: to represent remote data,\nwe only need a \u003Cstrong\u003Etiny handle\u003C/strong\u003E - the \u003Ccode\u003E(addr, rkey, size)\u003C/code\u003E tuple.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch wraps this in \u003Ccode\u003ERDMABuffer\u003C/code\u003E. Let's see how small it actually is:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "93cd1380c225976a61d1164279118d8e", "console": [], "id": "RGSE", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "33f52127ad06527402c41752fe53ec8f", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-03_15:15_736\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "RDMABuffer handle size vs actual tensor size:\n\nTensor Size  Actual Bytes    Handle Size     Ratio     \n-------------------------------------------------------\n1 KB                1,024 B      437 B               2x\n1 MB            1,048,576 B      440 B           2,383x\n10 MB          10,485,760 B      441 B          23,777x\n\n\u2192 Handle size is O(1) regardless of tensor size!\n", "type": "stream"}], "id": "Kclp", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "70a1235b5a21ad6ce9e6c68db0e1da21", "console": [], "id": "emfo", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"the-magic-pointer\"\u003EThe Magic Pointer\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is the core pattern: \u003Cstrong\u003Eseparate control plane from data plane\u003C/strong\u003E.\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EControl plane\u003C/strong\u003E (actor messages): Send tiny handle (~100 bytes)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EData plane\u003C/strong\u003E (RDMA): Bulk transfer of actual data (~10 GB)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThink of \u003Ccode\u003ERDMABuffer\u003C/code\u003E as a \u003Cstrong\u003Emagic pointer\u003C/strong\u003E - it's a pointer that works across machines:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E                              \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elocal\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecopy\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mh\"\u003E10\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGB\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eempty\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECreate\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eregister\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ememory\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ESend\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"o\"\u003E~\u003C/span\u003E\u003Cspan class=\"mh\"\u003E100\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebytes\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Evia\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eactor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"o\"\u003E~\u003C/span\u003E\u003Cspan class=\"mh\"\u003E10\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGB\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Evia\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehardware\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Einvolvement\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe trainer doesn't even know when generators pull weights. True one-sided.\u003C/span\u003E\n\u003Ch3 id=\"rdmabuffer-in-action\"\u003ERDMABuffer in Action\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFrom \u003Ccode\u003Emonarch.rdma\u003C/code\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch.rdma\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Trainer side: register weights\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erandn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Edevice\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;cuda\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Return buffer as part of an endpoint response\u003C/span\u003E\n\u003Cspan class=\"c1\"\u003E# This is a TINY message - just the handle!\u003C/span\u003E\n\u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Generator side: receive handle, pull directly into GPU\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# Tiny message\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E                   \u003Cspan class=\"c1\"\u003E# Bulk RDMA \u2192 GPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003ESee the \u003Ca href=\"https://meta-pytorch.org/monarch/generated/examples/grpo_actor.html\" rel=\"noopener noreferrer\" target=\"_blank\"\u003EGRPO Actor example\u003C/a\u003E\nfor a minimal implementation showing RDMA data flow. We'll build a more complete\nversion in the following sections.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "289e5d25880fe95c9cc9cfaa728a34fb", "console": [], "id": "Hstk", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"the-cost-of-memory-registration\"\u003EThe Cost of Memory Registration\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ERDMA memory registration is \u003Cstrong\u003Eexpensive\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EPins physical pages (prevents swapping)\u003C/li\u003E\n\u003Cli\u003ECreates IOMMU/DMA mappings in the NIC\u003C/li\u003E\n\u003Cli\u003ECan take milliseconds for large buffers\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EBut here's the good news: \u003Cstrong\u003EMonarch caches all memory region registrations.\u003C/strong\u003E Once a buffer\nis registered, subsequent uses hit the cache, making it essentially free in steady state.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's see this in action with 3 approaches:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "6e195070f991709a57a7bf019f11e5f5", "console": [], "id": "nWHF", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch4 id=\"approach-1-naive\"\u003EApproach 1: Naive\u003C/h4\u003E\n\u003Cspan class=\"paragraph\"\u003ECreate new RDMABuffer on each transfer - registration happens on first use:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cb0763f4294eadb91b3e3d6ecb7660ee", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "NaiveSender: Re-registers all parameters on every call\n", "type": "stream"}], "id": "iLit", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8ea12b5c5327cddc0ab2a40368431518", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch4 id=\"approach-2-contiguous-buffer\"\u003EApproach 2: Contiguous Buffer\u003C/h4\u003E\n\u003Cspan class=\"paragraph\"\u003EAllocate one buffer, register at init time:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b20940a01eb850b248043c377b34e75c", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "ContiguousSender: Registers once, reuses same handle\n", "type": "stream"}], "id": "ROlb", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "084714f2ffb4ab350d8eb1663c8d1346", "console": [], "id": "qnkX", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch4 id=\"approach-3-scattered-rdmaaction\"\u003EApproach 3: Scattered + RDMAAction\u003C/h4\u003E\n\u003Cspan class=\"paragraph\"\u003ERegister each buffer at init, build transfer plan once via handshake:\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat is RDMAAction?\u003C/strong\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThink of \u003Ccode\u003ERDMAAction\u003C/code\u003E as a \u003Cstrong\u003Etransfer plan\u003C/strong\u003E. You\ndescribe all the reads/writes you want\nto do, then \u003Ccode\u003Esubmit()\u003C/code\u003E executes the whole plan at once:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Build the plan once\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMAAction\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle1\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Elocal_buffer1\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle2\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Elocal_buffer2\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle3\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Elocal_buffer3\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Execute whenever you want - just one call\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eaction\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Esubmit\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is useful when you have many scattered buffers (like model parameters) and want to batch them into a single logical operation.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cf2558bd29e83f53df64e3e26f3b7b6d", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "ScatteredSender: Registers each layer once\nScatteredReceiver: handshake() builds plan, receive_step() executes it\n", "type": "stream"}], "id": "TqIu", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "bc36214cf2b8bb000ba1be74598e2f61", "console": [], "id": "Vxnm", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPattern recap:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003ENaive\u003C/strong\u003E: Create RDMABuffer in the transfer endpoint\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EContiguous\u003C/strong\u003E: Register one big buffer in \u003Ccode\u003E__init__\u003C/code\u003E\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EScattered + RDMAAction\u003C/strong\u003E: Register multiple buffers in \u003Ccode\u003E__init__\u003C/code\u003E, build transfer plan in \u003Ccode\u003Ehandshake()\u003C/code\u003E\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's benchmark to see the difference:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "df277977136dfc231595fcc694a54d3d", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "=== RDMA Registration Benchmark ===\nTransferring 8000 floats (31.2 KB) x 5 steps\n\nNaive (re-register each step):\n  Step 1: 2049.88ms\n  Step 2: 11.51ms\n  Step 3: 8.87ms\n  Step 4: 14.32ms\n  Step 5: 11.24ms\n  Average: 419.16ms\n\nContiguous (register once):\n  Step 1: 4.23ms\n  Step 2: 3.42ms\n  Step 3: 3.25ms\n  Step 4: 3.59ms\n  Step 5: 3.62ms\n  Average: 3.62ms\n\nScattered + RDMAAction (register once, batch):\n  Step 1: 9.94ms\n  Step 2: 8.53ms\n  Step 3: 8.14ms\n  Step 4: 5.54ms\n  Step 5: 7.35ms\n  Average: 7.90ms\n\n=== What's Happening ===\nNaive step 1: Cold MR registration (~2000ms)\nNaive steps 2+: Cache hit, MR already registered (~10ms)\nContiguous/Scattered: Registration happened at spawn time, not during benchmark\n", "type": "stream"}], "id": "DnEU", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "cb64b2d65765fb608f01d2e9c51384c0", "console": [], "id": "ulZA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat the benchmark shows:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003ENaive\u003C/strong\u003E: First call is ~2000ms (cold registration), subsequent calls ~10ms (cache hit)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EContiguous/Scattered\u003C/strong\u003E: All calls are fast (~4-9ms) because registration happened\n  at spawn time, before the timing loop started\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cem\u003ENote: RDMAAction (~9ms) is slower than Contiguous (~4ms) due to Python overhead.\nMoving the batching logic to Rust is a planned optimization.\u003C/em\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b95b07f45da7a3e33ec1b3389ffa3e1d", "console": [], "id": "ecfG", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"two-weight-sync-patterns\"\u003ETwo Weight Sync Patterns\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EWith RDMABuffer as our building block, there are two main approaches:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EPattern\u003C/th\u003E\n\u003Cth\u003EHow it works\u003C/th\u003E\n\u003Cth\u003ETrade-offs\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ECPU Staging\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EGPU \u2192 CPU buffer \u2192 RDMA \u2192 CPU \u2192 GPU\u003C/td\u003E\n\u003Ctd\u003EOne MR, simple, but copies\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003EDirect GPU\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003EGPU \u2192 RDMA \u2192 GPU (GPUDirect)\u003C/td\u003E\n\u003Ctd\u003ENo copies, but one MR per param\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPattern 1: CPU Staging (Contiguous Buffer)\u003C/strong\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EPack all parameters into one contiguous CPU buffer, register once:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Calculate total size for all parameters\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Etotal_bytes\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"nb\"\u003Esum\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ep\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Enumel\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E \u003Cspan class=\"o\"\u003E*\u003C/span\u003E \u003Cspan class=\"n\"\u003Ep\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eelement_size\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E \u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003Ep\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eparameters\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\n        \u003Cspan class=\"c1\"\u003E# Allocate ONE contiguous buffer, register ONCE\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging_buffer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eempty\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etotal_bytes\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Edtype\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging_buffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n        \u003Cspan class=\"c1\"\u003E# Track where each param lives in the buffer\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eparam_offsets\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ecompute_offsets\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Epack_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"sd\"\u003E\u0026#39;\u0026#39;\u0026#39;Copy all params into contiguous buffer.\u0026#39;\u0026#39;\u0026#39;\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003Ename\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eparam\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Enamed_parameters\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003Eoffset\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eparam_offsets\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Ename\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n            \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging_buffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eoffset\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"n\"\u003Eoffset\u003C/span\u003E\u003Cspan class=\"o\"\u003E+\u003C/span\u003E\u003Cspan class=\"n\"\u003Esize\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecopy_\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eparam\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E))\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Epack_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# Same handle, new data\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPattern 2: Direct GPU MRs\u003C/strong\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ERegister each GPU parameter directly, no CPU copies:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Register each param ONCE at startup\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandles\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"p\"\u003E{}\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003Ename\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eparam\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Enamed_parameters\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003Ebyte_view\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Eparam\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Edata\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n            \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandles\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Ename\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebyte_view\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_param_handles\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"nb\"\u003Edict\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"nb\"\u003Estr\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E]:\u003C/span\u003E\n        \u003Cspan class=\"c1\"\u003E# Handles are reused - data updates in place\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandles\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EBoth patterns amortize MR registration cost across training iterations.\nLet's look at CPU staging in more detail (it's more common in async RL).\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "95ddd9de3d438a8eef2049b1c18a7d8c", "console": [], "id": "Pvdt", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"6-cpu-staging-pattern\"\u003E6. CPU Staging Pattern\u003C/h2\u003E\n\u003Ch3 id=\"gpu-native-rdma-works\"\u003EGPU-Native RDMA Works!\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFirst, let's be clear: \u003Cstrong\u003EGPU-native RDMA works\u003C/strong\u003E and is fast:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EGPUDirect RDMA: NIC reads directly from GPU memory\u003C/li\u003E\n\u003Cli\u003ENo CPU copy needed (when hardware supports it)\u003C/li\u003E\n\u003Cli\u003EGreat for synchronous transfers\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"why-cpu-staging-for-async-rl\"\u003EWhy CPU Staging for Async RL?\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThe issue isn't bandwidth - it's \u003Cstrong\u003Etiming\u003C/strong\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EDirect GPU\u2192GPU RDMA:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Generator GPU is mid-inference                       \u2502\n\u2502 \u251c\u2500\u2500 layer 1 \u2500\u2500\u2524 [RDMA arrives, needs sync!]         \u2502\n\u2502               \u2193                                      \u2502\n\u2502         cudaDeviceSynchronize()  \u2190 Blocks inference! \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EWith CPU staging, nothing on the critical path blocks:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eregistered\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003ESits\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehere\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eready\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eanytime\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egrabs\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eready\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe CPU buffer is a \u003Cstrong\u003Etemporal decoupling point\u003C/strong\u003E.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "dd06d4354b46dece7fc2c1062c403486", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Trainer: Weights copied to CPU staging buffer (RDMA registered)\n  GPU memory: cuda:0\n  CPU staging: pinned=True\nGenerator: Weights loaded directly to GPU (via RDMA)\n  Weights match: True\n", "type": "stream"}], "id": "ZBYS", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "309c675f1f544527fcf5a1fb0f8ee398", "console": [], "id": "aLJB", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"7-circular-weight-buffers\"\u003E7. Circular Weight Buffers\u003C/h2\u003E\n\u003Ch3 id=\"the-versioning-problem\"\u003EThe Versioning Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EIn async RL, trainer updates weights continuously. Generators need to:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003EGrab the latest\u003C/strong\u003E weights (not stale ones)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ENot block\u003C/strong\u003E waiting for updates\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EAvoid memory churn\u003C/strong\u003E (re-registering RDMA buffers is expensive)\u003C/li\u003E\n\u003C/ol\u003E\n\u003Ch3 id=\"solution-circular-buffer\"\u003ESolution: Circular Buffer\u003C/h3\u003E\n\u003Cdiv class=\"language-tsql codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Ewrites\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E...\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EBuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Eslots\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot0\u003C/span\u003E\u003Cspan class=\"o\"\u003E][\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot1\u003C/span\u003E\u003Cspan class=\"o\"\u003E][\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot2\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecircular\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereused\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Ereads\u003C/span\u003E\u003Cspan class=\"err\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E\u0026quot;Give me latest\u0026quot;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EBenefits:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EPre-registered RDMA buffers\u003C/strong\u003E - no memory registration on hot path\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ELock-free reads\u003C/strong\u003E - generators always get a consistent snapshot\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EBounded memory\u003C/strong\u003E - only N versions in flight\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "d6d5d71e57550b8cb9c32b20239ef5bc", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Published version 0\nPublished version 1\nPublished version 2\nPublished version 3\nPublished version 4\n\nGenerator got version 4, weights mean: -0.05\nVersion 1 available: False\n\nIn production: RDMABuffer handles would be pre-registered at init time\nGenerators would call get_latest_handle() to get RDMA handle + version\n", "type": "stream"}], "id": "nHfw", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "410bc4300bcb24d7481c1df0d3cc170f", "console": [], "id": "xXTn", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"8-weight-re-sharding\"\u003E8. Weight Re-sharding\u003C/h2\u003E\n\u003Ch3 id=\"the-sharding-mismatch-problem\"\u003EThe Sharding Mismatch Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETrainer and Generator often have \u003Cstrong\u003Edifferent tensor layouts\u003C/strong\u003E:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ERole\u003C/th\u003E\n\u003Cth\u003EParallelism\u003C/th\u003E\n\u003Cth\u003ESharding\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ETrainer\u003C/td\u003E\n\u003Ctd\u003EFSDP (8 GPUs)\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003EShard(0)\u003C/code\u003E - rows split across 8 GPUs\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGenerator\u003C/td\u003E\n\u003Ctd\u003ETP (2 GPUs)\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003EShard(1)\u003C/code\u003E - columns split across 2 GPUs\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EDirect weight transfer doesn't work - we need \u003Cstrong\u003Ere-sharding\u003C/strong\u003E.\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003ETrainer (row-sharded):          Generator (column-sharded):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GPU 0: rows 0-127\u2502            \u2502 GPU 0   \u2502 GPU 1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u2192      \u2502 cols    \u2502 cols    \u2502\n\u2502 GPU 1: rows 128+ \u2502            \u2502 0-511   \u2502 512+    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cf55cb42141c833974d8ecb1b6877238", "console": [], "id": "AjVT", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"approach-1-gather-then-slice\"\u003EApproach 1: Gather Then Slice\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ESimple but inefficient:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E1. Each receiver gathers ALL sender shards \u2192 full tensor\n\n2. Each receiver slices out its portion\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPros\u003C/strong\u003E: Simple, works with any sharding\n\u003Cstrong\u003ECons\u003C/strong\u003E: 2x redundant data transfer (each receiver gets everything)\u003C/span\u003E\n\u003Ch3 id=\"approach-2-routeddirect-transfer\"\u003EApproach 2: Routed/Direct Transfer\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EOptimal but complex:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EPre\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecompute\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhich\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Esender\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Echunks\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eoverlap\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhich\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceiver\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eregions\u003C/span\u003E\n\n\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ESend\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eonly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ethe\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eexact\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Echunks\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\n\n\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EReceivers\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eplace\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Echunks\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Edirectly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ein\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecorrect\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Epositions\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPros\u003C/strong\u003E: Minimal bandwidth (no redundancy)\n\u003Cstrong\u003ECons\u003C/strong\u003E: Complex overlap computation\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "01a93cde7e5ea82b6a4aa8a7a8c4acf8", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Trainer shards (row-wise, 4 GPUs):\n  Rank 0: offset=(0, 0), shape=(256, 1024)\n  Rank 1: offset=(256, 0), shape=(256, 1024)\n  Rank 2: offset=(512, 0), shape=(256, 1024)\n  Rank 3: offset=(768, 0), shape=(256, 1024)\n\nGenerator shards (column-wise, 2 GPUs):\n  Rank 0: offset=(0, 0), shape=(1024, 512)\n  Rank 1: offset=(0, 512), shape=(1024, 512)\n", "type": "stream"}], "id": "pHFh", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "dd9ef142fcda82825b003d755d4b8bc5", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "Transfer plan: 8 chunks needed\n\nSender 0 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (0, 0)\n\nSender 0 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (0, 0)\n\nSender 1 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (256, 0)\n\nSender 1 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (256, 0)\n\nSender 2 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (512, 0)\n\nSender 2 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (512, 0)\n\nSender 3 \u2192 Receiver 0\n  Read from sender offset (0, 0), shape (256, 512)\n  Write to receiver offset (768, 0)\n\nSender 3 \u2192 Receiver 1\n  Read from sender offset (0, 512), shape (256, 512)\n  Write to receiver offset (768, 0)\n\n", "type": "stream"}], "id": "NCOB", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "f26af2d921295d23ea615b4e023bb94d", "console": [], "id": "aqbW", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"live-benchmark-gather-vs-routed\"\u003ELive Benchmark: Gather vs Routed\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's benchmark the two approaches with \u003Cstrong\u003E3 layers sharded differently\u003C/strong\u003E:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ELayer\u003C/th\u003E\n\u003Cth\u003EShape\u003C/th\u003E\n\u003Cth\u003ETrainer Sharding\u003C/th\u003E\n\u003Cth\u003EGenerator Sharding\u003C/th\u003E\n\u003Cth\u003ERouting Opportunity\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E0\u003C/td\u003E\n\u003Ctd\u003E1024\u00d71024\u003C/td\u003E\n\u003Ctd\u003ERow-sharded (4-way)\u003C/td\u003E\n\u003Ctd\u003ERow-sharded (2-way)\u003C/td\u003E\n\u003Ctd\u003EYes! Same dim\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E1\u003C/td\u003E\n\u003Ctd\u003E512\u00d72048\u003C/td\u003E\n\u003Ctd\u003ECol-sharded (4-way)\u003C/td\u003E\n\u003Ctd\u003ECol-sharded (2-way)\u003C/td\u003E\n\u003Ctd\u003EYes! Same dim\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E2\u003C/td\u003E\n\u003Ctd\u003E256\u00d7256\u003C/td\u003E\n\u003Ctd\u003EReplicated\u003C/td\u003E\n\u003Ctd\u003EReplicated\u003C/td\u003E\n\u003Ctd\u003ENo sharding\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cdiv class=\"language-actionscript3 codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003EExample\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ELayer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EBoth\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erow\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Esharded\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Edifferent\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egranularity\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003ETRAINER\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eway\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erow\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E                       \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eway\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erow\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erows\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E255\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erows\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E511\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E512\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2191\u003C/span\u003E\u003Cspan class=\"w\"\u003E                           \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erows\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E511\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E+\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eonly\u003C/span\u003E\u003Cspan class=\"w\"\u003E                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erows\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E512\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E767\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EG1\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erows\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E512\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1023\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E512\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2191\u003C/span\u003E\u003Cspan class=\"w\"\u003E                           \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Erows\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E768\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1023\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E+\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eonly\u003C/span\u003E\u003Cspan class=\"w\"\u003E                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003EGATHER\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAPPROACH\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"n\"\u003EROUTED\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAPPROACH\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efull\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2713\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efull\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2713\u003C/span\u003E\u003Cspan class=\"w\"\u003E            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efull\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2713\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efull\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2713\u003C/span\u003E\u003Cspan class=\"w\"\u003E            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efull\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2717\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EWASTED\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eskips\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eoverlap\u003C/span\u003E\u003Cspan class=\"o\"\u003E!)\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efull\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E256\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u00d7\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2717\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EWASTED\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etransfers\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eshards\u003C/span\u003E\u003Cspan class=\"w\"\u003E            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etransfers\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eshards\u003C/span\u003E\u003Cspan class=\"w\"\u003E            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EG1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etransfers\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eshards\u003C/span\u003E\u003Cspan class=\"w\"\u003E            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EG1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etransfers\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eshards\u003C/span\u003E\u003Cspan class=\"w\"\u003E            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003ETotal\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E8\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etransfers\u003C/span\u003E\u003Cspan class=\"w\"\u003E                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003ETotal\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etransfers\u003C/span\u003E\u003Cspan class=\"w\"\u003E                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E50\u003C/span\u003E\u003Cspan class=\"o\"\u003E%\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewasted\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebandwidth\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"o\"\u003E%\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewasted\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebandwidth\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis exercises the re-sharding logic across different patterns. We'll use RDMAAction\nto batch all the transfers and compare:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EGather\u003C/strong\u003E: Each receiver gets ALL data from ALL senders, then slices locally\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERouted\u003C/strong\u003E: Each receiver only gets data it actually needs (based on overlap)\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "7124722cbde534cdb102f483afec2d65", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "DTensor actors defined (using placement metadata for routing)\n", "type": "stream"}], "id": "TRpd", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "b33f716dfcd3b58035412e825f1f7060", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "\n=== DTensor Reshard Benchmark ===\nTrainer mesh: 4 ranks, Generator mesh: 2 ranks\nLayer configs:\n  Layer 0: (1024, 1024), trainer=S(0), gen=S(0)\n  Layer 1: (512, 2048), trainer=S(1), gen=S(1)\n  Layer 2: (256, 256), trainer=R, gen=R\n\nSetting up distributed...\n[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 0 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 1 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 3 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\n[Gloo] Rank 2 is connected to 3 peer ranks. Expected number of connected peer ranks is : 3\nTrainer 1: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\nTrainer 0: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\nTrainer 3: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\nTrainer 2: shapes=[(256, 1024), (512, 512), (256, 256)], placements=['S(0)', 'S(1)', 'R']\n[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n[Gloo] Rank 1 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\n[Gloo] Rank 0 is connected to 1 peer ranks. Expected number of connected peer ranks is : 1\nGenerator 1: distributed initialized\nGenerator 0: distributed initialized\n  Trainer shapes: [[(256, 1024), (512, 512), (256, 256)], [(256, 1024), (512, 512), (256, 256)], [(256, 1024), (512, 512), (256, 256)], [(256, 1024), (512, 512), (256, 256)]]\n  Generator world sizes: [2, 2]\n\nBuilding transfer plans (using placement metadata)...\n  Generator 0: ({'procs': 0/2}, 'Routed: 5 transfers (placement-aware)')\n  Generator 1: ({'procs': 1/2}, 'Routed: 5 transfers (placement-aware)')\n\nRunning transfers...\n  Step 1: 1082.0ms\n  Step 2: 9.9ms\n  Step 3: 12.0ms\n  Average: 368.0ms\n\nDistributed cleanup complete\n", "type": "stream"}], "id": "TXez", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "150a68bfdccb5ee2c66b01b6ea038293", "console": [], "id": "dNNg", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat the benchmark shows:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EGather\u003C/strong\u003E: Each receiver talks to ALL trainers and receives ALL their data, then discards\n  what it doesn't need. With 4 trainers and 2 generators, that's 8 transfers per layer.\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERouted\u003C/strong\u003E: Each receiver only talks to trainers with overlapping data. For same-dimension\n  sharding (trainer 4-way, generator 2-way), each generator only needs 2 of the 4 shards.\n  That's 4 transfers per layer - \u003Cstrong\u003E50% fewer connections\u003C/strong\u003E.\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EFor large models where weight sync is a bottleneck, the routed approach can save\nsignificant bandwidth. The handshake pattern amortizes the overlap computation cost.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key insight: \u003Cstrong\u003ERDMAAction lets you batch all the routed transfers into one plan\u003C/strong\u003E,\nso you get the efficiency of smart routing with the simplicity of a single \u003Ccode\u003Esubmit()\u003C/code\u003E call.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "451e5f375cd885f5faa4be78edff6345", "console": [], "id": "yCnT", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"the-dtensor-dream-and-reality\"\u003EThe DTensor Dream (and Reality)\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EIf trainer and generator both used \u003Cstrong\u003EDTensor\u003C/strong\u003E with the same sharding spec, re-sharding\nwould be automatic - the framework handles overlap computation and transfers.\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Ideal world: DTensor handles it\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Etrainer_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"n\"\u003EDTensor\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# Shard(0) across 8 GPUs\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerator_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"n\"\u003EDTensor\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# Shard(1) across 2 GPUs\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Re-sharding is just redistribution\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerator_weights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_weights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eredistribute\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egenerator_placement\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EIn practice, it's harder\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EvLLM does its own sharding and weight fusing (not DTensor-compatible)\u003C/li\u003E\n\u003Cli\u003ETraining frameworks (FSDP, etc.) have different abstractions\u003C/li\u003E\n\u003Cli\u003EYou often need custom overlap computation like we showed above\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThe routed approach (compute overlaps, send only needed chunks) is 2x faster than\nnaive gather-then-slice, but requires this manual coordination.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EFor cross-node RDMA transfers\u003C/strong\u003E, the key insight remains: pre-compute the transfer\nplan once, then each sync just executes the planned RDMA operations with RDMAAction.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "4ee241f55b0f0e4b6423165320d8eb6f", "console": [], "id": "wlCL", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"9-putting-it-all-together\"\u003E9. Putting It All Together\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe full async RL weight sync pattern:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"n\"\u003ETRAINER\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ETrain\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estep\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecompletes\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECopy\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Enon\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eblocking\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ED2H\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EPublish\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecircular\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etag\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E4.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EContinue\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etraining\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eblocking\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E                            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u003Cspan class=\"n\"\u003ECIRCULAR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EBUFFER\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eregistered\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E0\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E1\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E2\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2191\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey properties:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ETrainer never blocks waiting for generators\u003C/li\u003E\n\u003Cli\u003EGenerators pull directly to GPU when \u003Cem\u003Ethey're\u003C/em\u003E ready\u003C/li\u003E\n\u003Cli\u003ERe-sharding happens locally on each generator\u003C/li\u003E\n\u003Cli\u003ECircular buffer bounds memory, reuses RDMA registrations\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "26dba11147530b7414a96869242e3902", "console": [], "id": "kqZH", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"code-pattern\"\u003ECode Pattern\u003C/h3\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Trainer side\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweight_buffer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ECircularWeightBuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003Etemplate\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estate_dict_tensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E(),\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003En_slots\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\n        \u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n    \u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003ETuple\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"nb\"\u003Eint\u003C/span\u003E\u003Cspan class=\"p\"\u003E]:\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"sd\"\u003E\u0026#39;\u0026#39;\u0026#39;Return handle to latest weights and version.\u0026#39;\u0026#39;\u0026#39;\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Eslot_idx\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweight_buffer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest_version\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E%\u003C/span\u003E \u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweight_buffer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erdma_handles\u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot_idx\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweight_buffer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest_version\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\n\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Etrain_loop\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ewhile\u003C/span\u003E \u003Cspan class=\"kc\"\u003ETrue\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003Eloss\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrain_step\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n            \u003Cspan class=\"k\"\u003Eif\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estep\u003C/span\u003E \u003Cspan class=\"o\"\u003E%\u003C/span\u003E \u003Cspan class=\"n\"\u003Esync_interval\u003C/span\u003E \u003Cspan class=\"o\"\u003E==\u003C/span\u003E \u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n                \u003Cspan class=\"c1\"\u003E# Non-blocking publish\u003C/span\u003E\n                \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweight_buffer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Epublish\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Generator side\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eclass\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nc\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003EActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"fm\"\u003E__init__\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_ref\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_ref\u003C/span\u003E\n        \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecurrent_version\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\n\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Emaybe_sync_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Eif\u003C/span\u003E \u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E \u003Cspan class=\"o\"\u003E\u0026gt;\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecurrent_version\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n            \u003Cspan class=\"c1\"\u003E# Pull via RDMA directly into GPU memory\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n            \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n            \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecurrent_version\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\n\n    \u003Cspan class=\"k\"\u003Easync\u003C/span\u003E \u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Egenerate_loop\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n        \u003Cspan class=\"k\"\u003Ewhile\u003C/span\u003E \u003Cspan class=\"kc\"\u003ETrue\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n            \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Emaybe_sync_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n            \u003Cspan class=\"n\"\u003Eoutput\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Egenerate\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eprompt\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n            \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Esubmit_to_buffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eoutput\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "3133bc88ab2a0a882aaa3a0475a44017", "console": [], "id": "wAgl", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"10-going-further-torchstore\"\u003E10. Going Further: TorchStore\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EAll the patterns we've covered - RDMA memory registration, magic pointers, circular buffers,\npre-computed transfer plans - are building blocks. If you need a \u003Cstrong\u003Eproduction-ready solution\u003C/strong\u003E,\ncheck out \u003Ca href=\"https://github.com/meta-pytorch/torchstore\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ETorchStore\u003C/a\u003E.\u003C/span\u003E\n\u003Ch3 id=\"what-is-torchstore\"\u003EWhat is TorchStore?\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETorchStore is a \u003Cstrong\u003Edistributed, asynchronous key-value store for PyTorch tensors\u003C/strong\u003E built on\nMonarch's actor framework. It abstracts away the RDMA complexity while giving you:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Etorchstore\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003ETorchStore\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Store tensors with async API\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eput\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;model/layer1/weights\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Retrieve with optional in-place and slice semantics\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;model/layer1/weights\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Einplace_tensor\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Native PyTorch checkpoint support\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eput_state_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estate_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eloaded\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_state_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"rdma-under-the-hood\"\u003ERDMA Under the Hood\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETorchStore implements the patterns we've discussed:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ETransport abstraction\u003C/strong\u003E with automatic RDMA detection:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003ETorchComms RDMA (highest performance)\u003C/li\u003E\n\u003Cli\u003EMonarch RDMA (fallback)\u003C/li\u003E\n\u003Cli\u003EMonarch RPC (no RDMA available)\u003C/li\u003E\n\u003C/ol\u003E\n\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EMemory region management\u003C/strong\u003E: Pre-registers buffers, handles cleanup\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EDTensor support\u003C/strong\u003E: Efficiently stores/retrieves tensor shards across ranks\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ETensor slicing\u003C/strong\u003E: Fetch arbitrary slices without retrieving the whole tensor\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key insight: \u003Cstrong\u003ETorchStore lets you think in key-value semantics while getting RDMA\nperformance\u003C/strong\u003E. No manual buffer management, no handle passing, no overlap computation.\u003C/span\u003E\n\u003Ch3 id=\"when-to-use-what\"\u003EWhen to Use What\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EScenario\u003C/th\u003E\n\u003Cth\u003ESolution\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELearning RDMA patterns\u003C/td\u003E\n\u003Ctd\u003EThis notebook's examples\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ECustom RL weight sync\u003C/td\u003E\n\u003Ctd\u003EBuild on \u003Ccode\u003ERDMABuffer\u003C/code\u003E + \u003Ccode\u003ERDMAAction\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGeneral tensor storage\u003C/td\u003E\n\u003Ctd\u003EUse TorchStore\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ECheckpointing\u003C/td\u003E\n\u003Ctd\u003EUse TorchStore's \u003Ccode\u003Eput_state_dict\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "a3abb4c511005ddfec0279d1c84e6846", "console": [], "id": "rEll", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"summary\"\u003ESummary\u003C/h2\u003E\n\u003Ch3 id=\"key-takeaways\"\u003EKey Takeaways\u003C/h3\u003E\n\u003Col\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EBandwidth hierarchy matters\u003C/strong\u003E: NVLink (450 GB/s) \u0026gt;\u0026gt; InfiniBand (50-100 GB/s) \u0026gt;\u0026gt; PCIe\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EKnow your hardware, optimize for the right interconnect\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECollectives vs P2P\u003C/strong\u003E: Collectives are synchronized; RL needs async P2P\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EHigh variance in generation times makes blocking expensive\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EMagic pointer pattern\u003C/strong\u003E: Tiny handle over control plane, bulk data over data plane\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E~100 bytes to describe 10 GB transfer\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECPU staging\u003C/strong\u003E: Temporal decoupling for async RL\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EGPU-native RDMA works for sync cases\u003C/li\u003E\n\u003Cli\u003ECPU staging ensures nothing blocks on the critical path\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECircular buffers\u003C/strong\u003E: Version weights without memory churn\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EPre-register RDMA buffers, reuse slots\u003C/li\u003E\n\u003Cli\u003EGenerators grab latest, never stale\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWeight re-sharding\u003C/strong\u003E: Different layouts need overlap computation\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ERouted approach is 2x faster than gather\u003C/li\u003E\n\u003Cli\u003EPre-compute transfer plan, minimize redundant data\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003C/ol\u003E\n\u003Ch3 id=\"next-steps\"\u003ENext Steps\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ESee \u003Cstrong\u003E07_async_rl_e2e.py\u003C/strong\u003E for a complete async RL system that uses these patterns.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.19.7%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20RDMA%20%26%20Weight%20Synchronization%0A%0A%20%20%20%20This%20notebook%20explores%20efficient%20weight%20synchronization%20for%20async%20RL%20systems.%0A%0A%20%20%20%20**Outline%3A**%0A%0A%20%20%20%201.%20**Why%20Weight%20Sync%20Matters**%20-%20On-policy%20vs%20off-policy%2C%20model%20scale%0A%20%20%20%202.%20**The%20Bandwidth%20Hierarchy**%20-%20NVLink%2C%20InfiniBand%2C%20PCIe%0A%20%20%20%203.%20**The%20Problem%3A%20Collectives%20Are%20Blocking**%20-%20Why%20RL%20needs%20something%20different%0A%20%20%20%204.%20**How%20RDMA%20Works**%20-%20ibverbs%2C%20one-sided%20operations%0A%20%20%20%205.%20**The%20Magic%20Pointer%20Pattern**%20-%20Control%20plane%20vs%20data%20plane%20separation%0A%20%20%20%206.%20**CPU%20Staging**%20-%20Decoupling%20trainer%20and%20generator%20timing%0A%20%20%20%207.%20**Circular%20Weight%20Buffers**%20-%20Versioning%20without%20memory%20churn%0A%20%20%20%208.%20**Weight%20Re-sharding**%20-%20Handling%20different%20tensor%20layouts%0A%20%20%20%209.%20**Putting%20It%20All%20Together**%20-%20The%20complete%20pattern%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%201.%20Why%20Weight%20Sync%20Matters%0A%0A%20%20%20%20%23%23%23%20The%20On-Policy%20Problem%0A%0A%20%20%20%20Traditional%20RL%20algorithms%20want%20to%20be%20**on-policy**%3A%20generate%20experience%20using%20the%20current%0A%20%20%20%20policy%2C%20then%20immediately%20use%20that%20experience%20to%20update%20the%20policy.%20This%20creates%20a%20tight%20loop%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20On-Policy%20RL%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20generate(policy_v1)%20%E2%86%92%20train(samples)%20%E2%86%92%20policy_v2%20%E2%86%92%20repeat%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Experience%20from%20v1%20is%20only%20valid%20for%20updating%20v1%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Async%20RL%20breaks%20this%20rule.**%20Generators%20run%20continuously%20while%20the%20trainer%20updates%20weights.%0A%20%20%20%20By%20the%20time%20a%20sample%20reaches%20the%20trainer%2C%20it%20was%20generated%20by%20an%20old%20policy%20version%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Async%20RL%20(off-policy)%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20Generator%3A%20policy_v1%20%E2%86%92%20sample%E2%82%81%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Trainer%3A%20%20%20train(sample%E2%82%81)%20%E2%86%92%20policy_v2%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Generator%3A%20policy_v1%20%E2%86%92%20sample%E2%82%82%20%20%E2%86%90%20still%20using%20v1!%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Trainer%3A%20%20%20train(sample%E2%82%82)%20%E2%86%92%20policy_v3%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Samples%20are%20%22stale%22%20-%20generated%20by%20older%20policy%20versions%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20**off-policy-ness**%20can%20work%20up%20to%20a%20degree%2C%20but%20must%20be%20limited.%20The%20generators%0A%20%20%20%20need%20fresh%20weights%20regularly%20to%20stay%20%22close%20enough%22%20to%20on-policy.%20Weight%20sync%20frequency%0A%20%20%20%20becomes%20a%20key%20hyperparameter%20trading%20off%3A%0A%0A%20%20%20%20-%20**Too%20slow**%3A%20Samples%20become%20too%20stale%2C%20training%20diverges%0A%20%20%20%20-%20**Too%20fast**%3A%20Weight%20sync%20overhead%20dominates%2C%20negating%20async%20benefits%0A%0A%20%20%20%20%23%23%23%20The%20Scale%20Problem%0A%0A%20%20%20%20For%20LLM-based%20RL%2C%20the%20weights%20are%20**massive**.%20Let's%20calculate%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20%23%20Calculate%20model%20sizes%0A%20%20%20%20_models%20%3D%20%5B%0A%20%20%20%20%20%20%20%20(%22Llama%203.2%203B%22%2C%203)%2C%0A%20%20%20%20%20%20%20%20(%22Qwen%202.5%207B%22%2C%207)%2C%0A%20%20%20%20%20%20%20%20(%22Llama%203.1%2070B%22%2C%2070)%2C%0A%20%20%20%20%20%20%20%20(%22Llama%203.1%20405B%22%2C%20405)%2C%0A%20%20%20%20%20%20%20%20(%22DeepSeek%20V3%20671B%22%2C%20671)%2C%0A%20%20%20%20%5D%0A%0A%20%20%20%20print(%22Model%20Weight%20Sizes%20(bf16%20precision)%3A%5Cn%22)%0A%20%20%20%20print(f%22%7B'Model'%3A%3C20%7D%20%7B'Weight%20Size'%7D%22)%0A%20%20%20%20print(%22-%22%20*%2035)%0A%0A%20%20%20%20for%20_name%2C%20_params_b%20in%20_models%3A%0A%20%20%20%20%20%20%20%20_size_gb%20%3D%20_params_b%20*%202%20%20%23%20bf16%20%3D%202%20bytes%20per%20param%0A%0A%20%20%20%20%20%20%20%20if%20_size_gb%20%3E%3D%201000%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_size_str%20%3D%20f%22%7B_size_gb%2F1000%3A.1f%7D%20TB%22%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_size_str%20%3D%20f%22%7B_size_gb%3A.0f%7D%20GB%22%0A%0A%20%20%20%20%20%20%20%20print(f%22%7B_name%3A%3C20%7D%20%7B_size_str%7D%22)%0A%0A%20%20%20%20print(%22%5Cn%E2%86%92%20These%20weights%20need%20to%20move%20from%20trainer%20%E2%86%92%20generators%22)%0A%20%20%20%20print(%22%E2%86%92%20For%20large%20models%2C%20this%20means%20crossing%20the%20network%20fabric%22)%0A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Why%20This%20Forces%20Cross-Node%20Transfer%0A%0A%20%20%20%20The%20numbers%20speak%20for%20themselves%3A%0A%0A%20%20%20%20-%20A%20**70B%20model**%20has%20140%20GB%20of%20weights%0A%20%20%20%20-%20A%20**405B%20model**%20has%20810%20GB%20of%20weights%0A%20%20%20%20-%20**DeepSeek%20V3**%20has%201.3%20TB%20of%20weights%0A%0A%20%20%20%20These%20models%20are%20sharded%20across%20many%20GPUs%2C%20often%20spanning%20multiple%20nodes.%0A%20%20%20%20Weight%20sync%20can't%20rely%20on%20NVLink%20alone%20-%20it%20must%20cross%20InfiniBand%2FRoCE.%0A%0A%20%20%20%20This%20is%20why%20we%20need%20RDMA.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%202.%20The%20Bandwidth%20Hierarchy%0A%0A%20%20%20%20Modern%20HPC%20clusters%20have%20multiple%20interconnects%20with%20vastly%20different%20bandwidths%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NODE%20A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NVSwitch%20%2F%20NVLink%20Fabric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s%20NVLink%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2064%20GB%2Fs%20PCIe%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20------%2048%20GB%2Fs%20------%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20CPU%200%20%20%E2%94%82%20%20%20%20%20CPU%20interconnect%20%20%20%E2%94%82%20%20CPU%201%20%20%E2%94%82%20%3D%3D%3D%3D%3D%3D%2064%20GB%2Fs%20%E2%95%90%E2%95%90%E2%94%82%20NIC%200%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20NIC%201%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20PCIe%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%2064%20GB%2Fs%20PCIe%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2050%20GB%2Fs%20%20%20%3D%3D%3D%3D%3D%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20IB%20NDR400%20%20%20%20%20%20%20%20%20IB%20NDR400%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20InfiniBand%20Switch%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2050%20GB%2Fs%20%20%20%3D%3D%3D%3D%3D%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20IB%20NDR400%20%20%20%20%20%20%20%20%20IB%20NDR400%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%2064%20GB%2Fs%20PCIe%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20PCIe%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20CPU%200%20%20%E2%94%82%20%20%20%20%20CPU%20interconnect%20%20%20%E2%94%82%20%20CPU%201%20%20%E2%94%82%20%3D%3D%3D%3D%3D%3D%2064%20GB%2Fs%20%E2%95%90%E2%95%90%E2%94%82%20NIC%200%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20NIC%201%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20------%2048%20GB%2Fs%20------%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2064%20GB%2Fs%20PCIe%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%20%20900%20GB%2Fs%20NVLink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witch%20%2F%20NVLink%20Fabric%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NODE%20B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%0A%20%20%20%20Bandwidth%20encoding%20(line%20intensity)%3A%0A%20%20%20%20%20%20%23%23%23%23%23%23%23%23%20%20NVLink%2FNVSwitch%20%20%20900%20GB%2Fs%20%20%20(GPU%20%E2%86%94%20GPU%2C%20same%20node)%0A%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%3D%3D%20%20PCIe%20Gen5%20%2F%20IB%20%20%20%20%2050-64%20GB%2Fs%20(CPU%E2%86%94GPU%2C%20CPU%E2%86%94NIC%2C%20cross-node)%0A%20%20%20%20%20%20--------%20%20CPU%20interconnect%20%20%2048%20GB%2Fs%20%20%20(CPU%20%E2%86%94%20CPU%2C%20same%20node)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20RDMA%20can%20transfer%20between%20any%20registered%20memory%20(CPU%20or%20GPU)%20via%20the%20NICs.%0A%0A%20%20%20%20%7C%20Interconnect%20%7C%20Bandwidth%20%7C%20Latency%20%7C%20Use%20Case%20%7C%0A%20%20%20%20%7C--------------%7C-----------%7C---------%7C----------%7C%0A%20%20%20%20%7C%20**NVLink%2FNVSwitch**%20%7C%20900%20GB%2Fs%20%7C%20~1%20%CE%BCs%20%7C%20Same-node%20GPU%E2%86%94GPU%20%7C%0A%20%20%20%20%7C%20**InfiniBand%20NDR400**%20%7C%2050%20GB%2Fs%20%7C%20~1-2%20%CE%BCs%20%7C%20Cross-node%20RDMA%20%7C%0A%20%20%20%20%7C%20**PCIe%20Gen5%20x16**%20%7C%2064%20GB%2Fs%20%7C%20~1-2%20%CE%BCs%20%7C%20CPU%E2%86%94GPU%2C%20CPU%E2%86%94NIC%20%7C%0A%20%20%20%20%7C%20**CPU%20interconnect**%20%7C%2048%20GB%2Fs%20%7C%20~100%20ns%20%7C%20CPU%E2%86%94CPU%20(same%20node)%20%7C%0A%0A%20%20%20%20**Key%20observations%3A**%0A%0A%20%20%20%201.%20**NVLink%20dominates**%20-%20900%20GB%2Fs%20is%20~18x%20faster%20than%20cross-node%20RDMA.%20Same-node%20GPU%E2%86%94GPU%0A%20%20%20%20%20%20%20communication%20is%20nearly%20free%20compared%20to%20crossing%20the%20network.%0A%0A%20%20%20%202.%20**RDMA%20%3E%3E%20Ethernet**%20-%20InfiniBand%2FRoCE%20at%2050%20GB%2Fs%20is%20~4x%20faster%20than%20100GbE%20(12.5%20GB%2Fs)%2C%0A%20%20%20%20%20%20%20plus%20kernel%20bypass%20and%20lower%20latency.%20Worth%20the%20complexity%20for%20HPC%20workloads.%0A%0A%20%20%20%203.%20**PCIe%20is%20faster%20than%20you'd%20think**%20-%20At%2064%20GB%2Fs%2C%20CPU%E2%86%94GPU%20transfers%20aren't%20the%20bottleneck%0A%20%20%20%20%20%20%20people%20often%20assume.%20The%20real%20cost%20is%20synchronization%2C%20not%20bandwidth.%0A%0A%20%20%20%20**Rule%20of%20thumb**%3A%20Place%20the%20most%20bandwidth-intensive%2C%20frequent%20operations%20on%20NVLink%0A%20%20%20%20(gradients%2C%20activations).%20Use%20RDMA%20for%20cross-node%20communication%20(weight%20sync%2C%20sharding).%0A%20%20%20%20PCIe%20is%20fine%20for%20occasional%20CPU%E2%86%94GPU%20transfers.%0A%0A%20%20%20%20We'll%20focus%20primarily%20on%20**NVLink**%20and%20**RDMA**%20for%20this%20notebook.%20Most%20people%20use%20these%0A%20%20%20%20via%20**collectives**%2C%20exposed%20through%20PyTorch%20distributed%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20import%20torch.distributed%20as%20dist%0A%0A%20%20%20%20%23%20Initialize%20process%20group%20-%20NCCL%20uses%20NVLink%20(same-node)%20and%20RDMA%20(cross-node)%0A%20%20%20%20dist.init_process_group(backend%3D%22nccl%22)%0A%0A%20%20%20%20%23%20All-reduce%3A%20average%20gradients%20across%20all%20GPUs%0A%20%20%20%20dist.all_reduce(gradients%2C%20op%3Ddist.ReduceOp.SUM)%0A%20%20%20%20gradients%20%2F%3D%20world_size%0A%0A%20%20%20%20%23%20All-gather%3A%20collect%20tensors%20from%20all%20ranks%0A%20%20%20%20gathered%20%3D%20%5Btorch.empty_like(tensor)%20for%20_%20in%20range(world_size)%5D%0A%20%20%20%20dist.all_gather(gathered%2C%20tensor)%0A%0A%20%20%20%20%23%20Broadcast%3A%20send%20from%20rank%200%20to%20all%20others%0A%20%20%20%20dist.broadcast(weights%2C%20src%3D0)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20works%20great%20for%20training.%20But%20for%20RL%20weight%20sync%2C%20we%20need%20something%20different...%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20torch%0A%20%20%20%20return%20(torch%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%203.%20The%20Problem%3A%20Collectives%20Are%20Blocking%0A%0A%20%20%20%20Collectives%20work%20great%20for%20training%20-%20everyone%20computes%20gradients%2C%20then%20synchronizes.%0A%20%20%20%20But%20async%20RL%20has%20a%20different%20access%20pattern.%0A%0A%20%20%20%20%23%23%23%20High%20Variance%20in%20Generation%20Times%0A%0A%20%20%20%20Generators%20have%20wildly%20different%20completion%20times%3A%0A%20%20%20%20-%20Some%20prompts%20%E2%86%92%2010%20tokens%20(fast)%0A%20%20%20%20-%20Other%20prompts%20%E2%86%92%201000%20tokens%20(slow)%0A%0A%20%20%20%20With%20collectives%2C%20fast%20generators%20wait%20for%20slow%20ones%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Generator%200%3A%20%E2%94%9C%E2%94%80%E2%94%80%20gen%20(fast)%20%E2%94%80%E2%94%80%E2%94%A4%20%20%E2%9A%A0%EF%B8%8F%20WAITING...%0A%20%20%20%20Generator%201%3A%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%20gen%20(slow)%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20Generator%202%3A%20%E2%94%9C%E2%94%80%E2%94%80%20gen%20(fast)%20%E2%94%80%E2%94%80%E2%94%A4%20%20%E2%9A%A0%EF%B8%8F%20WAITING...%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20all_gather(weights)%20%20%23%20Everyone%20waits!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20What%20About%20send%2Frecv%3F%0A%0A%20%20%20%20PyTorch%20distributed%20does%20have%20point-to-point%20primitives%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Sender%20side%0A%20%20%20%20dist.send(tensor%2C%20dst%3Dreceiver_rank)%0A%0A%20%20%20%20%23%20Receiver%20side%0A%20%20%20%20dist.recv(tensor%2C%20src%3Dsender_rank)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20But%20this%20is%20**two-sided**%20-%20both%20sender%20and%20receiver%20must%20coordinate%3A%0A%20%20%20%20-%20Receiver%20must%20call%20%60recv()%60%20before%20sender's%20%60send()%60%20completes%0A%20%20%20%20-%20Trainer%20would%20need%20to%20wait%20until%20generators%20are%20ready%20to%20receive%0A%20%20%20%20-%20Still%20blocking%20on%20coordination!%0A%0A%20%20%20%20%23%23%23%20The%20One-Sided%20Solution%3A%20RDMA%0A%0A%20%20%20%20What%20if%20the%20sender%20could%20write%20directly%20to%20the%20receiver's%20memory%20without%20coordination%3F%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Two-sided%20(send%2Frecv)%3A%0A%20%20%20%20%20%20Sender%3A%20%22I%20have%20data%22%20%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20Receiver%3A%20%22I'm%20ready%22%0A%20%20%20%20%20%20Sender%3A%20sends%20data%20%20%20%20%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20Receiver%3A%20receives%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%202%20messages%20required%0A%0A%20%20%20%20One-sided%20(RDMA)%3A%0A%20%20%20%20%20%20Sender%3A%20writes%20directly%20to%20receiver's%20memory%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20No%20coordination%20needed!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20what%20RDMA%20enables%3A%20**one-sided%20memory%20operations**.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%204.%20How%20RDMA%20Works%20(ibverbs)%0A%0A%20%20%20%20RDMA%20(Remote%20Direct%20Memory%20Access)%20lets%20one%20machine%20read%2Fwrite%20another%20machine's%20memory%0A%20%20%20%20directly%2C%20bypassing%20the%20kernel%20and%20CPU%20on%20both%20sides.%0A%0A%20%20%20%20%23%23%23%20The%20ibverbs%20Stack%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20Application%20(PyTorch%2C%20Monarch%2C%20etc.)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20%20libibverbs%20%20(userspace%20RDMA%20API)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20%20Provider%20driver%20(mlx5%2C%20efa%2C%20rxe%2C%20etc.)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20%20Hardware%20(InfiniBand%20NIC%2C%20RoCE%20NIC%2C%20etc.)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20We'll%20focus%20on%20**InfiniBand**%20and%20**RoCE**%20(RDMA%20over%20Converged%20Ethernet).%0A%20%20%20%20Other%20transports%20like%20AWS%20EFA%20exist%20but%20we%20won't%20cover%20them%20here.%0A%0A%20%20%20%20%23%23%23%20Key%20RDMA%20Operations%0A%0A%20%20%20%20%7C%20Operation%20%7C%20Description%20%7C%0A%20%20%20%20%7C-----------%7C-------------%7C%0A%20%20%20%20%7C%20%60RDMA_WRITE%60%20%7C%20Write%20to%20remote%20memory%20(one-sided)%20%7C%0A%20%20%20%20%7C%20%60RDMA_READ%60%20%7C%20Read%20from%20remote%20memory%20(one-sided)%20%7C%0A%20%20%20%20%7C%20%60SEND%2FRECV%60%20%7C%20Two-sided%20messaging%20(like%20TCP)%20%7C%0A%0A%20%20%20%20The%20magic%20is%20in%20%60RDMA_WRITE%60%20and%20%60RDMA_READ%60%20-%20they're%20**one-sided**%3A%0A%20%20%20%20-%20Remote%20CPU%20is%20not%20involved%0A%20%20%20%20-%20Remote%20application%20doesn't%20need%20to%20call%20anything%0A%20%20%20%20-%20NIC%20handles%20everything%20in%20hardware%0A%0A%20%20%20%20%23%23%23%20Memory%20Registration%0A%0A%20%20%20%20Before%20RDMA%2C%20memory%20must%20be%20**registered**%20with%20the%20NIC%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Conceptually%20(actual%20ibverbs%20API%20is%20in%20C)%0A%20%20%20%20mr%20%3D%20rdma_register_memory(buffer%2C%20size)%0A%20%20%20%20%23%20Returns%3A%0A%20%20%20%20%23%20%20%20-%20lkey%3A%20local%20access%20key%20(for%20local%20operations)%0A%20%20%20%20%23%20%20%20-%20rkey%3A%20remote%20access%20key%20(share%20with%20remote%20peer)%0A%20%20%20%20%23%20%20%20-%20addr%3A%20physical%2Fvirtual%20address%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20%60(addr%2C%20rkey)%60%20pair%20is%20a%20**remote-accessible%20pointer**.%20Share%20it%20with%20a%20peer%2C%0A%20%20%20%20and%20they%20can%20read%2Fwrite%20your%20memory%20directly.%0A%0A%20%20%20%20%23%23%23%20Queue%20Pair%20Setup%0A%0A%20%20%20%20Before%20any%20RDMA%20operations%2C%20you%20need%20to%20establish%20a%20**Queue%20Pair%20(QP)**%20between%0A%20%20%20%20sender%20and%20receiver.%20This%20is%20a%20one-time%20connection%20setup%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20Sender%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20Receiver%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Create%20QP%20%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%20exchange%20QP%20info%20%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%E2%94%82%20%20Create%20QP%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20(qp_num%2C%20%20%20%E2%94%82%20%E2%97%84%E2%94%80%E2%94%80%20(qp_num%2C%20lid%2C%20gid)%20%E2%94%80%E2%94%80%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20lid%2C%20gid)%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Move%20QP%20to%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20Move%20QP%20to%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20RTR%20%E2%86%92%20RTS%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20RTR%20%E2%86%92%20RTS%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Now%20ready%20%20%E2%94%82%20%E2%95%90%E2%95%90%E2%95%90%20RDMA%20operations%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%96%BA%20%E2%94%82%20%20Now%20ready%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20for%20RDMA!%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20for%20RDMA!%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20where%20**Monarch%20actors**%20shine.%20Because%20you%20can%20spawn%20arbitrary%20actors%2C%0A%20%20%20%20you%20can%20create%20**RDMA%20Manager%20actors**%20that%3A%0A%20%20%20%20-%20Initialize%20QPs%20on%20their%20respective%20hosts%0A%20%20%20%20-%20Exchange%20QP%20info%20via%20actor%20messages%0A%20%20%20%20-%20Manage%20the%20connection%20lifecycle%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Monarch%20pattern%3A%20RDMA%20managers%20as%20actors%0A%20%20%20%20class%20RDMAManager(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.qp%20%3D%20create_queue_pair()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.qp_info%20%3D%20get_qp_info(self.qp)%20%20%23%20(qp_num%2C%20lid%2C%20gid)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_qp_info(self)%20-%3E%20QpInfo%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.qp_info%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20connect(self%2C%20remote_qp_info%3A%20QpInfo)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Transition%20QP%3A%20INIT%20%E2%86%92%20RTR%20%E2%86%92%20RTS%0A%20%20%20%20%20%20%20%20%20%20%20%20connect_qp(self.qp%2C%20remote_qp_info)%0A%0A%20%20%20%20%23%20Setup%3A%20exchange%20QP%20info%20via%20actor%20messages%2C%20then%20RDMA%20is%20ready%0A%20%20%20%20trainer_info%20%3D%20trainer_rdma.get_qp_info.call_one().get()%0A%20%20%20%20generator_rdma.connect.call_one(trainer_info).get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20actor%20abstraction%20makes%20RDMA%20connection%20management%20natural%20and%20composable.%0A%0A%20%20%20%20%23%23%23%20Monarch%20Using%20Monarch%3A%20RdmaController%0A%0A%20%20%20%20Here's%20the%20cool%20part%3A%20**Monarch%20uses%20itself**%20to%20manage%20RDMA%20infrastructure.%20Looking%20at%0A%20%20%20%20the%20actual%20Python%20code%20in%20%60monarch%2F_src%2Frdma%2Frdma.py%60%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20From%20Monarch's%20RDMA%20implementation%0A%20%20%20%20from%20monarch._src.actor.proc_mesh%20import%20get_or_spawn_controller%0A%0A%20%20%20%20class%20RdmaController(Actor)%3A%0A%20%20%20%20%20%20%20%20'''Singleton%20controller%20that%20coordinates%20RDMA%20initialization.'''%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Track%20which%20proc%20meshes%20have%20RDMA%20initialized%0A%20%20%20%20%20%20%20%20%20%20%20%20self._manager_futures%3A%20dict%5BProcMesh%2C%20Future%5BRdmaManager%5D%5D%20%3D%20%7B%7D%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20async%20def%20init_rdma_on_mesh(self%2C%20proc_mesh%3A%20ProcMesh)%20-%3E%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20'''Lazily%20initialize%20RDMA%20on%20a%20proc%20mesh.'''%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20proc_mesh%20not%20in%20self._manager_futures%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self._manager_futures%5Bproc_mesh%5D%20%3D%20Future(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20coro%3DRdmaManager.create(proc_mesh)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20await%20self._manager_futures%5Bproc_mesh%5D%0A%0A%20%20%20%20%23%20Cached%20initialization%20-%20only%20runs%20once%20per%20process%0A%20%20%20%20%40functools.cache%0A%20%20%20%20def%20_ensure_init_rdma_manager()%3A%0A%20%20%20%20%20%20%20%20async%20def%20task()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20controller%20%3D%20await%20get_or_spawn_controller(%22rdma_controller%22%2C%20RdmaController)%0A%20%20%20%20%20%20%20%20%20%20%20%20await%20controller.init_rdma_on_mesh.call_one(current_proc_mesh())%0A%20%20%20%20%20%20%20%20return%20spawn_task(task())%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20**Monarch%20building%20Monarch**%20-%20the%20RDMA%20subsystem%20uses%20the%20same%20patterns%3A%0A%0A%20%20%20%20-%20%60get_or_spawn_controller(%22rdma_controller%22%2C%20RdmaController)%60%20ensures%20one%20global%20controller%0A%20%20%20%20-%20The%20controller%20lazily%20initializes%20RDMA%20managers%20per%20proc%20mesh%0A%20%20%20%20-%20%60%40functools.cache%60%20ensures%20we%20only%20bootstrap%20once%20per%20process%0A%20%20%20%20-%20Under%20the%20hood%2C%20the%20actual%20RDMA%20operations%20are%20in%20Rust%20(%60RdmaManagerActor%60)%0A%0A%20%20%20%20It's%20actors%20all%20the%20way%20down.%0A%0A%20%20%20%20%23%23%23%20Why%20This%20Matters%20for%20Weight%20Sync%0A%0A%20%20%20%20Remember%3A%20CPU%20memory%20AND%20GPU%20memory%20can%20both%20be%20registered%20for%20RDMA.%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%3A%0A%20%20%20%20%20%201.%20Register%20weight%20buffer%20with%20RDMA%20NIC%0A%20%20%20%20%20%202.%20Get%20(addr%2C%20rkey)%20handle%0A%20%20%20%20%20%203.%20Share%20handle%20with%20generators%20(tiny%20message)%0A%0A%20%20%20%20Generator%3A%0A%20%20%20%20%20%201.%20Receive%20handle%0A%20%20%20%20%20%202.%20RDMA_READ%20directly%20from%20trainer's%20memory%0A%20%20%20%20%20%203.%20No%20coordination%20with%20trainer%20needed!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20trainer%20doesn't%20even%20know%20when%20generators%20pull%20weights.%20True%20one-sided.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%205.%20The%20Magic%20Pointer%20Pattern%0A%0A%20%20%20%20Now%20here's%20the%20key%20insight%20from%20our%20RDMA%20discussion%3A%20to%20represent%20remote%20data%2C%0A%20%20%20%20we%20only%20need%20a%20**tiny%20handle**%20-%20the%20%60(addr%2C%20rkey%2C%20size)%60%20tuple.%0A%0A%20%20%20%20Monarch%20wraps%20this%20in%20%60RDMABuffer%60.%20Let's%20see%20how%20small%20it%20actually%20is%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23%20Central%20imports%20for%20all%20RDMA%20examples%20in%20this%20notebook%0A%20%20%20%20import%20time%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20this_host%2C%20current_rank%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%2C%20RDMAAction%2C%20is_rdma_available%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20Actor%2C%0A%20%20%20%20%20%20%20%20RDMAAction%2C%0A%20%20%20%20%20%20%20%20RDMABuffer%2C%0A%20%20%20%20%20%20%20%20current_rank%2C%0A%20%20%20%20%20%20%20%20endpoint%2C%0A%20%20%20%20%20%20%20%20is_rdma_available%2C%0A%20%20%20%20%20%20%20%20this_host%2C%0A%20%20%20%20%20%20%20%20time%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20endpoint%2C%20is_rdma_available%2C%20this_host%2C%20torch)%3A%0A%20%20%20%20%23%20Measure%20actual%20size%20of%20RDMABuffer%20handles%0A%20%20%20%20import%20pickle%0A%0A%20%20%20%20def%20show_fallback()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Fallback%3A%20show%20expected%20sizes%20based%20on%20RDMABuffer%20structure.%22%22%22%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20expected%20handle%20sizes)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%22RDMABuffer%20contains%3A%20addr%20(8B)%20%2B%20rkey%20(4B)%20%2B%20size%20(8B)%20%2B%20owner%20(~100B)%22)%0A%20%20%20%20%20%20%20%20print(%22Total%20serialized%20size%3A%20~150-200%20bytes%20regardless%20of%20tensor%20size%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20sizes%20%3D%20%5B(%221%20KB%22%2C%201024)%2C%20(%221%20MB%22%2C%201024**2)%2C%20(%221%20GB%22%2C%201024**3)%5D%0A%20%20%20%20%20%20%20%20handle_bytes%20%3D%20150%20%20%23%20approximate%0A%0A%20%20%20%20%20%20%20%20for%20name%2C%20tensor_bytes%20in%20sizes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20ratio%20%3D%20tensor_bytes%20%2F%20handle_bytes%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bname%3A%3C8%7D%20tensor%20%E2%86%92%20~150%20byte%20handle%20%E2%86%92%20%7Bratio%3A%2C.0f%7Dx%20compression%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Handle%20size%20is%20O(1)%20regardless%20of%20tensor%20size!%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20BufferSizeDemo(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Actor%20that%20creates%20RDMABuffers%20and%20measures%20their%20size.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20measure_buffer_sizes(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20pickle%20as%20_pickle%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20results%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sizes%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%221%20KB%22%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%221%20MB%22%2C%20256%20*%201024)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%2210%20MB%22%2C%20256%20*%201024%20*%2010)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20numel%20in%20sizes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tensor%20%3D%20torch.randn(numel)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tensor_bytes%20%3D%20tensor.numel()%20*%20tensor.element_size()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_tensor%20%3D%20tensor.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20buffer%20%3D%20RDMABuffer(byte_tensor)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle_bytes%20%3D%20len(_pickle.dumps(buffer))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20results.append((name%2C%20tensor_bytes%2C%20handle_bytes))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20results%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20%20%20%20%20%20%20%20%20proc%20%3D%20host.spawn_procs(%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20%20%20%20%20demo%20%3D%20proc.spawn(%22buffer_demo%22%2C%20BufferSizeDemo)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20results%20%3D%20demo.measure_buffer_sizes.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22RDMABuffer%20handle%20size%20vs%20actual%20tensor%20size%3A%5Cn%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7B'Tensor%20Size'%3A%3C12%7D%20%7B'Actual%20Bytes'%3A%3C15%7D%20%7B'Handle%20Size'%3A%3C15%7D%20%7B'Ratio'%3A%3C10%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22-%22%20*%2055)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20tensor_bytes%2C%20handle_bytes%20in%20results%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ratio%20%3D%20tensor_bytes%20%2F%20handle_bytes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bname%3A%3C12%7D%20%7Btensor_bytes%3A%3E12%2C%7D%20B%20%20%20%7Bhandle_bytes%3A%3E6%7D%20B%20%20%20%20%20%20%20%20%7Bratio%3A%3E8%2C.0f%7Dx%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Handle%20size%20is%20O(1)%20regardless%20of%20tensor%20size!%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22(RDMA%20setup%20failed%3A%20%7Be%7D)%5Cn%22)%0A%20%20%20%20%20%20%20%20show_fallback()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20The%20Magic%20Pointer%0A%0A%20%20%20%20This%20is%20the%20core%20pattern%3A%20**separate%20control%20plane%20from%20data%20plane**.%0A%0A%20%20%20%20-%20**Control%20plane**%20(actor%20messages)%3A%20Send%20tiny%20handle%20(~100%20bytes)%0A%20%20%20%20-%20**Data%20plane**%20(RDMA)%3A%20Bulk%20transfer%20of%20actual%20data%20(~10%20GB)%0A%0A%20%20%20%20Think%20of%20%60RDMABuffer%60%20as%20a%20**magic%20pointer**%20-%20it's%20a%20pointer%20that%20works%20across%20machines%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20Generator%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20weights%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20local%20copy%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20(10%20GB)%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20(empty)%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%201.%20Create%20RDMABuffer%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20(register%20memory%2C%20get%20handle)%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%202.%20Send%20handle%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%E2%94%82%20%20(~100%20bytes%20via%20actor)%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%E2%97%84%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%203.%20RDMA%20read%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20(~10%20GB%20via%20hardware)%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20(no%20trainer%20involvement!)%20%20%E2%94%82%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20trainer%20doesn't%20even%20know%20when%20generators%20pull%20weights.%20True%20one-sided.%0A%0A%20%20%20%20%23%23%23%20RDMABuffer%20in%20Action%0A%0A%20%20%20%20From%20%60monarch.rdma%60%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%0A%0A%20%20%20%20%23%20Trainer%20side%3A%20register%20weights%0A%20%20%20%20weights%20%3D%20torch.randn(1024%2C%201024%2C%20device%3D%22cuda%22)%0A%20%20%20%20buffer%20%3D%20RDMABuffer(weights.view(torch.uint8).flatten())%0A%0A%20%20%20%20%23%20Return%20buffer%20as%20part%20of%20an%20endpoint%20response%0A%20%20%20%20%23%20This%20is%20a%20TINY%20message%20-%20just%20the%20handle!%0A%20%20%20%20%40endpoint%0A%20%20%20%20def%20get_weight_handle(self)%20-%3E%20RDMABuffer%3A%0A%20%20%20%20%20%20%20%20return%20self.buffer%0A%0A%20%20%20%20%23%20Generator%20side%3A%20receive%20handle%2C%20pull%20directly%20into%20GPU%0A%20%20%20%20handle%20%3D%20trainer.get_weight_handle.call_one().get()%20%20%23%20Tiny%20message%0A%20%20%20%20gpu_weights%20%3D%20model.weights.view(torch.uint8).flatten()%0A%20%20%20%20handle.read_into(gpu_weights).get()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Bulk%20RDMA%20%E2%86%92%20GPU%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20See%20the%20%5BGRPO%20Actor%20example%5D(https%3A%2F%2Fmeta-pytorch.org%2Fmonarch%2Fgenerated%2Fexamples%2Fgrpo_actor.html)%0A%20%20%20%20for%20a%20minimal%20implementation%20showing%20RDMA%20data%20flow.%20We'll%20build%20a%20more%20complete%0A%20%20%20%20version%20in%20the%20following%20sections.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20The%20Cost%20of%20Memory%20Registration%0A%0A%20%20%20%20RDMA%20memory%20registration%20is%20**expensive**%3A%0A%20%20%20%20-%20Pins%20physical%20pages%20(prevents%20swapping)%0A%20%20%20%20-%20Creates%20IOMMU%2FDMA%20mappings%20in%20the%20NIC%0A%20%20%20%20-%20Can%20take%20milliseconds%20for%20large%20buffers%0A%0A%20%20%20%20But%20here's%20the%20good%20news%3A%20**Monarch%20caches%20all%20memory%20region%20registrations.**%20Once%20a%20buffer%0A%20%20%20%20is%20registered%2C%20subsequent%20uses%20hit%20the%20cache%2C%20making%20it%20essentially%20free%20in%20steady%20state.%0A%0A%20%20%20%20Let's%20see%20this%20in%20action%20with%203%20approaches%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%23%20Approach%201%3A%20Naive%0A%0A%20%20%20%20Create%20new%20RDMABuffer%20on%20each%20transfer%20-%20registration%20happens%20on%20first%20use%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20current_rank%2C%20endpoint%2C%20time%2C%20torch)%3A%0A%20%20%20%20class%20NaiveSender(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Creates%20new%20RDMABuffer%20handles%20every%20transfer.%20Expensive!%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5Btorch.zeros(size%2C%20dtype%3Dtorch.float32)%20for%20size%20in%20layer_sizes%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20layer%20in%20enumerate(self.layers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer.fill_(float(i%20%2B%201))%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_fresh_handles(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20size%2C%20layer%20in%20zip(self.layer_sizes%2C%20self.layers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20layer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handles.append((size%2C%20RDMABuffer(byte_view)))%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20handles%0A%0A%0A%20%20%20%20class%20NaiveReceiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Receives%20from%20naive%20sender%20-%20pays%20MR%20cost%20every%20step.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5Btorch.zeros(size%2C%20dtype%3Dtorch.float32)%20for%20size%20in%20layer_sizes%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_step(self%2C%20sender%3A%20NaiveSender)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20handles%20%3D%20sender.get_fresh_handles.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20(size%2C%20handle)%20in%20enumerate(handles)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.layers%5Bi%5D.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(byte_view).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20print(%22NaiveSender%3A%20Re-registers%20all%20parameters%20on%20every%20call%22)%0A%20%20%20%20return%20NaiveReceiver%2C%20NaiveSender%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%23%20Approach%202%3A%20Contiguous%20Buffer%0A%0A%20%20%20%20Allocate%20one%20buffer%2C%20register%20at%20init%20time%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20current_rank%2C%20endpoint%2C%20time%2C%20torch)%3A%0A%20%20%20%20class%20ContiguousSender(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22One%20buffer%2C%20one%20MR%2C%20registered%20at%20startup.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20total_size%20%3D%20sum(layer_sizes)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20One%20contiguous%20buffer%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%20%3D%20torch.zeros(total_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20size%20in%20enumerate(layer_sizes)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%5Boffset%20%3A%20offset%20%2B%20size%5D.fill_(float(i%20%2B%201))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%20%2B%3D%20size%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20ONCE%20at%20startup%0A%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.buffer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handle%20%3D%20RDMABuffer(byte_view)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_handle(self)%20-%3E%20tuple%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20(len(self.buffer)%2C%20self.handle)%20%20%23%20Same%20handle%20every%20time!%0A%0A%0A%20%20%20%20class%20ContiguousReceiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Receives%20from%20contiguous%20sender%20-%20fast%20after%20first%20step.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20total_size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%20%3D%20torch.zeros(total_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_step(self%2C%20sender%3A%20ContiguousSender)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20size%2C%20handle%20%3D%20sender.get_handle.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.buffer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(byte_view).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20print(%22ContiguousSender%3A%20Registers%20once%2C%20reuses%20same%20handle%22)%0A%20%20%20%20return%20ContiguousReceiver%2C%20ContiguousSender%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%23%20Approach%203%3A%20Scattered%20%2B%20RDMAAction%0A%0A%20%20%20%20Register%20each%20buffer%20at%20init%2C%20build%20transfer%20plan%20once%20via%20handshake%3A%0A%0A%0A%20%20%20%20**What%20is%20RDMAAction%3F**%0A%0A%20%20%20%20Think%20of%20%60RDMAAction%60%20as%20a%20**transfer%20plan**.%20You%0A%20%20%20%20describe%20all%20the%20reads%2Fwrites%20you%20want%0A%20%20%20%20to%20do%2C%20then%20%60submit()%60%20executes%20the%20whole%20plan%20at%20once%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Build%20the%20plan%20once%0A%20%20%20%20action%20%3D%20RDMAAction()%0A%20%20%20%20action.read_into(handle1%2C%20local_buffer1)%0A%20%20%20%20action.read_into(handle2%2C%20local_buffer2)%0A%20%20%20%20action.read_into(handle3%2C%20local_buffer3)%0A%0A%20%20%20%20%23%20Execute%20whenever%20you%20want%20-%20just%20one%20call%0A%20%20%20%20action.submit().get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20useful%20when%20you%20have%20many%20scattered%20buffers%20(like%20model%20parameters)%20and%20want%20to%20batch%20them%20into%20a%20single%20logical%20operation.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMAAction%2C%20RDMABuffer%2C%20current_rank%2C%20endpoint%2C%20time%2C%20torch)%3A%0A%20%20%20%20class%20ScatteredSender(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Multiple%20buffers%2C%20each%20registered%20once%20at%20startup.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%5B%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20size%20in%20enumerate(layer_sizes)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer%20%3D%20torch.zeros(size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer.fill_(float(i%20%2B%201))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.layers.append(layer)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20ONCE%20at%20startup%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20layer.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles.append(RDMABuffer(byte_view))%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_handles(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B(size%2C%20handle)%20for%20size%2C%20handle%20in%20zip(self.layer_sizes%2C%20self.handles)%5D%0A%0A%20%20%20%20class%20ScatteredReceiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Receives%20from%20scattered%20sender%20with%20RDMAAction%20batching.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20layer_sizes%3A%20list)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layer_sizes%20%3D%20layer_sizes%0A%20%20%20%20%20%20%20%20%20%20%20%20self.layers%20%3D%20%5Btorch.zeros(size%2C%20dtype%3Dtorch.float32)%20for%20size%20in%20layer_sizes%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20None%20%20%23%20Built%20on%20handshake%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20handshake(self%2C%20sender%3A%20ScatteredSender)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Call%20once%20to%20build%20the%20RDMAAction%20transfer%20plan.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20handles%20%3D%20sender.get_handles.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20RDMAAction()%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20(size%2C%20handle)%20in%20enumerate(handles)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20self.layers%5Bi%5D.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.action.read_into(handle%2C%20byte_view)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%22Transfer%20plan%20ready%22%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_step(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Execute%20the%20cached%20transfer%20plan.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action.submit().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20print(%22ScatteredSender%3A%20Registers%20each%20layer%20once%22)%0A%20%20%20%20print(%22ScatteredReceiver%3A%20handshake()%20builds%20plan%2C%20receive_step()%20executes%20it%22)%0A%20%20%20%20return%20ScatteredReceiver%2C%20ScatteredSender%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20**Pattern%20recap%3A**%0A%0A%20%20%20%20-%20**Naive**%3A%20Create%20RDMABuffer%20in%20the%20transfer%20endpoint%0A%20%20%20%20-%20**Contiguous**%3A%20Register%20one%20big%20buffer%20in%20%60__init__%60%0A%20%20%20%20-%20**Scattered%20%2B%20RDMAAction**%3A%20Register%20multiple%20buffers%20in%20%60__init__%60%2C%20build%20transfer%20plan%20in%20%60handshake()%60%0A%0A%20%20%20%20Let's%20benchmark%20to%20see%20the%20difference%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20ContiguousReceiver%2C%0A%20%20%20%20ContiguousSender%2C%0A%20%20%20%20NaiveReceiver%2C%0A%20%20%20%20NaiveSender%2C%0A%20%20%20%20ScatteredReceiver%2C%0A%20%20%20%20ScatteredSender%2C%0A%20%20%20%20this_host%2C%0A)%3A%0A%20%20%20%20def%20run_benchmark()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compare%20the%20three%20approaches%20over%20multiple%20steps.%22%22%22%0A%20%20%20%20%20%20%20%20layer_sizes%20%3D%20%5B1000%2C%205000%2C%202000%5D%20%20%23%208000%20floats%20total%0A%20%20%20%20%20%20%20%20total_size%20%3D%20sum(layer_sizes)%0A%20%20%20%20%20%20%20%20num_steps%20%3D%205%0A%0A%20%20%20%20%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20%20%20%20%20sender_procs%20%3D%20host.spawn_procs(%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20receiver_procs%20%3D%20host.spawn_procs(%7B%22procs%22%3A%201%7D)%0A%0A%20%20%20%20%20%20%20%20print(%22%3D%3D%3D%20RDMA%20Registration%20Benchmark%20%3D%3D%3D%22)%0A%20%20%20%20%20%20%20%20print(f%22Transferring%20%7Btotal_size%7D%20floats%20(%7Btotal_size%20*%204%20%2F%201024%3A.1f%7D%20KB)%20x%20%7Bnum_steps%7D%20steps%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20results%20%3D%20%7B%7D%0A%0A%20%20%20%20%20%20%20%20%23%20Naive%20approach%0A%20%20%20%20%20%20%20%20naive_sender%20%3D%20sender_procs.spawn(%22naive_s%22%2C%20NaiveSender%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20naive_receiver%20%3D%20receiver_procs.spawn(%22naive_r%22%2C%20NaiveReceiver%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20times%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(num_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20naive_receiver.receive_step.call_one(naive_sender).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20times.append(r%5B%22elapsed_ms%22%5D)%0A%20%20%20%20%20%20%20%20results%5B%22Naive%22%5D%20%3D%20times%0A%20%20%20%20%20%20%20%20print(f%22Naive%20(re-register%20each%20step)%3A%22)%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(times)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7Bi%2B1%7D%3A%20%7Bt%3A.2f%7Dms%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Average%3A%20%7Bsum(times)%2Flen(times)%3A.2f%7Dms%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Contiguous%20approach%0A%20%20%20%20%20%20%20%20cont_sender%20%3D%20sender_procs.spawn(%22cont_s%22%2C%20ContiguousSender%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20cont_receiver%20%3D%20receiver_procs.spawn(%22cont_r%22%2C%20ContiguousReceiver%2C%20total_size)%0A%20%20%20%20%20%20%20%20times%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(num_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20cont_receiver.receive_step.call_one(cont_sender).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20times.append(r%5B%22elapsed_ms%22%5D)%0A%20%20%20%20%20%20%20%20results%5B%22Contiguous%22%5D%20%3D%20times%0A%20%20%20%20%20%20%20%20print(f%22Contiguous%20(register%20once)%3A%22)%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(times)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7Bi%2B1%7D%3A%20%7Bt%3A.2f%7Dms%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Average%3A%20%7Bsum(times)%2Flen(times)%3A.2f%7Dms%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Scattered%20%2B%20RDMAAction%20approach%0A%20%20%20%20%20%20%20%20scat_sender%20%3D%20sender_procs.spawn(%22scat_s%22%2C%20ScatteredSender%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20scat_receiver%20%3D%20receiver_procs.spawn(%22scat_r%22%2C%20ScatteredReceiver%2C%20layer_sizes)%0A%20%20%20%20%20%20%20%20scat_receiver.handshake.call_one(scat_sender).get()%20%20%23%20Build%20transfer%20plan%20once%0A%20%20%20%20%20%20%20%20times%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20step%20in%20range(num_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20r%20%3D%20scat_receiver.receive_step.call_one().get()%20%20%23%20Just%20execute%20cached%20plan%0A%20%20%20%20%20%20%20%20%20%20%20%20times.append(r%5B%22elapsed_ms%22%5D)%0A%20%20%20%20%20%20%20%20results%5B%22Scattered%22%5D%20%3D%20times%0A%20%20%20%20%20%20%20%20print(f%22Scattered%20%2B%20RDMAAction%20(register%20once%2C%20batch)%3A%22)%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(times)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7Bi%2B1%7D%3A%20%7Bt%3A.2f%7Dms%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Average%3A%20%7Bsum(times)%2Flen(times)%3A.2f%7Dms%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%3D%3D%3D%20What's%20Happening%20%3D%3D%3D%22)%0A%20%20%20%20%20%20%20%20print(%22Naive%20step%201%3A%20Cold%20MR%20registration%20(~2000ms)%22)%0A%20%20%20%20%20%20%20%20print(%22Naive%20steps%202%2B%3A%20Cache%20hit%2C%20MR%20already%20registered%20(~10ms)%22)%0A%20%20%20%20%20%20%20%20print(%22Contiguous%2FScattered%3A%20Registration%20happened%20at%20spawn%20time%2C%20not%20during%20benchmark%22)%0A%0A%20%20%20%20%20%20%20%20return%20results%0A%0A%20%20%20%20benchmark_results%20%3D%20run_benchmark()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20**What%20the%20benchmark%20shows%3A**%0A%0A%20%20%20%20-%20**Naive**%3A%20First%20call%20is%20~2000ms%20(cold%20registration)%2C%20subsequent%20calls%20~10ms%20(cache%20hit)%0A%20%20%20%20-%20**Contiguous%2FScattered**%3A%20All%20calls%20are%20fast%20(~4-9ms)%20because%20registration%20happened%0A%20%20%20%20%20%20at%20spawn%20time%2C%20before%20the%20timing%20loop%20started%0A%0A%20%20%20%20*Note%3A%20RDMAAction%20(~9ms)%20is%20slower%20than%20Contiguous%20(~4ms)%20due%20to%20Python%20overhead.%0A%20%20%20%20Moving%20the%20batching%20logic%20to%20Rust%20is%20a%20planned%20optimization.*%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Two%20Weight%20Sync%20Patterns%0A%0A%20%20%20%20With%20RDMABuffer%20as%20our%20building%20block%2C%20there%20are%20two%20main%20approaches%3A%0A%0A%20%20%20%20%7C%20Pattern%20%7C%20How%20it%20works%20%7C%20Trade-offs%20%7C%0A%20%20%20%20%7C---------%7C--------------%7C------------%7C%0A%20%20%20%20%7C%20**CPU%20Staging**%20%7C%20GPU%20%E2%86%92%20CPU%20buffer%20%E2%86%92%20RDMA%20%E2%86%92%20CPU%20%E2%86%92%20GPU%20%7C%20One%20MR%2C%20simple%2C%20but%20copies%20%7C%0A%20%20%20%20%7C%20**Direct%20GPU**%20%7C%20GPU%20%E2%86%92%20RDMA%20%E2%86%92%20GPU%20(GPUDirect)%20%7C%20No%20copies%2C%20but%20one%20MR%20per%20param%20%7C%0A%0A%20%20%20%20**Pattern%201%3A%20CPU%20Staging%20(Contiguous%20Buffer)**%0A%0A%20%20%20%20Pack%20all%20parameters%20into%20one%20contiguous%20CPU%20buffer%2C%20register%20once%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20class%20Trainer(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Calculate%20total%20size%20for%20all%20parameters%0A%20%20%20%20%20%20%20%20%20%20%20%20total_bytes%20%3D%20sum(p.numel()%20*%20p.element_size()%20for%20p%20in%20model.parameters())%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Allocate%20ONE%20contiguous%20buffer%2C%20register%20ONCE%0A%20%20%20%20%20%20%20%20%20%20%20%20self.staging_buffer%20%3D%20torch.empty(total_bytes%2C%20dtype%3Dtorch.uint8)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handle%20%3D%20RDMABuffer(self.staging_buffer)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Track%20where%20each%20param%20lives%20in%20the%20buffer%0A%20%20%20%20%20%20%20%20%20%20%20%20self.param_offsets%20%3D%20compute_offsets(model)%0A%0A%20%20%20%20%20%20%20%20def%20pack_weights(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20'''Copy%20all%20params%20into%20contiguous%20buffer.'''%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20param%20in%20model.named_parameters()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%20self.param_offsets%5Bname%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.staging_buffer%5Boffset%3Aoffset%2Bsize%5D.copy_(param.view(torch.uint8))%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_weight_handle(self)%20-%3E%20RDMABuffer%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.pack_weights()%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.handle%20%20%23%20Same%20handle%2C%20new%20data%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Pattern%202%3A%20Direct%20GPU%20MRs**%0A%0A%20%20%20%20Register%20each%20GPU%20parameter%20directly%2C%20no%20CPU%20copies%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20class%20Trainer(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20each%20param%20ONCE%20at%20startup%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%7B%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20param%20in%20model.named_parameters()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_view%20%3D%20param.data.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles%5Bname%5D%20%3D%20RDMABuffer(byte_view)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_param_handles(self)%20-%3E%20dict%5Bstr%2C%20RDMABuffer%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Handles%20are%20reused%20-%20data%20updates%20in%20place%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20self.handles%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Both%20patterns%20amortize%20MR%20registration%20cost%20across%20training%20iterations.%0A%20%20%20%20Let's%20look%20at%20CPU%20staging%20in%20more%20detail%20(it's%20more%20common%20in%20async%20RL).%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%206.%20CPU%20Staging%20Pattern%0A%0A%20%20%20%20%23%23%23%20GPU-Native%20RDMA%20Works!%0A%0A%20%20%20%20First%2C%20let's%20be%20clear%3A%20**GPU-native%20RDMA%20works**%20and%20is%20fast%3A%0A%20%20%20%20-%20GPUDirect%20RDMA%3A%20NIC%20reads%20directly%20from%20GPU%20memory%0A%20%20%20%20-%20No%20CPU%20copy%20needed%20(when%20hardware%20supports%20it)%0A%20%20%20%20-%20Great%20for%20synchronous%20transfers%0A%0A%20%20%20%20%23%23%23%20Why%20CPU%20Staging%20for%20Async%20RL%3F%0A%0A%20%20%20%20The%20issue%20isn't%20bandwidth%20-%20it's%20**timing**%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Direct%20GPU%E2%86%92GPU%20RDMA%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20Generator%20GPU%20is%20mid-inference%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%E2%94%9C%E2%94%80%E2%94%80%20layer%201%20%E2%94%80%E2%94%80%E2%94%A4%20%5BRDMA%20arrives%2C%20needs%20sync!%5D%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20cudaDeviceSynchronize()%20%20%E2%86%90%20Blocks%20inference!%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20With%20CPU%20staging%2C%20nothing%20on%20the%20critical%20path%20blocks%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20GPU%20%E2%94%80%E2%94%80%E2%96%BA%20CPU%20staging%20buffer%20(RDMA%20registered)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%5BSits%20here%2C%20ready%20anytime%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20Generator%20grabs%20when%20ready%20%E2%94%80%E2%94%80%E2%96%BA%20Generator%20GPU%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20CPU%20buffer%20is%20a%20**temporal%20decoupling%20point**.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(torch)%3A%0A%20%20%20%20def%20demonstrate_cpu_staging()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Demonstrate%20the%20CPU%20staging%20pattern.%22%22%22%0A%20%20%20%20%20%20%20%20if%20not%20torch.cuda.is_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22CUDA%20not%20available%20-%20showing%20conceptual%20flow%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%0A%0A%20%20%20%20%20%20%20%20%23%20Trainer%20side%3A%20GPU%20weights%20%E2%86%92%20CPU%20staging%20buffer%20(RDMA%20registered)%0A%20%20%20%20%20%20%20%20trainer_weights%20%3D%20torch.randn(1000%2C%201000%2C%20device%3D%22cuda%3A0%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Pin%20memory%20for%20efficient%20transfers%20and%20RDMA%20registration%0A%20%20%20%20%20%20%20%20cpu_staging%20%3D%20torch.empty_like(trainer_weights%2C%20device%3D%22cpu%22).pin_memory()%0A%0A%20%20%20%20%20%20%20%20%23%20D2H%3A%20Trainer%20dumps%20to%20CPU%20(async%2C%20non-blocking%20for%20trainer)%0A%20%20%20%20%20%20%20%20cpu_staging.copy_(trainer_weights%2C%20non_blocking%3DTrue)%0A%20%20%20%20%20%20%20%20torch.cuda.synchronize()%20%20%23%20Just%20for%20timing%20demo%0A%0A%20%20%20%20%20%20%20%20print(%22Trainer%3A%20Weights%20copied%20to%20CPU%20staging%20buffer%20(RDMA%20registered)%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20GPU%20memory%3A%20%7Btrainer_weights.device%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20CPU%20staging%3A%20pinned%3D%7Bcpu_staging.is_pinned()%7D%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Generator%20side%3A%20RDMA%20pulls%20from%20trainer's%20CPU%20%E2%86%92%20directly%20to%20generator's%20GPU%0A%20%20%20%20%20%20%20%20%23%20(In%20this%20demo%20we%20simulate%20the%20RDMA%20transfer%20with%20a%20local%20copy)%0A%20%20%20%20%20%20%20%20generator_gpu_weights%20%3D%20torch.empty_like(cpu_staging%2C%20device%3D%22cuda%3A0%22)%0A%20%20%20%20%20%20%20%20generator_gpu_weights.copy_(cpu_staging%2C%20non_blocking%3DTrue)%20%20%23%20Simulates%20RDMA%20%E2%86%92%20GPU%0A%20%20%20%20%20%20%20%20torch.cuda.synchronize()%0A%0A%20%20%20%20%20%20%20%20print(%22Generator%3A%20Weights%20loaded%20directly%20to%20GPU%20(via%20RDMA)%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Weights%20match%3A%20%7Btorch.allclose(trainer_weights%2C%20generator_gpu_weights)%7D%22)%0A%0A%20%20%20%20demonstrate_cpu_staging()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%207.%20Circular%20Weight%20Buffers%0A%0A%20%20%20%20%23%23%23%20The%20Versioning%20Problem%0A%0A%20%20%20%20In%20async%20RL%2C%20trainer%20updates%20weights%20continuously.%20Generators%20need%20to%3A%0A%20%20%20%201.%20**Grab%20the%20latest**%20weights%20(not%20stale%20ones)%0A%20%20%20%202.%20**Not%20block**%20waiting%20for%20updates%0A%20%20%20%203.%20**Avoid%20memory%20churn**%20(re-registering%20RDMA%20buffers%20is%20expensive)%0A%0A%20%20%20%20%23%23%23%20Solution%3A%20Circular%20Buffer%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20writes%3A%20%20%20%20%20v0%20%E2%86%92%20v1%20%E2%86%92%20v2%20%E2%86%92%20v3%20%E2%86%92%20v4%20%E2%86%92%20v5%20%E2%86%92%20...%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%E2%86%93%20%20%20%20%E2%86%93%0A%20%20%20%20Buffer%20slots%3A%20%20%20%20%20%20%5Bslot0%5D%5Bslot1%5D%5Bslot2%5D%20%20(circular%2C%20reused)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v3%20%20%20%20v4%20%20%20%20v5%0A%0A%20%20%20%20Generator%20reads%3A%20%22Give%20me%20latest%22%20%E2%86%92%20v5%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Benefits%3A%0A%20%20%20%20-%20**Pre-registered%20RDMA%20buffers**%20-%20no%20memory%20registration%20on%20hot%20path%0A%20%20%20%20-%20**Lock-free%20reads**%20-%20generators%20always%20get%20a%20consistent%20snapshot%0A%20%20%20%20-%20**Bounded%20memory**%20-%20only%20N%20versions%20in%20flight%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(torch)%3A%0A%20%20%20%20from%20threading%20import%20Lock%20as%20_Lock%0A%20%20%20%20from%20typing%20import%20Tuple%20as%20_Tuple%2C%20Optional%20as%20_Opt%0A%0A%20%20%20%20class%20CircularWeightBuffer%3A%0A%20%20%20%20%20%20%20%20%22%22%22Circular%20buffer%20for%20versioned%20weight%20storage.%0A%0A%20%20%20%20%20%20%20%20In%20production%2C%20this%20would%20be%20used%20inside%20a%20Monarch%20actor%20and%20slots%0A%20%20%20%20%20%20%20%20would%20be%20registered%20with%20RDMABuffer%20at%20init%20time.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20template_tensor%3A%20torch.Tensor%2C%20n_slots%3A%20int%20%3D%203)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.n_slots%20%3D%20n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20self.slots%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.empty_like(template_tensor).pin_memory()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20template_tensor.device.type%20%3D%3D%20%22cpu%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%20torch.empty_like(template_tensor%2C%20device%3D%22cpu%22).pin_memory()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(n_slots)%0A%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.latest_version%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20self._lock%20%3D%20_Lock()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20In%20production%20(inside%20a%20Monarch%20actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20self.rdma_handles%20%3D%20%5BRDMABuffer(slot.view(torch.uint8).flatten())%20for%20slot%20in%20self.slots%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20pre-registers%20all%20slots%20with%20RDMA%20at%20init%20time%20(amortizes%20MR%20cost)%0A%0A%20%20%20%20%20%20%20%20def%20publish(self%2C%20weights%3A%20torch.Tensor)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Trainer%20publishes%20new%20weights.%20Returns%20version%20number.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20self._lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20self.latest_version%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots%5Bslot_idx%5D.copy_(weights)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.latest_version%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.latest_version%20-%201%0A%0A%20%20%20%20%20%20%20%20def%20get_latest(self)%20-%3E%20_Tuple%5Btorch.Tensor%2C%20int%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Generator%20gets%20latest%20weights.%20Non-blocking.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20self._lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20self.latest_version%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20raise%20RuntimeError(%22No%20weights%20published%20yet%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20(self.latest_version%20-%201)%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20version%20%3D%20self.latest_version%20-%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.slots%5Bslot_idx%5D.clone()%2C%20version%0A%0A%20%20%20%20%20%20%20%20def%20get_version(self%2C%20version%3A%20int)%20-%3E%20_Opt%5Btorch.Tensor%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Get%20specific%20version%20if%20still%20available.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20with%20self._lock%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20oldest_available%20%3D%20max(0%2C%20self.latest_version%20-%20self.n_slots)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3C%20oldest_available%20or%20version%20%3E%3D%20self.latest_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20version%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.slots%5Bslot_idx%5D.clone()%0A%0A%20%20%20%20%23%20Demo%0A%20%20%20%20_template%20%3D%20torch.randn(100%2C%20100)%0A%20%20%20%20weight_buffer%20%3D%20CircularWeightBuffer(_template%2C%20n_slots%3D3)%0A%0A%20%20%20%20%23%20Trainer%20publishes%20versions%0A%20%20%20%20for%20_v%20in%20range(5)%3A%0A%20%20%20%20%20%20%20%20_new_weights%20%3D%20torch.randn(100%2C%20100)%20*%20(_v%20%2B%201)%0A%20%20%20%20%20%20%20%20published_v%20%3D%20weight_buffer.publish(_new_weights)%0A%20%20%20%20%20%20%20%20print(f%22Published%20version%20%7Bpublished_v%7D%22)%0A%0A%20%20%20%20%23%20Generator%20grabs%20latest%0A%20%20%20%20latest_weights%2C%20latest_version%20%3D%20weight_buffer.get_latest()%0A%20%20%20%20print(f%22%5CnGenerator%20got%20version%20%7Blatest_version%7D%2C%20weights%20mean%3A%20%7Blatest_weights.mean()%3A.2f%7D%22)%0A%0A%20%20%20%20%23%20Try%20to%20get%20old%20version%20(might%20be%20evicted)%0A%20%20%20%20old_weights%20%3D%20weight_buffer.get_version(1)%0A%20%20%20%20print(f%22Version%201%20available%3A%20%7Bold_weights%20is%20not%20None%7D%22)%0A%0A%20%20%20%20print(%22%5CnIn%20production%3A%20RDMABuffer%20handles%20would%20be%20pre-registered%20at%20init%20time%22)%0A%20%20%20%20print(%22Generators%20would%20call%20get_latest_handle()%20to%20get%20RDMA%20handle%20%2B%20version%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%208.%20Weight%20Re-sharding%0A%0A%20%20%20%20%23%23%23%20The%20Sharding%20Mismatch%20Problem%0A%0A%20%20%20%20Trainer%20and%20Generator%20often%20have%20**different%20tensor%20layouts**%3A%0A%0A%20%20%20%20%7C%20Role%20%7C%20Parallelism%20%7C%20Sharding%20%7C%0A%20%20%20%20%7C------%7C-------------%7C----------%7C%0A%20%20%20%20%7C%20Trainer%20%7C%20FSDP%20(8%20GPUs)%20%7C%20%60Shard(0)%60%20-%20rows%20split%20across%208%20GPUs%20%7C%0A%20%20%20%20%7C%20Generator%20%7C%20TP%20(2%20GPUs)%20%7C%20%60Shard(1)%60%20-%20columns%20split%20across%202%20GPUs%20%7C%0A%0A%20%20%20%20Direct%20weight%20transfer%20doesn't%20work%20-%20we%20need%20**re-sharding**.%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20(row-sharded)%3A%20%20%20%20%20%20%20%20%20%20Generator%20(column-sharded)%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20GPU%200%3A%20rows%200-127%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20GPU%200%20%20%20%E2%94%82%20GPU%201%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20%20%20%20%E2%86%92%20%20%20%20%20%20%E2%94%82%20cols%20%20%20%20%E2%94%82%20cols%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20GPU%201%3A%20rows%20128%2B%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%200-511%20%20%20%E2%94%82%20512%2B%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Approach%201%3A%20Gather%20Then%20Slice%0A%0A%20%20%20%20Simple%20but%20inefficient%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%201.%20Each%20receiver%20gathers%20ALL%20sender%20shards%20%E2%86%92%20full%20tensor%0A%20%20%20%202.%20Each%20receiver%20slices%20out%20its%20portion%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Pros**%3A%20Simple%2C%20works%20with%20any%20sharding%0A%20%20%20%20**Cons**%3A%202x%20redundant%20data%20transfer%20(each%20receiver%20gets%20everything)%0A%0A%20%20%20%20%23%23%23%20Approach%202%3A%20Routed%2FDirect%20Transfer%0A%0A%20%20%20%20Optimal%20but%20complex%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%201.%20Pre-compute%20which%20sender%20chunks%20overlap%20with%20which%20receiver%20regions%0A%20%20%20%202.%20Send%20only%20the%20exact%20chunks%20needed%0A%20%20%20%203.%20Receivers%20place%20chunks%20directly%20in%20correct%20positions%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Pros**%3A%20Minimal%20bandwidth%20(no%20redundancy)%0A%20%20%20%20**Cons**%3A%20Complex%20overlap%20computation%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20dataclasses%20import%20dataclass%0A%20%20%20%20from%20typing%20import%20List%2C%20Tuple%0A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20ShardMetadata%3A%0A%20%20%20%20%20%20%20%20%22%22%22Metadata%20describing%20a%20tensor%20shard.%22%22%22%0A%20%20%20%20%20%20%20%20rank%3A%20int%0A%20%20%20%20%20%20%20%20global_shape%3A%20Tuple%5Bint%2C%20...%5D%0A%20%20%20%20%20%20%20%20offset%3A%20Tuple%5Bint%2C%20...%5D%20%20%23%20Start%20position%20in%20global%20tensor%0A%20%20%20%20%20%20%20%20local_shape%3A%20Tuple%5Bint%2C%20...%5D%20%20%23%20Shape%20of%20this%20shard%0A%0A%20%20%20%20def%20compute_shard_metadata(%0A%20%20%20%20%20%20%20%20global_shape%3A%20Tuple%5Bint%2C%20int%5D%2C%0A%20%20%20%20%20%20%20%20num_ranks%3A%20int%2C%0A%20%20%20%20%20%20%20%20shard_dim%3A%20int%2C%0A%20%20%20%20)%20-%3E%20List%5BShardMetadata%5D%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20shard%20metadata%20for%20a%20given%20sharding.%22%22%22%0A%20%20%20%20%20%20%20%20shards%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20dim_size%20%3D%20global_shape%5Bshard_dim%5D%0A%20%20%20%20%20%20%20%20shard_size%20%3D%20dim_size%20%2F%2F%20num_ranks%0A%0A%20%20%20%20%20%20%20%20for%20rank%20in%20range(num_ranks)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%20%5B0%2C%200%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20list(global_shape)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%5Bshard_dim%5D%20%3D%20rank%20*%20shard_size%0A%20%20%20%20%20%20%20%20%20%20%20%20local_shape%5Bshard_dim%5D%20%3D%20shard_size%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20shards.append(ShardMetadata(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rank%3Drank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20global_shape%3Dglobal_shape%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%3Dtuple(offset)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%3Dtuple(local_shape)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20))%0A%0A%20%20%20%20%20%20%20%20return%20shards%0A%0A%20%20%20%20%23%20Demo%3A%20Trainer%20has%20row-sharding%2C%20Generator%20has%20column-sharding%0A%20%20%20%20_global_shape%20%3D%20(1024%2C%201024)%0A%0A%20%20%20%20trainer_shards%20%3D%20compute_shard_metadata(_global_shape%2C%20num_ranks%3D4%2C%20shard_dim%3D0)%0A%20%20%20%20generator_shards%20%3D%20compute_shard_metadata(_global_shape%2C%20num_ranks%3D2%2C%20shard_dim%3D1)%0A%0A%20%20%20%20print(%22Trainer%20shards%20(row-wise%2C%204%20GPUs)%3A%22)%0A%20%20%20%20for%20s%20in%20trainer_shards%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Rank%20%7Bs.rank%7D%3A%20offset%3D%7Bs.offset%7D%2C%20shape%3D%7Bs.local_shape%7D%22)%0A%0A%20%20%20%20print(%22%5CnGenerator%20shards%20(column-wise%2C%202%20GPUs)%3A%22)%0A%20%20%20%20for%20s%20in%20generator_shards%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Rank%20%7Bs.rank%7D%3A%20offset%3D%7Bs.offset%7D%2C%20shape%3D%7Bs.local_shape%7D%22)%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20List%2C%0A%20%20%20%20%20%20%20%20ShardMetadata%2C%0A%20%20%20%20%20%20%20%20Tuple%2C%0A%20%20%20%20%20%20%20%20compute_shard_metadata%2C%0A%20%20%20%20%20%20%20%20dataclass%2C%0A%20%20%20%20%20%20%20%20generator_shards%2C%0A%20%20%20%20%20%20%20%20trainer_shards%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(List%2C%20ShardMetadata%2C%20Tuple%2C%20dataclass%2C%20generator_shards%2C%20trainer_shards)%3A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20TransferChunk%3A%0A%20%20%20%20%20%20%20%20%22%22%22A%20chunk%20to%20transfer%20from%20sender%20to%20receiver.%22%22%22%0A%20%20%20%20%20%20%20%20sender_rank%3A%20int%0A%20%20%20%20%20%20%20%20receiver_rank%3A%20int%0A%20%20%20%20%20%20%20%20sender_offset%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Where%20to%20read%20from%20sender%0A%20%20%20%20%20%20%20%20receiver_offset%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Where%20to%20write%20in%20receiver%0A%20%20%20%20%20%20%20%20shape%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Shape%20of%20the%20chunk%0A%0A%20%20%20%20def%20compute_overlap(%0A%20%20%20%20%20%20%20%20sender%3A%20ShardMetadata%2C%0A%20%20%20%20%20%20%20%20receiver%3A%20ShardMetadata%2C%0A%20%20%20%20)%20-%3E%20TransferChunk%20%7C%20None%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20overlap%20between%20sender%20and%20receiver%20shards.%22%22%22%0A%20%20%20%20%20%20%20%20%23%20Find%20intersection%20in%20global%20coordinates%0A%20%20%20%20%20%20%20%20s_start%20%3D%20sender.offset%0A%20%20%20%20%20%20%20%20s_end%20%3D%20(s_start%5B0%5D%20%2B%20sender.local_shape%5B0%5D%2C%20s_start%5B1%5D%20%2B%20sender.local_shape%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20r_start%20%3D%20receiver.offset%0A%20%20%20%20%20%20%20%20r_end%20%3D%20(r_start%5B0%5D%20%2B%20receiver.local_shape%5B0%5D%2C%20r_start%5B1%5D%20%2B%20receiver.local_shape%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20%23%20Compute%20intersection%0A%20%20%20%20%20%20%20%20inter_start%20%3D%20(max(s_start%5B0%5D%2C%20r_start%5B0%5D)%2C%20max(s_start%5B1%5D%2C%20r_start%5B1%5D))%0A%20%20%20%20%20%20%20%20inter_end%20%3D%20(min(s_end%5B0%5D%2C%20r_end%5B0%5D)%2C%20min(s_end%5B1%5D%2C%20r_end%5B1%5D))%0A%0A%20%20%20%20%20%20%20%20%23%20Check%20if%20there's%20actual%20overlap%0A%20%20%20%20%20%20%20%20if%20inter_start%5B0%5D%20%3E%3D%20inter_end%5B0%5D%20or%20inter_start%5B1%5D%20%3E%3D%20inter_end%5B1%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20None%0A%0A%20%20%20%20%20%20%20%20shape%20%3D%20(inter_end%5B0%5D%20-%20inter_start%5B0%5D%2C%20inter_end%5B1%5D%20-%20inter_start%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20%23%20Convert%20to%20local%20coordinates%0A%20%20%20%20%20%20%20%20sender_local%20%3D%20(inter_start%5B0%5D%20-%20s_start%5B0%5D%2C%20inter_start%5B1%5D%20-%20s_start%5B1%5D)%0A%20%20%20%20%20%20%20%20receiver_local%20%3D%20(inter_start%5B0%5D%20-%20r_start%5B0%5D%2C%20inter_start%5B1%5D%20-%20r_start%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20return%20TransferChunk(%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_rank%3Dsender.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_rank%3Dreceiver.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_offset%3Dsender_local%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_offset%3Dreceiver_local%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20shape%3Dshape%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20def%20compute_transfer_plan(%0A%20%20%20%20%20%20%20%20sender_shards%3A%20List%5BShardMetadata%5D%2C%0A%20%20%20%20%20%20%20%20receiver_shards%3A%20List%5BShardMetadata%5D%2C%0A%20%20%20%20)%20-%3E%20List%5BTransferChunk%5D%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20all%20transfers%20needed%20for%20re-sharding.%22%22%22%0A%20%20%20%20%20%20%20%20transfers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20sender%20in%20sender_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20receiver%20in%20receiver_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chunk%20%3D%20compute_overlap(sender%2C%20receiver)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20chunk%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20transfers.append(chunk)%0A%20%20%20%20%20%20%20%20return%20transfers%0A%0A%20%20%20%20%23%20Compute%20transfer%20plan%0A%20%20%20%20transfer_plan%20%3D%20compute_transfer_plan(trainer_shards%2C%20generator_shards)%0A%0A%20%20%20%20print(f%22Transfer%20plan%3A%20%7Blen(transfer_plan)%7D%20chunks%20needed%5Cn%22)%0A%20%20%20%20for%20chunk%20in%20transfer_plan%3A%0A%20%20%20%20%20%20%20%20print(f%22Sender%20%7Bchunk.sender_rank%7D%20%E2%86%92%20Receiver%20%7Bchunk.receiver_rank%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Read%20from%20sender%20offset%20%7Bchunk.sender_offset%7D%2C%20shape%20%7Bchunk.shape%7D%22)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Write%20to%20receiver%20offset%20%7Bchunk.receiver_offset%7D%22)%0A%20%20%20%20%20%20%20%20print()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Live%20Benchmark%3A%20Gather%20vs%20Routed%0A%0A%20%20%20%20Let's%20benchmark%20the%20two%20approaches%20with%20**3%20layers%20sharded%20differently**%3A%0A%0A%20%20%20%20%7C%20Layer%20%7C%20Shape%20%7C%20Trainer%20Sharding%20%7C%20Generator%20Sharding%20%7C%20Routing%20Opportunity%20%7C%0A%20%20%20%20%7C-------%7C-------%7C------------------%7C-------------------%7C---------------------%7C%0A%20%20%20%20%7C%200%20%7C%201024%C3%971024%20%7C%20Row-sharded%20(4-way)%20%7C%20Row-sharded%20(2-way)%20%7C%20Yes!%20Same%20dim%20%7C%0A%20%20%20%20%7C%201%20%7C%20512%C3%972048%20%7C%20Col-sharded%20(4-way)%20%7C%20Col-sharded%20(2-way)%20%7C%20Yes!%20Same%20dim%20%7C%0A%20%20%20%20%7C%202%20%7C%20256%C3%97256%20%7C%20Replicated%20%7C%20Replicated%20%7C%20No%20sharding%20%7C%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Example%3A%20Layer%200%20(1024%C3%971024)%20-%20Both%20row-sharded%2C%20different%20granularity%0A%0A%20%20%20%20TRAINER%20(4-way%20row%20shard)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20GENERATOR%20(2-way%20row%20shard)%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20T0%3A%20rows%200-255%20%20%20%20%5B256%C3%971024%5D%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%E2%94%82%20G0%3A%20rows%200-511%20%20%20%20%5B512%C3%971024%5D%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%86%91%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20T1%3A%20rows%20256-511%20%20%5B256%C3%971024%5D%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%82%20%20%20%20%20T0%20%2B%20T1%20only%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20%E2%94%82%20T2%3A%20rows%20512-767%20%20%5B256%C3%971024%5D%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%82%20G1%3A%20rows%20512-1023%20%5B512%C3%971024%5D%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%86%91%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20T3%3A%20rows%20768-1023%20%5B256%C3%971024%5D%20%E2%94%82%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%E2%94%82%20%20%20%20%20T2%20%2B%20T3%20only%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%0A%20%20%20%20GATHER%20APPROACH%3A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ROUTED%20APPROACH%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20G0%20receives%3A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20G0%20receives%3A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20T0%20%E2%86%92%20full%20256%C3%971024%20%E2%9C%93%20needed%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20T0%20%E2%86%92%20full%20256%C3%971024%20%E2%9C%93%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20T1%20%E2%86%92%20full%20256%C3%971024%20%E2%9C%93%20needed%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20T1%20%E2%86%92%20full%20256%C3%971024%20%E2%9C%93%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20T2%20%E2%86%92%20full%20256%C3%971024%20%E2%9C%97%20WASTED%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20(skips%20T2%2C%20T3%20-%20no%20overlap!)%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20T3%20%E2%86%92%20full%20256%C3%971024%20%E2%9C%97%20WASTED%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20G0%20transfers%3A%204%20shards%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20G0%20transfers%3A%202%20shards%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20G1%20transfers%3A%204%20shards%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20G1%20transfers%3A%202%20shards%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Total%3A%208%20transfers%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20Total%3A%204%20transfers%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%2050%25%20wasted%20bandwidth!%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%200%25%20wasted%20bandwidth!%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20exercises%20the%20re-sharding%20logic%20across%20different%20patterns.%20We'll%20use%20RDMAAction%0A%20%20%20%20to%20batch%20all%20the%20transfers%20and%20compare%3A%0A%0A%20%20%20%20-%20**Gather**%3A%20Each%20receiver%20gets%20ALL%20data%20from%20ALL%20senders%2C%20then%20slices%20locally%0A%20%20%20%20-%20**Routed**%3A%20Each%20receiver%20only%20gets%20data%20it%20actually%20needs%20(based%20on%20overlap)%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Actor%2C%0A%20%20%20%20RDMAAction%2C%0A%20%20%20%20RDMABuffer%2C%0A%20%20%20%20compute_shard_metadata%2C%0A%20%20%20%20current_rank%2C%0A%20%20%20%20endpoint%2C%0A%20%20%20%20time%2C%0A%20%20%20%20torch%2C%0A)%3A%0A%20%20%20%20import%20os%0A%20%20%20%20from%20torch.distributed._tensor%20import%20DTensor%2C%20Shard%2C%20Replicate%2C%20init_device_mesh%0A%0A%20%20%20%20%23%20Configuration%0A%20%20%20%20NUM_TRAINER_RANKS%20%3D%204%0A%20%20%20%20NUM_GENERATOR_RANKS%20%3D%202%0A%0A%20%20%20%20%23%20Layer%20configs%3A%20(global_shape%2C%20trainer_placement%2C%20generator_placement)%0A%20%20%20%20%23%20The%20placements%20define%20how%20each%20side%20shards%20the%20tensor%0A%20%20%20%20LAYER_CONFIGS%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%23%20Layer%200%3A%201024x1024%2C%20both%20row-sharded%20(Shard(0))%20but%20different%20granularity%0A%20%20%20%20%20%20%20%20%7B%22shape%22%3A%20(1024%2C%201024)%2C%20%22trainer_place%22%3A%20Shard(0)%2C%20%22gen_place%22%3A%20Shard(0)%7D%2C%0A%20%20%20%20%20%20%20%20%23%20Layer%201%3A%20512x2048%2C%20both%20col-sharded%20(Shard(1))%20but%20different%20granularity%0A%20%20%20%20%20%20%20%20%7B%22shape%22%3A%20(512%2C%202048)%2C%20%22trainer_place%22%3A%20Shard(1)%2C%20%22gen_place%22%3A%20Shard(1)%7D%2C%0A%20%20%20%20%20%20%20%20%23%20Layer%202%3A%20256x256%2C%20replicated%20on%20both%20sides%0A%20%20%20%20%20%20%20%20%7B%22shape%22%3A%20(256%2C%20256)%2C%20%22trainer_place%22%3A%20Replicate()%2C%20%22gen_place%22%3A%20Replicate()%7D%2C%0A%20%20%20%20%5D%0A%0A%20%20%20%20def%20placement_to_shard_dim(placement)%20-%3E%20int%20%7C%20None%3A%0A%20%20%20%20%20%20%20%20%22%22%22Extract%20shard%20dimension%20from%20DTensor%20placement.%22%22%22%0A%20%20%20%20%20%20%20%20if%20isinstance(placement%2C%20Shard)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20placement.dim%0A%20%20%20%20%20%20%20%20return%20None%20%20%23%20Replicate%20or%20other%0A%0A%20%20%20%20def%20compute_layer_transfer_plan(layer_cfg%2C%20trainer_ranks%2C%20gen_ranks%2C%20gen_rank)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Use%20DTensor%20placement%20metadata%20to%20compute%20transfer%20plan%20for%20one%20layer.%22%22%22%0A%20%20%20%20%20%20%20%20trainer_dim%20%3D%20placement_to_shard_dim(layer_cfg%5B%22trainer_place%22%5D)%0A%20%20%20%20%20%20%20%20gen_dim%20%3D%20placement_to_shard_dim(layer_cfg%5B%22gen_place%22%5D)%0A%0A%20%20%20%20%20%20%20%20if%20trainer_dim%20is%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Replicated%20on%20trainer%20side%20-%20just%20need%20one%20trainer%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B(0%2C%20None)%5D%20%20%23%20(trainer_rank%2C%20chunk_info)%0A%0A%20%20%20%20%20%20%20%20if%20gen_dim%20is%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Replicated%20on%20generator%20side%20-%20need%20all%20trainers%20to%20reconstruct%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%5B(t%2C%20None)%20for%20t%20in%20range(trainer_ranks)%5D%0A%0A%20%20%20%20%20%20%20%20%23%20Both%20sharded%20-%20use%20compute_transfer_plan%20to%20find%20overlaps%0A%20%20%20%20%20%20%20%20trainer_shards%20%3D%20compute_shard_metadata(layer_cfg%5B%22shape%22%5D%2C%20trainer_ranks%2C%20trainer_dim)%0A%20%20%20%20%20%20%20%20gen_shards%20%3D%20compute_shard_metadata(layer_cfg%5B%22shape%22%5D%2C%20gen_ranks%2C%20gen_dim)%0A%0A%20%20%20%20%20%20%20%20%23%20Get%20this%20generator's%20shard%20metadata%0A%20%20%20%20%20%20%20%20my_shard%20%3D%20gen_shards%5Bgen_rank%5D%0A%0A%20%20%20%20%20%20%20%20%23%20Find%20which%20trainers%20have%20overlapping%20data%0A%20%20%20%20%20%20%20%20overlapping%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20t_shard%20in%20trainer_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Check%20if%20there's%20any%20overlap%0A%20%20%20%20%20%20%20%20%20%20%20%20t_start%20%3D%20t_shard.offset%5Btrainer_dim%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20t_end%20%3D%20t_start%20%2B%20t_shard.local_shape%5Btrainer_dim%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20g_start%20%3D%20my_shard.offset%5Bgen_dim%5D%20if%20gen_dim%20%3D%3D%20trainer_dim%20else%200%0A%20%20%20%20%20%20%20%20%20%20%20%20g_end%20%3D%20(my_shard.offset%5Bgen_dim%5D%20%2B%20my_shard.local_shape%5Bgen_dim%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20gen_dim%20%3D%3D%20trainer_dim%20else%20layer_cfg%5B%22shape%22%5D%5Btrainer_dim%5D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20t_end%20%3E%20g_start%20and%20t_start%20%3C%20g_end%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlapping.append((t_shard.rank%2C%20t_shard))%0A%0A%20%20%20%20%20%20%20%20return%20overlapping%0A%0A%20%20%20%20class%20DTensorTrainer(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Trainer%20with%20DTensor%20shards%20-%20uses%20placement%20metadata%20for%20resharding.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.dtensors%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20setup_distributed(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Initialize%20distributed%20and%20create%20DTensors%20with%20proper%20placements.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20world_size%20%3D%20int(os.environ.get(%22WORLD_SIZE%22%2C%20%221%22))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20not%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.init_process_group(backend%3D%22gloo%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20init_device_mesh(%22cpu%22%2C%20(world_size%2C))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20DTensors%20based%20on%20layer%20configs%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%2C%20cfg%20in%20enumerate(LAYER_CONFIGS)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20placement%20%3D%20cfg%5B%22trainer_place%22%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20shard_dim%20%3D%20placement_to_shard_dim(placement)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20shard_dim%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Sharded%3A%20compute%20local%20shape%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20list(cfg%5B%22shape%22%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%5Bshard_dim%5D%20%3D%20cfg%5B%22shape%22%5D%5Bshard_dim%5D%20%2F%2F%20world_size%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20tuple(local_shape)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Replicated%3A%20full%20shape%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20cfg%5B%22shape%22%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_tensor%20%3D%20torch.zeros(local_shape%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_tensor.fill_(float(i%20*%2010%20%2B%20self.rank))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20dt%20%3D%20DTensor.from_local(local_tensor%2C%20self.device_mesh%2C%20%5Bplacement%5D%2C%20run_check%3DFalse)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.dtensors.append(dt)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles.append(RDMABuffer(local_tensor.view(torch.uint8).flatten()))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20shapes%20%3D%20%5Btuple(dt.to_local().shape)%20for%20dt%20in%20self.dtensors%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20placements%20%3D%20%5Bstr(cfg%5B%22trainer_place%22%5D)%20for%20cfg%20in%20LAYER_CONFIGS%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Trainer%20%7Bself.rank%7D%3A%20shapes%3D%7Bshapes%7D%2C%20placements%3D%7Bplacements%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20shapes%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_layer_handle(self%2C%20layer_idx%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Return%20(shape%2C%20handle)%20for%20a%20layer's%20local%20shard.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20(tuple(self.dtensors%5Blayer_idx%5D.to_local().shape)%2C%20self.handles%5Blayer_idx%5D)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20destroy(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.destroy_process_group()%0A%0A%20%20%20%20class%20DTensorGenerator(Actor)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Generator%20that%20uses%20DTensor%20placement%20metadata%20for%20smart%20resharding.%22%22%22%0A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20None%0A%20%20%20%20%20%20%20%20%20%20%20%20self.recv_buffers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20None%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20setup_distributed(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20world_size%20%3D%20int(os.environ.get(%22WORLD_SIZE%22%2C%20%221%22))%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20not%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.init_process_group(backend%3D%22gloo%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20self.device_mesh%20%3D%20init_device_mesh(%22cpu%22%2C%20(world_size%2C))%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Generator%20%7Bself.rank%7D%3A%20distributed%20initialized%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20world_size%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20handshake_gather(self%2C%20trainers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Gather%20approach%3A%20fetch%20ALL%20shards%20(ignores%20placement%20metadata).%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20total%20%3D%20len(trainers)%20*%20len(LAYER_CONFIGS)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20f%22Gather%3A%20%7Btotal%7D%20transfers%20(all%20trainers%20%C3%97%20all%20layers)%22%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20handshake_routed(self%2C%20trainers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Routed%20approach%3A%20use%20DTensor%20placements%20to%20compute%20minimal%20transfers.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action%20%3D%20RDMAAction()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.recv_buffers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20total_transfers%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20layer_idx%2C%20cfg%20in%20enumerate(LAYER_CONFIGS)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Use%20placement%20metadata%20to%20compute%20which%20trainers%20we%20need%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlapping%20%3D%20compute_layer_transfer_plan(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cfg%2C%20NUM_TRAINER_RANKS%2C%20NUM_GENERATOR_RANKS%2C%20self.rank%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20t_rank%2C%20_%20in%20overlapping%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20shape%2C%20handle%20%3D%20trainers%5Bt_rank%5D.get_layer_handle.call_one(layer_idx).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20buf%20%3D%20torch.zeros(shape%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.recv_buffers.append(buf)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.action.read_into(handle%2C%20buf.view(torch.uint8).flatten())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20total_transfers%20%2B%3D%201%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20f%22Routed%3A%20%7Btotal_transfers%7D%20transfers%20(placement-aware)%22%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20receive_routed(self)%20-%3E%20dict%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20%20%20%20%20self.action.submit().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20elapsed_ms%20%3D%20(time.perf_counter()%20-%20start)%20*%201000%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20%7B%22elapsed_ms%22%3A%20elapsed_ms%7D%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20destroy(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20torch.distributed.is_initialized()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20torch.distributed.destroy_process_group()%0A%0A%20%20%20%20print(%22DTensor%20actors%20defined%20(using%20placement%20metadata%20for%20routing)%22)%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20DTensorGenerator%2C%0A%20%20%20%20%20%20%20%20DTensorTrainer%2C%0A%20%20%20%20%20%20%20%20LAYER_CONFIGS%2C%0A%20%20%20%20%20%20%20%20NUM_GENERATOR_RANKS%2C%0A%20%20%20%20%20%20%20%20NUM_TRAINER_RANKS%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20DTensorGenerator%2C%0A%20%20%20%20DTensorTrainer%2C%0A%20%20%20%20LAYER_CONFIGS%2C%0A%20%20%20%20NUM_GENERATOR_RANKS%2C%0A%20%20%20%20NUM_TRAINER_RANKS%2C%0A%20%20%20%20this_host%2C%0A%20%20%20%20time%2C%0A)%3A%0A%20%20%20%20from%20monarch.spmd%20import%20setup_torch_elastic_env%0A%0A%20%20%20%20%23%20Spawn%20trainer%20mesh%20(4%20procs%2C%20one%20actor%20per%20proc)%0A%20%20%20%20_trainer_procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%20NUM_TRAINER_RANKS%7D)%0A%20%20%20%20setup_torch_elastic_env(_trainer_procs)%20%20%23%20Sets%20WORLD_SIZE%2C%20RANK%2C%20MASTER_ADDR%2C%20etc.%0A%20%20%20%20_trainers%20%3D%20_trainer_procs.spawn(%22trainers%22%2C%20DTensorTrainer)%0A%0A%20%20%20%20%23%20Spawn%20generator%20mesh%20(2%20procs)%0A%20%20%20%20_gen_procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%20NUM_GENERATOR_RANKS%7D)%0A%20%20%20%20setup_torch_elastic_env(_gen_procs)%0A%20%20%20%20_generators%20%3D%20_gen_procs.spawn(%22generators%22%2C%20DTensorGenerator)%0A%0A%20%20%20%20print(%22%5Cn%3D%3D%3D%20DTensor%20Reshard%20Benchmark%20%3D%3D%3D%22)%0A%20%20%20%20print(f%22Trainer%20mesh%3A%20%7BNUM_TRAINER_RANKS%7D%20ranks%2C%20Generator%20mesh%3A%20%7BNUM_GENERATOR_RANKS%7D%20ranks%22)%0A%20%20%20%20print(%22Layer%20configs%3A%22)%0A%20%20%20%20for%20i%2C%20cfg%20in%20enumerate(LAYER_CONFIGS)%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Layer%20%7Bi%7D%3A%20%7Bcfg%5B'shape'%5D%7D%2C%20trainer%3D%7Bcfg%5B'trainer_place'%5D%7D%2C%20gen%3D%7Bcfg%5B'gen_place'%5D%7D%22)%0A%0A%20%20%20%20%23%20Initialize%20distributed%20on%20trainers%20and%20generators%20(separate%20process%20groups)%0A%20%20%20%20print(%22%5CnSetting%20up%20distributed...%22)%0A%20%20%20%20_trainer_shapes%20%3D%20_trainers.setup_distributed.call().get()%0A%20%20%20%20_gen_world%20%3D%20_generators.setup_distributed.call().get()%0A%20%20%20%20print(f%22%20%20Trainer%20shapes%3A%20%7B%5Bs%20for%20_%2C%20s%20in%20_trainer_shapes%5D%7D%22)%0A%20%20%20%20print(f%22%20%20Generator%20world%20sizes%3A%20%7B%5Bw%20for%20_%2C%20w%20in%20_gen_world%5D%7D%22)%0A%0A%20%20%20%20%23%20Get%20list%20of%20individual%20trainer%20actors%20for%20the%20generators%20to%20call%0A%20%20%20%20_trainer_list%20%3D%20%5B_trainers.slice(procs%3Di)%20for%20i%20in%20range(NUM_TRAINER_RANKS)%5D%0A%0A%20%20%20%20%23%20Handshake%20to%20build%20transfer%20plans%20(uses%20DTensor%20placement%20metadata!)%0A%20%20%20%20print(%22%5CnBuilding%20transfer%20plans%20(using%20placement%20metadata)...%22)%0A%20%20%20%20_results%20%3D%20_generators.handshake_routed.call(_trainer_list).get()%0A%20%20%20%20for%20_i%2C%20_r%20in%20enumerate(_results)%3A%0A%20%20%20%20%20%20%20%20print(f%22%20%20Generator%20%7B_i%7D%3A%20%7B_r%7D%22)%0A%0A%20%20%20%20%23%20Run%20benchmark%0A%20%20%20%20print(%22%5CnRunning%20transfers...%22)%0A%20%20%20%20_times%20%3D%20%5B%5D%0A%20%20%20%20for%20_step%20in%20range(3)%3A%0A%20%20%20%20%20%20%20%20_step_start%20%3D%20time.perf_counter()%0A%20%20%20%20%20%20%20%20_results%20%3D%20_generators.receive_routed.call().get()%0A%20%20%20%20%20%20%20%20_step_ms%20%3D%20(time.perf_counter()%20-%20_step_start)%20*%201000%0A%20%20%20%20%20%20%20%20_times.append(_step_ms)%0A%20%20%20%20%20%20%20%20print(f%22%20%20Step%20%7B_step%20%2B%201%7D%3A%20%7B_step_ms%3A.1f%7Dms%22)%0A%0A%20%20%20%20_avg%20%3D%20sum(_times)%20%2F%20len(_times)%0A%20%20%20%20print(f%22%20%20Average%3A%20%7B_avg%3A.1f%7Dms%22)%0A%0A%20%20%20%20%23%20Cleanup%20distributed%20process%20groups%0A%20%20%20%20_trainers.destroy.call().get()%0A%20%20%20%20_generators.destroy.call().get()%0A%20%20%20%20print(%22%5CnDistributed%20cleanup%20complete%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20**What%20the%20benchmark%20shows%3A**%0A%0A%20%20%20%20-%20**Gather**%3A%20Each%20receiver%20talks%20to%20ALL%20trainers%20and%20receives%20ALL%20their%20data%2C%20then%20discards%0A%20%20%20%20%20%20what%20it%20doesn't%20need.%20With%204%20trainers%20and%202%20generators%2C%20that's%208%20transfers%20per%20layer.%0A%20%20%20%20-%20**Routed**%3A%20Each%20receiver%20only%20talks%20to%20trainers%20with%20overlapping%20data.%20For%20same-dimension%0A%20%20%20%20%20%20sharding%20(trainer%204-way%2C%20generator%202-way)%2C%20each%20generator%20only%20needs%202%20of%20the%204%20shards.%0A%20%20%20%20%20%20That's%204%20transfers%20per%20layer%20-%20**50%25%20fewer%20connections**.%0A%0A%20%20%20%20For%20large%20models%20where%20weight%20sync%20is%20a%20bottleneck%2C%20the%20routed%20approach%20can%20save%0A%20%20%20%20significant%20bandwidth.%20The%20handshake%20pattern%20amortizes%20the%20overlap%20computation%20cost.%0A%0A%20%20%20%20The%20key%20insight%3A%20**RDMAAction%20lets%20you%20batch%20all%20the%20routed%20transfers%20into%20one%20plan**%2C%0A%20%20%20%20so%20you%20get%20the%20efficiency%20of%20smart%20routing%20with%20the%20simplicity%20of%20a%20single%20%60submit()%60%20call.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20The%20DTensor%20Dream%20(and%20Reality)%0A%0A%20%20%20%20If%20trainer%20and%20generator%20both%20used%20**DTensor**%20with%20the%20same%20sharding%20spec%2C%20re-sharding%0A%20%20%20%20would%20be%20automatic%20-%20the%20framework%20handles%20overlap%20computation%20and%20transfers.%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Ideal%20world%3A%20DTensor%20handles%20it%0A%20%20%20%20trainer_weights%3A%20DTensor%20%20%23%20Shard(0)%20across%208%20GPUs%0A%20%20%20%20generator_weights%3A%20DTensor%20%20%23%20Shard(1)%20across%202%20GPUs%0A%0A%20%20%20%20%23%20Re-sharding%20is%20just%20redistribution%0A%20%20%20%20generator_weights%20%3D%20trainer_weights.redistribute(generator_placement)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**In%20practice%2C%20it's%20harder**%3A%0A%20%20%20%20-%20vLLM%20does%20its%20own%20sharding%20and%20weight%20fusing%20(not%20DTensor-compatible)%0A%20%20%20%20-%20Training%20frameworks%20(FSDP%2C%20etc.)%20have%20different%20abstractions%0A%20%20%20%20-%20You%20often%20need%20custom%20overlap%20computation%20like%20we%20showed%20above%0A%0A%20%20%20%20The%20routed%20approach%20(compute%20overlaps%2C%20send%20only%20needed%20chunks)%20is%202x%20faster%20than%0A%20%20%20%20naive%20gather-then-slice%2C%20but%20requires%20this%20manual%20coordination.%0A%0A%20%20%20%20**For%20cross-node%20RDMA%20transfers**%2C%20the%20key%20insight%20remains%3A%20pre-compute%20the%20transfer%0A%20%20%20%20plan%20once%2C%20then%20each%20sync%20just%20executes%20the%20planned%20RDMA%20operations%20with%20RDMAAction.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%209.%20Putting%20It%20All%20Together%0A%0A%20%20%20%20The%20full%20async%20RL%20weight%20sync%20pattern%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20TRAINER%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%201.%20Train%20step%20completes%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%202.%20Copy%20weights%20to%20CPU%20staging%20buffer%20(non-blocking%20D2H)%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%203.%20Publish%20to%20circular%20buffer%20with%20version%20tag%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%204.%20Continue%20training%20(no%20blocking!)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20CIRCULAR%20BUFFER%20(CPU%2C%20RDMA-registered)%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%5Bslot%200%3A%20v3%5D%20%5Bslot%201%3A%20v4%5D%20%5Bslot%202%3A%20v5%5D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%91%20latest%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20GENERATOR%200%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20GENERATOR%201%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20GENERATOR%202%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%0A%20%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Key%20properties%3A**%0A%20%20%20%20-%20Trainer%20never%20blocks%20waiting%20for%20generators%0A%20%20%20%20-%20Generators%20pull%20directly%20to%20GPU%20when%20*they're*%20ready%0A%20%20%20%20-%20Re-sharding%20happens%20locally%20on%20each%20generator%0A%20%20%20%20-%20Circular%20buffer%20bounds%20memory%2C%20reuses%20RDMA%20registrations%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Code%20Pattern%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Trainer%20side%0A%20%20%20%20class%20Trainer(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.weight_buffer%20%3D%20CircularWeightBuffer(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20template%3Dself.model.state_dict_tensor()%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20n_slots%3D3%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20get_weight_handle(self)%20-%3E%20Tuple%5BRDMABuffer%2C%20int%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20'''Return%20handle%20to%20latest%20weights%20and%20version.'''%0A%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20(self.weight_buffer.latest_version%20-%201)%20%25%203%0A%20%20%20%20%20%20%20%20%20%20%20%20handle%20%3D%20self.weight_buffer.rdma_handles%5Bslot_idx%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20version%20%3D%20self.weight_buffer.latest_version%20-%201%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20handle%2C%20version%0A%0A%20%20%20%20%20%20%20%20async%20def%20train_loop(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20while%20True%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20loss%20%3D%20self.train_step()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20self.step%20%25%20sync_interval%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Non-blocking%20publish%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.weight_buffer.publish(self.model.weights)%0A%0A%20%20%20%20%23%20Generator%20side%0A%20%20%20%20class%20Generator(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self%2C%20trainer_ref)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.trainer%20%3D%20trainer_ref%0A%20%20%20%20%20%20%20%20%20%20%20%20self.current_version%20%3D%20-1%0A%0A%20%20%20%20%20%20%20%20async%20def%20maybe_sync_weights(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20handle%2C%20version%20%3D%20await%20self.trainer.get_weight_handle.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3E%20self.current_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Pull%20via%20RDMA%20directly%20into%20GPU%20memory%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gpu_weights%20%3D%20self.model.weights.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20await%20handle.read_into(gpu_weights)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.current_version%20%3D%20version%0A%0A%20%20%20%20%20%20%20%20async%20def%20generate_loop(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20while%20True%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20await%20self.maybe_sync_weights()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20output%20%3D%20self.generate(prompt)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.submit_to_buffer(output)%0A%20%20%20%20%60%60%60%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%2010.%20Going%20Further%3A%20TorchStore%0A%0A%20%20%20%20All%20the%20patterns%20we've%20covered%20-%20RDMA%20memory%20registration%2C%20magic%20pointers%2C%20circular%20buffers%2C%0A%20%20%20%20pre-computed%20transfer%20plans%20-%20are%20building%20blocks.%20If%20you%20need%20a%20**production-ready%20solution**%2C%0A%20%20%20%20check%20out%20%5BTorchStore%5D(https%3A%2F%2Fgithub.com%2Fmeta-pytorch%2Ftorchstore).%0A%0A%20%20%20%20%23%23%23%20What%20is%20TorchStore%3F%0A%0A%20%20%20%20TorchStore%20is%20a%20**distributed%2C%20asynchronous%20key-value%20store%20for%20PyTorch%20tensors**%20built%20on%0A%20%20%20%20Monarch's%20actor%20framework.%20It%20abstracts%20away%20the%20RDMA%20complexity%20while%20giving%20you%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20torchstore%20import%20TorchStore%0A%0A%20%20%20%20%23%20Store%20tensors%20with%20async%20API%0A%20%20%20%20await%20ts.put(%22model%2Flayer1%2Fweights%22%2C%20tensor)%0A%0A%20%20%20%20%23%20Retrieve%20with%20optional%20in-place%20and%20slice%20semantics%0A%20%20%20%20await%20ts.get(%22model%2Flayer1%2Fweights%22%2C%20inplace_tensor%3Dbuffer)%0A%0A%20%20%20%20%23%20Native%20PyTorch%20checkpoint%20support%0A%20%20%20%20await%20ts.put_state_dict(model.state_dict())%0A%20%20%20%20loaded%20%3D%20await%20ts.get_state_dict()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20RDMA%20Under%20the%20Hood%0A%0A%20%20%20%20TorchStore%20implements%20the%20patterns%20we've%20discussed%3A%0A%0A%20%20%20%20-%20**Transport%20abstraction**%20with%20automatic%20RDMA%20detection%3A%0A%20%20%20%20%20%201.%20TorchComms%20RDMA%20(highest%20performance)%0A%20%20%20%20%20%202.%20Monarch%20RDMA%20(fallback)%0A%20%20%20%20%20%203.%20Monarch%20RPC%20(no%20RDMA%20available)%0A%0A%20%20%20%20-%20**Memory%20region%20management**%3A%20Pre-registers%20buffers%2C%20handles%20cleanup%0A%0A%20%20%20%20-%20**DTensor%20support**%3A%20Efficiently%20stores%2Fretrieves%20tensor%20shards%20across%20ranks%0A%0A%20%20%20%20-%20**Tensor%20slicing**%3A%20Fetch%20arbitrary%20slices%20without%20retrieving%20the%20whole%20tensor%0A%0A%20%20%20%20The%20key%20insight%3A%20**TorchStore%20lets%20you%20think%20in%20key-value%20semantics%20while%20getting%20RDMA%0A%20%20%20%20performance**.%20No%20manual%20buffer%20management%2C%20no%20handle%20passing%2C%20no%20overlap%20computation.%0A%0A%20%20%20%20%23%23%23%20When%20to%20Use%20What%0A%0A%20%20%20%20%7C%20Scenario%20%7C%20Solution%20%7C%0A%20%20%20%20%7C----------%7C----------%7C%0A%20%20%20%20%7C%20Learning%20RDMA%20patterns%20%7C%20This%20notebook's%20examples%20%7C%0A%20%20%20%20%7C%20Custom%20RL%20weight%20sync%20%7C%20Build%20on%20%60RDMABuffer%60%20%2B%20%60RDMAAction%60%20%7C%0A%20%20%20%20%7C%20General%20tensor%20storage%20%7C%20Use%20TorchStore%20%7C%0A%20%20%20%20%7C%20Checkpointing%20%7C%20Use%20TorchStore's%20%60put_state_dict%60%20%7C%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20%23%23%23%20Key%20Takeaways%0A%0A%20%20%20%201.%20**Bandwidth%20hierarchy%20matters**%3A%20NVLink%20(450%20GB%2Fs)%20%3E%3E%20InfiniBand%20(50-100%20GB%2Fs)%20%3E%3E%20PCIe%0A%20%20%20%20%20%20%20-%20Know%20your%20hardware%2C%20optimize%20for%20the%20right%20interconnect%0A%0A%20%20%20%202.%20**Collectives%20vs%20P2P**%3A%20Collectives%20are%20synchronized%3B%20RL%20needs%20async%20P2P%0A%20%20%20%20%20%20%20-%20High%20variance%20in%20generation%20times%20makes%20blocking%20expensive%0A%0A%20%20%20%203.%20**Magic%20pointer%20pattern**%3A%20Tiny%20handle%20over%20control%20plane%2C%20bulk%20data%20over%20data%20plane%0A%20%20%20%20%20%20%20-%20~100%20bytes%20to%20describe%2010%20GB%20transfer%0A%0A%20%20%20%204.%20**CPU%20staging**%3A%20Temporal%20decoupling%20for%20async%20RL%0A%20%20%20%20%20%20%20-%20GPU-native%20RDMA%20works%20for%20sync%20cases%0A%20%20%20%20%20%20%20-%20CPU%20staging%20ensures%20nothing%20blocks%20on%20the%20critical%20path%0A%0A%20%20%20%205.%20**Circular%20buffers**%3A%20Version%20weights%20without%20memory%20churn%0A%20%20%20%20%20%20%20-%20Pre-register%20RDMA%20buffers%2C%20reuse%20slots%0A%20%20%20%20%20%20%20-%20Generators%20grab%20latest%2C%20never%20stale%0A%0A%20%20%20%206.%20**Weight%20re-sharding**%3A%20Different%20layouts%20need%20overlap%20computation%0A%20%20%20%20%20%20%20-%20Routed%20approach%20is%202x%20faster%20than%20gather%0A%20%20%20%20%20%20%20-%20Pre-compute%20transfer%20plan%2C%20minimize%20redundant%20data%0A%0A%20%20%20%20%23%23%23%20Next%20Steps%0A%0A%20%20%20%20See%20**07_async_rl_e2e.py**%20for%20a%20complete%20async%20RL%20system%20that%20uses%20these%20patterns.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">8d3d4cf466ce363d676fb1740e1d7d30</marimo-code-hash>
</body>
</html>
