<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>07_rdma_weight_sync.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>07 rdma weight sync</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/index-CD6Gw4UH.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/preload-helper-D2MJg03u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/react-Bj1aDYRI.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/compiler-runtime-B3qBwwSJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/badge-DX6CQ6PA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useEventListener-Cb-RVVEn.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/button-CZ3Cs4qb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/react-dom-CSu739Rf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/Combination-BAEdC-rz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/menu-items-BMjcEb2j.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-DwV58Fb1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/createLucideIcon-BCdY6lG5.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/check-Dr3SxUsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/x-ZP5cObgf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/select-BVdzZKAh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/tooltip-CMQz28hC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/use-toast-BDYuj3zG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useEvent-BhXAndur.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/zod-H_cgTO0M.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/utils-YqBXNpsM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/Deferred-DxQeE5uh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/uuid-DXdzqzcr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/DeferredRequestRegistry-CMf25YiV.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/session-BOFn9QrD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/config-Q0O7_stz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/requests-B4FYHTZl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useLifecycle-ClI_npeg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useNonce-CS26E0hA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useTheme-DQozhcp1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/createReducer-B3rBsy4P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/paths-BzSgteR-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-Dcqqg9UU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-sMh6mJ2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-Btv5Rh1v.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-bBwmhqty.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-CoCQUAeM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/stex-jWatZkll.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toDate-DETS9bBd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/database-zap-k4ePIFAU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cells-DPp5cDaO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/spinner-DA8-7wQv.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chevron-right--18M_6o9.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dropdown-menu-ldcmQvIV.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/kbd-Cm6Ba9qg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/renderShortcut-BckyRbYt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/multi-map-DxdLNTBd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/alert-BOoN6gJ1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/card-OlSjYhmd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/alert-dialog-BW4srmS0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dialog-eb-NieZw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-CDXJRSCj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/label-E64zk6_7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDebounce-7iEVSqwM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/textarea-CRI7xDBj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/numbers-D7O23mOZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/SSRProvider-BIDQNg9Q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/context-BfYAMNLF.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useNumberFormatter-Db6Vjve5.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/usePress-C__vuri5.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/input-DUrq2DiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/links-7AQBmdyV.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/popover-CH1FzjxU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/switch-dWLWbbtg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/table-DScsXgJW.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/mode-Bn7pdJvO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useAsyncData-BMGLSTg8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/errors-TZBmrJmc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/error-banner-B9ts0mNl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/copy-DHrHayPa.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/copy-D-8y6iMN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/plus-B7DF33lD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/refresh-cw-Dx8TEWFP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/trash-2-DDsWrxuJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/triangle-alert-CebQ7XwA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/ai-model-dropdown-Dk2SdB3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/defaultLocale-JieDVWC_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/precisionRound-CU2C3Vxx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/defaultLocale-BLne0bXb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/vega-loader.browser-DXARUlxo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/tooltip-DxKBXCGp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/ErrorBoundary-B9Ifj8Jf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useInstallPackage-D4fX0Ee_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/ImperativeModal-BNN1HA7x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cell-link-B9b7J8QK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/datasource-CtyqtITR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/state-D4T75eZb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/MarimoErrorOutput-Lf9P8Fhl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/copy-icon-v8ME_JKB.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/html-to-image-CIQqSu-S.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/focus-C1YokgL7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/LazyAnyLanguageCodeMirror-DgZ8iknE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chunk-5FQGJX7Z-DPlx2kjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/katex-CDLTCvjQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/markdown-renderer-DJy8ww5d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/command-2ElA5IkO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/download-os8QlW6l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useRunCells-D2HBb4DB.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/purify.es-DZrAQFIu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/RenderHTML-D-of_-s7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useIframeCapabilities-B_pQb20b.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/formats-CobRswjh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/en-US-CCVfmA-q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/isValid-DDt9wNjK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dates-CrvjILe3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/maps-D2_Mq1pZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/extends-BiFDv3jB.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/emotion-is-prop-valid.esm-C59xfSYt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDateFormatter-CqhdUl2n.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/table-CfDbAm78.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/JsonOutput-PE5ko4gi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDeleteCell-DdRX94yC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/icons-CCHmxi8d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/process-output-ByfLnk6j.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/blob-D-eV0cU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/objectWithoutPropertiesLoose-DfWeGRFv.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/esm-Bmu2DhPy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/file-Ch78NKWp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/play-GLWQQs7F.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/add-cell-with-ai-e_HMl7UU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/bot-message-square-B2ThzDUZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chat-display--jAB7huF.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chart-no-axes-column-qvVRjhv1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/square-function-B6mgCeFJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/spec-Ch0xnJY4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/column-preview-CXjSXUhP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toggle-zVW4FXNz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/globals-BgACvYmr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/share-ipf2hrOh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/react-resizable-panels.browser.esm-Da3ksQXL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/utilities.esm-dm9SQStE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/floating-outline-BtdqbkUq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useAddCell-CmuX2hOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/eye-off-AK_9uodG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/readonly-python-code-WjTf6Pdd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/file-video-camera-C3wGzBnE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/types-BRfQN3HL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/refresh-ccw-DN_xCV6A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/form-BidPUZUn.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/field-CySaBlkz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useBoolean-Ck_unDZw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDeepCompareMemoize-5OUgerQ3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/types-C1UhS3qM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/prop-types-DaaA-ptl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/es-BYgU_srD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/code-xml-CgN_Yig7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/download-Dg7clfkc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/square-CuJ72M8f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/settings-OBbrbhij.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/bundle.esm-i_UbZC0w.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/index-CeUwN_0i.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "07_rdma_weight_sync.py",
            "mode": "read",
            "version": "0.19.9",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "# Shared imports for the notebook\nimport time\nimport torch\nfrom monarch.actor import Actor, endpoint, this_host, current_rank\nfrom monarch.rdma import RDMABuffer, is_rdma_available", "code_hash": "8e01abc14814a6848ee5704e220ac262", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n# RDMA \u0026 Weight Synchronization\n\nYou've built your async RL system. Generators are humming, the trainer is\nlearning. Then you check GPU utilization and discover that most of your\n\"training\" time is spent copying weights. Your async system has become a\nweight-syncing system that occasionally does RL.\n\nThis notebook is about making that problem disappear \u2014 using RDMA to move\nweights from trainer to generators so fast it becomes invisible.\n\n**Want to go deeper?** Check out **07b_weight_sync_deep_dive.py** for ibverbs internals\nand RDMA buffer patterns. This notebook focuses on\nthe concepts and patterns you need to know for async RL.\n\"\"\")", "code_hash": "66da605d1067548d1c58e4c1c1b15afe", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Prerequisites\n\nThis notebook assumes familiarity with:\n\n- **PyTorch basics** - tensors, dtypes, device placement\n- **On-policy vs off-policy RL** - covered in [NB05: RL Intro](./05_rl_intro.html)\n- **Monarch Actor model** - spawning actors, endpoints, `call_one`/`call` (from [NB01](./01_history_and_vision.py) and [NB02](./02_interactive_devx.py))\n- **Basic networking concepts** - what bandwidth and latency mean, client-server vs peer-to-peer\n\"\"\")", "code_hash": "270e51d3ae33004215f4634a0b2711c0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 1. Why Weight Sync Matters\n\n### The On-Policy Problem\n\nTraditional RL algorithms want to be **on-policy**: generate experience using the current\npolicy, then immediately use that experience to update the policy. This creates a tight loop:\n\n```\nOn-Policy RL:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  generate(policy_v1) \u2192 train(samples) \u2192 policy_v2 \u2192 repeat       \u2502\n\u2502                                                                  \u2502\n\u2502  Experience from v1 is only valid for updating v1                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Async RL breaks this rule.** Generators run continuously while the trainer updates weights.\nBy the time a sample reaches the trainer, it was generated by an old policy version:\n\n```\nAsync RL (off-policy):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator: policy_v1 \u2192 sample\u2081                                  \u2502\n\u2502  Trainer:   train(sample\u2081) \u2192 policy_v2                           \u2502\n\u2502  Generator: policy_v1 \u2192 sample\u2082  \u2190 still using v1!               \u2502\n\u2502  Trainer:   train(sample\u2082) \u2192 policy_v3                           \u2502\n\u2502                                                                  \u2502\n\u2502  Samples are \"stale\" - generated by older policy versions        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis **off-policy-ness** can work up to a degree, but must be limited. The generators\nneed fresh weights regularly to stay \"close enough\" to on-policy. Weight sync frequency\nbecomes a key hyperparameter trading off:\n\n- **Too slow**: Samples become too stale, training diverges\n- **Too fast**: Weight sync overhead dominates, negating async benefits\n\n### The Scale Problem\n\nFor LLM-based RL, the weights are **massive**. Back-of-envelope math\n(1 parameter \u2248 2 bytes in bf16):\n\n| Model | Weight Size |\n|-------|-------------|\n| Llama 3.1 70B | ~140 GB |\n| Llama 3.1 405B | ~810 GB |\n| DeepSeek V3 671B | ~1.3 TB |\n\nThese weights need to move from trainer \u2192 generators regularly. If we're\nnot careful, our \"async RL training workload\" just becomes a weight syncing\nworkload. Let's look at the bandwidth hierarchy to understand why this is\ntricky and what we can do about it.\n\"\"\")", "code_hash": "1129f2591acb6dea584177d1666eb658", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 2. The Bandwidth Hierarchy\n\nFor weight sync, we care about one specific data path \u2014 trainer GPU to generator\nGPU, across nodes. Here's the chain of interconnects a weight tensor traverses:\n\n```\nTrainer GPU \u2500\u2500PCIe\u2500\u2500\u25ba CPU \u2500\u2500PCIe\u2500\u2500\u25ba NIC \u2550\u2550RDMA\u2550\u2550\u25ba NIC \u2500\u2500PCIe\u2500\u2500\u25ba CPU \u2500\u2500PCIe\u2500\u2500\u25ba Generator GPU\n  same node     (64 GB/s)    (50 GB/s)     (64 GB/s)      same node\n```\n\nThe bottleneck is the cross-node RDMA link at 50 GB/s per NIC. But modern nodes\nhave **8 NICs** (one per GPU), so aggregate cross-node bandwidth is 400 GB/s.\n\nHere's how all these interconnects fit together in a full node:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                              NODE A                                                      \u2502\n\u2502                                                                                                          \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                         ======  64 GB/s PCIe                                             \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502                        \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518      PCIe        \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518          \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                  RDMA (IB/RoCE)   RDMA (IB/RoCE)\n                                                                         \u2502                  \u2502\n                                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                                                        \u2502                                                    \u2502\n                                                        \u2502              InfiniBand Switch                     \u2502\n                                                        \u2502                                                    \u2502\n                                                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                                                         \u2502                  \u2502\n                                                                       ======  50 GB/s   ======\n                                                                  RDMA (IB/RoCE)   RDMA (IB/RoCE)\n                                                                         \u2502                  \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                                        \u2502                  \u2502              \u2502\n\u2502         \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550 64 GB/s PCIe \u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a              \u2502\n\u2502         \u2502                                  \u2502                           \u2502                  \u2502              \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510                        \u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510      PCIe        \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510          \u2502\n\u2502    \u2502  CPU 0  \u2502                        \u2502  CPU 1  \u2502 ====== 64 GB/s \u2550\u2550\u2502 NIC 0 \u2502          \u2502 NIC 1 \u2502          \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502                                           ======  64 GB/s PCIe                                           \u2502\n\u2502                                              \u2502                                                           \u2502\n\u2502    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u2502\n\u2502    \u2502     ########################################################################  900 GB/s NVLink \u2502     \u2502\n\u2502    \u2502  \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510                      \u2502     \u2502\n\u2502    \u2502  \u2502GPU 0 \u2502 \u2502GPU 1 \u2502 \u2502GPU 2 \u2502 \u2502GPU 3 \u2502 \u2502GPU 4 \u2502 \u2502GPU 5 \u2502 \u2502GPU 6 \u2502 \u2502GPU 7 \u2502                      \u2502     \u2502\n\u2502    \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518                      \u2502     \u2502\n\u2502    \u2502                              NVSwitch / NVLink Fabric                                         \u2502     \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2502\n\u2502                                              NODE B                                                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nBandwidth encoding (line intensity):\n  ########  NVLink/NVSwitch   900 GB/s bidirectional (GPU \u2194 GPU, same node)\n  ========  PCIe Gen5 / RDMA  50-64 GB/s unidirectional (CPU\u2194GPU, CPU\u2194NIC, cross-node)\n  (Showing 2 of 8 NICs for clarity \u2014 each GPU has a dedicated NIC)\n```\n\n### A Note on Bandwidth Numbers\n\nBandwidth specs vary by hardware generation, cluster configuration, and vendor.\nWe'll use numbers from Meta's published Llama 3 training infrastructure\n([Building Meta's GenAI Infrastructure](https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/)):\n\n\u003E \"Both of these solutions interconnect **400 Gbps endpoints**... we have successfully\n\u003E used both RoCE and InfiniBand clusters for large, GenAI workloads (including our\n\u003E ongoing training of Llama 3 on our RoCE cluster) without any network bottlenecks.\"\n\n**Important**: \"400 Gbps\" in networking is **full-duplex** - meaning 400 Gbps transmit\nAND 400 Gbps receive simultaneously. For weight sync (unidirectional: trainer \u2192 generator),\nwe get the full 400 Gbps = **50 GB/s per NIC**.\n\nMeta's Grand Teton nodes have **8 RDMA NICs** (one per GPU, 1:1 mapping), giving\n400 GB/s aggregate unidirectional bandwidth per node. For more details on Grand Teton\nand Monarch's RDMA architecture, see the SIGCOMM 2024 paper:\n[RDMA over Ethernet for Distributed AI Training at Meta Scale](https://cs.stanford.edu/~keithw/sigcomm2024/sigcomm24-final246-acmpaginated.pdf).\n\n| Interconnect | Bandwidth | Notes |\n|--------------|-----------|-------|\n| **NVLink 4.0** | 900 GB/s bidirectional | ~450 GB/s per direction |\n| **RDMA (IB/RoCE)** | 400 Gbps = 50 GB/s | Per NIC, full-duplex |\n| **PCIe Gen5 x16** | 64 GB/s | Per direction |\n\n**Key observations:**\n\n1. **NVLink is fast but same-node only** - 450 GB/s, but can't cross the network\n2. **RDMA \u003E\u003E TCP** - 50 GB/s with zero-copy beats TCP significantly for cross-node\n3. **Multi-NIC scales** - 8 NICs \u00d7 50 GB/s = 400 GB/s, approaching NVLink speeds\n\n**Rule of thumb**: NVLink for same-node ops (gradients, activations).\nRDMA for cross-node communication (weight sync) - it's the only practical option.\n\"\"\")", "code_hash": "dc9cb7704ba53d09e209242f825d9e56", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n### 2b. Back-of-Envelope: Syncing Large Models\n\nLet's do some quick math. DeepSeek V3 has 671B parameters (~1.34 TB in bf16).\n\nThe key insight: **you're not shoving 1.3 TB through a single NIC**. The weights\nare distributed across many GPUs (via some combination of PP, EP, TP, FSDP),\nand each GPU has its own NIC. You get **aggregate bandwidth** across all NICs.\n\nThe actual sync time depends on **both sides**:\n- **Trainer's aggregate upload bandwidth** (sending weights out)\n- **Generator's aggregate download bandwidth** (receiving weights)\n\nThe bottleneck is whichever is smaller. And if multiple generators pull from\nthe same trainer simultaneously, the trainer's bandwidth is divided among them.\n\nWith Grand Teton's 8 NICs per node at 50 GB/s each (400 GB/s per node),\nthe math is simple: **Time = Shard Size / Bandwidth**.\n\nThe per-node shard size depends on how many nodes the model is spread across:\n- DeepSeek V3 (1.3 TB) across 8 nodes \u2192 ~160 GB per node\n- DeepSeek V3 (1.3 TB) across 16 nodes \u2192 ~80 GB per node\n\n| Per-node shard | Time to sync |\n|----------------|--------------|\n| ~160 GB (8 nodes) | 160 / 400 = **0.4 seconds** |\n| ~80 GB (16 nodes) | 80 / 400 = **0.2 seconds** |\n\nThe exact per-node shard size depends on your parallelism strategy (PP, EP, TP, etc.),\nbut the math works out: with modern RDMA hardware, you can sync even the largest\nmodels in **sub-second time**.\n\nCompare this to naive TCP: kernel copies, socket overhead, no zero-copy...\neasily 10x slower. **RDMA is the only way to make async RL practical at scale.**\n\"\"\")", "code_hash": "b339ab67a809fda89538a7ed9d38ac50", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 3. The Problem: Collectives Are Blocking\n\nMost people use RDMA via **collectives** through PyTorch distributed:\n\n```python\nimport torch.distributed as dist\n\ndist.init_process_group(backend=\"nccl\")\ndist.all_reduce(gradients, op=dist.ReduceOp.SUM)\ndist.broadcast(weights, src=0)\n```\n\nThis works great for training. But async RL has a different access pattern.\n\n### High Variance in Generation Times\n\nGenerators have wildly different completion times:\n- Some prompts \u2192 10 tokens (fast)\n- Other prompts \u2192 1000 tokens (slow)\n\nWith collectives, fast generators wait for slow ones:\n\n```\nGenerator 0: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\nGenerator 1: \u251c\u2500\u2500\u2500\u2500\u2500\u2500 gen (slow) \u2500\u2500\u2500\u2500\u2500\u2500\u2524\nGenerator 2: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\n                                      \u2193\n                          all_gather(weights)  # Everyone waits!\n```\n\n### The One-Sided Solution: RDMA\n\nWhat if the sender could write directly to the receiver's memory without coordination?\n\n```\nTwo-sided (send/recv):\n  Sender: \"I have data\"  \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  Receiver: \"I'm ready\"\n  Sender: sends data     \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  Receiver: receives data\n                         2 messages required\n\nOne-sided (RDMA):\n  Sender: writes directly to receiver's memory\n                         No coordination needed!\n```\n\nThis is what RDMA enables: **one-sided memory operations**.\nThe trainer doesn't even know when generators pull weights - this is truly async!\n\nRDMA isn't just \"faster TCP\" \u2014 it bypasses the kernel entirely. No socket buffers,\nno context switches, no serialization. The NIC reads directly from registered memory.\n\"\"\")", "code_hash": "81511d7e65b4d0a2633996f8cded8b04", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 4. The Magic Pointer Pattern\n\nOne natural question that arises is along the lines of, \"How do we actually represent one-sided puts/gets if not with NCCL collectives?\"\n\nHere's a key insight: to represent remote data, we only need a **tiny handle** -\nan `(addr, rkey, size)` tuple that says \"here's where my data lives.\"\n\nMonarch wraps this in `RDMABuffer`. Let's see how small it actually is:\n\"\"\")", "code_hash": "cb76c2f11c389956cc5404a2489a841e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "# Measure actual size of RDMABuffer handles\nimport pickle\n\ndef show_fallback_sizes():\n    \"\"\"Fallback: show expected sizes based on RDMABuffer structure.\"\"\"\n    print(\"(RDMA not available - showing expected handle sizes)\\n\")\n    print(\"RDMABuffer contains: addr (8B) + rkey (4B) + size (8B) + owner (~100B)\")\n    print(\"Total serialized size: ~150-200 bytes regardless of tensor size\\n\")\n\n    sizes = [(\"1 KB\", 1024), (\"1 MB\", 1024**2), (\"1 GB\", 1024**3)]\n    handle_bytes = 150  # approximate\n\n    for name, tensor_bytes in sizes:\n        ratio = tensor_bytes / handle_bytes\n        print(f\"{name:\u003C8} tensor \u2192 ~150 byte handle \u2192 {ratio:,.0f}x compression\")\n\n    print(\"\\n\u2192 Handle size is O(1) regardless of tensor size!\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback_sizes()\n    else:\n        class BufferSizeDemo(Actor):\n            \"\"\"Actor that creates RDMABuffers and measures their size.\"\"\"\n\n            @endpoint\n            def measure_buffer_sizes(self) -\u003E list:\n                import pickle as _pickle\n                results = []\n                sizes = [\n                    (\"1 KB\", 256),\n                    (\"1 MB\", 256 * 1024),\n                    (\"10 MB\", 256 * 1024 * 10),\n                ]\n\n                for name, numel in sizes:\n                    tensor = torch.randn(numel)\n                    tensor_bytes = tensor.numel() * tensor.element_size()\n\n                    byte_tensor = tensor.view(torch.uint8).flatten()\n                    buffer = RDMABuffer(byte_tensor)\n                    handle_bytes = len(_pickle.dumps(buffer))\n\n                    results.append((name, tensor_bytes, handle_bytes))\n\n                return results\n\n        proc = this_host().spawn_procs(per_host={\"procs\": 1})\n        demo = proc.spawn(\"buffer_demo\", BufferSizeDemo)\n\n        results = demo.measure_buffer_sizes.call_one().get()\n\n        print(\"RDMABuffer handle size vs actual tensor size:\\n\")\n        print(f\"{'Tensor Size':\u003C12} {'Actual Bytes':\u003C15} {'Handle Size':\u003C15} {'Ratio':\u003C10}\")\n        print(\"-\" * 55)\n\n        for name, tensor_bytes, handle_bytes in results:\n            ratio = tensor_bytes / handle_bytes\n            print(f\"{name:\u003C12} {tensor_bytes:\u003E12,} B   {handle_bytes:\u003E6} B        {ratio:\u003E8,.0f}x\")\n\n        print(\"\\n\u2192 Handle size is O(1) regardless of tensor size!\")\n\nexcept Exception as e:\n    print(f\"(RDMA setup failed: {e})\\n\")\n    show_fallback_sizes()", "code_hash": "3d6ad99e96a0aafd076b1cd1ded4f8b9", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "mo.md(r\"\"\"\n### The Magic Pointer\n\nThis is the core pattern: **separate control plane from data plane**.\n\n- **Control plane** (actor messages): Send tiny handle (~100 bytes)\n- **Data plane** (RDMA): Bulk transfer of actual data (~10 GB)\n\nThink of `RDMABuffer` as a **magic pointer** - it's a pointer that works across machines:\n\n```\nTrainer                              Generator\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 weights     \u2502                     \u2502 local copy  \u2502\n\u2502 (10 GB)     \u2502                     \u2502 (empty)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502                                   \u2502\n       \u2502  1. Create RDMABuffer             \u2502\n       \u2502     (register memory, get handle) \u2502\n       \u2502                                   \u2502\n       \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500 2. Send handle \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502  (~100 bytes via actor)\n       \u2502                                   \u2502\n       \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500 3. RDMA read \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524  (~10 GB via hardware)\n       \u2502        (no trainer involvement!)  \u2502\n```\n\nThe trainer doesn't even know when generators pull weights. True one-sided.\n\n### RDMABuffer in Action\n\n```python\nfrom monarch.rdma import RDMABuffer\n\n# Trainer side: register weights\nweights = torch.randn(1024, 1024, device=\"cuda\")\nbuffer = RDMABuffer(weights.view(torch.uint8).flatten())\n\n# Return buffer as part of an endpoint response\n@endpoint\ndef get_weight_handle(self) -\u003E RDMABuffer:\n    return self.buffer\n\n# Generator side: receive handle, pull directly into GPU\nhandle = trainer.get_weight_handle.call_one().get()  # Tiny message\ngpu_weights = model.weights.view(torch.uint8).flatten()\nhandle.read_into(gpu_weights).get()                   # Bulk RDMA transfer\n\n# Push model: caller writes local src_tensor into the remote RDMABuffer\nbuffer.write_from(src_tensor).get()\n```\n\n**Pull vs Push**: `read_into` is the **pull** model (generator reads remote data into\nits local buffer), while `write_from` is the **push** model (caller writes local data\ninto the remote buffer). Both are one-sided RDMA operations \u2014 the remote side is not\ninvolved. In async RL, pull is more natural because each generator decides *when* it\nneeds fresh weights.\n\n**Want to understand how RDMA works under the hood?** Check out **07b_weight_sync_deep_dive.py**\nfor ibverbs internals, queue pair setup, and why Monarch's actor model is such a natural fit\nfor managing RDMA connections. It's actors all the way down!\n\"\"\")", "code_hash": "53525d9c44fe71fd4f526f646e7d143e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Live Demo: Trainer \u2192 Generator Weight Sync\n\nLet's see this in action with a simple example. A trainer holds weights,\na generator pulls them via RDMA.\n\"\"\")", "code_hash": "9b369b191c83a1c907ac9fc47f3166bc", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "emfo", "name": "_"}, {"code": "# Simple trainer \u2192 generator weight sync demo\n\ndef show_fallback_demo():\n    \"\"\"Show what would happen with RDMA.\"\"\"\n    print(\"(RDMA not available - showing conceptual flow)\\n\")\n    print(\"1. Trainer creates weights (e.g., 4 MB tensor)\")\n    print(\"2. Trainer wraps weights in RDMABuffer \u2192 tiny handle (~150 bytes)\")\n    print(\"3. Trainer sends handle to Generator via actor message\")\n    print(\"4. Generator calls handle.read_into(local_buffer)\")\n    print(\"5. RDMA hardware transfers 4 MB directly, trainer not involved!\")\n    print(\"\\n\u2192 Zero-copy, one-sided, no serialization overhead\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback_demo()\n    else:\n        class Sender(Actor):\n            \"\"\"Sender that holds data and exposes an RDMA handle.\"\"\"\n\n            def __init__(self, size: int):\n                # Create some data to send\n                self.data = torch.randn(size, dtype=torch.float32)\n                # Register with RDMA\n                self.data_bytes = self.data.view(torch.uint8).flatten()\n                self.buffer = RDMABuffer(self.data_bytes)\n                print(f\"[Sender] Created data: {self.data.numel() * 4 / 1e6:.1f} MB\")\n\n            @endpoint\n            def get_handle(self) -\u003E RDMABuffer:\n                \"\"\"Return tiny handle (not the data itself!)\"\"\"\n                return self.buffer\n\n            @endpoint\n            def get_checksum(self) -\u003E float:\n                \"\"\"For verification: sum of data\"\"\"\n                return float(self.data.sum())\n\n        class Receiver(Actor):\n            \"\"\"Receiver that pulls data from sender via RDMA.\"\"\"\n\n            def __init__(self, size: int):\n                # Pre-allocate space for data\n                self.data = torch.zeros(size, dtype=torch.float32)\n                self.data_bytes = self.data.view(torch.uint8).flatten()\n                print(f\"[Receiver] Allocated buffer: {self.data.numel() * 4 / 1e6:.1f} MB\")\n\n            @endpoint\n            def pull_data(self, handle: RDMABuffer) -\u003E float:\n                \"\"\"Pull data via RDMA read, return checksum for verification.\"\"\"\n                # This is the magic: RDMA read directly into our buffer\n                handle.read_into(self.data_bytes).get()\n                return float(self.data.sum())\n\n        # Spawn sender and receiver\n        procs = this_host().spawn_procs(per_host={\"procs\": 2})\n\n        sender = procs.slice(procs=0).spawn(\"sender\", Sender, 1024 * 1024)  # 4 MB\n        receiver = procs.slice(procs=1).spawn(\"receiver\", Receiver, 1024 * 1024)\n\n        # Step 1: Get handle from sender (tiny message!)\n        handle = sender.get_handle.call_one().get()\n        print(f\"\\n[Orchestrator] Got handle from sender\")\n\n        # Step 2: Send handle to receiver, have it pull data\n        receiver_checksum = receiver.pull_data.call_one(handle).get()\n        sender_checksum = sender.get_checksum.call_one().get()\n\n        print(f\"[Orchestrator] Sender checksum: {sender_checksum:.2f}\")\n        print(f\"[Orchestrator] Receiver checksum: {receiver_checksum:.2f}\")\n        print(f\"[Orchestrator] Match: {abs(sender_checksum - receiver_checksum) \u003C 0.01}\")\n\nexcept Exception as e:\n    print(f\"(Demo failed: {e})\\n\")\n    show_fallback_demo()", "code_hash": "9c7090020db0a6d3770e0f81a71d9cb5", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hstk", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 5. CPU Staging Pattern\n\n### GPU-Native RDMA Exists (and Monarch Supports It)\n\nGPU-native RDMA (GPUDirect) is real and works well - the NIC reads directly from GPU\nmemory with no CPU copy. Monarch supports this at the Rust level. For synchronous\nbulk transfers, it's excellent.\n\n### CPU Staging: A Deliberate Architectural Choice\n\nFor async RL, CPU staging isn't a workaround for missing GPUDirect - it's the\n**preferred production pattern**. The reason is **temporal decoupling**: trainers\nand generators operate on completely independent timelines, and we need a buffer\nbetween them.\n\nThe issue isn't bandwidth - it's **timing**:\n\n```\nDirect GPU\u2192GPU RDMA:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Generator GPU is mid-inference                       \u2502\n\u2502 \u251c\u2500\u2500 layer 1 \u2500\u2500\u2524 [RDMA arrives, needs sync!]          \u2502\n\u2502               \u2193                                      \u2502\n\u2502         cudaDeviceSynchronize()  \u2190 Blocks inference! \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nWith CPU staging, nothing on the critical path blocks:\n\n```\nTrainer GPU \u2500\u2500\u25ba CPU staging buffer (RDMA registered)\n                      \u2502\n                      \u2502 [Sits here, ready anytime]\n                      \u2502\n                      \u25bc\nGenerator grabs when ready \u2500\u2500\u25ba Generator GPU\n```\n\nThe CPU buffer is a **temporal decoupling point**.\n\nNote: the CPU staging path does involve GPU\u2194CPU copies on each end. When we say\nRDMA is \"zero-copy,\" we mean across the network \u2014 the NIC reads/writes directly\nfrom/to registered CPU memory with no kernel involvement.\n\"\"\")", "code_hash": "859d7e76f8c1080d35080b6fa774c6be", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "nWHF", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 6. Circular Weight Buffers\n\n### One-Sided Isn't Free\n\nOne-sided RDMA is powerful - trainers and generators can operate independently without\nexplicit send/recv coordination. But \"no coordination\" isn't quite right. There's still\na fundamental race condition lurking: **what if the trainer overwrites a buffer while a\ngenerator is reading from it?**\n\nWith a single buffer, this is a real problem:\n\n```\nTrainer: write v3 to buffer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba  [buffer: v3...v2...v3]  \u2190 corrupted!\nGenerator: reading v2 from buffer \u2500\u2500\u2500\u2500\u25ba  read gets mix of v2 and v3\n```\n\nWe need *some* form of coordination. The question is: do we go back to message-passing\n(explicit locks, barriers, acknowledgments) and lose the async benefits? Or can we get\ncoordination from the **structure itself**?\n\n### Solution: Circular Buffer as Structural Coordination\n\nThe key insight: GPU memory is scarce, but **CPU memory is abundant**. We can afford to\nkeep multiple versions of the weights in CPU staging buffers. By writing to slots in a\ncircular pattern, the trainer never overwrites a slot that a generator might still be\nreading - as long as we have enough slots to cover the timing gap.\n\nThis is **structural coordination**: the circular buffer's design eliminates the race\ncondition without any explicit synchronization messages between trainer and generator.\n\n```\nTrainer writes:     v0    \u2192  v1  \u2192  v2  \u2192  v3  \u2192  v4  \u2192  v5  \u2192 ...\n                     \u2193        \u2193      \u2193\nBuffer slots:      [slot0] [slot1] [slot2]  (circular, reused)\n                     v3      v4      v5\n\nGenerator reads: \"Give me latest\" \u2192 v5\n```\n\nBenefits:\n- **No message-based coordination** - structure prevents races, not locks\n- **Pre-registered RDMA buffers** - no memory registration on hot path\n- **Lock-free reads** - generators always get a consistent snapshot\n- **Bounded memory** - only N versions in flight\n\n**Memory cost is real**: for a 70B model (140 GB in bf16), 5 slots = 700 GB of CPU RAM.\nThis is feasible on HPC nodes (Grand Teton has ~1.5 TB RAM per node), but `n_slots` is\nbounded by available CPU memory, not just timing.\n\nThe key design constraint: register all slots at init time, then just write to them.\nNo allocation, no registration on the critical path. Tune `n_slots` so that the trainer\ncan't lap the slowest generator \u2014 if it does, the generator reads a corrupted mix of\ntwo versions (not a graceful error, just silent data corruption).\n\"\"\")", "code_hash": "b73698a1a338c37b7ceff5b2720da81e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "iLit", "name": "_"}, {"code": "circ_slots_slider = mo.ui.slider(1, 8, value=3, label=\"Buffer slots (n_slots)\")\ncirc_writes_slider = mo.ui.slider(1, 10, value=2, label=\"Trainer writes per generator sync\")\nmo.vstack([\n    mo.md(\"**Try it**: adjust slots and write speed to see when lapping causes a race condition.\"),\n    mo.hstack([circ_slots_slider, circ_writes_slider], justify=\"center\", gap=1),\n])", "code_hash": "2972a45cdad599233d8b7a937c1ca25a", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZHCJ", "name": "_"}, {"code": "_n = circ_slots_slider.value\n_w = circ_writes_slider.value\n_safe = _w \u003C _n\n\n# Build SVG showing circular buffer slots with write pointer and read pointer\n_slot_w, _slot_h = 64, 48\n_gap = 6\n_pad = 30\n_total_w = max(_n * (_slot_w + _gap) - _gap + 2 * _pad, 300)\n_total_h = 130\n\n_parts = [\n    f'\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"{_total_w}\" height=\"{_total_h}\" '\n    f'style=\"font-family: -apple-system, sans-serif;\"\u003E'\n]\n\n# Title\n_parts.append(\n    f'\u003Ctext x=\"{_total_w / 2}\" y=\"18\" text-anchor=\"middle\" '\n    f'font-size=\"12\" fill=\"#666\"\u003ETrainer writes {_w} version{\"s\" if _w != 1 else \"\"} '\n    f'while generator reads from slot 0\u003C/text\u003E'\n)\n\n_slot_y = 50\nfor _i in range(_n):\n    _x = _pad + _i * (_slot_w + _gap)\n\n    # Which trainer write steps land on this slot?\n    # Trainer writes to slots 1, 2, ..., wrapping around\n    _write_steps = [j + 1 for j in range(_w) if (1 + j) % _n == _i]\n    _is_gen_read = (_i == 0)\n    _is_written = len(_write_steps) \u003E 0\n    _collision = _is_gen_read and _is_written\n\n    # Colors\n    if _collision:\n        _fill, _stroke = \"#fecaca\", \"#dc2626\"\n    elif _is_gen_read:\n        _fill, _stroke = \"#dbeafe\", \"#2563eb\"\n    elif _is_written:\n        _fill, _stroke = \"#dcfce7\", \"#16a34a\"\n    else:\n        _fill, _stroke = \"#f3f4f6\", \"#9ca3af\"\n\n    # Slot rectangle\n    _parts.append(\n        f'\u003Crect x=\"{_x}\" y=\"{_slot_y}\" width=\"{_slot_w}\" height=\"{_slot_h}\" rx=\"5\" '\n        f'fill=\"{_fill}\" stroke=\"{_stroke}\" stroke-width=\"2\"/\u003E'\n    )\n    # Slot label\n    _parts.append(\n        f'\u003Ctext x=\"{_x + _slot_w / 2}\" y=\"{_slot_y + _slot_h / 2}\" text-anchor=\"middle\" '\n        f'dominant-baseline=\"central\" font-size=\"13\" font-weight=\"bold\" '\n        f'fill=\"{_stroke}\"\u003Eslot {_i}\u003C/text\u003E'\n    )\n    # Write step markers above slot\n    if _write_steps:\n        _step_label = \",\".join(str(s) for s in _write_steps)\n        _marker_color = \"#dc2626\" if _collision else \"#16a34a\"\n        _parts.append(\n            f'\u003Ctext x=\"{_x + _slot_w / 2}\" y=\"{_slot_y - 8}\" text-anchor=\"middle\" '\n            f'font-size=\"10\" fill=\"{_marker_color}\"\u003Ewrite #{_step_label}\u003C/text\u003E'\n        )\n    # Generator reading label below slot 0\n    if _is_gen_read:\n        _gen_label = (\n            \"\u25b2 gen reading \u2014 OVERWRITTEN!\" if _collision else \"\u25b2 gen reading\"\n        )\n        _gen_color = \"#dc2626\" if _collision else \"#2563eb\"\n        _gen_weight = \"bold\" if _collision else \"normal\"\n        _parts.append(\n            f'\u003Ctext x=\"{_x + _slot_w / 2}\" y=\"{_slot_y + _slot_h + 16}\" '\n            f'text-anchor=\"middle\" font-size=\"10\" font-weight=\"{_gen_weight}\" '\n            f'fill=\"{_gen_color}\"\u003E{_gen_label}\u003C/text\u003E'\n        )\n\n_parts.append(\"\u003C/svg\u003E\")\n_svg = \"\\n\".join(_parts)\n\nif _safe:\n    _callout = mo.callout(mo.md(\n        f\"**Safe** \u2014 {_n} slots, {_w} trainer writes between generator reads. \"\n        f\"Generator finishes reading slot 0 before trainer wraps around to overwrite it.\"\n    ), kind=\"success\")\nelse:\n    _callout = mo.callout(mo.md(\n        f\"**RACE CONDITION** \u2014 {_n} slots, {_w} trainer writes per generator read. \"\n        f\"Trainer wraps around and overwrites slot 0 on write #{_n} while generator is \"\n        f\"still reading it! Result: corrupted weights (silent data corruption, not an error).\\n\\n\"\n        f\"**Fix**: increase to at least **{_w + 1} slots**.\"\n    ), kind=\"danger\")\n\nmo.vstack([mo.Html(_svg), _callout])", "code_hash": "255121e1cced3e3d5bbaafd0e4c7af5b", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ROlb", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 7. Weight Re-sharding\n\n### The Sharding Mismatch Problem\n\nTrainer and Generator often have **different tensor layouts**. Consider an example:\n\n| Role | Parallelism | Sharding |\n|------|-------------|----------|\n| Trainer | FSDP (8 GPUs) | `Shard(0)` - rows split across 8 GPUs |\n| Generator | TP (2 GPUs) | `Shard(1)` - columns split across 2 GPUs |\n\nTherefore we cannot always directly transfer weights - we need **re-sharding**.\n\nConsider a simple example where the trainer may be row-sharded and the generator may be column-sharded:\n\n```\nTrainer (row-sharded):          Generator (column-sharded):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GPU 0: rows 0-127\u2502            \u2502 GPU 0   \u2502 GPU 1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u2192      \u2502 cols    \u2502 cols    \u2502\n\u2502 GPU 1: rows 128+ \u2502            \u2502 0-511   \u2502 512+    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n### Two Approaches\n\n**Gather Then Slice** (simple but wasteful):\nOne approach is to materialize the entire tensor, i.e. `gather`, transfer the full tensor, and then slice on the receiver side:\n1. Each receiver gathers ALL sender shards \u2192 full tensor\n2. Each receiver slices out its portion\n3. **Problem**: 2x redundant data transfer\n\n**Routed Transfer** (optimal):\nA more efficient approach is to only transfer the data that needs to be transferred:\n1. Pre-compute which sender chunks overlap with which receiver regions\n2. Send only the exact chunks needed\n3. **Benefit**: Minimal bandwidth, no redundancy\n\n```\nGATHER: G0 receives T0,T1,T2,T3 \u2192 discards T2,T3 (50% waste!)\nROUTED: G0 receives T0,T1 only \u2192 exactly what it needs\n```\n\nThe routed approach batches all needed transfers into one plan.\nPre-compute the plan once at handshake, execute it on each sync.\n\"\"\")", "code_hash": "5e6c22ad44dd0f96e888bca6469b57d2", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "qnkX", "name": "_"}, {"code": "from dataclasses import dataclass\nfrom typing import List, Tuple\n\n@dataclass\nclass ShardMetadata:\n    \"\"\"Metadata describing a tensor shard.\"\"\"\n    rank: int\n    global_shape: Tuple[int, ...]\n    offset: Tuple[int, ...]  # Start position in global tensor\n    local_shape: Tuple[int, ...]  # Shape of this shard\n\n@dataclass\nclass TransferChunk:\n    \"\"\"A chunk to transfer from sender to receiver.\"\"\"\n    sender_rank: int\n    receiver_rank: int\n    sender_offset: Tuple[int, int]  # Where to read from sender\n    receiver_offset: Tuple[int, int]  # Where to write in receiver\n    shape: Tuple[int, int]  # Shape of the chunk\n\ndef compute_shard_metadata(\n    global_shape: Tuple[int, int],\n    num_ranks: int,\n    shard_dim: int,\n) -\u003E List[ShardMetadata]:\n    \"\"\"Compute shard metadata for a given sharding.\"\"\"\n    shards = []\n    dim_size = global_shape[shard_dim]\n    shard_size = dim_size // num_ranks\n\n    for rank in range(num_ranks):\n        offset = [0, 0]\n        local_shape = list(global_shape)\n\n        offset[shard_dim] = rank * shard_size\n        local_shape[shard_dim] = shard_size\n\n        shards.append(ShardMetadata(\n            rank=rank,\n            global_shape=global_shape,\n            offset=tuple(offset),\n            local_shape=tuple(local_shape),\n        ))\n\n    return shards\n\ndef compute_overlap(\n    sender: ShardMetadata,\n    receiver: ShardMetadata,\n) -\u003E \"TransferChunk | None\":\n    \"\"\"Compute overlap between sender and receiver shards.\"\"\"\n    s_start = sender.offset\n    s_end = (s_start[0] + sender.local_shape[0], s_start[1] + sender.local_shape[1])\n\n    r_start = receiver.offset\n    r_end = (r_start[0] + receiver.local_shape[0], r_start[1] + receiver.local_shape[1])\n\n    inter_start = (max(s_start[0], r_start[0]), max(s_start[1], r_start[1]))\n    inter_end = (min(s_end[0], r_end[0]), min(s_end[1], r_end[1]))\n\n    if inter_start[0] \u003E= inter_end[0] or inter_start[1] \u003E= inter_end[1]:\n        return None\n\n    shape = (inter_end[0] - inter_start[0], inter_end[1] - inter_start[1])\n\n    sender_local = (inter_start[0] - s_start[0], inter_start[1] - s_start[1])\n    receiver_local = (inter_start[0] - r_start[0], inter_start[1] - r_start[1])\n\n    return TransferChunk(\n        sender_rank=sender.rank,\n        receiver_rank=receiver.rank,\n        sender_offset=sender_local,\n        receiver_offset=receiver_local,\n        shape=shape,\n    )\n\ndef compute_transfer_plan(\n    sender_shards: List[ShardMetadata],\n    receiver_shards: List[ShardMetadata],\n) -\u003E List[TransferChunk]:\n    \"\"\"Compute all transfers needed for re-sharding.\"\"\"\n    transfers = []\n    for sender in sender_shards:\n        for receiver in receiver_shards:\n            chunk = compute_overlap(sender, receiver)\n            if chunk is not None:\n                transfers.append(chunk)\n    return transfers\n\ndef render_resharding_svg(trainer_shards, gen_shards, transfer_plan, global_shape):\n    \"\"\"Render a color-matched visualization of the re-sharding transfer plan.\n\n    Returns HTML string with:\n    - Two grids (trainer left, generator right) where each transfer chunk\n      is colored the same on both sides so you can visually match them.\n    - A transfer matrix table below showing which chunks move where.\n    \"\"\"\n    # Layout constants\n    grid_w, grid_h = 280, 240\n    left_x, right_x = 80, 520\n    top_y = 50\n    svg_w = 880\n    rows, cols = global_shape\n\n    # Generate distinct colors for each transfer\n    # Use HSL with evenly spaced hues for maximum distinction\n    n_transfers = len(transfer_plan)\n    transfer_colors = []\n    for i in range(max(n_transfers, 1)):\n        hue = (i * 360 // max(n_transfers, 1) + 10) % 360\n        transfer_colors.append(f\"hsl({hue}, 70%, 55%)\")\n\n    # Also need light shard background colors (just for shard boundaries)\n    shard_border_color = \"#444\"\n\n    parts = []\n    svg_h = top_y + grid_h + 50\n    parts.append(\n        f'\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"{svg_w}\" height=\"{svg_h}\" '\n        f'viewBox=\"0 0 {svg_w} {svg_h}\" '\n        f'style=\"font-family: -apple-system, sans-serif; font-size: 12px;\"\u003E'\n    )\n\n    # Title labels\n    parts.append(f'\u003Ctext x=\"{left_x + grid_w // 2}\" y=\"22\" text-anchor=\"middle\" '\n                  f'font-weight=\"bold\" font-size=\"15\"\u003ETrainer shards\u003C/text\u003E')\n    parts.append(f'\u003Ctext x=\"{right_x + grid_w // 2}\" y=\"22\" text-anchor=\"middle\" '\n                  f'font-weight=\"bold\" font-size=\"15\"\u003EGenerator shards\u003C/text\u003E')\n\n    # Subtitle showing shard dim\n    t_dim = \"row\" if (trainer_shards and trainer_shards[0].offset == (0, 0)\n                      and len(trainer_shards) \u003E 1\n                      and trainer_shards[1].offset[0] \u003E 0) else \"col\"\n    g_dim = \"row\" if (gen_shards and gen_shards[0].offset == (0, 0)\n                      and len(gen_shards) \u003E 1\n                      and gen_shards[1].offset[0] \u003E 0) else \"col\"\n    parts.append(f'\u003Ctext x=\"{left_x + grid_w // 2}\" y=\"38\" text-anchor=\"middle\" '\n                  f'font-size=\"11\" fill=\"#666\"\u003E{len(trainer_shards)} GPUs, {t_dim}-sharded\u003C/text\u003E')\n    parts.append(f'\u003Ctext x=\"{right_x + grid_w // 2}\" y=\"38\" text-anchor=\"middle\" '\n                  f'font-size=\"11\" fill=\"#666\"\u003E{len(gen_shards)} GPUs, {g_dim}-sharded\u003C/text\u003E')\n\n    # Helper: map global (row, col, h, w) to pixel rect\n    def to_px(base_x, r, c, h, w):\n        px = base_x + (c / cols) * grid_w\n        py = top_y + (r / rows) * grid_h\n        pw = (w / cols) * grid_w\n        ph = (h / rows) * grid_h\n        return px, py, pw, ph\n\n    # Draw transfer chunks as colored rectangles on BOTH grids\n    for i, t in enumerate(transfer_plan):\n        color = transfer_colors[i]\n\n        # Find sender/receiver shard global offsets\n        s_shard = next(s for s in trainer_shards if s.rank == t.sender_rank)\n        r_shard = next(s for s in gen_shards if s.rank == t.receiver_rank)\n\n        # Trainer side: chunk in global coords\n        s_row = s_shard.offset[0] + t.sender_offset[0]\n        s_col = s_shard.offset[1] + t.sender_offset[1]\n        px, py, pw, ph = to_px(left_x, s_row, s_col, t.shape[0], t.shape[1])\n        parts.append(\n            f'\u003Crect x=\"{px:.1f}\" y=\"{py:.1f}\" width=\"{pw:.1f}\" height=\"{ph:.1f}\" '\n            f'fill=\"{color}\" fill-opacity=\"0.55\" stroke=\"{color}\" stroke-width=\"0.5\"/\u003E'\n        )\n\n        # Generator side: chunk in global coords\n        r_row = r_shard.offset[0] + t.receiver_offset[0]\n        r_col = r_shard.offset[1] + t.receiver_offset[1]\n        px, py, pw, ph = to_px(right_x, r_row, r_col, t.shape[0], t.shape[1])\n        parts.append(\n            f'\u003Crect x=\"{px:.1f}\" y=\"{py:.1f}\" width=\"{pw:.1f}\" height=\"{ph:.1f}\" '\n            f'fill=\"{color}\" fill-opacity=\"0.55\" stroke=\"{color}\" stroke-width=\"0.5\"/\u003E'\n        )\n\n    # Draw shard boundary outlines and rank labels on top\n    def draw_shard_outlines(shards, base_x, prefix):\n        for s in shards:\n            x = base_x + (s.offset[1] / cols) * grid_w\n            y = top_y + (s.offset[0] / rows) * grid_h\n            w = (s.local_shape[1] / cols) * grid_w\n            h = (s.local_shape[0] / rows) * grid_h\n            parts.append(\n                f'\u003Crect x=\"{x:.1f}\" y=\"{y:.1f}\" width=\"{w:.1f}\" height=\"{h:.1f}\" '\n                f'fill=\"none\" stroke=\"{shard_border_color}\" stroke-width=\"2\"/\u003E'\n            )\n            # Rank label\n            cx, cy = x + w / 2, y + h / 2\n            parts.append(\n                f'\u003Ctext x=\"{cx:.1f}\" y=\"{cy:.1f}\" text-anchor=\"middle\" '\n                f'dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" '\n                f'fill=\"#222\"\u003E{prefix}{s.rank}\u003C/text\u003E'\n            )\n\n    draw_shard_outlines(trainer_shards, left_x, \"T\")\n    draw_shard_outlines(gen_shards, right_x, \"G\")\n\n    # Outer boxes\n    parts.append(f'\u003Crect x=\"{left_x}\" y=\"{top_y}\" width=\"{grid_w}\" height=\"{grid_h}\" '\n                  f'fill=\"none\" stroke=\"#222\" stroke-width=\"2.5\"/\u003E')\n    parts.append(f'\u003Crect x=\"{right_x}\" y=\"{top_y}\" width=\"{grid_w}\" height=\"{grid_h}\" '\n                  f'fill=\"none\" stroke=\"#222\" stroke-width=\"2.5\"/\u003E')\n\n    # \"=\" sign between grids to show equivalence\n    mid_x = (left_x + grid_w + right_x) // 2\n    mid_y = top_y + grid_h // 2\n    parts.append(f'\u003Ctext x=\"{mid_x}\" y=\"{mid_y}\" text-anchor=\"middle\" '\n                  f'dominant-baseline=\"central\" font-size=\"28\" fill=\"#888\"\u003E=\u003C/text\u003E')\n    parts.append(f'\u003Ctext x=\"{mid_x}\" y=\"{mid_y + 22}\" text-anchor=\"middle\" '\n                  f'font-size=\"10\" fill=\"#888\"\u003Esame data\u003C/text\u003E')\n\n    # Global shape label\n    parts.append(\n        f'\u003Ctext x=\"{svg_w // 2}\" y=\"{svg_h - 8}\" text-anchor=\"middle\" '\n        f'font-size=\"11\" fill=\"#888\"\u003EGlobal tensor: {rows} x {cols}\u003C/text\u003E'\n    )\n\n    parts.append(\"\u003C/svg\u003E\")\n    svg_str = \"\\n\".join(parts)\n\n    # Build transfer matrix HTML table\n    n_trainers = len(trainer_shards)\n    n_gens = len(gen_shards)\n\n    # Build lookup: (sender_rank, receiver_rank) -\u003E (transfer_index, chunk)\n    transfer_lookup = {}\n    for i, t in enumerate(transfer_plan):\n        transfer_lookup[(t.sender_rank, t.receiver_rank)] = (i, t)\n\n    table_parts = [\n        '\u003Ctable style=\"border-collapse: collapse; margin-top: 12px; font-family: monospace; font-size: 12px;\"\u003E',\n        '\u003Ctr\u003E\u003Cth style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5;\"\u003E\u003C/th\u003E',\n    ]\n    for g in range(n_gens):\n        table_parts.append(\n            f'\u003Cth style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5;\"\u003EG{g}\u003C/th\u003E'\n        )\n    table_parts.append('\u003C/tr\u003E')\n\n    for t_rank in range(n_trainers):\n        table_parts.append(\n            f'\u003Ctr\u003E\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; '\n            f'background: #f5f5f5; font-weight: bold;\"\u003ET{t_rank}\u003C/td\u003E'\n        )\n        for g_rank in range(n_gens):\n            key = (t_rank, g_rank)\n            if key in transfer_lookup:\n                idx, chunk = transfer_lookup[key]\n                color = transfer_colors[idx]\n                table_parts.append(\n                    f'\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; '\n                    f'background: {color}; color: white; text-align: center; '\n                    f'font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E'\n                    f'{chunk.shape[0]}x{chunk.shape[1]}\u003C/td\u003E'\n                )\n            else:\n                table_parts.append(\n                    '\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; '\n                    'text-align: center; color: #ccc;\"\u003E\u0026mdash;\u003C/td\u003E'\n                )\n        table_parts.append('\u003C/tr\u003E')\n\n    table_parts.append('\u003C/table\u003E')\n    table_str = \"\\n\".join(table_parts)\n\n    # Combine SVG + table\n    return (\n        f'\u003Cdiv style=\"display: flex; flex-direction: column; align-items: center;\"\u003E'\n        f'{svg_str}'\n        f'\u003Cdiv style=\"margin-top: 4px; font-size: 12px; color: #666;\"\u003E'\n        f'Matching colors = same data chunk. Matrix shows chunk shapes transferred.\u003C/div\u003E'\n        f'{table_str}'\n        f'\u003C/div\u003E'\n    )", "code_hash": "58e99d9b510522e6757f98c52f2fa447", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "TqIu", "name": "_"}, {"code": "# Interactive controls for re-sharding visualization\ntrainer_gpu_slider = mo.ui.slider(1, 8, value=4, label=\"Trainer GPUs\")\ngen_gpu_slider = mo.ui.slider(1, 8, value=2, label=\"Generator GPUs\")\ntrainer_dim_dropdown = mo.ui.dropdown(\n    options={\"Row (dim 0)\": 0, \"Col (dim 1)\": 1},\n    value=\"Row (dim 0)\",\n    label=\"Trainer shard dim\",\n)\ngen_dim_dropdown = mo.ui.dropdown(\n    options={\"Row (dim 0)\": 0, \"Col (dim 1)\": 1},\n    value=\"Col (dim 1)\",\n    label=\"Generator shard dim\",\n)\n\nmo.hstack(\n    [trainer_gpu_slider, trainer_dim_dropdown, gen_gpu_slider, gen_dim_dropdown],\n    justify=\"center\",\n    gap=1,\n)", "code_hash": "56d96d299c91b1332dd5472987f17216", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Vxnm", "name": "_"}, {"code": "# Compute shards and transfer plan based on widget values\n_global_shape = (512, 512)\n_t_shards = compute_shard_metadata(_global_shape, trainer_gpu_slider.value, trainer_dim_dropdown.value)\n_g_shards = compute_shard_metadata(_global_shape, gen_gpu_slider.value, gen_dim_dropdown.value)\n_plan = compute_transfer_plan(_t_shards, _g_shards)\n\n_svg = render_resharding_svg(_t_shards, _g_shards, _plan, _global_shape)\n\n# Compute stats for the callout\n_routed_bytes = sum(t.shape[0] * t.shape[1] * 2 for t in _plan)  # bf16 = 2 bytes\n_gather_bytes = _global_shape[0] * _global_shape[1] * 2 * gen_gpu_slider.value\n_waste_pct = (1 - _routed_bytes / _gather_bytes) * 100 if _gather_bytes \u003E 0 else 0\n\nresharding_stats = {\n    \"transfers\": len(_plan),\n    \"routed_bytes\": _routed_bytes,\n    \"gather_bytes\": _gather_bytes,\n    \"waste_pct\": _waste_pct,\n}\n\n_stats_md = mo.md(f\"\"\"\n**Transfer Plan Stats** | **Transfers**: {len(_plan)} chunks | **Routed**: {_routed_bytes / 1024:.1f} KB | **Gather**: {_gather_bytes / 1024:.1f} KB | **Saved**: {_waste_pct:.0f}%\n\"\"\")\n\nmo.vstack([mo.Html(_svg), mo.callout(_stats_md, kind=\"info\")])", "code_hash": "d6af84c7c6399d896fa3a07a45a32d48", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "DnEU", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 8. Putting It All Together\n\nThe full async RL weight sync pattern:\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         TRAINER                                 \u2502\n\u2502  1. Train step completes                                        \u2502\n\u2502  2. Copy weights to CPU staging buffer (non-blocking D2H)       \u2502\n\u2502  3. Publish to circular buffer with version tag                 \u2502\n\u2502  4. Continue training (no blocking!)                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                                \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              CIRCULAR BUFFER (CPU, RDMA-registered)             \u2502\n\u2502  [slot 0: v3] [slot 1: v4] [slot 2: v5]                         \u2502\n\u2502                                 \u2191 latest                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                     \u25bc                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   GENERATOR 0   \u2502   \u2502   GENERATOR 1   \u2502   \u2502   GENERATOR 2   \u2502\n\u2502                 \u2502   \u2502                 \u2502   \u2502                 \u2502\n\u2502 After gen done: \u2502   \u2502 After gen done: \u2502   \u2502 After gen done: \u2502\n\u2502 1. Get latest   \u2502   \u2502 1. Get latest   \u2502   \u2502 1. Get latest   \u2502\n\u2502    version      \u2502   \u2502    version      \u2502   \u2502    version      \u2502\n\u2502 2. RDMA read    \u2502   \u2502 2. RDMA read    \u2502   \u2502 2. RDMA read    \u2502\n\u2502    \u2192 GPU        \u2502   \u2502    \u2192 GPU        \u2502   \u2502    \u2192 GPU        \u2502\n\u2502 3. Re-shard if  \u2502   \u2502 3. Re-shard if  \u2502   \u2502 3. Re-shard if  \u2502\n\u2502    needed       \u2502   \u2502    needed       \u2502   \u2502    needed       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\n**Key properties:**\n- Trainer never blocks waiting for generators\n- Generators pull directly to GPU when *they're* ready\n- Re-sharding happens locally on each generator\n- Circular buffer bounds memory, reuses RDMA registrations\n\"\"\")", "code_hash": "2264a8f1068ea8a261a9b035995c277e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ulZA", "name": "_"}, {"code": "mo.md(r\"\"\"\n### Live Demo: Async Weight Sync\n\nLet's see this in action! We'll simulate the core async RL pattern:\n\n- **1 Trainer**: Runs training steps, publishes new weights to a 3-slot circular buffer\n- **4 Generators**: Each independently syncs to latest weights, then generates\n\nAll 5 actors run **concurrently and independently**. The trainer never waits for generators,\nand each generator grabs weights whenever it's ready (at slightly different rates to show\nthe async behavior). To verify correctness, we set weights to `version` and check on read.\n\n**Race condition safety**: The circular buffer's slot count is tuned so that\n`buffer_size \u00d7 update_interval \u003E\u003E sync_time`. This ensures a slot isn't overwritten\nwhile a generator is reading it. In this demo: 5 slots, ~1s between trainer updates,\nRDMA sync takes ~ms, so a race is effectively impossible. In production, tune\n`buffer_size` based on actual sync time and update frequency.\n\"\"\")", "code_hash": "d33fa245d02abe2e113666d5a6fda2e1", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ecfG", "name": "_"}, {"code": "import threading\n\ndef show_fallback():\n    print(\"(RDMA not available - showing conceptual flow)\\n\")\n    print(\"What would happen with RDMA:\")\n    print(\"  [Trainer] Publishes v0, v1, v2... to circular buffer\")\n    print(\"  [Generator] Syncs when ready, verifies weights match version\")\n    print(\"  Both run independently, no blocking!\")\n\ntry:\n    if not is_rdma_available():\n        show_fallback()\n    else:\n        class Trainer(Actor):\n            \"\"\"Trainer with circular buffer for weight versioning.\"\"\"\n\n            def __init__(self, weight_size: int):\n                self.n_slots = 5\n                self.version = 0\n                self.slots = []\n                self.handles = []\n                for _ in range(self.n_slots):\n                    slot = torch.zeros(weight_size, dtype=torch.float32)\n                    self.slots.append(slot)\n                    self.handles.append(RDMABuffer(slot.view(torch.uint8).flatten()))\n                print(f\"[Trainer] Initialized {self.n_slots}-slot circular buffer\")\n\n            @endpoint\n            def get_latest(self) -\u003E tuple:\n                if self.version == 0:\n                    return None, -1\n                v = self.version - 1\n                return self.handles[v % self.n_slots], v\n\n            @endpoint\n            def train_step(self):\n                \"\"\"Single training step: publish new weights.\"\"\"\n                import sys\n                slot_idx = self.version % self.n_slots\n                self.slots[slot_idx].fill_(float(self.version))\n                self.version += 1\n                print(f\"[Trainer] Published v{self.version - 1}\")\n                sys.stdout.flush()\n                return self.version\n\n        class Generator(Actor):\n            \"\"\"Generator that syncs weights and generates.\"\"\"\n\n            def __init__(self, weight_size: int, trainer):\n                self.gen_id = current_rank().rank\n                self.trainer = trainer\n                self.weights = torch.zeros(weight_size, dtype=torch.float32)\n                self.weight_bytes = self.weights.view(torch.uint8).flatten()\n                self.current_version = -1\n                print(f\"[Gen {self.gen_id}] Initialized\")\n\n            @endpoint\n            def generate_step(self) -\u003E int:\n                \"\"\"Single generate step: sync if needed, then generate.\"\"\"\n                import sys\n                # Try to sync weights\n                handle, version = self.trainer.get_latest.call_one().get()\n                if handle is not None and version \u003E self.current_version:\n                    handle.read_into(self.weight_bytes).get()\n                    actual = int(self.weights[0].item())\n                    if actual \u003E= version:  # \u003E= not == : a later version may have written to same slot\n                        self.current_version = actual\n                        print(f\"[Gen {self.gen_id}] Synced to v{actual}\")\n                        sys.stdout.flush()\n                return self.current_version\n\n        # Spawn trainer and generators\n        n_generators = 4\n        trainer_proc = this_host().spawn_procs(per_host={\"procs\": 1})\n        generator_procs = this_host().spawn_procs(per_host={\"procs\": n_generators})\n\n        trainer = trainer_proc.spawn(\"trainer\", Trainer, weight_size=1024)\n        generators = generator_procs.spawn(\"generators\", Generator, weight_size=1024, trainer=trainer)\n\n        print(\"\\n--- Running async RL simulation ---\\n\")\n\n        # Results storage\n        _results = {\"trainer\": None, \"generators\": [None] * n_generators}\n\n        def run_trainer(n_steps, step_time):\n            import time\n            for _ in range(n_steps):\n                time.sleep(step_time)\n                _results[\"trainer\"] = trainer.train_step.call_one().get()\n\n        def run_generator(gen_actor, gen_idx, n_iters, gen_time):\n            import time\n            for _ in range(n_iters):\n                version = gen_actor.generate_step.call_one().get()\n                if version \u003E= 0:\n                    time.sleep(gen_time)\n                    print(f\"[Gen {gen_idx}] Generated (v{version})\")\n                else:\n                    time.sleep(0.05)\n            _results[\"generators\"][gen_idx] = version\n\n        # Create threads for trainer and each generator\n        threads = []\n\n        # Trainer thread\n        t = threading.Thread(target=run_trainer, args=(6, 1.0))  # 1 second per step\n        threads.append(t)\n\n        # Generator threads\n        for i in range(n_generators):\n            gen_actor = generators.slice(procs=i)\n            t = threading.Thread(target=run_generator, args=(gen_actor, i, 5, 0.25))\n            threads.append(t)\n\n        # Start all threads\n        for t in threads:\n            t.start()\n\n        # Wait for all to complete\n        for t in threads:\n            t.join()\n\n        print(f\"\\n--- Done! Trainer published {_results['trainer']} versions ---\")\n        print(f\"Generators ended on versions: {_results['generators']}\")\n        print(\"All pulled independently via RDMA, weights verified!\")\n\nexcept Exception as e:\n    import traceback\n    traceback.print_exc()\n    print(f\"(Demo failed: {e})\")\n    show_fallback()", "code_hash": "23723f3e7ec84ee775b019276dac3168", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Pvdt", "name": "_"}, {"code": "mo.md(r\"\"\"\n## 9. Going Further: TorchStore\n\nAll the patterns we've covered - RDMA memory registration, magic pointers, circular buffers,\npre-computed transfer plans - are building blocks. If you need a **production-ready solution**,\ncheck out [TorchStore](https://github.com/meta-pytorch/torchstore).\n\n### What is TorchStore?\n\nTorchStore is a **distributed, asynchronous key-value store for PyTorch tensors** built on\nMonarch's actor framework. It abstracts away the RDMA complexity while giving you:\n\n```python\nfrom torchstore import TorchStore\n\n# Store tensors with async API\nawait ts.put(\"model/layer1/weights\", tensor)\n\n# Retrieve with optional in-place and slice semantics\nawait ts.get(\"model/layer1/weights\", inplace_tensor=buffer)\n\n# Native PyTorch checkpoint support\nawait ts.put_state_dict(model.state_dict())\nloaded = await ts.get_state_dict()\n```\n\n### When to Use What\n\n| Scenario | Solution |\n|----------|----------|\n| Learning RDMA patterns | This notebook + 06b |\n| Custom RL weight sync | See 06b for `RDMABuffer` + `RDMAAction` patterns |\n| General tensor storage | Use TorchStore |\n| Checkpointing | Use TorchStore's `put_state_dict` |\n\"\"\")", "code_hash": "073a87de27a68088af5e59280149bddb", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "ZBYS", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Summary\n\n### Key Takeaways\n\n1. **Bandwidth hierarchy matters**: NVLink (900 GB/s) \u003E\u003E InfiniBand (50 GB/s)\n   - Keep frequent operations on NVLink, use RDMA for cross-node\n\n2. **Collectives block, RL needs async**: High variance in generation times makes\n   synchronous operations expensive\n\n3. **Magic pointer pattern**: Tiny handle over control plane, bulk data over data plane\n   - ~100 bytes to describe 10 GB transfer\n\n4. **CPU staging**: Temporal decoupling for async RL\n   - Nothing blocks on the critical path\n\n5. **Circular buffers**: Version weights without memory churn\n   - Pre-register RDMA buffers, reuse slots\n\n6. **Weight re-sharding**: Different layouts need overlap computation\n   - Routed approach avoids redundant transfers\n\n### Want More?\n\n- **07b_weight_sync_deep_dive.py** - ibverbs internals, RDMA buffer patterns\n- **08_rl_e2e.py** - Complete async RL system using these patterns\n\n---\n\n**Previous:** [NB06 \u2014 Services](./06_services.html) \u00b7 **Next:** [NB07b \u2014 RDMA Deep Dive](./07b_weight_sync_deep_dive.html)\n\"\"\")", "code_hash": "c5d90beee85a8c570d106a19a7d9a1d6", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "aLJB", "name": "_"}], "metadata": {"marimo_version": "0.19.9"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "8e01abc14814a6848ee5704e220ac262", "console": [], "id": "MJUe", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "66da605d1067548d1c58e4c1c1b15afe", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"rdma-weight-synchronization\"\u003ERDMA \u0026amp; Weight Synchronization\u003C/h1\u003E\n\u003Cspan class=\"paragraph\"\u003EYou've built your async RL system. Generators are humming, the trainer is\nlearning. Then you check GPU utilization and discover that most of your\n\"training\" time is spent copying weights. Your async system has become a\nweight-syncing system that occasionally does RL.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis notebook is about making that problem disappear \u2014 using RDMA to move\nweights from trainer to generators so fast it becomes invisible.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWant to go deeper?\u003C/strong\u003E Check out \u003Cstrong\u003E07b_weight_sync_deep_dive.py\u003C/strong\u003E for ibverbs internals\nand RDMA buffer patterns. This notebook focuses on\nthe concepts and patterns you need to know for async RL.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "270e51d3ae33004215f4634a0b2711c0", "console": [], "id": "bkHC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"prerequisites\"\u003EPrerequisites\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThis notebook assumes familiarity with:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EPyTorch basics\u003C/strong\u003E - tensors, dtypes, device placement\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EOn-policy vs off-policy RL\u003C/strong\u003E - covered in \u003Ca href=\"./05_rl_intro.html\"\u003ENB05: RL Intro\u003C/a\u003E\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EMonarch Actor model\u003C/strong\u003E - spawning actors, endpoints, \u003Ccode\u003Ecall_one\u003C/code\u003E/\u003Ccode\u003Ecall\u003C/code\u003E (from \u003Ca href=\"./01_history_and_vision.py\"\u003ENB01\u003C/a\u003E and \u003Ca href=\"./02_interactive_devx.py\"\u003ENB02\u003C/a\u003E)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EBasic networking concepts\u003C/strong\u003E - what bandwidth and latency mean, client-server vs peer-to-peer\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "1129f2591acb6dea584177d1666eb658", "console": [], "id": "lEQa", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"1-why-weight-sync-matters\"\u003E1. Why Weight Sync Matters\u003C/h2\u003E\n\u003Ch3 id=\"the-on-policy-problem\"\u003EThe On-Policy Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETraditional RL algorithms want to be \u003Cstrong\u003Eon-policy\u003C/strong\u003E: generate experience using the current\npolicy, then immediately use that experience to update the policy. This creates a tight loop:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EOn-Policy RL:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  generate(policy_v1) \u2192 train(samples) \u2192 policy_v2 \u2192 repeat       \u2502\n\u2502                                                                  \u2502\n\u2502  Experience from v1 is only valid for updating v1                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EAsync RL breaks this rule.\u003C/strong\u003E Generators run continuously while the trainer updates weights.\nBy the time a sample reaches the trainer, it was generated by an old policy version:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EAsync RL (off-policy):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Generator: policy_v1 \u2192 sample\u2081                                  \u2502\n\u2502  Trainer:   train(sample\u2081) \u2192 policy_v2                           \u2502\n\u2502  Generator: policy_v1 \u2192 sample\u2082  \u2190 still using v1!               \u2502\n\u2502  Trainer:   train(sample\u2082) \u2192 policy_v3                           \u2502\n\u2502                                                                  \u2502\n\u2502  Samples are \u0026quot;stale\u0026quot; - generated by older policy versions        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis \u003Cstrong\u003Eoff-policy-ness\u003C/strong\u003E can work up to a degree, but must be limited. The generators\nneed fresh weights regularly to stay \"close enough\" to on-policy. Weight sync frequency\nbecomes a key hyperparameter trading off:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EToo slow\u003C/strong\u003E: Samples become too stale, training diverges\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EToo fast\u003C/strong\u003E: Weight sync overhead dominates, negating async benefits\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ch3 id=\"the-scale-problem\"\u003EThe Scale Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFor LLM-based RL, the weights are \u003Cstrong\u003Emassive\u003C/strong\u003E. Back-of-envelope math\n(1 parameter \u2248 2 bytes in bf16):\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EModel\u003C/th\u003E\n\u003Cth\u003EWeight Size\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELlama 3.1 70B\u003C/td\u003E\n\u003Ctd\u003E~140 GB\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELlama 3.1 405B\u003C/td\u003E\n\u003Ctd\u003E~810 GB\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EDeepSeek V3 671B\u003C/td\u003E\n\u003Ctd\u003E~1.3 TB\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThese weights need to move from trainer \u2192 generators regularly. If we're\nnot careful, our \"async RL training workload\" just becomes a weight syncing\nworkload. Let's look at the bandwidth hierarchy to understand why this is\ntricky and what we can do about it.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "dc9cb7704ba53d09e209242f825d9e56", "console": [], "id": "PKri", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"2-the-bandwidth-hierarchy\"\u003E2. The Bandwidth Hierarchy\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EFor weight sync, we care about one specific data path \u2014 trainer GPU to generator\nGPU, across nodes. Here's the chain of interconnects a weight tensor traverses:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003ETrainer GPU \u2500\u2500PCIe\u2500\u2500\u25ba CPU \u2500\u2500PCIe\u2500\u2500\u25ba NIC \u2550\u2550RDMA\u2550\u2550\u25ba NIC \u2500\u2500PCIe\u2500\u2500\u25ba CPU \u2500\u2500PCIe\u2500\u2500\u25ba Generator GPU\n  same node     (64 GB/s)    (50 GB/s)     (64 GB/s)      same node\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe bottleneck is the cross-node RDMA link at 50 GB/s per NIC. But modern nodes\nhave \u003Cstrong\u003E8 NICs\u003C/strong\u003E (one per GPU), so aggregate cross-node bandwidth is 400 GB/s.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EHere's how all these interconnects fit together in a full node:\u003C/span\u003E\n\u003Cdiv class=\"language-teratermmacro codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502\u003Cspan class=\"w\"\u003E                                              \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENODE\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EA\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                                      \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                                                                                          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                              \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVSwitch\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVLink\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EFabric\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E5\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E6\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E7\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E########################################################################\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E900\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVLink\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                              \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                                           \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                         \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                             \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                              \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                                           \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2550\u2550\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENIC\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENIC\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                           \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                                                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003Cspan class=\"w\"\u003E                                                                         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\n\u003Cspan class=\"w\"\u003E                                                                       \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E50\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                                                  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003EIB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERoCE\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003EIB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERoCE\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                                                         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\n\u003Cspan class=\"w\"\u003E                                                        \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u003Cspan class=\"w\"\u003E                                                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                                    \u003C/span\u003E\u2502\n\u003Cspan class=\"w\"\u003E                                                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u003Cspan class=\"nv\"\u003EInfiniBand\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESwitch\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u2502\n\u003Cspan class=\"w\"\u003E                                                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                                    \u003C/span\u003E\u2502\n\u003Cspan class=\"w\"\u003E                                                        \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003Cspan class=\"w\"\u003E                                                                         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\n\u003Cspan class=\"w\"\u003E                                                                       \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E50\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                                                  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003EIB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERoCE\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003EIB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERoCE\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                                                         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502\u003Cspan class=\"w\"\u003E                                                                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                           \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2550\u2550\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENIC\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENIC\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E                  \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                              \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                                           \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                           \u003C/span\u003E\u003Cspan class=\"o\"\u003E======\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                           \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                              \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                                                           \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E########################################################################\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E900\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVLink\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u250c\u2500\u2500\u2534\u2500\u2500\u2500\u2510\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E5\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E6\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E7\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E                              \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVSwitch\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVLink\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EFabric\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                         \u003C/span\u003E\u2502\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2502\n\u2502\u003Cspan class=\"w\"\u003E                                              \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENODE\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EB\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                                      \u003C/span\u003E\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n\u003Cspan class=\"nv\"\u003EBandwidth\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eencoding\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003Eline\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eintensity\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E########\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVLink\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003ENVSwitch\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"mi\"\u003E900\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ebidirectional\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2194\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E,\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Esame\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Enode\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E========\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EPCIe\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGen5\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mi\"\u003E50\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"mi\"\u003E64\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGB\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eunidirectional\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003ECPU\u003C/span\u003E\u2194\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E,\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ECPU\u003C/span\u003E\u2194\u003Cspan class=\"nv\"\u003ENIC\u003C/span\u003E,\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ecross\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Enode\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003EShowing\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eof\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E8\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENICs\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Efor\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eclarity\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u2014\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eeach\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ehas\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ea\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ededicated\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003ENIC\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"a-note-on-bandwidth-numbers\"\u003EA Note on Bandwidth Numbers\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EBandwidth specs vary by hardware generation, cluster configuration, and vendor.\nWe'll use numbers from Meta's published Llama 3 training infrastructure\n(\u003Ca href=\"https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/\" rel=\"noopener noreferrer\" target=\"_blank\"\u003EBuilding Meta's GenAI Infrastructure\u003C/a\u003E):\u003C/span\u003E\n\u003Cblockquote\u003E\n\u003Cspan class=\"paragraph\"\u003E\"Both of these solutions interconnect \u003Cstrong\u003E400 Gbps endpoints\u003C/strong\u003E... we have successfully\nused both RoCE and InfiniBand clusters for large, GenAI workloads (including our\nongoing training of Llama 3 on our RoCE cluster) without any network bottlenecks.\"\u003C/span\u003E\n\u003C/blockquote\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EImportant\u003C/strong\u003E: \"400 Gbps\" in networking is \u003Cstrong\u003Efull-duplex\u003C/strong\u003E - meaning 400 Gbps transmit\nAND 400 Gbps receive simultaneously. For weight sync (unidirectional: trainer \u2192 generator),\nwe get the full 400 Gbps = \u003Cstrong\u003E50 GB/s per NIC\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMeta's Grand Teton nodes have \u003Cstrong\u003E8 RDMA NICs\u003C/strong\u003E (one per GPU, 1:1 mapping), giving\n400 GB/s aggregate unidirectional bandwidth per node. For more details on Grand Teton\nand Monarch's RDMA architecture, see the SIGCOMM 2024 paper:\n\u003Ca href=\"https://cs.stanford.edu/~keithw/sigcomm2024/sigcomm24-final246-acmpaginated.pdf\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ERDMA over Ethernet for Distributed AI Training at Meta Scale\u003C/a\u003E.\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EInterconnect\u003C/th\u003E\n\u003Cth\u003EBandwidth\u003C/th\u003E\n\u003Cth\u003ENotes\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ENVLink 4.0\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E900 GB/s bidirectional\u003C/td\u003E\n\u003Ctd\u003E~450 GB/s per direction\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003ERDMA (IB/RoCE)\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E400 Gbps = 50 GB/s\u003C/td\u003E\n\u003Ctd\u003EPer NIC, full-duplex\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E\u003Cstrong\u003EPCIe Gen5 x16\u003C/strong\u003E\u003C/td\u003E\n\u003Ctd\u003E64 GB/s\u003C/td\u003E\n\u003Ctd\u003EPer direction\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey observations:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003ENVLink is fast but same-node only\u003C/strong\u003E - 450 GB/s, but can't cross the network\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERDMA \u0026gt;\u0026gt; TCP\u003C/strong\u003E - 50 GB/s with zero-copy beats TCP significantly for cross-node\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EMulti-NIC scales\u003C/strong\u003E - 8 NICs \u00d7 50 GB/s = 400 GB/s, approaching NVLink speeds\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ERule of thumb\u003C/strong\u003E: NVLink for same-node ops (gradients, activations).\nRDMA for cross-node communication (weight sync) - it's the only practical option.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b339ab67a809fda89538a7ed9d38ac50", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"2b-back-of-envelope-syncing-large-models\"\u003E2b. Back-of-Envelope: Syncing Large Models\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's do some quick math. DeepSeek V3 has 671B parameters (~1.34 TB in bf16).\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key insight: \u003Cstrong\u003Eyou're not shoving 1.3 TB through a single NIC\u003C/strong\u003E. The weights\nare distributed across many GPUs (via some combination of PP, EP, TP, FSDP),\nand each GPU has its own NIC. You get \u003Cstrong\u003Eaggregate bandwidth\u003C/strong\u003E across all NICs.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe actual sync time depends on \u003Cstrong\u003Eboth sides\u003C/strong\u003E:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003ETrainer's aggregate upload bandwidth\u003C/strong\u003E (sending weights out)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EGenerator's aggregate download bandwidth\u003C/strong\u003E (receiving weights)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThe bottleneck is whichever is smaller. And if multiple generators pull from\nthe same trainer simultaneously, the trainer's bandwidth is divided among them.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWith Grand Teton's 8 NICs per node at 50 GB/s each (400 GB/s per node),\nthe math is simple: \u003Cstrong\u003ETime = Shard Size / Bandwidth\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe per-node shard size depends on how many nodes the model is spread across:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EDeepSeek V3 (1.3 TB) across 8 nodes \u2192 ~160 GB per node\u003C/li\u003E\n\u003Cli\u003EDeepSeek V3 (1.3 TB) across 16 nodes \u2192 ~80 GB per node\u003C/li\u003E\n\u003C/ul\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EPer-node shard\u003C/th\u003E\n\u003Cth\u003ETime to sync\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E~160 GB (8 nodes)\u003C/td\u003E\n\u003Ctd\u003E160 / 400 = \u003Cstrong\u003E0.4 seconds\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E~80 GB (16 nodes)\u003C/td\u003E\n\u003Ctd\u003E80 / 400 = \u003Cstrong\u003E0.2 seconds\u003C/strong\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThe exact per-node shard size depends on your parallelism strategy (PP, EP, TP, etc.),\nbut the math works out: with modern RDMA hardware, you can sync even the largest\nmodels in \u003Cstrong\u003Esub-second time\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ECompare this to naive TCP: kernel copies, socket overhead, no zero-copy...\neasily 10x slower. \u003Cstrong\u003ERDMA is the only way to make async RL practical at scale.\u003C/strong\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "81511d7e65b4d0a2633996f8cded8b04", "console": [], "id": "SFPL", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"3-the-problem-collectives-are-blocking\"\u003E3. The Problem: Collectives Are Blocking\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EMost people use RDMA via \u003Cstrong\u003Ecollectives\u003C/strong\u003E through PyTorch distributed:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Etorch.distributed\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eas\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Edist\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Einit_process_group\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebackend\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;nccl\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eall_reduce\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egradients\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eop\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003EReduceOp\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003ESUM\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Edist\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebroadcast\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Esrc\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"mi\"\u003E0\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis works great for training. But async RL has a different access pattern.\u003C/span\u003E\n\u003Ch3 id=\"high-variance-in-generation-times\"\u003EHigh Variance in Generation Times\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EGenerators have wildly different completion times:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ESome prompts \u2192 10 tokens (fast)\u003C/li\u003E\n\u003Cli\u003EOther prompts \u2192 1000 tokens (slow)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EWith collectives, fast generators wait for slow ones:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EGenerator 0: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\nGenerator 1: \u251c\u2500\u2500\u2500\u2500\u2500\u2500 gen (slow) \u2500\u2500\u2500\u2500\u2500\u2500\u2524\nGenerator 2: \u251c\u2500\u2500 gen (fast) \u2500\u2500\u2524  \u26a0\ufe0f WAITING...\n                                      \u2193\n                          all_gather(weights)  # Everyone waits!\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"the-one-sided-solution-rdma\"\u003EThe One-Sided Solution: RDMA\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EWhat if the sender could write directly to the receiver's memory without coordination?\u003C/span\u003E\n\u003Cdiv class=\"language-teratermmacro codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"nv\"\u003ETwo\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Esided\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"k\"\u003Esend\u003C/span\u003E\u003Cspan class=\"o\"\u003E/\u003C/span\u003E\u003Cspan class=\"nv\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;I have data\u0026quot;\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EReceiver\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;I\u0026#39;m ready\u0026quot;\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Esends\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edata\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003EReceiver\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edata\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Emessages\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Erequired\u003C/span\u003E\n\n\u003Cspan class=\"nv\"\u003EOne\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"nv\"\u003Esided\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E(\u003C/span\u003E\u003Cspan class=\"nv\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"ss\"\u003E)\u003C/span\u003E:\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"nv\"\u003ESender\u003C/span\u003E:\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ewrites\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Edirectly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nv\"\u003Ereceiver\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u0026#39;s memory\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E                         No coordination needed!\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is what RDMA enables: \u003Cstrong\u003Eone-sided memory operations\u003C/strong\u003E.\nThe trainer doesn't even know when generators pull weights - this is truly async!\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ERDMA isn't just \"faster TCP\" \u2014 it bypasses the kernel entirely. No socket buffers,\nno context switches, no serialization. The NIC reads directly from registered memory.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cb76c2f11c389956cc5404a2489a841e", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"4-the-magic-pointer-pattern\"\u003E4. The Magic Pointer Pattern\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EOne natural question that arises is along the lines of, \"How do we actually represent one-sided puts/gets if not with NCCL collectives?\"\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EHere's a key insight: to represent remote data, we only need a \u003Cstrong\u003Etiny handle\u003C/strong\u003E -\nan \u003Ccode\u003E(addr, rkey, size)\u003C/code\u003E tuple that says \"here's where my data lives.\"\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch wraps this in \u003Ccode\u003ERDMABuffer\u003C/code\u003E. Let's see how small it actually is:\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "3d6ad99e96a0aafd076b1cd1ded4f8b9", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-07_10:56_223\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "RDMABuffer handle size vs actual tensor size:\n\nTensor Size  Actual Bytes    Handle Size     Ratio     \n-------------------------------------------------------\n1 KB                1,024 B      435 B               2x\n1 MB            1,048,576 B      440 B           2,383x\n10 MB          10,485,760 B      441 B          23,777x\n\n\u2192 Handle size is O(1) regardless of tensor size!\n", "type": "stream"}], "id": "RGSE", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "53525d9c44fe71fd4f526f646e7d143e", "console": [], "id": "Kclp", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"the-magic-pointer\"\u003EThe Magic Pointer\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is the core pattern: \u003Cstrong\u003Eseparate control plane from data plane\u003C/strong\u003E.\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EControl plane\u003C/strong\u003E (actor messages): Send tiny handle (~100 bytes)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EData plane\u003C/strong\u003E (RDMA): Bulk transfer of actual data (~10 GB)\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EThink of \u003Ccode\u003ERDMABuffer\u003C/code\u003E as a \u003Cstrong\u003Emagic pointer\u003C/strong\u003E - it's a pointer that works across machines:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E                              \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elocal\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecopy\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mh\"\u003E10\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGB\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eempty\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECreate\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eregister\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ememory\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ESend\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"o\"\u003E~\u003C/span\u003E\u003Cspan class=\"mh\"\u003E100\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebytes\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Evia\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eactor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"o\"\u003E~\u003C/span\u003E\u003Cspan class=\"mh\"\u003E10\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGB\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Evia\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehardware\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Einvolvement\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe trainer doesn't even know when generators pull weights. True one-sided.\u003C/span\u003E\n\u003Ch3 id=\"rdmabuffer-in-action\"\u003ERDMABuffer in Action\u003C/h3\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch.rdma\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Trainer side: register weights\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erandn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1024\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Edevice\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;cuda\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Return buffer as part of an endpoint response\u003C/span\u003E\n\u003Cspan class=\"nd\"\u003E@endpoint\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Edef\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nf\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E \u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E \u003Cspan class=\"n\"\u003ERDMABuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n    \u003Cspan class=\"k\"\u003Ereturn\u003C/span\u003E \u003Cspan class=\"bp\"\u003Eself\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Generator side: receive handle, pull directly into GPU\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_weight_handle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E  \u003Cspan class=\"c1\"\u003E# Tiny message\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eview\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Etorch\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Euint8\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eflatten\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehandle\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eread_into\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Egpu_weights\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E                   \u003Cspan class=\"c1\"\u003E# Bulk RDMA transfer\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Push model: caller writes local src_tensor into the remote RDMABuffer\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ewrite_from\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Esrc_tensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPull vs Push\u003C/strong\u003E: \u003Ccode\u003Eread_into\u003C/code\u003E is the \u003Cstrong\u003Epull\u003C/strong\u003E model (generator reads remote data into\nits local buffer), while \u003Ccode\u003Ewrite_from\u003C/code\u003E is the \u003Cstrong\u003Epush\u003C/strong\u003E model (caller writes local data\ninto the remote buffer). Both are one-sided RDMA operations \u2014 the remote side is not\ninvolved. In async RL, pull is more natural because each generator decides \u003Cem\u003Ewhen\u003C/em\u003E it\nneeds fresh weights.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWant to understand how RDMA works under the hood?\u003C/strong\u003E Check out \u003Cstrong\u003E07b_weight_sync_deep_dive.py\u003C/strong\u003E\nfor ibverbs internals, queue pair setup, and why Monarch's actor model is such a natural fit\nfor managing RDMA connections. It's actors all the way down!\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "9b369b191c83a1c907ac9fc47f3166bc", "console": [], "id": "emfo", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"live-demo-trainer-generator-weight-sync\"\u003ELive Demo: Trainer \u2192 Generator Weight Sync\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's see this in action with a simple example. A trainer holds weights,\na generator pulls them via RDMA.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "9c7090020db0a6d3770e0f81a71d9cb5", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "[Receiver] Allocated buffer: 4.2 MB\n[Sender] Created data: 4.2 MB\n\n[Orchestrator] Got handle from sender\n[Orchestrator] Sender checksum: 230.10\n[Orchestrator] Receiver checksum: 230.10\n[Orchestrator] Match: True\n", "type": "stream"}], "id": "Hstk", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "859d7e76f8c1080d35080b6fa774c6be", "console": [], "id": "nWHF", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"5-cpu-staging-pattern\"\u003E5. CPU Staging Pattern\u003C/h2\u003E\n\u003Ch3 id=\"gpu-native-rdma-exists-and-monarch-supports-it\"\u003EGPU-Native RDMA Exists (and Monarch Supports It)\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EGPU-native RDMA (GPUDirect) is real and works well - the NIC reads directly from GPU\nmemory with no CPU copy. Monarch supports this at the Rust level. For synchronous\nbulk transfers, it's excellent.\u003C/span\u003E\n\u003Ch3 id=\"cpu-staging-a-deliberate-architectural-choice\"\u003ECPU Staging: A Deliberate Architectural Choice\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EFor async RL, CPU staging isn't a workaround for missing GPUDirect - it's the\n\u003Cstrong\u003Epreferred production pattern\u003C/strong\u003E. The reason is \u003Cstrong\u003Etemporal decoupling\u003C/strong\u003E: trainers\nand generators operate on completely independent timelines, and we need a buffer\nbetween them.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe issue isn't bandwidth - it's \u003Cstrong\u003Etiming\u003C/strong\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EDirect GPU\u2192GPU RDMA:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Generator GPU is mid-inference                       \u2502\n\u2502 \u251c\u2500\u2500 layer 1 \u2500\u2500\u2524 [RDMA arrives, needs sync!]          \u2502\n\u2502               \u2193                                      \u2502\n\u2502         cudaDeviceSynchronize()  \u2190 Blocks inference! \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EWith CPU staging, nothing on the critical path blocks:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eregistered\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003ESits\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehere\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eready\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eanytime\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egrabs\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eready\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe CPU buffer is a \u003Cstrong\u003Etemporal decoupling point\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ENote: the CPU staging path does involve GPU\u2194CPU copies on each end. When we say\nRDMA is \"zero-copy,\" we mean across the network \u2014 the NIC reads/writes directly\nfrom/to registered CPU memory with no kernel involvement.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "b73698a1a338c37b7ceff5b2720da81e", "console": [], "id": "iLit", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"6-circular-weight-buffers\"\u003E6. Circular Weight Buffers\u003C/h2\u003E\n\u003Ch3 id=\"one-sided-isnt-free\"\u003EOne-Sided Isn't Free\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EOne-sided RDMA is powerful - trainers and generators can operate independently without\nexplicit send/recv coordination. But \"no coordination\" isn't quite right. There's still\na fundamental race condition lurking: \u003Cstrong\u003Ewhat if the trainer overwrites a buffer while a\ngenerator is reading from it?\u003C/strong\u003E\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EWith a single buffer, this is a real problem:\u003C/span\u003E\n\u003Cdiv class=\"language-actionscript3 codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewrite\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"o\"\u003E...\u003C/span\u003E\u003Cspan class=\"n\"\u003Ev2\u003C/span\u003E\u003Cspan class=\"o\"\u003E...\u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2190\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecorrupted\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereading\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2500\u2500\u2500\u2500\u25ba\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egets\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Emix\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eof\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eand\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EWe need \u003Cem\u003Esome\u003C/em\u003E form of coordination. The question is: do we go back to message-passing\n(explicit locks, barriers, acknowledgments) and lose the async benefits? Or can we get\ncoordination from the \u003Cstrong\u003Estructure itself\u003C/strong\u003E?\u003C/span\u003E\n\u003Ch3 id=\"solution-circular-buffer-as-structural-coordination\"\u003ESolution: Circular Buffer as Structural Coordination\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key insight: GPU memory is scarce, but \u003Cstrong\u003ECPU memory is abundant\u003C/strong\u003E. We can afford to\nkeep multiple versions of the weights in CPU staging buffers. By writing to slots in a\ncircular pattern, the trainer never overwrites a slot that a generator might still be\nreading - as long as we have enough slots to cover the timing gap.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is \u003Cstrong\u003Estructural coordination\u003C/strong\u003E: the circular buffer's design eliminates the race\ncondition without any explicit synchronization messages between trainer and generator.\u003C/span\u003E\n\u003Cdiv class=\"language-tsql codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003ETrainer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Ewrites\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E     \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev0\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev1\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev2\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E...\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2193\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EBuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Eslots\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot0\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot1\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot2\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecircular\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereused\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003EGenerator\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Ereads\u003C/span\u003E\u003Cspan class=\"err\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"ss\"\u003E\u0026quot;Give me latest\u0026quot;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EBenefits:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003ENo message-based coordination\u003C/strong\u003E - structure prevents races, not locks\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EPre-registered RDMA buffers\u003C/strong\u003E - no memory registration on hot path\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ELock-free reads\u003C/strong\u003E - generators always get a consistent snapshot\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EBounded memory\u003C/strong\u003E - only N versions in flight\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EMemory cost is real\u003C/strong\u003E: for a 70B model (140 GB in bf16), 5 slots = 700 GB of CPU RAM.\nThis is feasible on HPC nodes (Grand Teton has ~1.5 TB RAM per node), but \u003Ccode\u003En_slots\u003C/code\u003E is\nbounded by available CPU memory, not just timing.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe key design constraint: register all slots at init time, then just write to them.\nNo allocation, no registration on the critical path. Tune \u003Ccode\u003En_slots\u003C/code\u003E so that the trainer\ncan't lap the slowest generator \u2014 if it does, the generator reads a corrupted mix of\ntwo versions (not a graceful error, just silent data corruption).\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "2972a45cdad599233d8b7a937c1ca25a", "console": [], "id": "ZHCJ", "outputs": [{"data": {"text/html": "\u003Cdiv style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'\u003E\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ETry it\u003C/strong\u003E: adjust slots and write speed to see when lapping causes a race condition.\u003C/span\u003E\u003C/span\u003E\u003Cdiv style='display: flex;flex: 1;flex-direction: row;justify-content: center;align-items: normal;flex-wrap: nowrap;gap: 1rem'\u003E\u003Cmarimo-ui-element object-id='ZHCJ-0' random-id='949fef9f-2411-b1ee-4fab-3575a225d63c'\u003E\u003Cmarimo-slider data-initial-value='3' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Buffer slots (n_slots)\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='1' data-stop='8' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003Cmarimo-ui-element object-id='ZHCJ-1' random-id='2f5f74ca-2d13-1f55-524a-f3ae251dafe0'\u003E\u003Cmarimo-slider data-initial-value='2' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Trainer writes per generator sync\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='1' data-stop='10' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003C/div\u003E\u003C/div\u003E"}, "type": "data"}]}, {"code_hash": "255121e1cced3e3d5bbaafd0e4c7af5b", "console": [], "id": "ROlb", "outputs": [{"data": {"text/html": "\u003Cdiv style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'\u003E\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"300\" height=\"130\" style=\"font-family: -apple-system, sans-serif;\"\u003E\n\u003Ctext x=\"150.0\" y=\"18\" text-anchor=\"middle\" font-size=\"12\" fill=\"#666\"\u003ETrainer writes 2 versions while generator reads from slot 0\u003C/text\u003E\n\u003Crect x=\"30\" y=\"50\" width=\"64\" height=\"48\" rx=\"5\" fill=\"#dbeafe\" stroke=\"#2563eb\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"62.0\" y=\"74.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-size=\"13\" font-weight=\"bold\" fill=\"#2563eb\"\u003Eslot 0\u003C/text\u003E\n\u003Ctext x=\"62.0\" y=\"114\" text-anchor=\"middle\" font-size=\"10\" font-weight=\"normal\" fill=\"#2563eb\"\u003E\u25b2 gen reading\u003C/text\u003E\n\u003Crect x=\"100\" y=\"50\" width=\"64\" height=\"48\" rx=\"5\" fill=\"#dcfce7\" stroke=\"#16a34a\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"132.0\" y=\"74.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-size=\"13\" font-weight=\"bold\" fill=\"#16a34a\"\u003Eslot 1\u003C/text\u003E\n\u003Ctext x=\"132.0\" y=\"42\" text-anchor=\"middle\" font-size=\"10\" fill=\"#16a34a\"\u003Ewrite #1\u003C/text\u003E\n\u003Crect x=\"170\" y=\"50\" width=\"64\" height=\"48\" rx=\"5\" fill=\"#dcfce7\" stroke=\"#16a34a\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"202.0\" y=\"74.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-size=\"13\" font-weight=\"bold\" fill=\"#16a34a\"\u003Eslot 2\u003C/text\u003E\n\u003Ctext x=\"202.0\" y=\"42\" text-anchor=\"middle\" font-size=\"10\" fill=\"#16a34a\"\u003Ewrite #2\u003C/text\u003E\n\u003C/svg\u003E\u003Cmarimo-callout-output data-html='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;\u0026lt;strong\u0026gt;Safe\u0026lt;/strong\u0026gt; \u2014 3 slots, 2 trainer writes between generator reads. Generator finishes reading slot 0 before trainer wraps around to overwrite it.\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-kind='\u0026quot;success\u0026quot;'\u003E\u003C/marimo-callout-output\u003E\u003C/div\u003E"}, "type": "data"}]}, {"code_hash": "5e6c22ad44dd0f96e888bca6469b57d2", "console": [], "id": "qnkX", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"7-weight-re-sharding\"\u003E7. Weight Re-sharding\u003C/h2\u003E\n\u003Ch3 id=\"the-sharding-mismatch-problem\"\u003EThe Sharding Mismatch Problem\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETrainer and Generator often have \u003Cstrong\u003Edifferent tensor layouts\u003C/strong\u003E. Consider an example:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ERole\u003C/th\u003E\n\u003Cth\u003EParallelism\u003C/th\u003E\n\u003Cth\u003ESharding\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ETrainer\u003C/td\u003E\n\u003Ctd\u003EFSDP (8 GPUs)\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003EShard(0)\u003C/code\u003E - rows split across 8 GPUs\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGenerator\u003C/td\u003E\n\u003Ctd\u003ETP (2 GPUs)\u003C/td\u003E\n\u003Ctd\u003E\u003Ccode\u003EShard(1)\u003C/code\u003E - columns split across 2 GPUs\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003ETherefore we cannot always directly transfer weights - we need \u003Cstrong\u003Ere-sharding\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EConsider a simple example where the trainer may be row-sharded and the generator may be column-sharded:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003ETrainer (row-sharded):          Generator (column-sharded):\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 GPU 0: rows 0-127\u2502            \u2502 GPU 0   \u2502 GPU 1   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524     \u2192      \u2502 cols    \u2502 cols    \u2502\n\u2502 GPU 1: rows 128+ \u2502            \u2502 0-511   \u2502 512+    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"two-approaches\"\u003ETwo Approaches\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EGather Then Slice\u003C/strong\u003E (simple but wasteful):\nOne approach is to materialize the entire tensor, i.e. \u003Ccode\u003Egather\u003C/code\u003E, transfer the full tensor, and then slice on the receiver side:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EEach receiver gathers ALL sender shards \u2192 full tensor\u003C/li\u003E\n\u003Cli\u003EEach receiver slices out its portion\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EProblem\u003C/strong\u003E: 2x redundant data transfer\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ERouted Transfer\u003C/strong\u003E (optimal):\nA more efficient approach is to only transfer the data that needs to be transferred:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EPre-compute which sender chunks overlap with which receiver regions\u003C/li\u003E\n\u003Cli\u003ESend only the exact chunks needed\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EBenefit\u003C/strong\u003E: Minimal bandwidth, no redundancy\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cdiv class=\"language-actionscript3 codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003EGATHER\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ediscards\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET2\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET3\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E50\u003C/span\u003E\u003Cspan class=\"o\"\u003E%\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewaste\u003C/span\u003E\u003Cspan class=\"o\"\u003E!)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003EROUTED\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EG0\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ereceives\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ET0\u003C/span\u003E\u003Cspan class=\"o\"\u003E,\u003C/span\u003E\u003Cspan class=\"n\"\u003ET1\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eonly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eexactly\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewhat\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eit\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeds\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe routed approach batches all needed transfers into one plan.\nPre-compute the plan once at handshake, execute it on each sync.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "58e99d9b510522e6757f98c52f2fa447", "console": [], "id": "TqIu", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "56d96d299c91b1332dd5472987f17216", "console": [], "id": "Vxnm", "outputs": [{"data": {"text/html": "\u003Cdiv style='display: flex;flex: 1;flex-direction: row;justify-content: center;align-items: normal;flex-wrap: nowrap;gap: 1rem'\u003E\u003Cmarimo-ui-element object-id='Vxnm-0' random-id='998844e0-07c8-30f0-e96f-c3ba66e07da2'\u003E\u003Cmarimo-slider data-initial-value='4' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Trainer GPUs\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='1' data-stop='8' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003Cmarimo-ui-element object-id='Vxnm-2' random-id='5abc0a28-85af-7149-440a-7d9db5eff784'\u003E\u003Cmarimo-dropdown data-initial-value='[\u0026quot;Row (dim 0)\u0026quot;]' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Trainer shard dim\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-options='[\u0026quot;Row (dim 0)\u0026quot;,\u0026quot;Col (dim 1)\u0026quot;]' data-allow-select-none='false' data-searchable='false' data-full-width='false'\u003E\u003C/marimo-dropdown\u003E\u003C/marimo-ui-element\u003E\u003Cmarimo-ui-element object-id='Vxnm-1' random-id='ee92437c-773c-b422-0629-52bba7f79169'\u003E\u003Cmarimo-slider data-initial-value='2' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Generator GPUs\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-start='1' data-stop='8' data-steps='[]' data-debounce='false' data-disabled='false' data-orientation='\u0026quot;horizontal\u0026quot;' data-show-value='false' data-include-input='false' data-full-width='false'\u003E\u003C/marimo-slider\u003E\u003C/marimo-ui-element\u003E\u003Cmarimo-ui-element object-id='Vxnm-3' random-id='5b773eef-b0ae-6bde-f76e-2ca5dc623164'\u003E\u003Cmarimo-dropdown data-initial-value='[\u0026quot;Col (dim 1)\u0026quot;]' data-label='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;Generator shard dim\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-options='[\u0026quot;Row (dim 0)\u0026quot;,\u0026quot;Col (dim 1)\u0026quot;]' data-allow-select-none='false' data-searchable='false' data-full-width='false'\u003E\u003C/marimo-dropdown\u003E\u003C/marimo-ui-element\u003E\u003C/div\u003E"}, "type": "data"}]}, {"code_hash": "d6af84c7c6399d896fa3a07a45a32d48", "console": [], "id": "DnEU", "outputs": [{"data": {"text/html": "\u003Cdiv style='display: flex;flex: 1;flex-direction: column;justify-content: flex-start;align-items: normal;flex-wrap: nowrap;gap: 0.5rem'\u003E\u003Cdiv style=\"display: flex; flex-direction: column; align-items: center;\"\u003E\u003Csvg xmlns=\"http://www.w3.org/2000/svg\" width=\"880\" height=\"340\" viewBox=\"0 0 880 340\" style=\"font-family: -apple-system, sans-serif; font-size: 12px;\"\u003E\n\u003Ctext x=\"220\" y=\"22\" text-anchor=\"middle\" font-weight=\"bold\" font-size=\"15\"\u003ETrainer shards\u003C/text\u003E\n\u003Ctext x=\"660\" y=\"22\" text-anchor=\"middle\" font-weight=\"bold\" font-size=\"15\"\u003EGenerator shards\u003C/text\u003E\n\u003Ctext x=\"220\" y=\"38\" text-anchor=\"middle\" font-size=\"11\" fill=\"#666\"\u003E4 GPUs, row-sharded\u003C/text\u003E\n\u003Ctext x=\"660\" y=\"38\" text-anchor=\"middle\" font-size=\"11\" fill=\"#666\"\u003E2 GPUs, col-sharded\u003C/text\u003E\n\u003Crect x=\"80.0\" y=\"50.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(10, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(10, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"520.0\" y=\"50.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(10, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(10, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"220.0\" y=\"50.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(55, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(55, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"660.0\" y=\"50.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(55, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(55, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"80.0\" y=\"110.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(100, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(100, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"520.0\" y=\"110.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(100, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(100, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"220.0\" y=\"110.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(145, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(145, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"660.0\" y=\"110.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(145, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(145, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"80.0\" y=\"170.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(190, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(190, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"520.0\" y=\"170.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(190, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(190, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"220.0\" y=\"170.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(235, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(235, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"660.0\" y=\"170.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(235, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(235, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"80.0\" y=\"230.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(280, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(280, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"520.0\" y=\"230.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(280, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(280, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"220.0\" y=\"230.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(325, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(325, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"660.0\" y=\"230.0\" width=\"140.0\" height=\"60.0\" fill=\"hsl(325, 70%, 55%)\" fill-opacity=\"0.55\" stroke=\"hsl(325, 70%, 55%)\" stroke-width=\"0.5\"/\u003E\n\u003Crect x=\"80.0\" y=\"50.0\" width=\"280.0\" height=\"60.0\" fill=\"none\" stroke=\"#444\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"220.0\" y=\"80.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" fill=\"#222\"\u003ET0\u003C/text\u003E\n\u003Crect x=\"80.0\" y=\"110.0\" width=\"280.0\" height=\"60.0\" fill=\"none\" stroke=\"#444\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"220.0\" y=\"140.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" fill=\"#222\"\u003ET1\u003C/text\u003E\n\u003Crect x=\"80.0\" y=\"170.0\" width=\"280.0\" height=\"60.0\" fill=\"none\" stroke=\"#444\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"220.0\" y=\"200.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" fill=\"#222\"\u003ET2\u003C/text\u003E\n\u003Crect x=\"80.0\" y=\"230.0\" width=\"280.0\" height=\"60.0\" fill=\"none\" stroke=\"#444\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"220.0\" y=\"260.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" fill=\"#222\"\u003ET3\u003C/text\u003E\n\u003Crect x=\"520.0\" y=\"50.0\" width=\"140.0\" height=\"240.0\" fill=\"none\" stroke=\"#444\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"590.0\" y=\"170.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" fill=\"#222\"\u003EG0\u003C/text\u003E\n\u003Crect x=\"660.0\" y=\"50.0\" width=\"140.0\" height=\"240.0\" fill=\"none\" stroke=\"#444\" stroke-width=\"2\"/\u003E\n\u003Ctext x=\"730.0\" y=\"170.0\" text-anchor=\"middle\" dominant-baseline=\"central\" font-weight=\"bold\" font-size=\"13\" fill=\"#222\"\u003EG1\u003C/text\u003E\n\u003Crect x=\"80\" y=\"50\" width=\"280\" height=\"240\" fill=\"none\" stroke=\"#222\" stroke-width=\"2.5\"/\u003E\n\u003Crect x=\"520\" y=\"50\" width=\"280\" height=\"240\" fill=\"none\" stroke=\"#222\" stroke-width=\"2.5\"/\u003E\n\u003Ctext x=\"440\" y=\"170\" text-anchor=\"middle\" dominant-baseline=\"central\" font-size=\"28\" fill=\"#888\"\u003E=\u003C/text\u003E\n\u003Ctext x=\"440\" y=\"192\" text-anchor=\"middle\" font-size=\"10\" fill=\"#888\"\u003Esame data\u003C/text\u003E\n\u003Ctext x=\"440\" y=\"332\" text-anchor=\"middle\" font-size=\"11\" fill=\"#888\"\u003EGlobal tensor: 512 x 512\u003C/text\u003E\n\u003C/svg\u003E\u003Cdiv style=\"margin-top: 4px; font-size: 12px; color: #666;\"\u003EMatching colors = same data chunk. Matrix shows chunk shapes transferred.\u003C/div\u003E\u003Ctable style=\"border-collapse: collapse; margin-top: 12px; font-family: monospace; font-size: 12px;\"\u003E\n\u003Ctr\u003E\u003Cth style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5;\"\u003E\u003C/th\u003E\n\u003Cth style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5;\"\u003EG0\u003C/th\u003E\n\u003Cth style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5;\"\u003EG1\u003C/th\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5; font-weight: bold;\"\u003ET0\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(10, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(55, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5; font-weight: bold;\"\u003ET1\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(100, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(145, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5; font-weight: bold;\"\u003ET2\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(190, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(235, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: #f5f5f5; font-weight: bold;\"\u003ET3\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(280, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003Ctd style=\"border: 1px solid #ccc; padding: 6px 10px; background: hsl(325, 70%, 55%); color: white; text-align: center; font-weight: bold; text-shadow: 0 1px 2px rgba(0,0,0,0.4);\"\u003E128x256\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/table\u003E\u003C/div\u003E\u003Cmarimo-callout-output data-html='\u0026quot;\u0026lt;span class=\u0026#92;\u0026quot;markdown prose dark:prose-invert contents\u0026#92;\u0026quot;\u0026gt;\u0026lt;span class=\u0026#92;\u0026quot;paragraph\u0026#92;\u0026quot;\u0026gt;\u0026lt;strong\u0026gt;Transfer Plan Stats\u0026lt;/strong\u0026gt; | \u0026lt;strong\u0026gt;Transfers\u0026lt;/strong\u0026gt;: 8 chunks | \u0026lt;strong\u0026gt;Routed\u0026lt;/strong\u0026gt;: 512.0 KB | \u0026lt;strong\u0026gt;Gather\u0026lt;/strong\u0026gt;: 1024.0 KB | \u0026lt;strong\u0026gt;Saved\u0026lt;/strong\u0026gt;: 50%\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\u0026quot;' data-kind='\u0026quot;info\u0026quot;'\u003E\u003C/marimo-callout-output\u003E\u003C/div\u003E"}, "type": "data"}]}, {"code_hash": "2264a8f1068ea8a261a9b035995c277e", "console": [], "id": "ulZA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"8-putting-it-all-together\"\u003E8. Putting It All Together\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe full async RL weight sync pattern:\u003C/span\u003E\n\u003Cdiv class=\"language-verilog codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"n\"\u003ETRAINER\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ETrain\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estep\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecompletes\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECopy\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eweights\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Estaging\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Enon\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eblocking\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ED2H\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EPublish\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ecircular\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ewith\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etag\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"mf\"\u003E4.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EContinue\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Etraining\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eno\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eblocking\u003C/span\u003E\u003Cspan class=\"o\"\u003E!\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E                            \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E              \u003C/span\u003E\u003Cspan class=\"n\"\u003ECIRCULAR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EBUFFER\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003ECPU\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eregistered\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E             \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E0\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev3\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E1\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev4\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"p\"\u003E[\u003C/span\u003E\u003Cspan class=\"n\"\u003Eslot\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E2\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ev5\u003C/span\u003E\u003Cspan class=\"p\"\u003E]\u003C/span\u003E\u003Cspan class=\"w\"\u003E                         \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2191\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E                        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E                                \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E          \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\u003Cspan class=\"w\"\u003E                     \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u25bc\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E0\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E1\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"n\"\u003EGENERATOR\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mh\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E                 \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EAfter\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Egen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nl\"\u003Edone:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E1.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGet\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elatest\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eversion\u003C/span\u003E\u003Cspan class=\"w\"\u003E      \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E2.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERDMA\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eread\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2192\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EGPU\u003C/span\u003E\u003Cspan class=\"w\"\u003E        \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mf\"\u003E3.\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003ERe\u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u003C/span\u003E\u003Cspan class=\"n\"\u003Eshard\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\u003Cspan class=\"w\"\u003E    \u003C/span\u003E\u003Cspan class=\"n\"\u003Eneeded\u003C/span\u003E\u003Cspan class=\"w\"\u003E       \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2502\u003C/span\u003E\n\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\u003Cspan class=\"w\"\u003E   \u003C/span\u003E\u003Cspan class=\"err\"\u003E\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey properties:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ETrainer never blocks waiting for generators\u003C/li\u003E\n\u003Cli\u003EGenerators pull directly to GPU when \u003Cem\u003Ethey're\u003C/em\u003E ready\u003C/li\u003E\n\u003Cli\u003ERe-sharding happens locally on each generator\u003C/li\u003E\n\u003Cli\u003ECircular buffer bounds memory, reuses RDMA registrations\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "d33fa245d02abe2e113666d5a6fda2e1", "console": [], "id": "ecfG", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch3 id=\"live-demo-async-weight-sync\"\u003ELive Demo: Async Weight Sync\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's see this in action! We'll simulate the core async RL pattern:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003E1 Trainer\u003C/strong\u003E: Runs training steps, publishes new weights to a 3-slot circular buffer\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003E4 Generators\u003C/strong\u003E: Each independently syncs to latest weights, then generates\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EAll 5 actors run \u003Cstrong\u003Econcurrently and independently\u003C/strong\u003E. The trainer never waits for generators,\nand each generator grabs weights whenever it's ready (at slightly different rates to show\nthe async behavior). To verify correctness, we set weights to \u003Ccode\u003Eversion\u003C/code\u003E and check on read.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ERace condition safety\u003C/strong\u003E: The circular buffer's slot count is tuned so that\n\u003Ccode\u003Ebuffer_size \u00d7 update_interval \u0026gt;\u0026gt; sync_time\u003C/code\u003E. This ensures a slot isn't overwritten\nwhile a generator is reading it. In this demo: 5 slots, ~1s between trainer updates,\nRDMA sync takes ~ms, so a race is effectively impossible. In production, tune\n\u003Ccode\u003Ebuffer_size\u003C/code\u003E based on actual sync time and update frequency.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "23723f3e7ec84ee775b019276dac3168", "console": [{"mimetype": "text/plain", "name": "stdout", "text": "\n--- Running async RL simulation ---\n\n[Gen 3] Initialized\n[Gen 0] Initialized\n[Gen 2] Initialized\n[Gen 1] Initialized\n[Trainer] Initialized 5-slot circular buffer\n[Trainer] Published v0\n[Trainer] Published v1\n[Trainer] Published v2\n[Trainer] Published v3\n[Gen 2] Synced to v0\n[Gen 3] Synced to v0\n[Trainer] Published v4\n[Gen 1] Synced to v0\n[Gen 0] Synced to v0\n[Gen 2] Generated (v0)\n[Gen 2] Synced to v4\n[Gen 3] Generated (v0)\n[Gen 3] Synced to v4\n[Gen 1] Generated (v0)\n[Gen 1] Synced to v4\n[Gen 0] Generated (v0)\n[Gen 0] Synced to v4\n[Gen 2] Generated (v4)\n[Gen 3] Generated (v4)\n[Gen 1] Generated (v4)\n[Gen 0] Generated (v4)\n[Gen 2] Generated (v4)\n[Gen 3] Generated (v4)\n[Gen 1] Generated (v4)\n[Gen 0] Generated (v4)\n[Gen 2] Generated (v4)\n[Gen 3] Generated (v4)\n[Trainer] Published v5\n[Gen 1] Generated (v4)\n[Gen 1] Synced to v5\n[Gen 0] Generated (v4)\n[Gen 0] Synced to v5\n[Gen 2] Generated (v4)\n[Gen 3] Generated (v4)\n[Gen 1] Generated (v5)\n[Gen 0] Generated (v5)\n\n--- Done! Trainer published 6 versions ---\nGenerators ended on versions: [5, 5, 4, 4]\nAll pulled independently via RDMA, weights verified!\n", "type": "stream"}], "id": "Pvdt", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "073a87de27a68088af5e59280149bddb", "console": [], "id": "ZBYS", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"9-going-further-torchstore\"\u003E9. Going Further: TorchStore\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EAll the patterns we've covered - RDMA memory registration, magic pointers, circular buffers,\npre-computed transfer plans - are building blocks. If you need a \u003Cstrong\u003Eproduction-ready solution\u003C/strong\u003E,\ncheck out \u003Ca href=\"https://github.com/meta-pytorch/torchstore\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ETorchStore\u003C/a\u003E.\u003C/span\u003E\n\u003Ch3 id=\"what-is-torchstore\"\u003EWhat is TorchStore?\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003ETorchStore is a \u003Cstrong\u003Edistributed, asynchronous key-value store for PyTorch tensors\u003C/strong\u003E built on\nMonarch's actor framework. It abstracts away the RDMA complexity while giving you:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Etorchstore\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003ETorchStore\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Store tensors with async API\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eput\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;model/layer1/weights\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Etensor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Retrieve with optional in-place and slice semantics\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;model/layer1/weights\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Einplace_tensor\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Ebuffer\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Native PyTorch checkpoint support\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eput_state_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Emodel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Estate_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Eloaded\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"k\"\u003Eawait\u003C/span\u003E \u003Cspan class=\"n\"\u003Ets\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget_state_dict\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Ch3 id=\"when-to-use-what\"\u003EWhen to Use What\u003C/h3\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EScenario\u003C/th\u003E\n\u003Cth\u003ESolution\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ELearning RDMA patterns\u003C/td\u003E\n\u003Ctd\u003EThis notebook + 06b\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ECustom RL weight sync\u003C/td\u003E\n\u003Ctd\u003ESee 06b for \u003Ccode\u003ERDMABuffer\u003C/code\u003E + \u003Ccode\u003ERDMAAction\u003C/code\u003E patterns\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGeneral tensor storage\u003C/td\u003E\n\u003Ctd\u003EUse TorchStore\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ECheckpointing\u003C/td\u003E\n\u003Ctd\u003EUse TorchStore's \u003Ccode\u003Eput_state_dict\u003C/code\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "c5d90beee85a8c570d106a19a7d9a1d6", "console": [], "id": "aLJB", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"summary\"\u003ESummary\u003C/h2\u003E\n\u003Ch3 id=\"key-takeaways\"\u003EKey Takeaways\u003C/h3\u003E\n\u003Col\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EBandwidth hierarchy matters\u003C/strong\u003E: NVLink (900 GB/s) \u0026gt;\u0026gt; InfiniBand (50 GB/s)\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EKeep frequent operations on NVLink, use RDMA for cross-node\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ECollectives block, RL needs async\u003C/strong\u003E: High variance in generation times makes\n   synchronous operations expensive\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EMagic pointer pattern\u003C/strong\u003E: Tiny handle over control plane, bulk data over data plane\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E~100 bytes to describe 10 GB transfer\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECPU staging\u003C/strong\u003E: Temporal decoupling for async RL\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ENothing blocks on the critical path\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ECircular buffers\u003C/strong\u003E: Version weights without memory churn\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EPre-register RDMA buffers, reuse slots\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003Cli\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWeight re-sharding\u003C/strong\u003E: Different layouts need overlap computation\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003ERouted approach avoids redundant transfers\u003C/li\u003E\n\u003C/ul\u003E\n\u003C/li\u003E\n\u003C/ol\u003E\n\u003Ch3 id=\"want-more\"\u003EWant More?\u003C/h3\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003E07b_weight_sync_deep_dive.py\u003C/strong\u003E - ibverbs internals, RDMA buffer patterns\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003E08_rl_e2e.py\u003C/strong\u003E - Complete async RL system using these patterns\u003C/li\u003E\n\u003C/ul\u003E\n\u003Chr /\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EPrevious:\u003C/strong\u003E \u003Ca href=\"./06_services.html\"\u003ENB06 \u2014 Services\u003C/a\u003E \u00b7 \u003Cstrong\u003ENext:\u003C/strong\u003E \u003Ca href=\"./07b_weight_sync_deep_dive.html\"\u003ENB07b \u2014 RDMA Deep Dive\u003C/a\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.9"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.19.9%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20%23%20Shared%20imports%20for%20the%20notebook%0A%20%20%20%20import%20time%0A%20%20%20%20import%20torch%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20this_host%2C%20current_rank%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%2C%20is_rdma_available%0A%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20Actor%2C%0A%20%20%20%20%20%20%20%20RDMABuffer%2C%0A%20%20%20%20%20%20%20%20current_rank%2C%0A%20%20%20%20%20%20%20%20endpoint%2C%0A%20%20%20%20%20%20%20%20is_rdma_available%2C%0A%20%20%20%20%20%20%20%20this_host%2C%0A%20%20%20%20%20%20%20%20torch%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20RDMA%20%26%20Weight%20Synchronization%0A%0A%20%20%20%20You've%20built%20your%20async%20RL%20system.%20Generators%20are%20humming%2C%20the%20trainer%20is%0A%20%20%20%20learning.%20Then%20you%20check%20GPU%20utilization%20and%20discover%20that%20most%20of%20your%0A%20%20%20%20%22training%22%20time%20is%20spent%20copying%20weights.%20Your%20async%20system%20has%20become%20a%0A%20%20%20%20weight-syncing%20system%20that%20occasionally%20does%20RL.%0A%0A%20%20%20%20This%20notebook%20is%20about%20making%20that%20problem%20disappear%20%E2%80%94%20using%20RDMA%20to%20move%0A%20%20%20%20weights%20from%20trainer%20to%20generators%20so%20fast%20it%20becomes%20invisible.%0A%0A%20%20%20%20**Want%20to%20go%20deeper%3F**%20Check%20out%20**07b_weight_sync_deep_dive.py**%20for%20ibverbs%20internals%0A%20%20%20%20and%20RDMA%20buffer%20patterns.%20This%20notebook%20focuses%20on%0A%20%20%20%20the%20concepts%20and%20patterns%20you%20need%20to%20know%20for%20async%20RL.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Prerequisites%0A%0A%20%20%20%20This%20notebook%20assumes%20familiarity%20with%3A%0A%0A%20%20%20%20-%20**PyTorch%20basics**%20-%20tensors%2C%20dtypes%2C%20device%20placement%0A%20%20%20%20-%20**On-policy%20vs%20off-policy%20RL**%20-%20covered%20in%20%5BNB05%3A%20RL%20Intro%5D(.%2F05_rl_intro.html)%0A%20%20%20%20-%20**Monarch%20Actor%20model**%20-%20spawning%20actors%2C%20endpoints%2C%20%60call_one%60%2F%60call%60%20(from%20%5BNB01%5D(.%2F01_history_and_vision.py)%20and%20%5BNB02%5D(.%2F02_interactive_devx.py))%0A%20%20%20%20-%20**Basic%20networking%20concepts**%20-%20what%20bandwidth%20and%20latency%20mean%2C%20client-server%20vs%20peer-to-peer%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%201.%20Why%20Weight%20Sync%20Matters%0A%0A%20%20%20%20%23%23%23%20The%20On-Policy%20Problem%0A%0A%20%20%20%20Traditional%20RL%20algorithms%20want%20to%20be%20**on-policy**%3A%20generate%20experience%20using%20the%20current%0A%20%20%20%20policy%2C%20then%20immediately%20use%20that%20experience%20to%20update%20the%20policy.%20This%20creates%20a%20tight%20loop%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20On-Policy%20RL%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20generate(policy_v1)%20%E2%86%92%20train(samples)%20%E2%86%92%20policy_v2%20%E2%86%92%20repeat%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Experience%20from%20v1%20is%20only%20valid%20for%20updating%20v1%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Async%20RL%20breaks%20this%20rule.**%20Generators%20run%20continuously%20while%20the%20trainer%20updates%20weights.%0A%20%20%20%20By%20the%20time%20a%20sample%20reaches%20the%20trainer%2C%20it%20was%20generated%20by%20an%20old%20policy%20version%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Async%20RL%20(off-policy)%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20Generator%3A%20policy_v1%20%E2%86%92%20sample%E2%82%81%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Trainer%3A%20%20%20train(sample%E2%82%81)%20%E2%86%92%20policy_v2%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Generator%3A%20policy_v1%20%E2%86%92%20sample%E2%82%82%20%20%E2%86%90%20still%20using%20v1!%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Trainer%3A%20%20%20train(sample%E2%82%82)%20%E2%86%92%20policy_v3%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20Samples%20are%20%22stale%22%20-%20generated%20by%20older%20policy%20versions%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20**off-policy-ness**%20can%20work%20up%20to%20a%20degree%2C%20but%20must%20be%20limited.%20The%20generators%0A%20%20%20%20need%20fresh%20weights%20regularly%20to%20stay%20%22close%20enough%22%20to%20on-policy.%20Weight%20sync%20frequency%0A%20%20%20%20becomes%20a%20key%20hyperparameter%20trading%20off%3A%0A%0A%20%20%20%20-%20**Too%20slow**%3A%20Samples%20become%20too%20stale%2C%20training%20diverges%0A%20%20%20%20-%20**Too%20fast**%3A%20Weight%20sync%20overhead%20dominates%2C%20negating%20async%20benefits%0A%0A%20%20%20%20%23%23%23%20The%20Scale%20Problem%0A%0A%20%20%20%20For%20LLM-based%20RL%2C%20the%20weights%20are%20**massive**.%20Back-of-envelope%20math%0A%20%20%20%20(1%20parameter%20%E2%89%88%202%20bytes%20in%20bf16)%3A%0A%0A%20%20%20%20%7C%20Model%20%7C%20Weight%20Size%20%7C%0A%20%20%20%20%7C-------%7C-------------%7C%0A%20%20%20%20%7C%20Llama%203.1%2070B%20%7C%20~140%20GB%20%7C%0A%20%20%20%20%7C%20Llama%203.1%20405B%20%7C%20~810%20GB%20%7C%0A%20%20%20%20%7C%20DeepSeek%20V3%20671B%20%7C%20~1.3%20TB%20%7C%0A%0A%20%20%20%20These%20weights%20need%20to%20move%20from%20trainer%20%E2%86%92%20generators%20regularly.%20If%20we're%0A%20%20%20%20not%20careful%2C%20our%20%22async%20RL%20training%20workload%22%20just%20becomes%20a%20weight%20syncing%0A%20%20%20%20workload.%20Let's%20look%20at%20the%20bandwidth%20hierarchy%20to%20understand%20why%20this%20is%0A%20%20%20%20tricky%20and%20what%20we%20can%20do%20about%20it.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%202.%20The%20Bandwidth%20Hierarchy%0A%0A%20%20%20%20For%20weight%20sync%2C%20we%20care%20about%20one%20specific%20data%20path%20%E2%80%94%20trainer%20GPU%20to%20generator%0A%20%20%20%20GPU%2C%20across%20nodes.%20Here's%20the%20chain%20of%20interconnects%20a%20weight%20tensor%20traverses%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20GPU%20%E2%94%80%E2%94%80PCIe%E2%94%80%E2%94%80%E2%96%BA%20CPU%20%E2%94%80%E2%94%80PCIe%E2%94%80%E2%94%80%E2%96%BA%20NIC%20%E2%95%90%E2%95%90RDMA%E2%95%90%E2%95%90%E2%96%BA%20NIC%20%E2%94%80%E2%94%80PCIe%E2%94%80%E2%94%80%E2%96%BA%20CPU%20%E2%94%80%E2%94%80PCIe%E2%94%80%E2%94%80%E2%96%BA%20Generator%20GPU%0A%20%20%20%20%20%20same%20node%20%20%20%20%20(64%20GB%2Fs)%20%20%20%20(50%20GB%2Fs)%20%20%20%20%20(64%20GB%2Fs)%20%20%20%20%20%20same%20node%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20bottleneck%20is%20the%20cross-node%20RDMA%20link%20at%2050%20GB%2Fs%20per%20NIC.%20But%20modern%20nodes%0A%20%20%20%20have%20**8%20NICs**%20(one%20per%20GPU)%2C%20so%20aggregate%20cross-node%20bandwidth%20is%20400%20GB%2Fs.%0A%0A%20%20%20%20Here's%20how%20all%20these%20interconnects%20fit%20together%20in%20a%20full%20node%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NODE%20A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NVSwitch%20%2F%20NVLink%20Fabric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s%20NVLink%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2064%20GB%2Fs%20PCIe%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20CPU%200%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20CPU%201%20%20%E2%94%82%20%3D%3D%3D%3D%3D%3D%2064%20GB%2Fs%20%E2%95%90%E2%95%90%E2%94%82%20NIC%200%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20NIC%201%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20PCIe%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%2064%20GB%2Fs%20PCIe%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2050%20GB%2Fs%20%20%20%3D%3D%3D%3D%3D%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RDMA%20(IB%2FRoCE)%20%20%20RDMA%20(IB%2FRoCE)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20InfiniBand%20Switch%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2050%20GB%2Fs%20%20%20%3D%3D%3D%3D%3D%3D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20RDMA%20(IB%2FRoCE)%20%20%20RDMA%20(IB%2FRoCE)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%2064%20GB%2Fs%20PCIe%20%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%90%E2%95%AA%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20PCIe%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20CPU%200%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20CPU%201%20%20%E2%94%82%20%3D%3D%3D%3D%3D%3D%2064%20GB%2Fs%20%E2%95%90%E2%95%90%E2%94%82%20NIC%200%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%20NIC%201%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%20%2064%20GB%2Fs%20PCIe%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%82%20%20%20%20%20%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%23%20%20900%20GB%2Fs%20NVLink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witch%20%2F%20NVLink%20Fabric%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20NODE%20B%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%0A%20%20%20%20Bandwidth%20encoding%20(line%20intensity)%3A%0A%20%20%20%20%20%20%23%23%23%23%23%23%23%23%20%20NVLink%2FNVSwitch%20%20%20900%20GB%2Fs%20bidirectional%20(GPU%20%E2%86%94%20GPU%2C%20same%20node)%0A%20%20%20%20%20%20%3D%3D%3D%3D%3D%3D%3D%3D%20%20PCIe%20Gen5%20%2F%20RDMA%20%2050-64%20GB%2Fs%20unidirectional%20(CPU%E2%86%94GPU%2C%20CPU%E2%86%94NIC%2C%20cross-node)%0A%20%20%20%20%20%20(Showing%202%20of%208%20NICs%20for%20clarity%20%E2%80%94%20each%20GPU%20has%20a%20dedicated%20NIC)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20A%20Note%20on%20Bandwidth%20Numbers%0A%0A%20%20%20%20Bandwidth%20specs%20vary%20by%20hardware%20generation%2C%20cluster%20configuration%2C%20and%20vendor.%0A%20%20%20%20We'll%20use%20numbers%20from%20Meta's%20published%20Llama%203%20training%20infrastructure%0A%20%20%20%20(%5BBuilding%20Meta's%20GenAI%20Infrastructure%5D(https%3A%2F%2Fengineering.fb.com%2F2024%2F03%2F12%2Fdata-center-engineering%2Fbuilding-metas-genai-infrastructure%2F))%3A%0A%0A%20%20%20%20%3E%20%22Both%20of%20these%20solutions%20interconnect%20**400%20Gbps%20endpoints**...%20we%20have%20successfully%0A%20%20%20%20%3E%20used%20both%20RoCE%20and%20InfiniBand%20clusters%20for%20large%2C%20GenAI%20workloads%20(including%20our%0A%20%20%20%20%3E%20ongoing%20training%20of%20Llama%203%20on%20our%20RoCE%20cluster)%20without%20any%20network%20bottlenecks.%22%0A%0A%20%20%20%20**Important**%3A%20%22400%20Gbps%22%20in%20networking%20is%20**full-duplex**%20-%20meaning%20400%20Gbps%20transmit%0A%20%20%20%20AND%20400%20Gbps%20receive%20simultaneously.%20For%20weight%20sync%20(unidirectional%3A%20trainer%20%E2%86%92%20generator)%2C%0A%20%20%20%20we%20get%20the%20full%20400%20Gbps%20%3D%20**50%20GB%2Fs%20per%20NIC**.%0A%0A%20%20%20%20Meta's%20Grand%20Teton%20nodes%20have%20**8%20RDMA%20NICs**%20(one%20per%20GPU%2C%201%3A1%20mapping)%2C%20giving%0A%20%20%20%20400%20GB%2Fs%20aggregate%20unidirectional%20bandwidth%20per%20node.%20For%20more%20details%20on%20Grand%20Teton%0A%20%20%20%20and%20Monarch's%20RDMA%20architecture%2C%20see%20the%20SIGCOMM%202024%20paper%3A%0A%20%20%20%20%5BRDMA%20over%20Ethernet%20for%20Distributed%20AI%20Training%20at%20Meta%20Scale%5D(https%3A%2F%2Fcs.stanford.edu%2F~keithw%2Fsigcomm2024%2Fsigcomm24-final246-acmpaginated.pdf).%0A%0A%20%20%20%20%7C%20Interconnect%20%7C%20Bandwidth%20%7C%20Notes%20%7C%0A%20%20%20%20%7C--------------%7C-----------%7C-------%7C%0A%20%20%20%20%7C%20**NVLink%204.0**%20%7C%20900%20GB%2Fs%20bidirectional%20%7C%20~450%20GB%2Fs%20per%20direction%20%7C%0A%20%20%20%20%7C%20**RDMA%20(IB%2FRoCE)**%20%7C%20400%20Gbps%20%3D%2050%20GB%2Fs%20%7C%20Per%20NIC%2C%20full-duplex%20%7C%0A%20%20%20%20%7C%20**PCIe%20Gen5%20x16**%20%7C%2064%20GB%2Fs%20%7C%20Per%20direction%20%7C%0A%0A%20%20%20%20**Key%20observations%3A**%0A%0A%20%20%20%201.%20**NVLink%20is%20fast%20but%20same-node%20only**%20-%20450%20GB%2Fs%2C%20but%20can't%20cross%20the%20network%0A%20%20%20%202.%20**RDMA%20%3E%3E%20TCP**%20-%2050%20GB%2Fs%20with%20zero-copy%20beats%20TCP%20significantly%20for%20cross-node%0A%20%20%20%203.%20**Multi-NIC%20scales**%20-%208%20NICs%20%C3%97%2050%20GB%2Fs%20%3D%20400%20GB%2Fs%2C%20approaching%20NVLink%20speeds%0A%0A%20%20%20%20**Rule%20of%20thumb**%3A%20NVLink%20for%20same-node%20ops%20(gradients%2C%20activations).%0A%20%20%20%20RDMA%20for%20cross-node%20communication%20(weight%20sync)%20-%20it's%20the%20only%20practical%20option.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%202b.%20Back-of-Envelope%3A%20Syncing%20Large%20Models%0A%0A%20%20%20%20Let's%20do%20some%20quick%20math.%20DeepSeek%20V3%20has%20671B%20parameters%20(~1.34%20TB%20in%20bf16).%0A%0A%20%20%20%20The%20key%20insight%3A%20**you're%20not%20shoving%201.3%20TB%20through%20a%20single%20NIC**.%20The%20weights%0A%20%20%20%20are%20distributed%20across%20many%20GPUs%20(via%20some%20combination%20of%20PP%2C%20EP%2C%20TP%2C%20FSDP)%2C%0A%20%20%20%20and%20each%20GPU%20has%20its%20own%20NIC.%20You%20get%20**aggregate%20bandwidth**%20across%20all%20NICs.%0A%0A%20%20%20%20The%20actual%20sync%20time%20depends%20on%20**both%20sides**%3A%0A%20%20%20%20-%20**Trainer's%20aggregate%20upload%20bandwidth**%20(sending%20weights%20out)%0A%20%20%20%20-%20**Generator's%20aggregate%20download%20bandwidth**%20(receiving%20weights)%0A%0A%20%20%20%20The%20bottleneck%20is%20whichever%20is%20smaller.%20And%20if%20multiple%20generators%20pull%20from%0A%20%20%20%20the%20same%20trainer%20simultaneously%2C%20the%20trainer's%20bandwidth%20is%20divided%20among%20them.%0A%0A%20%20%20%20With%20Grand%20Teton's%208%20NICs%20per%20node%20at%2050%20GB%2Fs%20each%20(400%20GB%2Fs%20per%20node)%2C%0A%20%20%20%20the%20math%20is%20simple%3A%20**Time%20%3D%20Shard%20Size%20%2F%20Bandwidth**.%0A%0A%20%20%20%20The%20per-node%20shard%20size%20depends%20on%20how%20many%20nodes%20the%20model%20is%20spread%20across%3A%0A%20%20%20%20-%20DeepSeek%20V3%20(1.3%20TB)%20across%208%20nodes%20%E2%86%92%20~160%20GB%20per%20node%0A%20%20%20%20-%20DeepSeek%20V3%20(1.3%20TB)%20across%2016%20nodes%20%E2%86%92%20~80%20GB%20per%20node%0A%0A%20%20%20%20%7C%20Per-node%20shard%20%7C%20Time%20to%20sync%20%7C%0A%20%20%20%20%7C----------------%7C--------------%7C%0A%20%20%20%20%7C%20~160%20GB%20(8%20nodes)%20%7C%20160%20%2F%20400%20%3D%20**0.4%20seconds**%20%7C%0A%20%20%20%20%7C%20~80%20GB%20(16%20nodes)%20%7C%2080%20%2F%20400%20%3D%20**0.2%20seconds**%20%7C%0A%0A%20%20%20%20The%20exact%20per-node%20shard%20size%20depends%20on%20your%20parallelism%20strategy%20(PP%2C%20EP%2C%20TP%2C%20etc.)%2C%0A%20%20%20%20but%20the%20math%20works%20out%3A%20with%20modern%20RDMA%20hardware%2C%20you%20can%20sync%20even%20the%20largest%0A%20%20%20%20models%20in%20**sub-second%20time**.%0A%0A%20%20%20%20Compare%20this%20to%20naive%20TCP%3A%20kernel%20copies%2C%20socket%20overhead%2C%20no%20zero-copy...%0A%20%20%20%20easily%2010x%20slower.%20**RDMA%20is%20the%20only%20way%20to%20make%20async%20RL%20practical%20at%20scale.**%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%203.%20The%20Problem%3A%20Collectives%20Are%20Blocking%0A%0A%20%20%20%20Most%20people%20use%20RDMA%20via%20**collectives**%20through%20PyTorch%20distributed%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20import%20torch.distributed%20as%20dist%0A%0A%20%20%20%20dist.init_process_group(backend%3D%22nccl%22)%0A%20%20%20%20dist.all_reduce(gradients%2C%20op%3Ddist.ReduceOp.SUM)%0A%20%20%20%20dist.broadcast(weights%2C%20src%3D0)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20works%20great%20for%20training.%20But%20async%20RL%20has%20a%20different%20access%20pattern.%0A%0A%20%20%20%20%23%23%23%20High%20Variance%20in%20Generation%20Times%0A%0A%20%20%20%20Generators%20have%20wildly%20different%20completion%20times%3A%0A%20%20%20%20-%20Some%20prompts%20%E2%86%92%2010%20tokens%20(fast)%0A%20%20%20%20-%20Other%20prompts%20%E2%86%92%201000%20tokens%20(slow)%0A%0A%20%20%20%20With%20collectives%2C%20fast%20generators%20wait%20for%20slow%20ones%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Generator%200%3A%20%E2%94%9C%E2%94%80%E2%94%80%20gen%20(fast)%20%E2%94%80%E2%94%80%E2%94%A4%20%20%E2%9A%A0%EF%B8%8F%20WAITING...%0A%20%20%20%20Generator%201%3A%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%20gen%20(slow)%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%0A%20%20%20%20Generator%202%3A%20%E2%94%9C%E2%94%80%E2%94%80%20gen%20(fast)%20%E2%94%80%E2%94%80%E2%94%A4%20%20%E2%9A%A0%EF%B8%8F%20WAITING...%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20all_gather(weights)%20%20%23%20Everyone%20waits!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20The%20One-Sided%20Solution%3A%20RDMA%0A%0A%20%20%20%20What%20if%20the%20sender%20could%20write%20directly%20to%20the%20receiver's%20memory%20without%20coordination%3F%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Two-sided%20(send%2Frecv)%3A%0A%20%20%20%20%20%20Sender%3A%20%22I%20have%20data%22%20%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20Receiver%3A%20%22I'm%20ready%22%0A%20%20%20%20%20%20Sender%3A%20sends%20data%20%20%20%20%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20Receiver%3A%20receives%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%202%20messages%20required%0A%0A%20%20%20%20One-sided%20(RDMA)%3A%0A%20%20%20%20%20%20Sender%3A%20writes%20directly%20to%20receiver's%20memory%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20No%20coordination%20needed!%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20is%20what%20RDMA%20enables%3A%20**one-sided%20memory%20operations**.%0A%20%20%20%20The%20trainer%20doesn't%20even%20know%20when%20generators%20pull%20weights%20-%20this%20is%20truly%20async!%0A%0A%20%20%20%20RDMA%20isn't%20just%20%22faster%20TCP%22%20%E2%80%94%20it%20bypasses%20the%20kernel%20entirely.%20No%20socket%20buffers%2C%0A%20%20%20%20no%20context%20switches%2C%20no%20serialization.%20The%20NIC%20reads%20directly%20from%20registered%20memory.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%204.%20The%20Magic%20Pointer%20Pattern%0A%0A%20%20%20%20One%20natural%20question%20that%20arises%20is%20along%20the%20lines%20of%2C%20%22How%20do%20we%20actually%20represent%20one-sided%20puts%2Fgets%20if%20not%20with%20NCCL%20collectives%3F%22%0A%0A%20%20%20%20Here's%20a%20key%20insight%3A%20to%20represent%20remote%20data%2C%20we%20only%20need%20a%20**tiny%20handle**%20-%0A%20%20%20%20an%20%60(addr%2C%20rkey%2C%20size)%60%20tuple%20that%20says%20%22here's%20where%20my%20data%20lives.%22%0A%0A%20%20%20%20Monarch%20wraps%20this%20in%20%60RDMABuffer%60.%20Let's%20see%20how%20small%20it%20actually%20is%3A%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20endpoint%2C%20is_rdma_available%2C%20this_host%2C%20torch)%3A%0A%20%20%20%20%23%20Measure%20actual%20size%20of%20RDMABuffer%20handles%0A%20%20%20%20import%20pickle%0A%0A%20%20%20%20def%20show_fallback_sizes()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Fallback%3A%20show%20expected%20sizes%20based%20on%20RDMABuffer%20structure.%22%22%22%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20expected%20handle%20sizes)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%22RDMABuffer%20contains%3A%20addr%20(8B)%20%2B%20rkey%20(4B)%20%2B%20size%20(8B)%20%2B%20owner%20(~100B)%22)%0A%20%20%20%20%20%20%20%20print(%22Total%20serialized%20size%3A%20~150-200%20bytes%20regardless%20of%20tensor%20size%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20sizes%20%3D%20%5B(%221%20KB%22%2C%201024)%2C%20(%221%20MB%22%2C%201024**2)%2C%20(%221%20GB%22%2C%201024**3)%5D%0A%20%20%20%20%20%20%20%20handle_bytes%20%3D%20150%20%20%23%20approximate%0A%0A%20%20%20%20%20%20%20%20for%20name%2C%20tensor_bytes%20in%20sizes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20ratio%20%3D%20tensor_bytes%20%2F%20handle_bytes%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bname%3A%3C8%7D%20tensor%20%E2%86%92%20~150%20byte%20handle%20%E2%86%92%20%7Bratio%3A%2C.0f%7Dx%20compression%22)%0A%0A%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Handle%20size%20is%20O(1)%20regardless%20of%20tensor%20size!%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback_sizes()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20BufferSizeDemo(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Actor%20that%20creates%20RDMABuffers%20and%20measures%20their%20size.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20measure_buffer_sizes(self)%20-%3E%20list%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20pickle%20as%20_pickle%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20results%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sizes%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%221%20KB%22%2C%20256)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%221%20MB%22%2C%20256%20*%201024)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20(%2210%20MB%22%2C%20256%20*%201024%20*%2010)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20numel%20in%20sizes%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tensor%20%3D%20torch.randn(numel)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20tensor_bytes%20%3D%20tensor.numel()%20*%20tensor.element_size()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20byte_tensor%20%3D%20tensor.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20buffer%20%3D%20RDMABuffer(byte_tensor)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle_bytes%20%3D%20len(_pickle.dumps(buffer))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20results.append((name%2C%20tensor_bytes%2C%20handle_bytes))%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20results%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20proc%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20%20%20%20%20demo%20%3D%20proc.spawn(%22buffer_demo%22%2C%20BufferSizeDemo)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20results%20%3D%20demo.measure_buffer_sizes.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22RDMABuffer%20handle%20size%20vs%20actual%20tensor%20size%3A%5Cn%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7B'Tensor%20Size'%3A%3C12%7D%20%7B'Actual%20Bytes'%3A%3C15%7D%20%7B'Handle%20Size'%3A%3C15%7D%20%7B'Ratio'%3A%3C10%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22-%22%20*%2055)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20name%2C%20tensor_bytes%2C%20handle_bytes%20in%20results%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20ratio%20%3D%20tensor_bytes%20%2F%20handle_bytes%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bname%3A%3C12%7D%20%7Btensor_bytes%3A%3E12%2C%7D%20B%20%20%20%7Bhandle_bytes%3A%3E6%7D%20B%20%20%20%20%20%20%20%20%7Bratio%3A%3E8%2C.0f%7Dx%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Handle%20size%20is%20O(1)%20regardless%20of%20tensor%20size!%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22(RDMA%20setup%20failed%3A%20%7Be%7D)%5Cn%22)%0A%20%20%20%20%20%20%20%20show_fallback_sizes()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20The%20Magic%20Pointer%0A%0A%20%20%20%20This%20is%20the%20core%20pattern%3A%20**separate%20control%20plane%20from%20data%20plane**.%0A%0A%20%20%20%20-%20**Control%20plane**%20(actor%20messages)%3A%20Send%20tiny%20handle%20(~100%20bytes)%0A%20%20%20%20-%20**Data%20plane**%20(RDMA)%3A%20Bulk%20transfer%20of%20actual%20data%20(~10%20GB)%0A%0A%20%20%20%20Think%20of%20%60RDMABuffer%60%20as%20a%20**magic%20pointer**%20-%20it's%20a%20pointer%20that%20works%20across%20machines%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20Generator%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20weights%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20local%20copy%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20(10%20GB)%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20(empty)%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%201.%20Create%20RDMABuffer%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20(register%20memory%2C%20get%20handle)%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%202.%20Send%20handle%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%E2%94%82%20%20(~100%20bytes%20via%20actor)%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%E2%97%84%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%203.%20RDMA%20read%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20(~10%20GB%20via%20hardware)%0A%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20(no%20trainer%20involvement!)%20%20%E2%94%82%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20trainer%20doesn't%20even%20know%20when%20generators%20pull%20weights.%20True%20one-sided.%0A%0A%20%20%20%20%23%23%23%20RDMABuffer%20in%20Action%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20monarch.rdma%20import%20RDMABuffer%0A%0A%20%20%20%20%23%20Trainer%20side%3A%20register%20weights%0A%20%20%20%20weights%20%3D%20torch.randn(1024%2C%201024%2C%20device%3D%22cuda%22)%0A%20%20%20%20buffer%20%3D%20RDMABuffer(weights.view(torch.uint8).flatten())%0A%0A%20%20%20%20%23%20Return%20buffer%20as%20part%20of%20an%20endpoint%20response%0A%20%20%20%20%40endpoint%0A%20%20%20%20def%20get_weight_handle(self)%20-%3E%20RDMABuffer%3A%0A%20%20%20%20%20%20%20%20return%20self.buffer%0A%0A%20%20%20%20%23%20Generator%20side%3A%20receive%20handle%2C%20pull%20directly%20into%20GPU%0A%20%20%20%20handle%20%3D%20trainer.get_weight_handle.call_one().get()%20%20%23%20Tiny%20message%0A%20%20%20%20gpu_weights%20%3D%20model.weights.view(torch.uint8).flatten()%0A%20%20%20%20handle.read_into(gpu_weights).get()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Bulk%20RDMA%20transfer%0A%0A%20%20%20%20%23%20Push%20model%3A%20caller%20writes%20local%20src_tensor%20into%20the%20remote%20RDMABuffer%0A%20%20%20%20buffer.write_from(src_tensor).get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Pull%20vs%20Push**%3A%20%60read_into%60%20is%20the%20**pull**%20model%20(generator%20reads%20remote%20data%20into%0A%20%20%20%20its%20local%20buffer)%2C%20while%20%60write_from%60%20is%20the%20**push**%20model%20(caller%20writes%20local%20data%0A%20%20%20%20into%20the%20remote%20buffer).%20Both%20are%20one-sided%20RDMA%20operations%20%E2%80%94%20the%20remote%20side%20is%20not%0A%20%20%20%20involved.%20In%20async%20RL%2C%20pull%20is%20more%20natural%20because%20each%20generator%20decides%20*when*%20it%0A%20%20%20%20needs%20fresh%20weights.%0A%0A%20%20%20%20**Want%20to%20understand%20how%20RDMA%20works%20under%20the%20hood%3F**%20Check%20out%20**07b_weight_sync_deep_dive.py**%0A%20%20%20%20for%20ibverbs%20internals%2C%20queue%20pair%20setup%2C%20and%20why%20Monarch's%20actor%20model%20is%20such%20a%20natural%20fit%0A%20%20%20%20for%20managing%20RDMA%20connections.%20It's%20actors%20all%20the%20way%20down!%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Live%20Demo%3A%20Trainer%20%E2%86%92%20Generator%20Weight%20Sync%0A%0A%20%20%20%20Let's%20see%20this%20in%20action%20with%20a%20simple%20example.%20A%20trainer%20holds%20weights%2C%0A%20%20%20%20a%20generator%20pulls%20them%20via%20RDMA.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(Actor%2C%20RDMABuffer%2C%20endpoint%2C%20is_rdma_available%2C%20this_host%2C%20torch)%3A%0A%20%20%20%20%23%20Simple%20trainer%20%E2%86%92%20generator%20weight%20sync%20demo%0A%0A%20%20%20%20def%20show_fallback_demo()%3A%0A%20%20%20%20%20%20%20%20%22%22%22Show%20what%20would%20happen%20with%20RDMA.%22%22%22%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20conceptual%20flow)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%221.%20Trainer%20creates%20weights%20(e.g.%2C%204%20MB%20tensor)%22)%0A%20%20%20%20%20%20%20%20print(%222.%20Trainer%20wraps%20weights%20in%20RDMABuffer%20%E2%86%92%20tiny%20handle%20(~150%20bytes)%22)%0A%20%20%20%20%20%20%20%20print(%223.%20Trainer%20sends%20handle%20to%20Generator%20via%20actor%20message%22)%0A%20%20%20%20%20%20%20%20print(%224.%20Generator%20calls%20handle.read_into(local_buffer)%22)%0A%20%20%20%20%20%20%20%20print(%225.%20RDMA%20hardware%20transfers%204%20MB%20directly%2C%20trainer%20not%20involved!%22)%0A%20%20%20%20%20%20%20%20print(%22%5Cn%E2%86%92%20Zero-copy%2C%20one-sided%2C%20no%20serialization%20overhead%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback_demo()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Sender(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Sender%20that%20holds%20data%20and%20exposes%20an%20RDMA%20handle.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20some%20data%20to%20send%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data%20%3D%20torch.randn(size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Register%20with%20RDMA%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data_bytes%20%3D%20self.data.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.buffer%20%3D%20RDMABuffer(self.data_bytes)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BSender%5D%20Created%20data%3A%20%7Bself.data.numel()%20*%204%20%2F%201e6%3A.1f%7D%20MB%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20get_handle(self)%20-%3E%20RDMABuffer%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Return%20tiny%20handle%20(not%20the%20data%20itself!)%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.buffer%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20get_checksum(self)%20-%3E%20float%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22For%20verification%3A%20sum%20of%20data%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20float(self.data.sum())%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Receiver(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Receiver%20that%20pulls%20data%20from%20sender%20via%20RDMA.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Pre-allocate%20space%20for%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data%20%3D%20torch.zeros(size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.data_bytes%20%3D%20self.data.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BReceiver%5D%20Allocated%20buffer%3A%20%7Bself.data.numel()%20*%204%20%2F%201e6%3A.1f%7D%20MB%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20pull_data(self%2C%20handle%3A%20RDMABuffer)%20-%3E%20float%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Pull%20data%20via%20RDMA%20read%2C%20return%20checksum%20for%20verification.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20This%20is%20the%20magic%3A%20RDMA%20read%20directly%20into%20our%20buffer%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(self.data_bytes).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20float(self.data.sum())%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Spawn%20sender%20and%20receiver%0A%20%20%20%20%20%20%20%20%20%20%20%20procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%202%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20sender%20%3D%20procs.slice(procs%3D0).spawn(%22sender%22%2C%20Sender%2C%201024%20*%201024)%20%20%23%204%20MB%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver%20%3D%20procs.slice(procs%3D1).spawn(%22receiver%22%2C%20Receiver%2C%201024%20*%201024)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Step%201%3A%20Get%20handle%20from%20sender%20(tiny%20message!)%0A%20%20%20%20%20%20%20%20%20%20%20%20handle%20%3D%20sender.get_handle.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5Cn%5BOrchestrator%5D%20Got%20handle%20from%20sender%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Step%202%3A%20Send%20handle%20to%20receiver%2C%20have%20it%20pull%20data%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_checksum%20%3D%20receiver.pull_data.call_one(handle).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_checksum%20%3D%20sender.get_checksum.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BOrchestrator%5D%20Sender%20checksum%3A%20%7Bsender_checksum%3A.2f%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BOrchestrator%5D%20Receiver%20checksum%3A%20%7Breceiver_checksum%3A.2f%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BOrchestrator%5D%20Match%3A%20%7Babs(sender_checksum%20-%20receiver_checksum)%20%3C%200.01%7D%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20print(f%22(Demo%20failed%3A%20%7Be%7D)%5Cn%22)%0A%20%20%20%20%20%20%20%20show_fallback_demo()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%205.%20CPU%20Staging%20Pattern%0A%0A%20%20%20%20%23%23%23%20GPU-Native%20RDMA%20Exists%20(and%20Monarch%20Supports%20It)%0A%0A%20%20%20%20GPU-native%20RDMA%20(GPUDirect)%20is%20real%20and%20works%20well%20-%20the%20NIC%20reads%20directly%20from%20GPU%0A%20%20%20%20memory%20with%20no%20CPU%20copy.%20Monarch%20supports%20this%20at%20the%20Rust%20level.%20For%20synchronous%0A%20%20%20%20bulk%20transfers%2C%20it's%20excellent.%0A%0A%20%20%20%20%23%23%23%20CPU%20Staging%3A%20A%20Deliberate%20Architectural%20Choice%0A%0A%20%20%20%20For%20async%20RL%2C%20CPU%20staging%20isn't%20a%20workaround%20for%20missing%20GPUDirect%20-%20it's%20the%0A%20%20%20%20**preferred%20production%20pattern**.%20The%20reason%20is%20**temporal%20decoupling**%3A%20trainers%0A%20%20%20%20and%20generators%20operate%20on%20completely%20independent%20timelines%2C%20and%20we%20need%20a%20buffer%0A%20%20%20%20between%20them.%0A%0A%20%20%20%20The%20issue%20isn't%20bandwidth%20-%20it's%20**timing**%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Direct%20GPU%E2%86%92GPU%20RDMA%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20Generator%20GPU%20is%20mid-inference%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%E2%94%9C%E2%94%80%E2%94%80%20layer%201%20%E2%94%80%E2%94%80%E2%94%A4%20%5BRDMA%20arrives%2C%20needs%20sync!%5D%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20cudaDeviceSynchronize()%20%20%E2%86%90%20Blocks%20inference!%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20With%20CPU%20staging%2C%20nothing%20on%20the%20critical%20path%20blocks%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20GPU%20%E2%94%80%E2%94%80%E2%96%BA%20CPU%20staging%20buffer%20(RDMA%20registered)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%5BSits%20here%2C%20ready%20anytime%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20Generator%20grabs%20when%20ready%20%E2%94%80%E2%94%80%E2%96%BA%20Generator%20GPU%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20CPU%20buffer%20is%20a%20**temporal%20decoupling%20point**.%0A%0A%20%20%20%20Note%3A%20the%20CPU%20staging%20path%20does%20involve%20GPU%E2%86%94CPU%20copies%20on%20each%20end.%20When%20we%20say%0A%20%20%20%20RDMA%20is%20%22zero-copy%2C%22%20we%20mean%20across%20the%20network%20%E2%80%94%20the%20NIC%20reads%2Fwrites%20directly%0A%20%20%20%20from%2Fto%20registered%20CPU%20memory%20with%20no%20kernel%20involvement.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%206.%20Circular%20Weight%20Buffers%0A%0A%20%20%20%20%23%23%23%20One-Sided%20Isn't%20Free%0A%0A%20%20%20%20One-sided%20RDMA%20is%20powerful%20-%20trainers%20and%20generators%20can%20operate%20independently%20without%0A%20%20%20%20explicit%20send%2Frecv%20coordination.%20But%20%22no%20coordination%22%20isn't%20quite%20right.%20There's%20still%0A%20%20%20%20a%20fundamental%20race%20condition%20lurking%3A%20**what%20if%20the%20trainer%20overwrites%20a%20buffer%20while%20a%0A%20%20%20%20generator%20is%20reading%20from%20it%3F**%0A%0A%20%20%20%20With%20a%20single%20buffer%2C%20this%20is%20a%20real%20problem%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%3A%20write%20v3%20to%20buffer%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20%5Bbuffer%3A%20v3...v2...v3%5D%20%20%E2%86%90%20corrupted!%0A%20%20%20%20Generator%3A%20reading%20v2%20from%20buffer%20%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%96%BA%20%20read%20gets%20mix%20of%20v2%20and%20v3%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20We%20need%20*some*%20form%20of%20coordination.%20The%20question%20is%3A%20do%20we%20go%20back%20to%20message-passing%0A%20%20%20%20(explicit%20locks%2C%20barriers%2C%20acknowledgments)%20and%20lose%20the%20async%20benefits%3F%20Or%20can%20we%20get%0A%20%20%20%20coordination%20from%20the%20**structure%20itself**%3F%0A%0A%20%20%20%20%23%23%23%20Solution%3A%20Circular%20Buffer%20as%20Structural%20Coordination%0A%0A%20%20%20%20The%20key%20insight%3A%20GPU%20memory%20is%20scarce%2C%20but%20**CPU%20memory%20is%20abundant**.%20We%20can%20afford%20to%0A%20%20%20%20keep%20multiple%20versions%20of%20the%20weights%20in%20CPU%20staging%20buffers.%20By%20writing%20to%20slots%20in%20a%0A%20%20%20%20circular%20pattern%2C%20the%20trainer%20never%20overwrites%20a%20slot%20that%20a%20generator%20might%20still%20be%0A%20%20%20%20reading%20-%20as%20long%20as%20we%20have%20enough%20slots%20to%20cover%20the%20timing%20gap.%0A%0A%20%20%20%20This%20is%20**structural%20coordination**%3A%20the%20circular%20buffer's%20design%20eliminates%20the%20race%0A%20%20%20%20condition%20without%20any%20explicit%20synchronization%20messages%20between%20trainer%20and%20generator.%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20writes%3A%20%20%20%20%20v0%20%20%20%20%E2%86%92%20%20v1%20%20%E2%86%92%20%20v2%20%20%E2%86%92%20%20v3%20%20%E2%86%92%20%20v4%20%20%E2%86%92%20%20v5%20%20%E2%86%92%20...%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%20%20%E2%86%93%20%20%20%20%20%20%E2%86%93%0A%20%20%20%20Buffer%20slots%3A%20%20%20%20%20%20%5Bslot0%5D%20%5Bslot1%5D%20%5Bslot2%5D%20%20(circular%2C%20reused)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v3%20%20%20%20%20%20v4%20%20%20%20%20%20v5%0A%0A%20%20%20%20Generator%20reads%3A%20%22Give%20me%20latest%22%20%E2%86%92%20v5%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Benefits%3A%0A%20%20%20%20-%20**No%20message-based%20coordination**%20-%20structure%20prevents%20races%2C%20not%20locks%0A%20%20%20%20-%20**Pre-registered%20RDMA%20buffers**%20-%20no%20memory%20registration%20on%20hot%20path%0A%20%20%20%20-%20**Lock-free%20reads**%20-%20generators%20always%20get%20a%20consistent%20snapshot%0A%20%20%20%20-%20**Bounded%20memory**%20-%20only%20N%20versions%20in%20flight%0A%0A%20%20%20%20**Memory%20cost%20is%20real**%3A%20for%20a%2070B%20model%20(140%20GB%20in%20bf16)%2C%205%20slots%20%3D%20700%20GB%20of%20CPU%20RAM.%0A%20%20%20%20This%20is%20feasible%20on%20HPC%20nodes%20(Grand%20Teton%20has%20~1.5%20TB%20RAM%20per%20node)%2C%20but%20%60n_slots%60%20is%0A%20%20%20%20bounded%20by%20available%20CPU%20memory%2C%20not%20just%20timing.%0A%0A%20%20%20%20The%20key%20design%20constraint%3A%20register%20all%20slots%20at%20init%20time%2C%20then%20just%20write%20to%20them.%0A%20%20%20%20No%20allocation%2C%20no%20registration%20on%20the%20critical%20path.%20Tune%20%60n_slots%60%20so%20that%20the%20trainer%0A%20%20%20%20can't%20lap%20the%20slowest%20generator%20%E2%80%94%20if%20it%20does%2C%20the%20generator%20reads%20a%20corrupted%20mix%20of%0A%20%20%20%20two%20versions%20(not%20a%20graceful%20error%2C%20just%20silent%20data%20corruption).%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20circ_slots_slider%20%3D%20mo.ui.slider(1%2C%208%2C%20value%3D3%2C%20label%3D%22Buffer%20slots%20(n_slots)%22)%0A%20%20%20%20circ_writes_slider%20%3D%20mo.ui.slider(1%2C%2010%2C%20value%3D2%2C%20label%3D%22Trainer%20writes%20per%20generator%20sync%22)%0A%20%20%20%20mo.vstack(%5B%0A%20%20%20%20%20%20%20%20mo.md(%22**Try%20it**%3A%20adjust%20slots%20and%20write%20speed%20to%20see%20when%20lapping%20causes%20a%20race%20condition.%22)%2C%0A%20%20%20%20%20%20%20%20mo.hstack(%5Bcirc_slots_slider%2C%20circ_writes_slider%5D%2C%20justify%3D%22center%22%2C%20gap%3D1)%2C%0A%20%20%20%20%5D)%0A%20%20%20%20return%20circ_slots_slider%2C%20circ_writes_slider%0A%0A%0A%40app.cell%0Adef%20_(circ_slots_slider%2C%20circ_writes_slider%2C%20mo)%3A%0A%20%20%20%20_n%20%3D%20circ_slots_slider.value%0A%20%20%20%20_w%20%3D%20circ_writes_slider.value%0A%20%20%20%20_safe%20%3D%20_w%20%3C%20_n%0A%0A%20%20%20%20%23%20Build%20SVG%20showing%20circular%20buffer%20slots%20with%20write%20pointer%20and%20read%20pointer%0A%20%20%20%20_slot_w%2C%20_slot_h%20%3D%2064%2C%2048%0A%20%20%20%20_gap%20%3D%206%0A%20%20%20%20_pad%20%3D%2030%0A%20%20%20%20_total_w%20%3D%20max(_n%20*%20(_slot_w%20%2B%20_gap)%20-%20_gap%20%2B%202%20*%20_pad%2C%20300)%0A%20%20%20%20_total_h%20%3D%20130%0A%0A%20%20%20%20_parts%20%3D%20%5B%0A%20%20%20%20%20%20%20%20f'%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22%7B_total_w%7D%22%20height%3D%22%7B_total_h%7D%22%20'%0A%20%20%20%20%20%20%20%20f'style%3D%22font-family%3A%20-apple-system%2C%20sans-serif%3B%22%3E'%0A%20%20%20%20%5D%0A%0A%20%20%20%20%23%20Title%0A%20%20%20%20_parts.append(%0A%20%20%20%20%20%20%20%20f'%3Ctext%20x%3D%22%7B_total_w%20%2F%202%7D%22%20y%3D%2218%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20f'font-size%3D%2212%22%20fill%3D%22%23666%22%3ETrainer%20writes%20%7B_w%7D%20version%7B%22s%22%20if%20_w%20!%3D%201%20else%20%22%22%7D%20'%0A%20%20%20%20%20%20%20%20f'while%20generator%20reads%20from%20slot%200%3C%2Ftext%3E'%0A%20%20%20%20)%0A%0A%20%20%20%20_slot_y%20%3D%2050%0A%20%20%20%20for%20_i%20in%20range(_n)%3A%0A%20%20%20%20%20%20%20%20_x%20%3D%20_pad%20%2B%20_i%20*%20(_slot_w%20%2B%20_gap)%0A%0A%20%20%20%20%20%20%20%20%23%20Which%20trainer%20write%20steps%20land%20on%20this%20slot%3F%0A%20%20%20%20%20%20%20%20%23%20Trainer%20writes%20to%20slots%201%2C%202%2C%20...%2C%20wrapping%20around%0A%20%20%20%20%20%20%20%20_write_steps%20%3D%20%5Bj%20%2B%201%20for%20j%20in%20range(_w)%20if%20(1%20%2B%20j)%20%25%20_n%20%3D%3D%20_i%5D%0A%20%20%20%20%20%20%20%20_is_gen_read%20%3D%20(_i%20%3D%3D%200)%0A%20%20%20%20%20%20%20%20_is_written%20%3D%20len(_write_steps)%20%3E%200%0A%20%20%20%20%20%20%20%20_collision%20%3D%20_is_gen_read%20and%20_is_written%0A%0A%20%20%20%20%20%20%20%20%23%20Colors%0A%20%20%20%20%20%20%20%20if%20_collision%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_fill%2C%20_stroke%20%3D%20%22%23fecaca%22%2C%20%22%23dc2626%22%0A%20%20%20%20%20%20%20%20elif%20_is_gen_read%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_fill%2C%20_stroke%20%3D%20%22%23dbeafe%22%2C%20%22%232563eb%22%0A%20%20%20%20%20%20%20%20elif%20_is_written%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_fill%2C%20_stroke%20%3D%20%22%23dcfce7%22%2C%20%22%2316a34a%22%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_fill%2C%20_stroke%20%3D%20%22%23f3f4f6%22%2C%20%22%239ca3af%22%0A%0A%20%20%20%20%20%20%20%20%23%20Slot%20rectangle%0A%20%20%20%20%20%20%20%20_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3Crect%20x%3D%22%7B_x%7D%22%20y%3D%22%7B_slot_y%7D%22%20width%3D%22%7B_slot_w%7D%22%20height%3D%22%7B_slot_h%7D%22%20rx%3D%225%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22%7B_fill%7D%22%20stroke%3D%22%7B_stroke%7D%22%20stroke-width%3D%222%22%2F%3E'%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%23%20Slot%20label%0A%20%20%20%20%20%20%20%20_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctext%20x%3D%22%7B_x%20%2B%20_slot_w%20%2F%202%7D%22%20y%3D%22%7B_slot_y%20%2B%20_slot_h%20%2F%202%7D%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'dominant-baseline%3D%22central%22%20font-size%3D%2213%22%20font-weight%3D%22bold%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22%7B_stroke%7D%22%3Eslot%20%7B_i%7D%3C%2Ftext%3E'%0A%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%23%20Write%20step%20markers%20above%20slot%0A%20%20%20%20%20%20%20%20if%20_write_steps%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_step_label%20%3D%20%22%2C%22.join(str(s)%20for%20s%20in%20_write_steps)%0A%20%20%20%20%20%20%20%20%20%20%20%20_marker_color%20%3D%20%22%23dc2626%22%20if%20_collision%20else%20%22%2316a34a%22%0A%20%20%20%20%20%20%20%20%20%20%20%20_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctext%20x%3D%22%7B_x%20%2B%20_slot_w%20%2F%202%7D%22%20y%3D%22%7B_slot_y%20-%208%7D%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-size%3D%2210%22%20fill%3D%22%7B_marker_color%7D%22%3Ewrite%20%23%7B_step_label%7D%3C%2Ftext%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%23%20Generator%20reading%20label%20below%20slot%200%0A%20%20%20%20%20%20%20%20if%20_is_gen_read%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20_gen_label%20%3D%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%E2%96%B2%20gen%20reading%20%E2%80%94%20OVERWRITTEN!%22%20if%20_collision%20else%20%22%E2%96%B2%20gen%20reading%22%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20_gen_color%20%3D%20%22%23dc2626%22%20if%20_collision%20else%20%22%232563eb%22%0A%20%20%20%20%20%20%20%20%20%20%20%20_gen_weight%20%3D%20%22bold%22%20if%20_collision%20else%20%22normal%22%0A%20%20%20%20%20%20%20%20%20%20%20%20_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctext%20x%3D%22%7B_x%20%2B%20_slot_w%20%2F%202%7D%22%20y%3D%22%7B_slot_y%20%2B%20_slot_h%20%2B%2016%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'text-anchor%3D%22middle%22%20font-size%3D%2210%22%20font-weight%3D%22%7B_gen_weight%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22%7B_gen_color%7D%22%3E%7B_gen_label%7D%3C%2Ftext%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20_parts.append(%22%3C%2Fsvg%3E%22)%0A%20%20%20%20_svg%20%3D%20%22%5Cn%22.join(_parts)%0A%0A%20%20%20%20if%20_safe%3A%0A%20%20%20%20%20%20%20%20_callout%20%3D%20mo.callout(mo.md(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22**Safe**%20%E2%80%94%20%7B_n%7D%20slots%2C%20%7B_w%7D%20trainer%20writes%20between%20generator%20reads.%20%22%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22Generator%20finishes%20reading%20slot%200%20before%20trainer%20wraps%20around%20to%20overwrite%20it.%22%0A%20%20%20%20%20%20%20%20)%2C%20kind%3D%22success%22)%0A%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20_callout%20%3D%20mo.callout(mo.md(%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22**RACE%20CONDITION**%20%E2%80%94%20%7B_n%7D%20slots%2C%20%7B_w%7D%20trainer%20writes%20per%20generator%20read.%20%22%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22Trainer%20wraps%20around%20and%20overwrites%20slot%200%20on%20write%20%23%7B_n%7D%20while%20generator%20is%20%22%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22still%20reading%20it!%20Result%3A%20corrupted%20weights%20(silent%20data%20corruption%2C%20not%20an%20error).%5Cn%5Cn%22%0A%20%20%20%20%20%20%20%20%20%20%20%20f%22**Fix**%3A%20increase%20to%20at%20least%20**%7B_w%20%2B%201%7D%20slots**.%22%0A%20%20%20%20%20%20%20%20)%2C%20kind%3D%22danger%22)%0A%0A%20%20%20%20mo.vstack(%5Bmo.Html(_svg)%2C%20_callout%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%207.%20Weight%20Re-sharding%0A%0A%20%20%20%20%23%23%23%20The%20Sharding%20Mismatch%20Problem%0A%0A%20%20%20%20Trainer%20and%20Generator%20often%20have%20**different%20tensor%20layouts**.%20Consider%20an%20example%3A%0A%0A%20%20%20%20%7C%20Role%20%7C%20Parallelism%20%7C%20Sharding%20%7C%0A%20%20%20%20%7C------%7C-------------%7C----------%7C%0A%20%20%20%20%7C%20Trainer%20%7C%20FSDP%20(8%20GPUs)%20%7C%20%60Shard(0)%60%20-%20rows%20split%20across%208%20GPUs%20%7C%0A%20%20%20%20%7C%20Generator%20%7C%20TP%20(2%20GPUs)%20%7C%20%60Shard(1)%60%20-%20columns%20split%20across%202%20GPUs%20%7C%0A%0A%20%20%20%20Therefore%20we%20cannot%20always%20directly%20transfer%20weights%20-%20we%20need%20**re-sharding**.%0A%0A%20%20%20%20Consider%20a%20simple%20example%20where%20the%20trainer%20may%20be%20row-sharded%20and%20the%20generator%20may%20be%20column-sharded%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Trainer%20(row-sharded)%3A%20%20%20%20%20%20%20%20%20%20Generator%20(column-sharded)%3A%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20GPU%200%3A%20rows%200-127%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20GPU%200%20%20%20%E2%94%82%20GPU%201%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%A4%20%20%20%20%20%E2%86%92%20%20%20%20%20%20%E2%94%82%20cols%20%20%20%20%E2%94%82%20cols%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20GPU%201%3A%20rows%20128%2B%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%200-511%20%20%20%E2%94%82%20512%2B%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%B4%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20Two%20Approaches%0A%0A%20%20%20%20**Gather%20Then%20Slice**%20(simple%20but%20wasteful)%3A%0A%20%20%20%20One%20approach%20is%20to%20materialize%20the%20entire%20tensor%2C%20i.e.%20%60gather%60%2C%20transfer%20the%20full%20tensor%2C%20and%20then%20slice%20on%20the%20receiver%20side%3A%0A%20%20%20%201.%20Each%20receiver%20gathers%20ALL%20sender%20shards%20%E2%86%92%20full%20tensor%0A%20%20%20%202.%20Each%20receiver%20slices%20out%20its%20portion%0A%20%20%20%203.%20**Problem**%3A%202x%20redundant%20data%20transfer%0A%0A%20%20%20%20**Routed%20Transfer**%20(optimal)%3A%0A%20%20%20%20A%20more%20efficient%20approach%20is%20to%20only%20transfer%20the%20data%20that%20needs%20to%20be%20transferred%3A%0A%20%20%20%201.%20Pre-compute%20which%20sender%20chunks%20overlap%20with%20which%20receiver%20regions%0A%20%20%20%202.%20Send%20only%20the%20exact%20chunks%20needed%0A%20%20%20%203.%20**Benefit**%3A%20Minimal%20bandwidth%2C%20no%20redundancy%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20GATHER%3A%20G0%20receives%20T0%2CT1%2CT2%2CT3%20%E2%86%92%20discards%20T2%2CT3%20(50%25%20waste!)%0A%20%20%20%20ROUTED%3A%20G0%20receives%20T0%2CT1%20only%20%E2%86%92%20exactly%20what%20it%20needs%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20routed%20approach%20batches%20all%20needed%20transfers%20into%20one%20plan.%0A%20%20%20%20Pre-compute%20the%20plan%20once%20at%20handshake%2C%20execute%20it%20on%20each%20sync.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20dataclasses%20import%20dataclass%0A%20%20%20%20from%20typing%20import%20List%2C%20Tuple%0A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20ShardMetadata%3A%0A%20%20%20%20%20%20%20%20%22%22%22Metadata%20describing%20a%20tensor%20shard.%22%22%22%0A%20%20%20%20%20%20%20%20rank%3A%20int%0A%20%20%20%20%20%20%20%20global_shape%3A%20Tuple%5Bint%2C%20...%5D%0A%20%20%20%20%20%20%20%20offset%3A%20Tuple%5Bint%2C%20...%5D%20%20%23%20Start%20position%20in%20global%20tensor%0A%20%20%20%20%20%20%20%20local_shape%3A%20Tuple%5Bint%2C%20...%5D%20%20%23%20Shape%20of%20this%20shard%0A%0A%20%20%20%20%40dataclass%0A%20%20%20%20class%20TransferChunk%3A%0A%20%20%20%20%20%20%20%20%22%22%22A%20chunk%20to%20transfer%20from%20sender%20to%20receiver.%22%22%22%0A%20%20%20%20%20%20%20%20sender_rank%3A%20int%0A%20%20%20%20%20%20%20%20receiver_rank%3A%20int%0A%20%20%20%20%20%20%20%20sender_offset%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Where%20to%20read%20from%20sender%0A%20%20%20%20%20%20%20%20receiver_offset%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Where%20to%20write%20in%20receiver%0A%20%20%20%20%20%20%20%20shape%3A%20Tuple%5Bint%2C%20int%5D%20%20%23%20Shape%20of%20the%20chunk%0A%0A%20%20%20%20def%20compute_shard_metadata(%0A%20%20%20%20%20%20%20%20global_shape%3A%20Tuple%5Bint%2C%20int%5D%2C%0A%20%20%20%20%20%20%20%20num_ranks%3A%20int%2C%0A%20%20%20%20%20%20%20%20shard_dim%3A%20int%2C%0A%20%20%20%20)%20-%3E%20List%5BShardMetadata%5D%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20shard%20metadata%20for%20a%20given%20sharding.%22%22%22%0A%20%20%20%20%20%20%20%20shards%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20dim_size%20%3D%20global_shape%5Bshard_dim%5D%0A%20%20%20%20%20%20%20%20shard_size%20%3D%20dim_size%20%2F%2F%20num_ranks%0A%0A%20%20%20%20%20%20%20%20for%20rank%20in%20range(num_ranks)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%20%3D%20%5B0%2C%200%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20local_shape%20%3D%20list(global_shape)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20offset%5Bshard_dim%5D%20%3D%20rank%20*%20shard_size%0A%20%20%20%20%20%20%20%20%20%20%20%20local_shape%5Bshard_dim%5D%20%3D%20shard_size%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20shards.append(ShardMetadata(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20rank%3Drank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20global_shape%3Dglobal_shape%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20offset%3Dtuple(offset)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20local_shape%3Dtuple(local_shape)%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20))%0A%0A%20%20%20%20%20%20%20%20return%20shards%0A%0A%20%20%20%20def%20compute_overlap(%0A%20%20%20%20%20%20%20%20sender%3A%20ShardMetadata%2C%0A%20%20%20%20%20%20%20%20receiver%3A%20ShardMetadata%2C%0A%20%20%20%20)%20-%3E%20%22TransferChunk%20%7C%20None%22%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20overlap%20between%20sender%20and%20receiver%20shards.%22%22%22%0A%20%20%20%20%20%20%20%20s_start%20%3D%20sender.offset%0A%20%20%20%20%20%20%20%20s_end%20%3D%20(s_start%5B0%5D%20%2B%20sender.local_shape%5B0%5D%2C%20s_start%5B1%5D%20%2B%20sender.local_shape%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20r_start%20%3D%20receiver.offset%0A%20%20%20%20%20%20%20%20r_end%20%3D%20(r_start%5B0%5D%20%2B%20receiver.local_shape%5B0%5D%2C%20r_start%5B1%5D%20%2B%20receiver.local_shape%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20inter_start%20%3D%20(max(s_start%5B0%5D%2C%20r_start%5B0%5D)%2C%20max(s_start%5B1%5D%2C%20r_start%5B1%5D))%0A%20%20%20%20%20%20%20%20inter_end%20%3D%20(min(s_end%5B0%5D%2C%20r_end%5B0%5D)%2C%20min(s_end%5B1%5D%2C%20r_end%5B1%5D))%0A%0A%20%20%20%20%20%20%20%20if%20inter_start%5B0%5D%20%3E%3D%20inter_end%5B0%5D%20or%20inter_start%5B1%5D%20%3E%3D%20inter_end%5B1%5D%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20None%0A%0A%20%20%20%20%20%20%20%20shape%20%3D%20(inter_end%5B0%5D%20-%20inter_start%5B0%5D%2C%20inter_end%5B1%5D%20-%20inter_start%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20sender_local%20%3D%20(inter_start%5B0%5D%20-%20s_start%5B0%5D%2C%20inter_start%5B1%5D%20-%20s_start%5B1%5D)%0A%20%20%20%20%20%20%20%20receiver_local%20%3D%20(inter_start%5B0%5D%20-%20r_start%5B0%5D%2C%20inter_start%5B1%5D%20-%20r_start%5B1%5D)%0A%0A%20%20%20%20%20%20%20%20return%20TransferChunk(%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_rank%3Dsender.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_rank%3Dreceiver.rank%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20sender_offset%3Dsender_local%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20receiver_offset%3Dreceiver_local%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20shape%3Dshape%2C%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20def%20compute_transfer_plan(%0A%20%20%20%20%20%20%20%20sender_shards%3A%20List%5BShardMetadata%5D%2C%0A%20%20%20%20%20%20%20%20receiver_shards%3A%20List%5BShardMetadata%5D%2C%0A%20%20%20%20)%20-%3E%20List%5BTransferChunk%5D%3A%0A%20%20%20%20%20%20%20%20%22%22%22Compute%20all%20transfers%20needed%20for%20re-sharding.%22%22%22%0A%20%20%20%20%20%20%20%20transfers%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20sender%20in%20sender_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20receiver%20in%20receiver_shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20chunk%20%3D%20compute_overlap(sender%2C%20receiver)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20chunk%20is%20not%20None%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20transfers.append(chunk)%0A%20%20%20%20%20%20%20%20return%20transfers%0A%0A%20%20%20%20def%20render_resharding_svg(trainer_shards%2C%20gen_shards%2C%20transfer_plan%2C%20global_shape)%3A%0A%20%20%20%20%20%20%20%20%22%22%22Render%20a%20color-matched%20visualization%20of%20the%20re-sharding%20transfer%20plan.%0A%0A%20%20%20%20%20%20%20%20Returns%20HTML%20string%20with%3A%0A%20%20%20%20%20%20%20%20-%20Two%20grids%20(trainer%20left%2C%20generator%20right)%20where%20each%20transfer%20chunk%0A%20%20%20%20%20%20%20%20%20%20is%20colored%20the%20same%20on%20both%20sides%20so%20you%20can%20visually%20match%20them.%0A%20%20%20%20%20%20%20%20-%20A%20transfer%20matrix%20table%20below%20showing%20which%20chunks%20move%20where.%0A%20%20%20%20%20%20%20%20%22%22%22%0A%20%20%20%20%20%20%20%20%23%20Layout%20constants%0A%20%20%20%20%20%20%20%20grid_w%2C%20grid_h%20%3D%20280%2C%20240%0A%20%20%20%20%20%20%20%20left_x%2C%20right_x%20%3D%2080%2C%20520%0A%20%20%20%20%20%20%20%20top_y%20%3D%2050%0A%20%20%20%20%20%20%20%20svg_w%20%3D%20880%0A%20%20%20%20%20%20%20%20rows%2C%20cols%20%3D%20global_shape%0A%0A%20%20%20%20%20%20%20%20%23%20Generate%20distinct%20colors%20for%20each%20transfer%0A%20%20%20%20%20%20%20%20%23%20Use%20HSL%20with%20evenly%20spaced%20hues%20for%20maximum%20distinction%0A%20%20%20%20%20%20%20%20n_transfers%20%3D%20len(transfer_plan)%0A%20%20%20%20%20%20%20%20transfer_colors%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20for%20i%20in%20range(max(n_transfers%2C%201))%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20hue%20%3D%20(i%20*%20360%20%2F%2F%20max(n_transfers%2C%201)%20%2B%2010)%20%25%20360%0A%20%20%20%20%20%20%20%20%20%20%20%20transfer_colors.append(f%22hsl(%7Bhue%7D%2C%2070%25%2C%2055%25)%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Also%20need%20light%20shard%20background%20colors%20(just%20for%20shard%20boundaries)%0A%20%20%20%20%20%20%20%20shard_border_color%20%3D%20%22%23444%22%0A%0A%20%20%20%20%20%20%20%20parts%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20svg_h%20%3D%20top_y%20%2B%20grid_h%20%2B%2050%0A%20%20%20%20%20%20%20%20parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22%7Bsvg_w%7D%22%20height%3D%22%7Bsvg_h%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'viewBox%3D%220%200%20%7Bsvg_w%7D%20%7Bsvg_h%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'style%3D%22font-family%3A%20-apple-system%2C%20sans-serif%3B%20font-size%3A%2012px%3B%22%3E'%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Title%20labels%0A%20%20%20%20%20%20%20%20parts.append(f'%3Ctext%20x%3D%22%7Bleft_x%20%2B%20grid_w%20%2F%2F%202%7D%22%20y%3D%2222%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-weight%3D%22bold%22%20font-size%3D%2215%22%3ETrainer%20shards%3C%2Ftext%3E')%0A%20%20%20%20%20%20%20%20parts.append(f'%3Ctext%20x%3D%22%7Bright_x%20%2B%20grid_w%20%2F%2F%202%7D%22%20y%3D%2222%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-weight%3D%22bold%22%20font-size%3D%2215%22%3EGenerator%20shards%3C%2Ftext%3E')%0A%0A%20%20%20%20%20%20%20%20%23%20Subtitle%20showing%20shard%20dim%0A%20%20%20%20%20%20%20%20t_dim%20%3D%20%22row%22%20if%20(trainer_shards%20and%20trainer_shards%5B0%5D.offset%20%3D%3D%20(0%2C%200)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20and%20len(trainer_shards)%20%3E%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20and%20trainer_shards%5B1%5D.offset%5B0%5D%20%3E%200)%20else%20%22col%22%0A%20%20%20%20%20%20%20%20g_dim%20%3D%20%22row%22%20if%20(gen_shards%20and%20gen_shards%5B0%5D.offset%20%3D%3D%20(0%2C%200)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20and%20len(gen_shards)%20%3E%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20and%20gen_shards%5B1%5D.offset%5B0%5D%20%3E%200)%20else%20%22col%22%0A%20%20%20%20%20%20%20%20parts.append(f'%3Ctext%20x%3D%22%7Bleft_x%20%2B%20grid_w%20%2F%2F%202%7D%22%20y%3D%2238%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-size%3D%2211%22%20fill%3D%22%23666%22%3E%7Blen(trainer_shards)%7D%20GPUs%2C%20%7Bt_dim%7D-sharded%3C%2Ftext%3E')%0A%20%20%20%20%20%20%20%20parts.append(f'%3Ctext%20x%3D%22%7Bright_x%20%2B%20grid_w%20%2F%2F%202%7D%22%20y%3D%2238%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-size%3D%2211%22%20fill%3D%22%23666%22%3E%7Blen(gen_shards)%7D%20GPUs%2C%20%7Bg_dim%7D-sharded%3C%2Ftext%3E')%0A%0A%20%20%20%20%20%20%20%20%23%20Helper%3A%20map%20global%20(row%2C%20col%2C%20h%2C%20w)%20to%20pixel%20rect%0A%20%20%20%20%20%20%20%20def%20to_px(base_x%2C%20r%2C%20c%2C%20h%2C%20w)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20px%20%3D%20base_x%20%2B%20(c%20%2F%20cols)%20*%20grid_w%0A%20%20%20%20%20%20%20%20%20%20%20%20py%20%3D%20top_y%20%2B%20(r%20%2F%20rows)%20*%20grid_h%0A%20%20%20%20%20%20%20%20%20%20%20%20pw%20%3D%20(w%20%2F%20cols)%20*%20grid_w%0A%20%20%20%20%20%20%20%20%20%20%20%20ph%20%3D%20(h%20%2F%20rows)%20*%20grid_h%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20px%2C%20py%2C%20pw%2C%20ph%0A%0A%20%20%20%20%20%20%20%20%23%20Draw%20transfer%20chunks%20as%20colored%20rectangles%20on%20BOTH%20grids%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(transfer_plan)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20color%20%3D%20transfer_colors%5Bi%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Find%20sender%2Freceiver%20shard%20global%20offsets%0A%20%20%20%20%20%20%20%20%20%20%20%20s_shard%20%3D%20next(s%20for%20s%20in%20trainer_shards%20if%20s.rank%20%3D%3D%20t.sender_rank)%0A%20%20%20%20%20%20%20%20%20%20%20%20r_shard%20%3D%20next(s%20for%20s%20in%20gen_shards%20if%20s.rank%20%3D%3D%20t.receiver_rank)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Trainer%20side%3A%20chunk%20in%20global%20coords%0A%20%20%20%20%20%20%20%20%20%20%20%20s_row%20%3D%20s_shard.offset%5B0%5D%20%2B%20t.sender_offset%5B0%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20s_col%20%3D%20s_shard.offset%5B1%5D%20%2B%20t.sender_offset%5B1%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20px%2C%20py%2C%20pw%2C%20ph%20%3D%20to_px(left_x%2C%20s_row%2C%20s_col%2C%20t.shape%5B0%5D%2C%20t.shape%5B1%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Crect%20x%3D%22%7Bpx%3A.1f%7D%22%20y%3D%22%7Bpy%3A.1f%7D%22%20width%3D%22%7Bpw%3A.1f%7D%22%20height%3D%22%7Bph%3A.1f%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22%7Bcolor%7D%22%20fill-opacity%3D%220.55%22%20stroke%3D%22%7Bcolor%7D%22%20stroke-width%3D%220.5%22%2F%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Generator%20side%3A%20chunk%20in%20global%20coords%0A%20%20%20%20%20%20%20%20%20%20%20%20r_row%20%3D%20r_shard.offset%5B0%5D%20%2B%20t.receiver_offset%5B0%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20r_col%20%3D%20r_shard.offset%5B1%5D%20%2B%20t.receiver_offset%5B1%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20px%2C%20py%2C%20pw%2C%20ph%20%3D%20to_px(right_x%2C%20r_row%2C%20r_col%2C%20t.shape%5B0%5D%2C%20t.shape%5B1%5D)%0A%20%20%20%20%20%20%20%20%20%20%20%20parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Crect%20x%3D%22%7Bpx%3A.1f%7D%22%20y%3D%22%7Bpy%3A.1f%7D%22%20width%3D%22%7Bpw%3A.1f%7D%22%20height%3D%22%7Bph%3A.1f%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22%7Bcolor%7D%22%20fill-opacity%3D%220.55%22%20stroke%3D%22%7Bcolor%7D%22%20stroke-width%3D%220.5%22%2F%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20%23%20Draw%20shard%20boundary%20outlines%20and%20rank%20labels%20on%20top%0A%20%20%20%20%20%20%20%20def%20draw_shard_outlines(shards%2C%20base_x%2C%20prefix)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20s%20in%20shards%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20x%20%3D%20base_x%20%2B%20(s.offset%5B1%5D%20%2F%20cols)%20*%20grid_w%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20y%20%3D%20top_y%20%2B%20(s.offset%5B0%5D%20%2F%20rows)%20*%20grid_h%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20w%20%3D%20(s.local_shape%5B1%5D%20%2F%20cols)%20*%20grid_w%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20h%20%3D%20(s.local_shape%5B0%5D%20%2F%20rows)%20*%20grid_h%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Crect%20x%3D%22%7Bx%3A.1f%7D%22%20y%3D%22%7By%3A.1f%7D%22%20width%3D%22%7Bw%3A.1f%7D%22%20height%3D%22%7Bh%3A.1f%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22none%22%20stroke%3D%22%7Bshard_border_color%7D%22%20stroke-width%3D%222%22%2F%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Rank%20label%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20cx%2C%20cy%20%3D%20x%20%2B%20w%20%2F%202%2C%20y%20%2B%20h%20%2F%202%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctext%20x%3D%22%7Bcx%3A.1f%7D%22%20y%3D%22%7Bcy%3A.1f%7D%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'dominant-baseline%3D%22central%22%20font-weight%3D%22bold%22%20font-size%3D%2213%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22%23222%22%3E%7Bprefix%7D%7Bs.rank%7D%3C%2Ftext%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20draw_shard_outlines(trainer_shards%2C%20left_x%2C%20%22T%22)%0A%20%20%20%20%20%20%20%20draw_shard_outlines(gen_shards%2C%20right_x%2C%20%22G%22)%0A%0A%20%20%20%20%20%20%20%20%23%20Outer%20boxes%0A%20%20%20%20%20%20%20%20parts.append(f'%3Crect%20x%3D%22%7Bleft_x%7D%22%20y%3D%22%7Btop_y%7D%22%20width%3D%22%7Bgrid_w%7D%22%20height%3D%22%7Bgrid_h%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22none%22%20stroke%3D%22%23222%22%20stroke-width%3D%222.5%22%2F%3E')%0A%20%20%20%20%20%20%20%20parts.append(f'%3Crect%20x%3D%22%7Bright_x%7D%22%20y%3D%22%7Btop_y%7D%22%20width%3D%22%7Bgrid_w%7D%22%20height%3D%22%7Bgrid_h%7D%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'fill%3D%22none%22%20stroke%3D%22%23222%22%20stroke-width%3D%222.5%22%2F%3E')%0A%0A%20%20%20%20%20%20%20%20%23%20%22%3D%22%20sign%20between%20grids%20to%20show%20equivalence%0A%20%20%20%20%20%20%20%20mid_x%20%3D%20(left_x%20%2B%20grid_w%20%2B%20right_x)%20%2F%2F%202%0A%20%20%20%20%20%20%20%20mid_y%20%3D%20top_y%20%2B%20grid_h%20%2F%2F%202%0A%20%20%20%20%20%20%20%20parts.append(f'%3Ctext%20x%3D%22%7Bmid_x%7D%22%20y%3D%22%7Bmid_y%7D%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'dominant-baseline%3D%22central%22%20font-size%3D%2228%22%20fill%3D%22%23888%22%3E%3D%3C%2Ftext%3E')%0A%20%20%20%20%20%20%20%20parts.append(f'%3Ctext%20x%3D%22%7Bmid_x%7D%22%20y%3D%22%7Bmid_y%20%2B%2022%7D%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-size%3D%2210%22%20fill%3D%22%23888%22%3Esame%20data%3C%2Ftext%3E')%0A%0A%20%20%20%20%20%20%20%20%23%20Global%20shape%20label%0A%20%20%20%20%20%20%20%20parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctext%20x%3D%22%7Bsvg_w%20%2F%2F%202%7D%22%20y%3D%22%7Bsvg_h%20-%208%7D%22%20text-anchor%3D%22middle%22%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'font-size%3D%2211%22%20fill%3D%22%23888%22%3EGlobal%20tensor%3A%20%7Brows%7D%20x%20%7Bcols%7D%3C%2Ftext%3E'%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20%20%20%20%20parts.append(%22%3C%2Fsvg%3E%22)%0A%20%20%20%20%20%20%20%20svg_str%20%3D%20%22%5Cn%22.join(parts)%0A%0A%20%20%20%20%20%20%20%20%23%20Build%20transfer%20matrix%20HTML%20table%0A%20%20%20%20%20%20%20%20n_trainers%20%3D%20len(trainer_shards)%0A%20%20%20%20%20%20%20%20n_gens%20%3D%20len(gen_shards)%0A%0A%20%20%20%20%20%20%20%20%23%20Build%20lookup%3A%20(sender_rank%2C%20receiver_rank)%20-%3E%20(transfer_index%2C%20chunk)%0A%20%20%20%20%20%20%20%20transfer_lookup%20%3D%20%7B%7D%0A%20%20%20%20%20%20%20%20for%20i%2C%20t%20in%20enumerate(transfer_plan)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20transfer_lookup%5B(t.sender_rank%2C%20t.receiver_rank)%5D%20%3D%20(i%2C%20t)%0A%0A%20%20%20%20%20%20%20%20table_parts%20%3D%20%5B%0A%20%20%20%20%20%20%20%20%20%20%20%20'%3Ctable%20style%3D%22border-collapse%3A%20collapse%3B%20margin-top%3A%2012px%3B%20font-family%3A%20monospace%3B%20font-size%3A%2012px%3B%22%3E'%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20'%3Ctr%3E%3Cth%20style%3D%22border%3A%201px%20solid%20%23ccc%3B%20padding%3A%206px%2010px%3B%20background%3A%20%23f5f5f5%3B%22%3E%3C%2Fth%3E'%2C%0A%20%20%20%20%20%20%20%20%5D%0A%20%20%20%20%20%20%20%20for%20g%20in%20range(n_gens)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20table_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Cth%20style%3D%22border%3A%201px%20solid%20%23ccc%3B%20padding%3A%206px%2010px%3B%20background%3A%20%23f5f5f5%3B%22%3EG%7Bg%7D%3C%2Fth%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20table_parts.append('%3C%2Ftr%3E')%0A%0A%20%20%20%20%20%20%20%20for%20t_rank%20in%20range(n_trainers)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20table_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctr%3E%3Ctd%20style%3D%22border%3A%201px%20solid%20%23ccc%3B%20padding%3A%206px%2010px%3B%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'background%3A%20%23f5f5f5%3B%20font-weight%3A%20bold%3B%22%3ET%7Bt_rank%7D%3C%2Ftd%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20g_rank%20in%20range(n_gens)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20key%20%3D%20(t_rank%2C%20g_rank)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20key%20in%20transfer_lookup%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20idx%2C%20chunk%20%3D%20transfer_lookup%5Bkey%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20color%20%3D%20transfer_colors%5Bidx%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%3Ctd%20style%3D%22border%3A%201px%20solid%20%23ccc%3B%20padding%3A%206px%2010px%3B%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'background%3A%20%7Bcolor%7D%3B%20color%3A%20white%3B%20text-align%3A%20center%3B%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'font-weight%3A%20bold%3B%20text-shadow%3A%200%201px%202px%20rgba(0%2C0%2C0%2C0.4)%3B%22%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20f'%7Bchunk.shape%5B0%5D%7Dx%7Bchunk.shape%5B1%5D%7D%3C%2Ftd%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20table_parts.append(%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'%3Ctd%20style%3D%22border%3A%201px%20solid%20%23ccc%3B%20padding%3A%206px%2010px%3B%20'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20'text-align%3A%20center%3B%20color%3A%20%23ccc%3B%22%3E%26mdash%3B%3C%2Ftd%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20)%0A%20%20%20%20%20%20%20%20%20%20%20%20table_parts.append('%3C%2Ftr%3E')%0A%0A%20%20%20%20%20%20%20%20table_parts.append('%3C%2Ftable%3E')%0A%20%20%20%20%20%20%20%20table_str%20%3D%20%22%5Cn%22.join(table_parts)%0A%0A%20%20%20%20%20%20%20%20%23%20Combine%20SVG%20%2B%20table%0A%20%20%20%20%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3Cdiv%20style%3D%22display%3A%20flex%3B%20flex-direction%3A%20column%3B%20align-items%3A%20center%3B%22%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%7Bsvg_str%7D'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3Cdiv%20style%3D%22margin-top%3A%204px%3B%20font-size%3A%2012px%3B%20color%3A%20%23666%3B%22%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'Matching%20colors%20%3D%20same%20data%20chunk.%20Matrix%20shows%20chunk%20shapes%20transferred.%3C%2Fdiv%3E'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%7Btable_str%7D'%0A%20%20%20%20%20%20%20%20%20%20%20%20f'%3C%2Fdiv%3E'%0A%20%20%20%20%20%20%20%20)%0A%0A%20%20%20%20return%20compute_shard_metadata%2C%20compute_transfer_plan%2C%20render_resharding_svg%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20%23%20Interactive%20controls%20for%20re-sharding%20visualization%0A%20%20%20%20trainer_gpu_slider%20%3D%20mo.ui.slider(1%2C%208%2C%20value%3D4%2C%20label%3D%22Trainer%20GPUs%22)%0A%20%20%20%20gen_gpu_slider%20%3D%20mo.ui.slider(1%2C%208%2C%20value%3D2%2C%20label%3D%22Generator%20GPUs%22)%0A%20%20%20%20trainer_dim_dropdown%20%3D%20mo.ui.dropdown(%0A%20%20%20%20%20%20%20%20options%3D%7B%22Row%20(dim%200)%22%3A%200%2C%20%22Col%20(dim%201)%22%3A%201%7D%2C%0A%20%20%20%20%20%20%20%20value%3D%22Row%20(dim%200)%22%2C%0A%20%20%20%20%20%20%20%20label%3D%22Trainer%20shard%20dim%22%2C%0A%20%20%20%20)%0A%20%20%20%20gen_dim_dropdown%20%3D%20mo.ui.dropdown(%0A%20%20%20%20%20%20%20%20options%3D%7B%22Row%20(dim%200)%22%3A%200%2C%20%22Col%20(dim%201)%22%3A%201%7D%2C%0A%20%20%20%20%20%20%20%20value%3D%22Col%20(dim%201)%22%2C%0A%20%20%20%20%20%20%20%20label%3D%22Generator%20shard%20dim%22%2C%0A%20%20%20%20)%0A%0A%20%20%20%20mo.hstack(%0A%20%20%20%20%20%20%20%20%5Btrainer_gpu_slider%2C%20trainer_dim_dropdown%2C%20gen_gpu_slider%2C%20gen_dim_dropdown%5D%2C%0A%20%20%20%20%20%20%20%20justify%3D%22center%22%2C%0A%20%20%20%20%20%20%20%20gap%3D1%2C%0A%20%20%20%20)%0A%20%20%20%20return%20(%0A%20%20%20%20%20%20%20%20gen_dim_dropdown%2C%0A%20%20%20%20%20%20%20%20gen_gpu_slider%2C%0A%20%20%20%20%20%20%20%20trainer_dim_dropdown%2C%0A%20%20%20%20%20%20%20%20trainer_gpu_slider%2C%0A%20%20%20%20)%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20compute_shard_metadata%2C%0A%20%20%20%20compute_transfer_plan%2C%0A%20%20%20%20gen_dim_dropdown%2C%0A%20%20%20%20gen_gpu_slider%2C%0A%20%20%20%20mo%2C%0A%20%20%20%20render_resharding_svg%2C%0A%20%20%20%20trainer_dim_dropdown%2C%0A%20%20%20%20trainer_gpu_slider%2C%0A)%3A%0A%20%20%20%20%23%20Compute%20shards%20and%20transfer%20plan%20based%20on%20widget%20values%0A%20%20%20%20_global_shape%20%3D%20(512%2C%20512)%0A%20%20%20%20_t_shards%20%3D%20compute_shard_metadata(_global_shape%2C%20trainer_gpu_slider.value%2C%20trainer_dim_dropdown.value)%0A%20%20%20%20_g_shards%20%3D%20compute_shard_metadata(_global_shape%2C%20gen_gpu_slider.value%2C%20gen_dim_dropdown.value)%0A%20%20%20%20_plan%20%3D%20compute_transfer_plan(_t_shards%2C%20_g_shards)%0A%0A%20%20%20%20_svg%20%3D%20render_resharding_svg(_t_shards%2C%20_g_shards%2C%20_plan%2C%20_global_shape)%0A%0A%20%20%20%20%23%20Compute%20stats%20for%20the%20callout%0A%20%20%20%20_routed_bytes%20%3D%20sum(t.shape%5B0%5D%20*%20t.shape%5B1%5D%20*%202%20for%20t%20in%20_plan)%20%20%23%20bf16%20%3D%202%20bytes%0A%20%20%20%20_gather_bytes%20%3D%20_global_shape%5B0%5D%20*%20_global_shape%5B1%5D%20*%202%20*%20gen_gpu_slider.value%0A%20%20%20%20_waste_pct%20%3D%20(1%20-%20_routed_bytes%20%2F%20_gather_bytes)%20*%20100%20if%20_gather_bytes%20%3E%200%20else%200%0A%0A%20%20%20%20resharding_stats%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%22transfers%22%3A%20len(_plan)%2C%0A%20%20%20%20%20%20%20%20%22routed_bytes%22%3A%20_routed_bytes%2C%0A%20%20%20%20%20%20%20%20%22gather_bytes%22%3A%20_gather_bytes%2C%0A%20%20%20%20%20%20%20%20%22waste_pct%22%3A%20_waste_pct%2C%0A%20%20%20%20%7D%0A%0A%20%20%20%20_stats_md%20%3D%20mo.md(f%22%22%22%0A%20%20%20%20**Transfer%20Plan%20Stats**%20%7C%20**Transfers**%3A%20%7Blen(_plan)%7D%20chunks%20%7C%20**Routed**%3A%20%7B_routed_bytes%20%2F%201024%3A.1f%7D%20KB%20%7C%20**Gather**%3A%20%7B_gather_bytes%20%2F%201024%3A.1f%7D%20KB%20%7C%20**Saved**%3A%20%7B_waste_pct%3A.0f%7D%25%0A%20%20%20%20%22%22%22)%0A%0A%20%20%20%20mo.vstack(%5Bmo.Html(_svg)%2C%20mo.callout(_stats_md%2C%20kind%3D%22info%22)%5D)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%208.%20Putting%20It%20All%20Together%0A%0A%20%20%20%20The%20full%20async%20RL%20weight%20sync%20pattern%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20TRAINER%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%201.%20Train%20step%20completes%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%202.%20Copy%20weights%20to%20CPU%20staging%20buffer%20(non-blocking%20D2H)%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%203.%20Publish%20to%20circular%20buffer%20with%20version%20tag%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%204.%20Continue%20training%20(no%20blocking!)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20CIRCULAR%20BUFFER%20(CPU%2C%20RDMA-registered)%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%5Bslot%200%3A%20v3%5D%20%5Bslot%201%3A%20v4%5D%20%5Bslot%202%3A%20v5%5D%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%86%91%20latest%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20GENERATOR%200%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20GENERATOR%201%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20GENERATOR%202%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%20%20%20%E2%94%82%20After%20gen%20done%3A%20%E2%94%82%0A%20%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%20%20%20%E2%94%82%201.%20Get%20latest%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20version%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%20%20%20%E2%94%82%202.%20RDMA%20read%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20%E2%86%92%20GPU%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%20%20%20%E2%94%82%203.%20Re-shard%20if%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%20%20%20%E2%94%82%20%20%20%20needed%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Key%20properties%3A**%0A%20%20%20%20-%20Trainer%20never%20blocks%20waiting%20for%20generators%0A%20%20%20%20-%20Generators%20pull%20directly%20to%20GPU%20when%20*they're*%20ready%0A%20%20%20%20-%20Re-sharding%20happens%20locally%20on%20each%20generator%0A%20%20%20%20-%20Circular%20buffer%20bounds%20memory%2C%20reuses%20RDMA%20registrations%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%23%20Live%20Demo%3A%20Async%20Weight%20Sync%0A%0A%20%20%20%20Let's%20see%20this%20in%20action!%20We'll%20simulate%20the%20core%20async%20RL%20pattern%3A%0A%0A%20%20%20%20-%20**1%20Trainer**%3A%20Runs%20training%20steps%2C%20publishes%20new%20weights%20to%20a%203-slot%20circular%20buffer%0A%20%20%20%20-%20**4%20Generators**%3A%20Each%20independently%20syncs%20to%20latest%20weights%2C%20then%20generates%0A%0A%20%20%20%20All%205%20actors%20run%20**concurrently%20and%20independently**.%20The%20trainer%20never%20waits%20for%20generators%2C%0A%20%20%20%20and%20each%20generator%20grabs%20weights%20whenever%20it's%20ready%20(at%20slightly%20different%20rates%20to%20show%0A%20%20%20%20the%20async%20behavior).%20To%20verify%20correctness%2C%20we%20set%20weights%20to%20%60version%60%20and%20check%20on%20read.%0A%0A%20%20%20%20**Race%20condition%20safety**%3A%20The%20circular%20buffer's%20slot%20count%20is%20tuned%20so%20that%0A%20%20%20%20%60buffer_size%20%C3%97%20update_interval%20%3E%3E%20sync_time%60.%20This%20ensures%20a%20slot%20isn't%20overwritten%0A%20%20%20%20while%20a%20generator%20is%20reading%20it.%20In%20this%20demo%3A%205%20slots%2C%20~1s%20between%20trainer%20updates%2C%0A%20%20%20%20RDMA%20sync%20takes%20~ms%2C%20so%20a%20race%20is%20effectively%20impossible.%20In%20production%2C%20tune%0A%20%20%20%20%60buffer_size%60%20based%20on%20actual%20sync%20time%20and%20update%20frequency.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(%0A%20%20%20%20Actor%2C%0A%20%20%20%20RDMABuffer%2C%0A%20%20%20%20current_rank%2C%0A%20%20%20%20endpoint%2C%0A%20%20%20%20is_rdma_available%2C%0A%20%20%20%20this_host%2C%0A%20%20%20%20torch%2C%0A)%3A%0A%20%20%20%20import%20threading%0A%0A%20%20%20%20def%20show_fallback()%3A%0A%20%20%20%20%20%20%20%20print(%22(RDMA%20not%20available%20-%20showing%20conceptual%20flow)%5Cn%22)%0A%20%20%20%20%20%20%20%20print(%22What%20would%20happen%20with%20RDMA%3A%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%5BTrainer%5D%20Publishes%20v0%2C%20v1%2C%20v2...%20to%20circular%20buffer%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20%5BGenerator%5D%20Syncs%20when%20ready%2C%20verifies%20weights%20match%20version%22)%0A%20%20%20%20%20%20%20%20print(%22%20%20Both%20run%20independently%2C%20no%20blocking!%22)%0A%0A%20%20%20%20try%3A%0A%20%20%20%20%20%20%20%20if%20not%20is_rdma_available()%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20show_fallback()%0A%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Trainer(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Trainer%20with%20circular%20buffer%20for%20weight%20versioning.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20weight_size%3A%20int)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.n_slots%20%3D%205%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.version%20%3D%200%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles%20%3D%20%5B%5D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(self.n_slots)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot%20%3D%20torch.zeros(weight_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots.append(slot)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.handles.append(RDMABuffer(slot.view(torch.uint8).flatten()))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%5D%20Initialized%20%7Bself.n_slots%7D-slot%20circular%20buffer%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20get_latest(self)%20-%3E%20tuple%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20self.version%20%3D%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20None%2C%20-1%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20v%20%3D%20self.version%20-%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.handles%5Bv%20%25%20self.n_slots%5D%2C%20v%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20train_step(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Single%20training%20step%3A%20publish%20new%20weights.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20sys%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20slot_idx%20%3D%20self.version%20%25%20self.n_slots%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.slots%5Bslot_idx%5D.fill_(float(self.version))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.version%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BTrainer%5D%20Published%20v%7Bself.version%20-%201%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sys.stdout.flush()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.version%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20class%20Generator(Actor)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Generator%20that%20syncs%20weights%20and%20generates.%22%22%22%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20__init__(self%2C%20weight_size%3A%20int%2C%20trainer)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.gen_id%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.trainer%20%3D%20trainer%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.weights%20%3D%20torch.zeros(weight_size%2C%20dtype%3Dtorch.float32)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.weight_bytes%20%3D%20self.weights.view(torch.uint8).flatten()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.current_version%20%3D%20-1%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGen%20%7Bself.gen_id%7D%5D%20Initialized%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20def%20generate_step(self)%20-%3E%20int%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%22%22%22Single%20generate%20step%3A%20sync%20if%20needed%2C%20then%20generate.%22%22%22%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20sys%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20Try%20to%20sync%20weights%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle%2C%20version%20%3D%20self.trainer.get_latest.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20handle%20is%20not%20None%20and%20version%20%3E%20self.current_version%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20handle.read_into(self.weight_bytes).get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20actual%20%3D%20int(self.weights%5B0%5D.item())%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20actual%20%3E%3D%20version%3A%20%20%23%20%3E%3D%20not%20%3D%3D%20%3A%20a%20later%20version%20may%20have%20written%20to%20same%20slot%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20self.current_version%20%3D%20actual%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGen%20%7Bself.gen_id%7D%5D%20Synced%20to%20v%7Bactual%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20sys.stdout.flush()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20return%20self.current_version%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Spawn%20trainer%20and%20generators%0A%20%20%20%20%20%20%20%20%20%20%20%20n_generators%20%3D%204%0A%20%20%20%20%20%20%20%20%20%20%20%20trainer_proc%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%201%7D)%0A%20%20%20%20%20%20%20%20%20%20%20%20generator_procs%20%3D%20this_host().spawn_procs(per_host%3D%7B%22procs%22%3A%20n_generators%7D)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20trainer%20%3D%20trainer_proc.spawn(%22trainer%22%2C%20Trainer%2C%20weight_size%3D1024)%0A%20%20%20%20%20%20%20%20%20%20%20%20generators%20%3D%20generator_procs.spawn(%22generators%22%2C%20Generator%2C%20weight_size%3D1024%2C%20trainer%3Dtrainer)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22%5Cn---%20Running%20async%20RL%20simulation%20---%5Cn%22)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Results%20storage%0A%20%20%20%20%20%20%20%20%20%20%20%20_results%20%3D%20%7B%22trainer%22%3A%20None%2C%20%22generators%22%3A%20%5BNone%5D%20*%20n_generators%7D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20def%20run_trainer(n_steps%2C%20step_time)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20time%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(n_steps)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(step_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20_results%5B%22trainer%22%5D%20%3D%20trainer.train_step.call_one().get()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20def%20run_generator(gen_actor%2C%20gen_idx%2C%20n_iters%2C%20gen_time)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20import%20time%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20for%20_%20in%20range(n_iters)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20version%20%3D%20gen_actor.generate_step.call_one().get()%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20if%20version%20%3E%3D%200%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(gen_time)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5BGen%20%7Bgen_idx%7D%5D%20Generated%20(v%7Bversion%7D)%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20else%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20time.sleep(0.05)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20_results%5B%22generators%22%5D%5Bgen_idx%5D%20%3D%20version%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Create%20threads%20for%20trainer%20and%20each%20generator%0A%20%20%20%20%20%20%20%20%20%20%20%20threads%20%3D%20%5B%5D%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Trainer%20thread%0A%20%20%20%20%20%20%20%20%20%20%20%20t%20%3D%20threading.Thread(target%3Drun_trainer%2C%20args%3D(6%2C%201.0))%20%20%23%201%20second%20per%20step%0A%20%20%20%20%20%20%20%20%20%20%20%20threads.append(t)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Generator%20threads%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20i%20in%20range(n_generators)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20gen_actor%20%3D%20generators.slice(procs%3Di)%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20t%20%3D%20threading.Thread(target%3Drun_generator%2C%20args%3D(gen_actor%2C%20i%2C%205%2C%200.25))%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20threads.append(t)%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Start%20all%20threads%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20t%20in%20threads%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20t.start()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20%23%20Wait%20for%20all%20to%20complete%0A%20%20%20%20%20%20%20%20%20%20%20%20for%20t%20in%20threads%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20t.join()%0A%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%5Cn---%20Done!%20Trainer%20published%20%7B_results%5B'trainer'%5D%7D%20versions%20---%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22Generators%20ended%20on%20versions%3A%20%7B_results%5B'generators'%5D%7D%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20print(%22All%20pulled%20independently%20via%20RDMA%2C%20weights%20verified!%22)%0A%0A%20%20%20%20except%20Exception%20as%20e%3A%0A%20%20%20%20%20%20%20%20import%20traceback%0A%20%20%20%20%20%20%20%20traceback.print_exc()%0A%20%20%20%20%20%20%20%20print(f%22(Demo%20failed%3A%20%7Be%7D)%22)%0A%20%20%20%20%20%20%20%20show_fallback()%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%209.%20Going%20Further%3A%20TorchStore%0A%0A%20%20%20%20All%20the%20patterns%20we've%20covered%20-%20RDMA%20memory%20registration%2C%20magic%20pointers%2C%20circular%20buffers%2C%0A%20%20%20%20pre-computed%20transfer%20plans%20-%20are%20building%20blocks.%20If%20you%20need%20a%20**production-ready%20solution**%2C%0A%20%20%20%20check%20out%20%5BTorchStore%5D(https%3A%2F%2Fgithub.com%2Fmeta-pytorch%2Ftorchstore).%0A%0A%20%20%20%20%23%23%23%20What%20is%20TorchStore%3F%0A%0A%20%20%20%20TorchStore%20is%20a%20**distributed%2C%20asynchronous%20key-value%20store%20for%20PyTorch%20tensors**%20built%20on%0A%20%20%20%20Monarch's%20actor%20framework.%20It%20abstracts%20away%20the%20RDMA%20complexity%20while%20giving%20you%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20torchstore%20import%20TorchStore%0A%0A%20%20%20%20%23%20Store%20tensors%20with%20async%20API%0A%20%20%20%20await%20ts.put(%22model%2Flayer1%2Fweights%22%2C%20tensor)%0A%0A%20%20%20%20%23%20Retrieve%20with%20optional%20in-place%20and%20slice%20semantics%0A%20%20%20%20await%20ts.get(%22model%2Flayer1%2Fweights%22%2C%20inplace_tensor%3Dbuffer)%0A%0A%20%20%20%20%23%20Native%20PyTorch%20checkpoint%20support%0A%20%20%20%20await%20ts.put_state_dict(model.state_dict())%0A%20%20%20%20loaded%20%3D%20await%20ts.get_state_dict()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20%23%23%23%20When%20to%20Use%20What%0A%0A%20%20%20%20%7C%20Scenario%20%7C%20Solution%20%7C%0A%20%20%20%20%7C----------%7C----------%7C%0A%20%20%20%20%7C%20Learning%20RDMA%20patterns%20%7C%20This%20notebook%20%2B%2006b%20%7C%0A%20%20%20%20%7C%20Custom%20RL%20weight%20sync%20%7C%20See%2006b%20for%20%60RDMABuffer%60%20%2B%20%60RDMAAction%60%20patterns%20%7C%0A%20%20%20%20%7C%20General%20tensor%20storage%20%7C%20Use%20TorchStore%20%7C%0A%20%20%20%20%7C%20Checkpointing%20%7C%20Use%20TorchStore's%20%60put_state_dict%60%20%7C%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20%23%23%23%20Key%20Takeaways%0A%0A%20%20%20%201.%20**Bandwidth%20hierarchy%20matters**%3A%20NVLink%20(900%20GB%2Fs)%20%3E%3E%20InfiniBand%20(50%20GB%2Fs)%0A%20%20%20%20%20%20%20-%20Keep%20frequent%20operations%20on%20NVLink%2C%20use%20RDMA%20for%20cross-node%0A%0A%20%20%20%202.%20**Collectives%20block%2C%20RL%20needs%20async**%3A%20High%20variance%20in%20generation%20times%20makes%0A%20%20%20%20%20%20%20synchronous%20operations%20expensive%0A%0A%20%20%20%203.%20**Magic%20pointer%20pattern**%3A%20Tiny%20handle%20over%20control%20plane%2C%20bulk%20data%20over%20data%20plane%0A%20%20%20%20%20%20%20-%20~100%20bytes%20to%20describe%2010%20GB%20transfer%0A%0A%20%20%20%204.%20**CPU%20staging**%3A%20Temporal%20decoupling%20for%20async%20RL%0A%20%20%20%20%20%20%20-%20Nothing%20blocks%20on%20the%20critical%20path%0A%0A%20%20%20%205.%20**Circular%20buffers**%3A%20Version%20weights%20without%20memory%20churn%0A%20%20%20%20%20%20%20-%20Pre-register%20RDMA%20buffers%2C%20reuse%20slots%0A%0A%20%20%20%206.%20**Weight%20re-sharding**%3A%20Different%20layouts%20need%20overlap%20computation%0A%20%20%20%20%20%20%20-%20Routed%20approach%20avoids%20redundant%20transfers%0A%0A%20%20%20%20%23%23%23%20Want%20More%3F%0A%0A%20%20%20%20-%20**07b_weight_sync_deep_dive.py**%20-%20ibverbs%20internals%2C%20RDMA%20buffer%20patterns%0A%20%20%20%20-%20**08_rl_e2e.py**%20-%20Complete%20async%20RL%20system%20using%20these%20patterns%0A%0A%20%20%20%20---%0A%0A%20%20%20%20**Previous%3A**%20%5BNB06%20%E2%80%94%20Services%5D(.%2F06_services.html)%20%C2%B7%20**Next%3A**%20%5BNB07b%20%E2%80%94%20RDMA%20Deep%20Dive%5D(.%2F07b_weight_sync_deep_dive.html)%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">5ed062fd8bc0f29b859dd13072e87042</marimo-code-hash>
</body>
</html>
