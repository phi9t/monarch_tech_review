<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>01_history_and_vision.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>01 history and vision</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/index-CD6Gw4UH.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/preload-helper-D2MJg03u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/react-Bj1aDYRI.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/compiler-runtime-B3qBwwSJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/badge-DX6CQ6PA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useEventListener-Cb-RVVEn.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/button-CZ3Cs4qb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/react-dom-CSu739Rf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/Combination-BAEdC-rz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/menu-items-BMjcEb2j.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-DwV58Fb1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/createLucideIcon-BCdY6lG5.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/check-Dr3SxUsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/x-ZP5cObgf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/select-BVdzZKAh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/tooltip-CMQz28hC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/use-toast-BDYuj3zG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useEvent-BhXAndur.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/zod-H_cgTO0M.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/utils-YqBXNpsM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/Deferred-DxQeE5uh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/uuid-DXdzqzcr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/DeferredRequestRegistry-CMf25YiV.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/session-BOFn9QrD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/config-Q0O7_stz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/requests-B4FYHTZl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useLifecycle-ClI_npeg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useNonce-CS26E0hA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useTheme-DQozhcp1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/createReducer-B3rBsy4P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/paths-BzSgteR-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-Dcqqg9UU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-sMh6mJ2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-Btv5Rh1v.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-bBwmhqty.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-CoCQUAeM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/stex-jWatZkll.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toDate-DETS9bBd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/database-zap-k4ePIFAU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cells-DPp5cDaO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/spinner-DA8-7wQv.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chevron-right--18M_6o9.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dropdown-menu-ldcmQvIV.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/kbd-Cm6Ba9qg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/renderShortcut-BckyRbYt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/multi-map-DxdLNTBd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/alert-BOoN6gJ1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/card-OlSjYhmd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/alert-dialog-BW4srmS0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dialog-eb-NieZw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dist-CDXJRSCj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/label-E64zk6_7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDebounce-7iEVSqwM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/textarea-CRI7xDBj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/numbers-D7O23mOZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/SSRProvider-BIDQNg9Q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/context-BfYAMNLF.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useNumberFormatter-Db6Vjve5.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/usePress-C__vuri5.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/input-DUrq2DiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/links-7AQBmdyV.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/popover-CH1FzjxU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/switch-dWLWbbtg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/table-DScsXgJW.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/mode-Bn7pdJvO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useAsyncData-BMGLSTg8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/errors-TZBmrJmc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/error-banner-B9ts0mNl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/copy-DHrHayPa.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/copy-D-8y6iMN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/plus-B7DF33lD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/refresh-cw-Dx8TEWFP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/trash-2-DDsWrxuJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/triangle-alert-CebQ7XwA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/ai-model-dropdown-Dk2SdB3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/defaultLocale-JieDVWC_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/precisionRound-CU2C3Vxx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/defaultLocale-BLne0bXb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/vega-loader.browser-DXARUlxo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/tooltip-DxKBXCGp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/ErrorBoundary-B9Ifj8Jf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useInstallPackage-D4fX0Ee_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/ImperativeModal-BNN1HA7x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cell-link-B9b7J8QK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/datasource-CtyqtITR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/state-D4T75eZb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/MarimoErrorOutput-Lf9P8Fhl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/copy-icon-v8ME_JKB.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/html-to-image-CIQqSu-S.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/focus-C1YokgL7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/LazyAnyLanguageCodeMirror-DgZ8iknE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chunk-5FQGJX7Z-DPlx2kjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/katex-CDLTCvjQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/markdown-renderer-DJy8ww5d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/command-2ElA5IkO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/download-os8QlW6l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useRunCells-D2HBb4DB.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/purify.es-DZrAQFIu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/RenderHTML-D-of_-s7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useIframeCapabilities-B_pQb20b.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/formats-CobRswjh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/en-US-CCVfmA-q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/isValid-DDt9wNjK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/dates-CrvjILe3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/maps-D2_Mq1pZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/extends-BiFDv3jB.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/emotion-is-prop-valid.esm-C59xfSYt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDateFormatter-CqhdUl2n.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/table-CfDbAm78.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/JsonOutput-PE5ko4gi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDeleteCell-DdRX94yC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/icons-CCHmxi8d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/process-output-ByfLnk6j.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/blob-D-eV0cU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/objectWithoutPropertiesLoose-DfWeGRFv.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/esm-Bmu2DhPy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/file-Ch78NKWp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/play-GLWQQs7F.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/add-cell-with-ai-e_HMl7UU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/bot-message-square-B2ThzDUZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chat-display--jAB7huF.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/chart-no-axes-column-qvVRjhv1.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/square-function-B6mgCeFJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/spec-Ch0xnJY4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/column-preview-CXjSXUhP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/toggle-zVW4FXNz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/globals-BgACvYmr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/share-ipf2hrOh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/react-resizable-panels.browser.esm-Da3ksQXL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/utilities.esm-dm9SQStE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/floating-outline-BtdqbkUq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useAddCell-CmuX2hOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/eye-off-AK_9uodG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/readonly-python-code-WjTf6Pdd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/file-video-camera-C3wGzBnE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/types-BRfQN3HL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/refresh-ccw-DN_xCV6A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/form-BidPUZUn.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/field-CySaBlkz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useBoolean-Ck_unDZw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/useDeepCompareMemoize-5OUgerQ3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/types-C1UhS3qM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/prop-types-DaaA-ptl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/es-BYgU_srD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/code-xml-CgN_Yig7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/download-Dg7clfkc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/square-CuJ72M8f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/settings-OBbrbhij.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/bundle.esm-i_UbZC0w.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.9/dist/assets/index-CeUwN_0i.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "01_history_and_vision.py",
            "mode": "read",
            "version": "0.19.9",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(r\"\"\"\n# Monarch: History \u0026 Vision\n\"\"\")", "code_hash": "3c97da95ae698efc82d0b9b848a84d79", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Training at the Frontier Hurts\n\nBefore we look at any code, let's talk about **why Monarch exists**.\n\nDuring Llama 3 pre-training, Meta ran 16,384 GPUs for 54 days and hit\n**419 unexpected interruptions** \u2014 roughly one failure every 3 hours.\nThe breakdown tells you a lot about what goes wrong at scale:\n\n| Cause | % of interruptions | Count |\n|-------|-------------------|-------|\n| Faulty GPUs | 30.1% | 148 |\n| GPU HBM3 errors | 17.2% | 72 |\n| Software bugs | 12.9% | 54 |\n| Network / cables | 8.4% | 35 |\n...\n\nThis is \"just\" for 16K GPUs. If you further scale workloads to tens of thousands of GPUs, you should expect failures\nevery hour or more frequently. The distributed system must handle this gracefully \u2014 detect, checkpoint, recover, keep going\nautomatically, without requiring someone to SSH in to restart things manually.\n\n**Monarch was built for this reality.** It's a PyTorch-native distributed\nsystems framework designed from the ground up for fault tolerance, flexible\ncommunication patterns, and scale. Let's see how it got here.\n\n*(Failure data from the [Llama 3 paper](https://arxiv.org/abs/2407.21783);\nsee also [Introducing PyTorch Monarch](https://pytorch.org/blog/introducing-pytorch-monarch/))*\n\"\"\")", "code_hash": "4f52b743526376554bb79c91d8bd89e0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(r\"\"\"\n**What you'll learn:**\n\n1. Why Monarch exists (the pain that drove its creation)\n2. The tensor engine origin story\n3. The actor model and why it matters for distributed ML\n4. Your first Monarch program: ping-pong actors\n5. The Monarch ontology: World, Proc, Actor, Port\n6. Scalable messaging via meshes\n\"\"\")", "code_hash": "c122776a3ff170d72de7390f7c35e77c", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## The Tensor Engine Origin Story\n\nThe first step toward solving this was rethinking how we orchestrate\ndistributed computation.\n\nMonarch began as a **tensor engine** for distributed PyTorch.\nIt was built as a \"single controller\" that executed DTensor operations.\n\nIn other words, in Monarch we have a **single controller** that orchestrates many GPUs,\ninstead of SPMD (Single Program, Multiple Data) where every rank runs the same script.\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CONTROLLER (Python)                           \u2502\n\u2502                                                                  \u2502\n\u2502   # Create a mesh: 4 hosts x 8 GPUs = 32 GPUs total              \u2502\n\u2502   mesh = DeviceMesh(hosts=4, gpus_per_host=8, dims=(\"dp\", \"tp\")) \u2502\n\u2502                                                                  \u2502\n\u2502   with mesh.activate():                                          \u2502\n\u2502       loss = model(X)                                            \u2502\n\u2502       loss.backward()                                            \u2502\n\u2502       p.grad.reduce_(\"dp\", reduction=\"avg\")  # all-reduce        \u2502\n\u2502       optimizer.step()                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502 tensor commands\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                   \u25bc                   \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Host 0  \u2502         \u2502 Host 1  \u2502         \u2502 Host 2  \u2502  ...\n   \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502\n   \u2502 dp=0    \u2502         \u2502 dp=1    \u2502         \u2502 dp=2    \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis allows one Python script to orchestrate thousands of GPUs - bypassing SPMD-imposed complexities like per-rank checks, scattered logging, etc. Complex control flow becomes more natural to express in code.\n\nThe tensor engine still exists today, but Monarch has evolved beyond it.\n\"\"\")", "code_hash": "e41987afdfd8de124911801d71e6c724", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Evolution to Actors\n\nWhile building the tensor engine, the Monarch team realized that the system\nunderneath \u2014 the Rust runtime managing processes, message routing, and\nscheduling \u2014 was far more general than just tensor orchestration. The\n**actor model** underpinning everything was powerful on its own.\n\nSo the APIs shifted to bring those primitives directly to Python. Instead of\nonly exposing tensor operations, Monarch now lets you define arbitrary\n**actors** that communicate via **messages**.\n\n**What is an actor?** In the formal sense, an actor is a concurrent unit of\ncomputation that:\n\n1. Has **private state** \u2014 no shared memory with other actors\n2. Communicates exclusively by **sending and receiving messages**\n3. Can **create new actors**, send messages, and decide how to handle the next\n   message it receives\n\nA useful analogy: think of actors as workers in separate offices. They can't\nwalk over and read each other's notebooks \u2014 they can only communicate by\npassing notes through mail slots.\n\nThis model composes naturally with PyTorch's existing ecosystem. You can wrap any SPMD code with Monarch's actors,\nand command a group or \"gang\" of actors as a single addressable unit, and wire them together however your workload requires.\n\nTake RL for example (don't worry about the details of this snippet \u2014\nwe'll cover these APIs hands-on throughout the series):\n\n```python\n# Spawn different actor types across processes\nhost = this_host()\ntrainer_procs = host.spawn_procs(per_host={\"gpus\": 1})\ngenerator_procs = host.spawn_procs(per_host={\"gpus\": 4})\n\ntrainer = trainer_procs.spawn(\"trainer\", TrainerActor)\ngenerators = generator_procs.spawn(\"generators\", GeneratorActor)\n\n# Wire them together\nfor batch in training_loop:\n    # Call all generators (returns a ValueMesh)\n    sample_mesh = generators.generate.call(prompts).get()\n    # Extract values from the ValueMesh before passing along\n    samples = list(sample_mesh.values())\n    trainer.train_step.call_one(samples).get()\n```\n\nLet's make this concrete with a real program you can run.\n\"\"\")", "code_hash": "8d0b08e0fb70fea08acecfb09374c176", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Your First Monarch Program\n\nThe simplest possible Monarch program \u2014 two actors playing ping pong.\n\nReference: [ping_pong example](https://meta-pytorch.org/monarch/generated/examples/ping_pong.html)\n\"\"\")", "code_hash": "cb07500e453eac3cf305031c17180850", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "from monarch.actor import Actor, endpoint, current_rank, this_host\n\nclass PingPong(Actor):\n    def __init__(self):\n        rank = current_rank().rank\n        self.name = \"Ping\" if rank == 0 else \"Pong\"\n        self.count = 0\n\n    @endpoint\n    def ping(self, message: str) -\u003E str:\n        self.count += 1\n        print(f\"{self.name} received: {message} (count: {self.count})\")\n        return f\"pong from {self.name}\"\n\n# Spawn two actors on separate processes\nhost = this_host()\nprocs = host.spawn_procs(per_host={\"gpus\": 2})\nactors = procs.spawn(\"players\", PingPong)\n\n# Get individual actors via slicing\nping_actor = actors.slice(gpus=0)\npong_actor = actors.slice(gpus=1)\n\n# Play ping pong \u2014 call_one targets a single actor\nfor i in range(3):\n    response = ping_actor.ping.call_one(f\"round {i}\").get()\n    print(f\"Got: {response}\")\n    response = pong_actor.ping.call_one(f\"round {i}\").get()\n    print(f\"Got: {response}\")\n\n# .call() broadcasts to ALL actors and returns a ValueMesh \u2014 a dict-like\n# container mapping each actor's position to its return value.\nresults = actors.ping.call(\"hello everyone\").get()\nfor point, response in results.items():\n    print(f\"Actor at {point}: {response}\")", "code_hash": "0652f334956e48b327dd0c3d94b9127b", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Scalable Messaging\n\nMeshes of actors enable **scalable** messaging through tree-based routing.\n\nInstead of sending messages individually to every actor, Monarch routes through a\n**tree of intermediate hosts**, giving **O(log N) broadcast**. The same tree\naggregates responses on the way back up, giving **O(log N) reduce** as well.\n\nThis means primitives like barriers and all-reduces are as simple as\nwaiting for an aggregate response \u2014 and they scale to thousands of actors\nwithout bottlenecking the client.\n\n*(See the animated diagrams in the\n[Monarch presentation notebook](https://github.com/meta-pytorch/monarch/blob/main/examples/presentation/presentation.ipynb))*\n\"\"\")", "code_hash": "243633cc2ae229396eb7fd390e70fea3", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Channels and Low-level Messaging\n\nIt is sometimes useful to establish direct channels between two points, or forward\nthe handling of some messages from one actor to another. To enable this, all messaging\nin Monarch is built out of `Port` objects.\n\nAn actor can create a new `Channel`, which provides a `Port` for sending and a\n`PortReceiver` for receiving messages. The `Port` object can then be sent to any endpoint.\n\n```python\nfrom monarch.actor import Channel, Port\n\nport, recv = Channel.open()\n\nport.send(3)\nprint(recv.recv().get())\n```\n\nPorts can be passed as arguments to actors and sent a response remotely. We can also\ndirectly ask an endpoint to send its response to a port using the `send` messaging primitive.\n\n```python\nfrom monarch.actor import send\n\nwith trainer_procs.activate():\n    send(check_memory, args=(), kwargs={}, port=port)\n```\n\nThe port will receive a response from each actor sent the message:\n\n```python\nfor _ in range(4):\n    print(recv.recv().get())\n```\n\nThe other adverbs like `call`, `stream`, and `broadcast` are just implemented in terms\nof ports and `send`.\n\n### Message Ordering\n\nMessages from an actor are delivered to the destination actor in the order in which they\nare sent. If actor A sends message M0 to actor B, then later sends M1 to B, actor B will\nreceive M0 before M1. Messages sent to a mesh of actors behave as if sent individually\nto each destination.\n\nEach actor handles its messages **sequentially** \u2014 it must finish handling a message before\nthe next one is delivered. Different actors in the same process handle messages **concurrently**.\n\"\"\")", "code_hash": "bbc434aa3be22fbc4f10cf097b2cb530", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Summary\n\nMonarch uniquely provides:\n\n1. Scalable messaging using multidimensional meshes of actors\n2. Fault tolerance through supervision trees and `__supervise__`\n3. Point-to-point low-level RDMA\n4. Built-in distributed tensors\n\nThis foundation enables building sophisticated multi-machine training programs\nwith clear semantics for distribution, fault tolerance, and communication patterns.\n\nThe remaining sections fill in more details about how to accomplish common\npatterns with the above features.\n\n---\n\n**Next:** [NB02 \u2014 Interactive DevX](./02_interactive_devx.html)\n\"\"\")", "code_hash": "421da8017a7fbd1bfcf29303085ccefc", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}], "metadata": {"marimo_version": "0.19.9"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3c97da95ae698efc82d0b9b848a84d79", "console": [], "id": "MJUe", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"monarch-history-vision\"\u003EMonarch: History \u0026amp; Vision\u003C/h1\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "4f52b743526376554bb79c91d8bd89e0", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"training-at-the-frontier-hurts\"\u003ETraining at the Frontier Hurts\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EBefore we look at any code, let's talk about \u003Cstrong\u003Ewhy Monarch exists\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EDuring Llama 3 pre-training, Meta ran 16,384 GPUs for 54 days and hit\n\u003Cstrong\u003E419 unexpected interruptions\u003C/strong\u003E \u2014 roughly one failure every 3 hours.\nThe breakdown tells you a lot about what goes wrong at scale:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ECause\u003C/th\u003E\n\u003Cth\u003E% of interruptions\u003C/th\u003E\n\u003Cth\u003ECount\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EFaulty GPUs\u003C/td\u003E\n\u003Ctd\u003E30.1%\u003C/td\u003E\n\u003Ctd\u003E148\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGPU HBM3 errors\u003C/td\u003E\n\u003Ctd\u003E17.2%\u003C/td\u003E\n\u003Ctd\u003E72\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ESoftware bugs\u003C/td\u003E\n\u003Ctd\u003E12.9%\u003C/td\u003E\n\u003Ctd\u003E54\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ENetwork / cables\u003C/td\u003E\n\u003Ctd\u003E8.4%\u003C/td\u003E\n\u003Ctd\u003E35\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E...\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is \"just\" for 16K GPUs. If you further scale workloads to tens of thousands of GPUs, you should expect failures\nevery hour or more frequently. The distributed system must handle this gracefully \u2014 detect, checkpoint, recover, keep going\nautomatically, without requiring someone to SSH in to restart things manually.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EMonarch was built for this reality.\u003C/strong\u003E It's a PyTorch-native distributed\nsystems framework designed from the ground up for fault tolerance, flexible\ncommunication patterns, and scale. Let's see how it got here.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cem\u003E(Failure data from the \u003Ca href=\"https://arxiv.org/abs/2407.21783\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ELlama 3 paper\u003C/a\u003E;\nsee also \u003Ca href=\"https://pytorch.org/blog/introducing-pytorch-monarch/\" rel=\"noopener noreferrer\" target=\"_blank\"\u003EIntroducing PyTorch Monarch\u003C/a\u003E)\u003C/em\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "c122776a3ff170d72de7390f7c35e77c", "console": [], "id": "bkHC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat you'll learn:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EWhy Monarch exists (the pain that drove its creation)\u003C/li\u003E\n\u003Cli\u003EThe tensor engine origin story\u003C/li\u003E\n\u003Cli\u003EThe actor model and why it matters for distributed ML\u003C/li\u003E\n\u003Cli\u003EYour first Monarch program: ping-pong actors\u003C/li\u003E\n\u003Cli\u003EThe Monarch ontology: World, Proc, Actor, Port\u003C/li\u003E\n\u003Cli\u003EScalable messaging via meshes\u003C/li\u003E\n\u003C/ol\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e41987afdfd8de124911801d71e6c724", "console": [], "id": "lEQa", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"the-tensor-engine-origin-story\"\u003EThe Tensor Engine Origin Story\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe first step toward solving this was rethinking how we orchestrate\ndistributed computation.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch began as a \u003Cstrong\u003Etensor engine\u003C/strong\u003E for distributed PyTorch.\nIt was built as a \"single controller\" that executed DTensor operations.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EIn other words, in Monarch we have a \u003Cstrong\u003Esingle controller\u003C/strong\u003E that orchestrates many GPUs,\ninstead of SPMD (Single Program, Multiple Data) where every rank runs the same script.\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CONTROLLER (Python)                           \u2502\n\u2502                                                                  \u2502\n\u2502   # Create a mesh: 4 hosts x 8 GPUs = 32 GPUs total              \u2502\n\u2502   mesh = DeviceMesh(hosts=4, gpus_per_host=8, dims=(\u0026quot;dp\u0026quot;, \u0026quot;tp\u0026quot;)) \u2502\n\u2502                                                                  \u2502\n\u2502   with mesh.activate():                                          \u2502\n\u2502       loss = model(X)                                            \u2502\n\u2502       loss.backward()                                            \u2502\n\u2502       p.grad.reduce_(\u0026quot;dp\u0026quot;, reduction=\u0026quot;avg\u0026quot;)  # all-reduce        \u2502\n\u2502       optimizer.step()                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502 tensor commands\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                   \u25bc                   \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Host 0  \u2502         \u2502 Host 1  \u2502         \u2502 Host 2  \u2502  ...\n   \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502\n   \u2502 dp=0    \u2502         \u2502 dp=1    \u2502         \u2502 dp=2    \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis allows one Python script to orchestrate thousands of GPUs - bypassing SPMD-imposed complexities like per-rank checks, scattered logging, etc. Complex control flow becomes more natural to express in code.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe tensor engine still exists today, but Monarch has evolved beyond it.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "8d0b08e0fb70fea08acecfb09374c176", "console": [], "id": "PKri", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"evolution-to-actors\"\u003EEvolution to Actors\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWhile building the tensor engine, the Monarch team realized that the system\nunderneath \u2014 the Rust runtime managing processes, message routing, and\nscheduling \u2014 was far more general than just tensor orchestration. The\n\u003Cstrong\u003Eactor model\u003C/strong\u003E underpinning everything was powerful on its own.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ESo the APIs shifted to bring those primitives directly to Python. Instead of\nonly exposing tensor operations, Monarch now lets you define arbitrary\n\u003Cstrong\u003Eactors\u003C/strong\u003E that communicate via \u003Cstrong\u003Emessages\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat is an actor?\u003C/strong\u003E In the formal sense, an actor is a concurrent unit of\ncomputation that:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EHas \u003Cstrong\u003Eprivate state\u003C/strong\u003E \u2014 no shared memory with other actors\u003C/li\u003E\n\u003Cli\u003ECommunicates exclusively by \u003Cstrong\u003Esending and receiving messages\u003C/strong\u003E\u003C/li\u003E\n\u003Cli\u003ECan \u003Cstrong\u003Ecreate new actors\u003C/strong\u003E, send messages, and decide how to handle the next\n   message it receives\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EA useful analogy: think of actors as workers in separate offices. They can't\nwalk over and read each other's notebooks \u2014 they can only communicate by\npassing notes through mail slots.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis model composes naturally with PyTorch's existing ecosystem. You can wrap any SPMD code with Monarch's actors,\nand command a group or \"gang\" of actors as a single addressable unit, and wire them together however your workload requires.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ETake RL for example (don't worry about the details of this snippet \u2014\nwe'll cover these APIs hands-on throughout the series):\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Spawn different actor types across processes\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ethis_host\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Etrainer_procs\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn_procs\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eper_host\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"p\"\u003E{\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;gpus\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"p\"\u003E})\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerator_procs\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn_procs\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eper_host\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"p\"\u003E{\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;gpus\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"p\"\u003E})\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_procs\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;trainer\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003ETrainerActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerators\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Egenerator_procs\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;generators\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003EGeneratorActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Wire them together\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003Ebatch\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"n\"\u003Etraining_loop\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n    \u003Cspan class=\"c1\"\u003E# Call all generators (returns a ValueMesh)\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Esample_mesh\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Egenerators\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Egenerate\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eprompts\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n    \u003Cspan class=\"c1\"\u003E# Extract values from the ValueMesh before passing along\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Esamples\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"nb\"\u003Elist\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Esample_mesh\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Evalues\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrain_step\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Esamples\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's make this concrete with a real program you can run.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cb07500e453eac3cf305031c17180850", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"your-first-monarch-program\"\u003EYour First Monarch Program\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe simplest possible Monarch program \u2014 two actors playing ping pong.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EReference: \u003Ca href=\"https://meta-pytorch.org/monarch/generated/examples/ping_pong.html\" rel=\"noopener noreferrer\" target=\"_blank\"\u003Eping_pong example\u003C/a\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "0652f334956e48b327dd0c3d94b9127b", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-07_10:33_41\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "Ping received: round 0 (count: 1)\nGot: pong from Ping\nPong received: round 0 (count: 1)\nGot: pong from Pong\nPing received: round 1 (count: 2)\nGot: pong from Ping\nPong received: round 1 (count: 2)\nGot: pong from Pong\nPing received: round 2 (count: 3)\nGot: pong from Ping\nPong received: round 2 (count: 3)\nGot: pong from Pong\nPing received: hello everyone (count: 4)\nPong received: hello everyone (count: 4)\nActor at {'gpus': 0/2}: pong from Ping\nActor at {'gpus': 1/2}: pong from Pong\n", "type": "stream"}], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "243633cc2ae229396eb7fd390e70fea3", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"scalable-messaging\"\u003EScalable Messaging\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EMeshes of actors enable \u003Cstrong\u003Escalable\u003C/strong\u003E messaging through tree-based routing.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EInstead of sending messages individually to every actor, Monarch routes through a\n\u003Cstrong\u003Etree of intermediate hosts\u003C/strong\u003E, giving \u003Cstrong\u003EO(log N) broadcast\u003C/strong\u003E. The same tree\naggregates responses on the way back up, giving \u003Cstrong\u003EO(log N) reduce\u003C/strong\u003E as well.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis means primitives like barriers and all-reduces are as simple as\nwaiting for an aggregate response \u2014 and they scale to thousands of actors\nwithout bottlenecking the client.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cem\u003E(See the animated diagrams in the\n\u003Ca href=\"https://github.com/meta-pytorch/monarch/blob/main/examples/presentation/presentation.ipynb\" rel=\"noopener noreferrer\" target=\"_blank\"\u003EMonarch presentation notebook\u003C/a\u003E)\u003C/em\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "bbc434aa3be22fbc4f10cf097b2cb530", "console": [], "id": "RGSE", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"channels-and-low-level-messaging\"\u003EChannels and Low-level Messaging\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EIt is sometimes useful to establish direct channels between two points, or forward\nthe handling of some messages from one actor to another. To enable this, all messaging\nin Monarch is built out of \u003Ccode\u003EPort\u003C/code\u003E objects.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EAn actor can create a new \u003Ccode\u003EChannel\u003C/code\u003E, which provides a \u003Ccode\u003EPort\u003C/code\u003E for sending and a\n\u003Ccode\u003EPortReceiver\u003C/code\u003E for receiving messages. The \u003Ccode\u003EPort\u003C/code\u003E object can then be sent to any endpoint.\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch.actor\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003EChannel\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003EPort\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003Eport\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Erecv\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003EChannel\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eopen\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003Eport\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Esend\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"nb\"\u003Eprint\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EPorts can be passed as arguments to actors and sent a response remotely. We can also\ndirectly ask an endpoint to send its response to a port using the \u003Ccode\u003Esend\u003C/code\u003E messaging primitive.\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"kn\"\u003Efrom\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"nn\"\u003Emonarch.actor\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"kn\"\u003Eimport\u003C/span\u003E \u003Cspan class=\"n\"\u003Esend\u003C/span\u003E\n\n\u003Cspan class=\"k\"\u003Ewith\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_procs\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eactivate\u003C/span\u003E\u003Cspan class=\"p\"\u003E():\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Esend\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Echeck_memory\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003Eargs\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"p\"\u003E(),\u003C/span\u003E \u003Cspan class=\"n\"\u003Ekwargs\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"p\"\u003E{},\u003C/span\u003E \u003Cspan class=\"n\"\u003Eport\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"n\"\u003Eport\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe port will receive a response from each actor sent the message:\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003E_\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"nb\"\u003Erange\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"p\"\u003E):\u003C/span\u003E\n    \u003Cspan class=\"nb\"\u003Eprint\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Erecv\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThe other adverbs like \u003Ccode\u003Ecall\u003C/code\u003E, \u003Ccode\u003Estream\u003C/code\u003E, and \u003Ccode\u003Ebroadcast\u003C/code\u003E are just implemented in terms\nof ports and \u003Ccode\u003Esend\u003C/code\u003E.\u003C/span\u003E\n\u003Ch3 id=\"message-ordering\"\u003EMessage Ordering\u003C/h3\u003E\n\u003Cspan class=\"paragraph\"\u003EMessages from an actor are delivered to the destination actor in the order in which they\nare sent. If actor A sends message M0 to actor B, then later sends M1 to B, actor B will\nreceive M0 before M1. Messages sent to a mesh of actors behave as if sent individually\nto each destination.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EEach actor handles its messages \u003Cstrong\u003Esequentially\u003C/strong\u003E \u2014 it must finish handling a message before\nthe next one is delivered. Different actors in the same process handle messages \u003Cstrong\u003Econcurrently\u003C/strong\u003E.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "421da8017a7fbd1bfcf29303085ccefc", "console": [], "id": "Kclp", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"summary\"\u003ESummary\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch uniquely provides:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EScalable messaging using multidimensional meshes of actors\u003C/li\u003E\n\u003Cli\u003EFault tolerance through supervision trees and \u003Ccode\u003E__supervise__\u003C/code\u003E\u003C/li\u003E\n\u003Cli\u003EPoint-to-point low-level RDMA\u003C/li\u003E\n\u003Cli\u003EBuilt-in distributed tensors\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EThis foundation enables building sophisticated multi-machine training programs\nwith clear semantics for distribution, fault tolerance, and communication patterns.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe remaining sections fill in more details about how to accomplish common\npatterns with the above features.\u003C/span\u003E\n\u003Chr /\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003ENext:\u003C/strong\u003E \u003Ca href=\"./02_interactive_devx.html\"\u003ENB02 \u2014 Interactive DevX\u003C/a\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.9"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.19.9%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20Monarch%3A%20History%20%26%20Vision%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Training%20at%20the%20Frontier%20Hurts%0A%0A%20%20%20%20Before%20we%20look%20at%20any%20code%2C%20let's%20talk%20about%20**why%20Monarch%20exists**.%0A%0A%20%20%20%20During%20Llama%203%20pre-training%2C%20Meta%20ran%2016%2C384%20GPUs%20for%2054%20days%20and%20hit%0A%20%20%20%20**419%20unexpected%20interruptions**%20%E2%80%94%20roughly%20one%20failure%20every%203%20hours.%0A%20%20%20%20The%20breakdown%20tells%20you%20a%20lot%20about%20what%20goes%20wrong%20at%20scale%3A%0A%0A%20%20%20%20%7C%20Cause%20%7C%20%25%20of%20interruptions%20%7C%20Count%20%7C%0A%20%20%20%20%7C-------%7C-------------------%7C-------%7C%0A%20%20%20%20%7C%20Faulty%20GPUs%20%7C%2030.1%25%20%7C%20148%20%7C%0A%20%20%20%20%7C%20GPU%20HBM3%20errors%20%7C%2017.2%25%20%7C%2072%20%7C%0A%20%20%20%20%7C%20Software%20bugs%20%7C%2012.9%25%20%7C%2054%20%7C%0A%20%20%20%20%7C%20Network%20%2F%20cables%20%7C%208.4%25%20%7C%2035%20%7C%0A%20%20%20%20...%0A%0A%20%20%20%20This%20is%20%22just%22%20for%2016K%20GPUs.%20If%20you%20further%20scale%20workloads%20to%20tens%20of%20thousands%20of%20GPUs%2C%20you%20should%20expect%20failures%0A%20%20%20%20every%20hour%20or%20more%20frequently.%20The%20distributed%20system%20must%20handle%20this%20gracefully%20%E2%80%94%20detect%2C%20checkpoint%2C%20recover%2C%20keep%20going%0A%20%20%20%20automatically%2C%20without%20requiring%20someone%20to%20SSH%20in%20to%20restart%20things%20manually.%0A%0A%20%20%20%20**Monarch%20was%20built%20for%20this%20reality.**%20It's%20a%20PyTorch-native%20distributed%0A%20%20%20%20systems%20framework%20designed%20from%20the%20ground%20up%20for%20fault%20tolerance%2C%20flexible%0A%20%20%20%20communication%20patterns%2C%20and%20scale.%20Let's%20see%20how%20it%20got%20here.%0A%0A%20%20%20%20*(Failure%20data%20from%20the%20%5BLlama%203%20paper%5D(https%3A%2F%2Farxiv.org%2Fabs%2F2407.21783)%3B%0A%20%20%20%20see%20also%20%5BIntroducing%20PyTorch%20Monarch%5D(https%3A%2F%2Fpytorch.org%2Fblog%2Fintroducing-pytorch-monarch%2F))*%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20**What%20you'll%20learn%3A**%0A%0A%20%20%20%201.%20Why%20Monarch%20exists%20(the%20pain%20that%20drove%20its%20creation)%0A%20%20%20%202.%20The%20tensor%20engine%20origin%20story%0A%20%20%20%203.%20The%20actor%20model%20and%20why%20it%20matters%20for%20distributed%20ML%0A%20%20%20%204.%20Your%20first%20Monarch%20program%3A%20ping-pong%20actors%0A%20%20%20%205.%20The%20Monarch%20ontology%3A%20World%2C%20Proc%2C%20Actor%2C%20Port%0A%20%20%20%206.%20Scalable%20messaging%20via%20meshes%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20The%20Tensor%20Engine%20Origin%20Story%0A%0A%20%20%20%20The%20first%20step%20toward%20solving%20this%20was%20rethinking%20how%20we%20orchestrate%0A%20%20%20%20distributed%20computation.%0A%0A%20%20%20%20Monarch%20began%20as%20a%20**tensor%20engine**%20for%20distributed%20PyTorch.%0A%20%20%20%20It%20was%20built%20as%20a%20%22single%20controller%22%20that%20executed%20DTensor%20operations.%0A%0A%20%20%20%20In%20other%20words%2C%20in%20Monarch%20we%20have%20a%20**single%20controller**%20that%20orchestrates%20many%20GPUs%2C%0A%20%20%20%20instead%20of%20SPMD%20(Single%20Program%2C%20Multiple%20Data)%20where%20every%20rank%20runs%20the%20same%20script.%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONTROLLER%20(Python)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%23%20Create%20a%20mesh%3A%204%20hosts%20x%208%20GPUs%20%3D%2032%20GPUs%20total%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20mesh%20%3D%20DeviceMesh(hosts%3D4%2C%20gpus_per_host%3D8%2C%20dims%3D(%22dp%22%2C%20%22tp%22))%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20with%20mesh.activate()%3A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20loss%20%3D%20model(X)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20loss.backward()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20p.grad.reduce_(%22dp%22%2C%20reduction%3D%22avg%22)%20%20%23%20all-reduce%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20optimizer.step()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20tensor%20commands%0A%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%E2%94%82%20Host%200%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20Host%201%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20Host%202%20%20%E2%94%82%20%20...%0A%20%20%20%20%20%20%20%E2%94%82%208%20GPUs%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%208%20GPUs%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%208%20GPUs%20%20%E2%94%82%0A%20%20%20%20%20%20%20%E2%94%82%20dp%3D0%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20dp%3D1%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20dp%3D2%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20allows%20one%20Python%20script%20to%20orchestrate%20thousands%20of%20GPUs%20-%20bypassing%20SPMD-imposed%20complexities%20like%20per-rank%20checks%2C%20scattered%20logging%2C%20etc.%20Complex%20control%20flow%20becomes%20more%20natural%20to%20express%20in%20code.%0A%0A%20%20%20%20The%20tensor%20engine%20still%20exists%20today%2C%20but%20Monarch%20has%20evolved%20beyond%20it.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Evolution%20to%20Actors%0A%0A%20%20%20%20While%20building%20the%20tensor%20engine%2C%20the%20Monarch%20team%20realized%20that%20the%20system%0A%20%20%20%20underneath%20%E2%80%94%20the%20Rust%20runtime%20managing%20processes%2C%20message%20routing%2C%20and%0A%20%20%20%20scheduling%20%E2%80%94%20was%20far%20more%20general%20than%20just%20tensor%20orchestration.%20The%0A%20%20%20%20**actor%20model**%20underpinning%20everything%20was%20powerful%20on%20its%20own.%0A%0A%20%20%20%20So%20the%20APIs%20shifted%20to%20bring%20those%20primitives%20directly%20to%20Python.%20Instead%20of%0A%20%20%20%20only%20exposing%20tensor%20operations%2C%20Monarch%20now%20lets%20you%20define%20arbitrary%0A%20%20%20%20**actors**%20that%20communicate%20via%20**messages**.%0A%0A%20%20%20%20**What%20is%20an%20actor%3F**%20In%20the%20formal%20sense%2C%20an%20actor%20is%20a%20concurrent%20unit%20of%0A%20%20%20%20computation%20that%3A%0A%0A%20%20%20%201.%20Has%20**private%20state**%20%E2%80%94%20no%20shared%20memory%20with%20other%20actors%0A%20%20%20%202.%20Communicates%20exclusively%20by%20**sending%20and%20receiving%20messages**%0A%20%20%20%203.%20Can%20**create%20new%20actors**%2C%20send%20messages%2C%20and%20decide%20how%20to%20handle%20the%20next%0A%20%20%20%20%20%20%20message%20it%20receives%0A%0A%20%20%20%20A%20useful%20analogy%3A%20think%20of%20actors%20as%20workers%20in%20separate%20offices.%20They%20can't%0A%20%20%20%20walk%20over%20and%20read%20each%20other's%20notebooks%20%E2%80%94%20they%20can%20only%20communicate%20by%0A%20%20%20%20passing%20notes%20through%20mail%20slots.%0A%0A%20%20%20%20This%20model%20composes%20naturally%20with%20PyTorch's%20existing%20ecosystem.%20You%20can%20wrap%20any%20SPMD%20code%20with%20Monarch's%20actors%2C%0A%20%20%20%20and%20command%20a%20group%20or%20%22gang%22%20of%20actors%20as%20a%20single%20addressable%20unit%2C%20and%20wire%20them%20together%20however%20your%20workload%20requires.%0A%0A%20%20%20%20Take%20RL%20for%20example%20(don't%20worry%20about%20the%20details%20of%20this%20snippet%20%E2%80%94%0A%20%20%20%20we'll%20cover%20these%20APIs%20hands-on%20throughout%20the%20series)%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Spawn%20different%20actor%20types%20across%20processes%0A%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20trainer_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22gpus%22%3A%201%7D)%0A%20%20%20%20generator_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22gpus%22%3A%204%7D)%0A%0A%20%20%20%20trainer%20%3D%20trainer_procs.spawn(%22trainer%22%2C%20TrainerActor)%0A%20%20%20%20generators%20%3D%20generator_procs.spawn(%22generators%22%2C%20GeneratorActor)%0A%0A%20%20%20%20%23%20Wire%20them%20together%0A%20%20%20%20for%20batch%20in%20training_loop%3A%0A%20%20%20%20%20%20%20%20%23%20Call%20all%20generators%20(returns%20a%20ValueMesh)%0A%20%20%20%20%20%20%20%20sample_mesh%20%3D%20generators.generate.call(prompts).get()%0A%20%20%20%20%20%20%20%20%23%20Extract%20values%20from%20the%20ValueMesh%20before%20passing%20along%0A%20%20%20%20%20%20%20%20samples%20%3D%20list(sample_mesh.values())%0A%20%20%20%20%20%20%20%20trainer.train_step.call_one(samples).get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Let's%20make%20this%20concrete%20with%20a%20real%20program%20you%20can%20run.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Your%20First%20Monarch%20Program%0A%0A%20%20%20%20The%20simplest%20possible%20Monarch%20program%20%E2%80%94%20two%20actors%20playing%20ping%20pong.%0A%0A%20%20%20%20Reference%3A%20%5Bping_pong%20example%5D(https%3A%2F%2Fmeta-pytorch.org%2Fmonarch%2Fgenerated%2Fexamples%2Fping_pong.html)%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20current_rank%2C%20this_host%0A%0A%20%20%20%20class%20PingPong(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.name%20%3D%20%22Ping%22%20if%20rank%20%3D%3D%200%20else%20%22Pong%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.count%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20ping(self%2C%20message%3A%20str)%20-%3E%20str%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bself.name%7D%20received%3A%20%7Bmessage%7D%20(count%3A%20%7Bself.count%7D)%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20f%22pong%20from%20%7Bself.name%7D%22%0A%0A%20%20%20%20%23%20Spawn%20two%20actors%20on%20separate%20processes%0A%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20procs%20%3D%20host.spawn_procs(per_host%3D%7B%22gpus%22%3A%202%7D)%0A%20%20%20%20actors%20%3D%20procs.spawn(%22players%22%2C%20PingPong)%0A%0A%20%20%20%20%23%20Get%20individual%20actors%20via%20slicing%0A%20%20%20%20ping_actor%20%3D%20actors.slice(gpus%3D0)%0A%20%20%20%20pong_actor%20%3D%20actors.slice(gpus%3D1)%0A%0A%20%20%20%20%23%20Play%20ping%20pong%20%E2%80%94%20call_one%20targets%20a%20single%20actor%0A%20%20%20%20for%20i%20in%20range(3)%3A%0A%20%20%20%20%20%20%20%20response%20%3D%20ping_actor.ping.call_one(f%22round%20%7Bi%7D%22).get()%0A%20%20%20%20%20%20%20%20print(f%22Got%3A%20%7Bresponse%7D%22)%0A%20%20%20%20%20%20%20%20response%20%3D%20pong_actor.ping.call_one(f%22round%20%7Bi%7D%22).get()%0A%20%20%20%20%20%20%20%20print(f%22Got%3A%20%7Bresponse%7D%22)%0A%0A%20%20%20%20%23%20.call()%20broadcasts%20to%20ALL%20actors%20and%20returns%20a%20ValueMesh%20%E2%80%94%20a%20dict-like%0A%20%20%20%20%23%20container%20mapping%20each%20actor's%20position%20to%20its%20return%20value.%0A%20%20%20%20results%20%3D%20actors.ping.call(%22hello%20everyone%22).get()%0A%20%20%20%20for%20point%2C%20response%20in%20results.items()%3A%0A%20%20%20%20%20%20%20%20print(f%22Actor%20at%20%7Bpoint%7D%3A%20%7Bresponse%7D%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Scalable%20Messaging%0A%0A%20%20%20%20Meshes%20of%20actors%20enable%20**scalable**%20messaging%20through%20tree-based%20routing.%0A%0A%20%20%20%20Instead%20of%20sending%20messages%20individually%20to%20every%20actor%2C%20Monarch%20routes%20through%20a%0A%20%20%20%20**tree%20of%20intermediate%20hosts**%2C%20giving%20**O(log%20N)%20broadcast**.%20The%20same%20tree%0A%20%20%20%20aggregates%20responses%20on%20the%20way%20back%20up%2C%20giving%20**O(log%20N)%20reduce**%20as%20well.%0A%0A%20%20%20%20This%20means%20primitives%20like%20barriers%20and%20all-reduces%20are%20as%20simple%20as%0A%20%20%20%20waiting%20for%20an%20aggregate%20response%20%E2%80%94%20and%20they%20scale%20to%20thousands%20of%20actors%0A%20%20%20%20without%20bottlenecking%20the%20client.%0A%0A%20%20%20%20*(See%20the%20animated%20diagrams%20in%20the%0A%20%20%20%20%5BMonarch%20presentation%20notebook%5D(https%3A%2F%2Fgithub.com%2Fmeta-pytorch%2Fmonarch%2Fblob%2Fmain%2Fexamples%2Fpresentation%2Fpresentation.ipynb))*%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Channels%20and%20Low-level%20Messaging%0A%0A%20%20%20%20It%20is%20sometimes%20useful%20to%20establish%20direct%20channels%20between%20two%20points%2C%20or%20forward%0A%20%20%20%20the%20handling%20of%20some%20messages%20from%20one%20actor%20to%20another.%20To%20enable%20this%2C%20all%20messaging%0A%20%20%20%20in%20Monarch%20is%20built%20out%20of%20%60Port%60%20objects.%0A%0A%20%20%20%20An%20actor%20can%20create%20a%20new%20%60Channel%60%2C%20which%20provides%20a%20%60Port%60%20for%20sending%20and%20a%0A%20%20%20%20%60PortReceiver%60%20for%20receiving%20messages.%20The%20%60Port%60%20object%20can%20then%20be%20sent%20to%20any%20endpoint.%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20monarch.actor%20import%20Channel%2C%20Port%0A%0A%20%20%20%20port%2C%20recv%20%3D%20Channel.open()%0A%0A%20%20%20%20port.send(3)%0A%20%20%20%20print(recv.recv().get())%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Ports%20can%20be%20passed%20as%20arguments%20to%20actors%20and%20sent%20a%20response%20remotely.%20We%20can%20also%0A%20%20%20%20directly%20ask%20an%20endpoint%20to%20send%20its%20response%20to%20a%20port%20using%20the%20%60send%60%20messaging%20primitive.%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20from%20monarch.actor%20import%20send%0A%0A%20%20%20%20with%20trainer_procs.activate()%3A%0A%20%20%20%20%20%20%20%20send(check_memory%2C%20args%3D()%2C%20kwargs%3D%7B%7D%2C%20port%3Dport)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20port%20will%20receive%20a%20response%20from%20each%20actor%20sent%20the%20message%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20for%20_%20in%20range(4)%3A%0A%20%20%20%20%20%20%20%20print(recv.recv().get())%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20The%20other%20adverbs%20like%20%60call%60%2C%20%60stream%60%2C%20and%20%60broadcast%60%20are%20just%20implemented%20in%20terms%0A%20%20%20%20of%20ports%20and%20%60send%60.%0A%0A%20%20%20%20%23%23%23%20Message%20Ordering%0A%0A%20%20%20%20Messages%20from%20an%20actor%20are%20delivered%20to%20the%20destination%20actor%20in%20the%20order%20in%20which%20they%0A%20%20%20%20are%20sent.%20If%20actor%20A%20sends%20message%20M0%20to%20actor%20B%2C%20then%20later%20sends%20M1%20to%20B%2C%20actor%20B%20will%0A%20%20%20%20receive%20M0%20before%20M1.%20Messages%20sent%20to%20a%20mesh%20of%20actors%20behave%20as%20if%20sent%20individually%0A%20%20%20%20to%20each%20destination.%0A%0A%20%20%20%20Each%20actor%20handles%20its%20messages%20**sequentially**%20%E2%80%94%20it%20must%20finish%20handling%20a%20message%20before%0A%20%20%20%20the%20next%20one%20is%20delivered.%20Different%20actors%20in%20the%20same%20process%20handle%20messages%20**concurrently**.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20Monarch%20uniquely%20provides%3A%0A%0A%20%20%20%201.%20Scalable%20messaging%20using%20multidimensional%20meshes%20of%20actors%0A%20%20%20%202.%20Fault%20tolerance%20through%20supervision%20trees%20and%20%60__supervise__%60%0A%20%20%20%203.%20Point-to-point%20low-level%20RDMA%0A%20%20%20%204.%20Built-in%20distributed%20tensors%0A%0A%20%20%20%20This%20foundation%20enables%20building%20sophisticated%20multi-machine%20training%20programs%0A%20%20%20%20with%20clear%20semantics%20for%20distribution%2C%20fault%20tolerance%2C%20and%20communication%20patterns.%0A%0A%20%20%20%20The%20remaining%20sections%20fill%20in%20more%20details%20about%20how%20to%20accomplish%20common%0A%20%20%20%20patterns%20with%20the%20above%20features.%0A%0A%20%20%20%20---%0A%0A%20%20%20%20**Next%3A**%20%5BNB02%20%E2%80%94%20Interactive%20DevX%5D(.%2F02_interactive_devx.html)%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">bf2329ccf6e300fa8b0930089d0fc92d</marimo-code-hash>
</body>
</html>
