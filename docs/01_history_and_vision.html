<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/favicon.ico" />
    <!-- Preload is necessary because we show these images when we disconnect from the server,
    but at that point we cannot load these images from the server -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/gradient-yHQUC_QB.png" as="image" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/noise-60BoTA8O.png" as="image" />
    <!-- Preload the fonts -->
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Lora-VariableFont_wght-B2ootaw-.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Regular-CxL0S8W7.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/PTSans-Bold-D9fedIX3.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Regular-BTCkDNvf.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Medium-DU3aDxX5.ttf" as="font" crossorigin="anonymous" />
    <link rel="preload" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/FiraMono-Bold-CLVRCuM9.ttf" as="font" crossorigin="anonymous" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta name="description" content="a marimo app" />
    <link rel="apple-touch-icon" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/apple-touch-icon.png" />
    <link rel="manifest" crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/manifest.json" />

    <script data-marimo="true">
      function __resizeIframe(obj) {
        const scrollbarHeight = 20; // Max between windows, mac, and linux

        function setHeight() {
          // Guard against race condition where iframe isn't ready
          if (!obj.contentWindow?.document?.documentElement) {
            return;
          }
          const element = obj.contentWindow.document.documentElement;
          // If there is no vertical scrollbar, we don't need to resize the iframe
          if (element.scrollHeight === element.clientHeight) {
            return;
          }

          // Create a new height that includes the scrollbar height if it's visible
          const hasHorizontalScrollbar = element.scrollWidth > element.clientWidth;
          const newHeight = element.scrollHeight + (hasHorizontalScrollbar ? scrollbarHeight : 0);

          // Only update the height if it's different from the current height
          if (obj.style.height !== `${newHeight}px`) {
            obj.style.height = `${newHeight}px`;
          }
        }

        // Resize the iframe to the height of the content and bottom scrollbar height
        setHeight();

        // Resize the iframe when the content changes
        const resizeObserver = new ResizeObserver((_entries) => {
          setHeight();
        });
        // Only observe if iframe content is ready
        if (obj.contentWindow?.document?.body) {
          resizeObserver.observe(obj.contentWindow.document.body);
        }
      }
    </script>
    <marimo-filename hidden>01_history_and_vision.py</marimo-filename>
    <!-- TODO(Trevor): Legacy, required by VS Code plugin. Remove when plugin is updated (see marimo/server/_templates/template.py) -->
    <marimo-version data-version="{{ version }}" hidden></marimo-version>
    <marimo-user-config data-config="{{ user_config }}" hidden></marimo-user-config>
    <marimo-server-token data-token="{{ server_token }}" hidden></marimo-server-token>
    <!-- /TODO -->
    <title>01 history and vision</title>
    <script type="module" crossorigin crossorigin="anonymous" src="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-DGasP9Lh.js"></script>
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/preload-helper-DItdS47A.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/clsx-D8GwTfvk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cn-BKtXLv3a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-LvLJmgfZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-BGmjiNul.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/compiler-runtime-DeeZ7FnK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/jsx-runtime-ZmTK25f3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/badge-Ce8wRjuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hotkeys-BHHWjLlp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEventListener-DIUKKfEy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/button-YC1gW_kJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-dom-C9fstfnp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Combination-CMPwuAmi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/menu-items-CJhvWPOk.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-uzvC4uAK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createLucideIcon-CnW3RofX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/check-DdfN0k2d.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/select-V5IdpNiR.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-CEc2ajau.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/use-toast-rmUWldD_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_Uint8Array-BGESiCQL.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseIsEqual-B9N9Mw_N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useEvent-DO6uJBas.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/invariant-CAG_dYON.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFor-Duhs3RiJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/merge-BBX6ug-N.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/zod-Cg4WLWh2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utils-DXvhzCGS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/constants-B6Cb__3x.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/Deferred-CrO5-0RA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/config-CIrPQIbt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/uuid-DercMavo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/DeferredRequestRegistry-CO2AyNfd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/requests-BsVD4CdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isSymbol-BGkTcW3U.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toString-DlRqgfqz.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_hasUnicode-CWqKLxBC.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/assertNever-CBU83Y6o.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_arrayReduce-TT0iOGKY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useLifecycle-D35CBukS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNonce-_Aax6sXd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useTheme-DUdVAZI8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/once-Bul8mtFs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capabilities-MM7JYRxj.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/createReducer-Dnna-AUO.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-DBwNzi3C.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-ChS0Dc_R.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CtsanegT.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BIKFl48f.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-B0VqT_4z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-TiFCI16_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Cayq-K1c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-BYyu59D8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-Gqv0jSNr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/stex-CtmkcLz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toDate-CgbKQM5E.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cjs-CH5Rj0g8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseProperty-NKyJO2oh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/now-6sUe0ZdD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/debounce-B3mjKxHe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toInteger-CDcO32Gx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/database-zap-B9y7063w.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/main-U5Goe76G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-BpZ7g6ok.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spinner-DaIKav-i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chevron-right-DwagBitu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dropdown-menu-B-6unW-7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/kbd-C3JY7O_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/renderShortcut-DEwfrKeS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/multi-map-C8GlnP-4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-BrGyZf9c.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/alert-dialog-DwQffb13.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dialog-CxGKN4C_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dist-CdxIjAOP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/label-Be1daUcS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDebounce-D5NcotGm.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/textarea-DBO30D7K.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/numbers-iQunIAXf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/SSRProvider-CEHRCdjA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/context-JwD-oSsl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useNumberFormatter-c6GXymzg.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/usePress-Bup4EGrp.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/input-pAun1m1X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/links-DHZUhGz-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/popover-Gz-GJzym.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/switch-8sn_4qbh.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-C8uQmBAN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/mode-DX8pdI-l.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAsyncData-C4XRy1BE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/errors-2SszdW9t.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/error-banner-DUzsIXtq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-Bv2DBpIS.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/memoize-BCOZVFBt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/get-6uJrSKbw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/capitalize-CmNnkG9y.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-CQ15EONK.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/plus-BD5o34_i.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-cw-CQd-1kjx.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/trash-2-CyqGun26.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/triangle-alert-B65rDESJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ai-model-dropdown-71lgLrLy.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-D_rSvXvJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/precisionRound-BMPhtTJQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/defaultLocale-C92Rrpmf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/vega-loader.browser-CRZ52CKf.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/tooltip-BGrCWNss.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ErrorBoundary-ChCiwl15.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useInstallPackage-Bdnnp5fe.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/ImperativeModal-CUbWEBci.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cell-link-Bw5bzt4a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/datasource-B0OJBphG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/state-BfXVTTtD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/MarimoErrorOutput-5rudBbo3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/copy-icon-BhONVREY.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/html-to-image-DjukyIj4.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/focus-D51fcwZX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/LazyAnyLanguageCodeMirror-yzHjsVJt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chunk-5FQGJX7Z-CVUXBqX6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/katex-Dc8yG8NU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DhMlG2dP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/command-DhzFN2CJ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-BhCZMKuQ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useRunCells-24p6hn99.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/purify.es-DNVQZNFu.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/RenderHTML-CQZqVk1Z.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useIframeCapabilities-DuIDx9mD.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/formats-W1SWxSE3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/en-US-pRRbZZHE.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isValid-DcYggVWP.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/dates-Dhn1r-h6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/maps-t9yNKYA8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/extends-B2LJnKU3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/emotion-is-prop-valid.esm-DD4AwVTU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDateFormatter-CS4kbWl2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/range-D2UKkEg-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/table-DZR6ewbN.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-CknFTI_u.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-Cs1JbsV6.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/play-BPIh-ZEU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-components-CGlO4yUw.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/isEmpty-CgX_-6Mt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chat-display-B4mGvJ0X.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeleteCell-5uYlTcQZ.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/icons-BhEXrzsb.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/process-output-CagdHMzs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/blob-CuXvdYPX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/objectWithoutPropertiesLoose-DaPAPabU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/esm-DpMp6qko.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/add-cell-with-ai-pVFp5LZG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/chart-no-axes-column-W42b2ZIs.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-function-CqXXKtIq.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/spec-D1kBp3jX.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/column-preview-CxMrs0B_.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/toggle-jWKnIArU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/globals-DKH14XH0.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/share-CbPtIlnM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseSet-5Rdwpmr3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/react-resizable-panels.browser.esm-Ctj_10o2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/utilities.esm-CIPARd6-.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/floating-outline-DcxjrFFt.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useAddCell-BmeZUK02.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/eye-off-BhExYOph.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/readonly-python-code-DyP9LVLc.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/file-video-camera-DW3v07j2.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-DuQOSW7G.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/refresh-ccw-DLEiQDS3.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/form-DUA_Rz_a.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/field-BEg1eC0P.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useBoolean-B1Xeh6vA.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/useDeepCompareMemoize-ZPd9PxYl.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/types-CS34eOZi.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/prop-types-BiQYf0aU.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/es-D8BOePqo.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/hasIn-CycJImp8.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/_baseFlatten-CUZNxU8H.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/flatten-D-7VEN0q.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/pick-B_6Qi5aM.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/code-xml-XLwHyDBr.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/download-B9SUL40m.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/house-DhFkiXz7.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/settings-DOXWMfVd.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/square-C8Tw_XXG.js">
    <link rel="modulepreload" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/bundle.esm-2AjO7UK5.js">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/cells-jmgGt1lS.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/markdown-renderer-DdDKmWlR.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/JsonOutput-B7vuddcd.css">
    <link rel="stylesheet" crossorigin crossorigin="anonymous" href="https://cdn.jsdelivr.net/npm/@marimo-team/frontend@0.19.7/dist/assets/index-CikhHYAB.css">
  
<script data-marimo="true">
    window.__MARIMO_STATIC__ = {};
    window.__MARIMO_STATIC__.files = {};
</script>
</head>
  <body>
    <div id="root"></div>
    <!-- This is a portal for the data editor to render in -->
    <div id="portal" data-testid="glide-portal" style="position: fixed; left: 0; top: 0; z-index: 9999"></div>
    <script data-marimo="true">
      window.__MARIMO_MOUNT_CONFIG__ = {
            "filename": "01_history_and_vision.py",
            "mode": "read",
            "version": "0.19.7",
            "serverToken": "static",
            "config": {"ai": {"custom_providers": {}, "models": {"custom_models": [], "displayed_models": []}}, "completion": {"activate_on_typing": true, "copilot": false, "signature_hint_on_typing": false}, "diagnostics": {"sql_linter": true}, "display": {"cell_output": "below", "code_editor_font_size": 14, "dataframes": "rich", "default_table_max_columns": 50, "default_table_page_size": 10, "default_width": "medium", "reference_highlighting": true, "theme": "light"}, "formatting": {"line_length": 79}, "keymap": {"overrides": {}, "preset": "default"}, "language_servers": {"pylsp": {"enable_flake8": false, "enable_mypy": true, "enable_pydocstyle": false, "enable_pyflakes": false, "enable_pylint": false, "enable_ruff": true, "enabled": false}}, "mcp": {"mcpServers": {}, "presets": []}, "package_management": {"manager": "uv"}, "runtime": {"auto_instantiate": false, "auto_reload": "off", "default_csv_encoding": "utf-8", "default_sql_output": "auto", "on_cell_change": "autorun", "output_max_bytes": 8000000, "reactive_tests": true, "std_stream_max_bytes": 1000000, "watcher_on_save": "lazy"}, "save": {"autosave": "after_delay", "autosave_delay": 1000, "format_on_save": false}, "server": {"browser": "default", "follow_symlink": false}, "snippets": {"custom_paths": [], "include_default_snippets": true}},
            "configOverrides": {},
            "appConfig": {"sql_output": "auto", "width": "medium"},
            "view": {"showAppCode": true},
            "notebook": {"cells": [{"code": "import marimo as mo", "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Hbol", "name": "_"}, {"code": "mo.md(r\"\"\"\n# Monarch: History \u0026 Vision\n\"\"\")", "code_hash": "3c97da95ae698efc82d0b9b848a84d79", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "MJUe", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Training at the Frontier Hurts\n\nBefore we look at any code, let's talk about **why Monarch exists**.\n\nDuring Llama 3 pre-training, Meta ran 16,384 GPUs for 54 days and hit\n**419 unexpected interruptions** \u2014 roughly one failure every 3 hours.\nThe breakdown tells you a lot about what goes wrong at scale:\n\n| Cause | % of interruptions | Count |\n|-------|-------------------|-------|\n| Faulty GPUs | 30.1% | 148 |\n| GPU HBM3 errors | 17.2% | 72 |\n| Software bugs | 12.9% | 54 |\n| Network / cables | 8.4% | 35 |\n...\n\nThis is \"just\" for 16K GPUs. If you further scale workloads to tens of thousands of GPUs, you should expect failures\nevery hour or more frequently. The distributed system must handle this gracefully \u2014 detect, checkpoint, recover, keep going\nautomatically, without requiring someone to SSH in to restart things manually.\n\n**Monarch was built for this reality.** It's a PyTorch-native distributed\nsystems framework designed from the ground up for fault tolerance, flexible\ncommunication patterns, and scale. Let's see how it got here.\n\n*(Failure data from the [Llama 3 paper](https://arxiv.org/abs/2407.21783);\nsee also [Introducing PyTorch Monarch](https://pytorch.org/blog/introducing-pytorch-monarch/))*\n\"\"\")", "code_hash": "4f52b743526376554bb79c91d8bd89e0", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "vblA", "name": "_"}, {"code": "mo.md(r\"\"\"\n**What you'll learn:**\n\n1. Why Monarch exists (the pain that drove its creation)\n2. The tensor engine origin story\n3. The actor model and why it matters for distributed ML\n4. Your first Monarch program: ping-pong actors\n5. The Monarch ontology: World, Proc, Actor, Port\n6. How Monarch scales\n\"\"\")", "code_hash": "e790d8a1795856fccf3677f473010b75", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "bkHC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## The Tensor Engine Origin Story\n\nThe first step toward solving this was rethinking how we orchestrate\ndistributed computation.\n\nMonarch began as a **tensor engine** for distributed PyTorch.\nIt was built as a \"single controller\" that executed DTensor operations.\n\nIn other words, in Monarch we have a **single controller** that orchestrates many GPUs,\ninstead of SPMD (Single Program, Multiple Data) where every rank runs the same script.\n\n```\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CONTROLLER (Python)                           \u2502\n\u2502                                                                  \u2502\n\u2502   # Create a mesh: 4 hosts x 8 GPUs = 32 GPUs total              \u2502\n\u2502   mesh = DeviceMesh(hosts=4, gpus_per_host=8, dims=(\"dp\", \"tp\")) \u2502\n\u2502                                                                  \u2502\n\u2502   with mesh.activate():                                          \u2502\n\u2502       loss = model(X)                                            \u2502\n\u2502       loss.backward()                                            \u2502\n\u2502       p.grad.reduce_(\"dp\", reduction=\"avg\")  # all-reduce        \u2502\n\u2502       optimizer.step()                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502 tensor commands\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                   \u25bc                   \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Host 0  \u2502         \u2502 Host 1  \u2502         \u2502 Host 2  \u2502  ...\n   \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502\n   \u2502 dp=0    \u2502         \u2502 dp=1    \u2502         \u2502 dp=2    \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nThis allows one Python script to orchestrate thousands of GPUs - bypassing SPMD-imposed complexities like per-rank checks, scattered logging, etc. Complex control flow becomes more natural to express in code.\n\nThe tensor engine still exists today, but Monarch has evolved beyond it.\n\"\"\")", "code_hash": "e41987afdfd8de124911801d71e6c724", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "lEQa", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Evolution to Actors\n\nWhile building the tensor engine, the Monarch team realized that the system\nunderneath \u2014 the Rust runtime managing processes, message routing, and\nscheduling \u2014 was far more general than just tensor orchestration. The\n**actor model** underpinning everything was powerful on its own.\n\nSo the APIs shifted to bring those primitives directly to Python. Instead of\nonly exposing tensor operations, Monarch now lets you define arbitrary\n**actors** that communicate via **messages**.\n\n**What is an actor?** In the formal sense, an actor is a concurrent unit of\ncomputation that:\n\n1. Has **private state** \u2014 no shared memory with other actors\n2. Communicates exclusively by **sending and receiving messages**\n3. Can **create new actors**, send messages, and decide how to handle the next\n   message it receives\n\nA useful analogy: think of actors as workers in separate offices. They can't\nwalk over and read each other's notebooks \u2014 they can only communicate by\npassing notes through mail slots.\n\nThis model composes naturally with PyTorch's existing ecosystem. You can wrap any SPMD code with Monarch's actors,\nand command a group or \"gang\" of actors as a single addressable unit, and wire them together however your workload requires.\n\nTake RL for example (don't worry about the details of this snippet \u2014\nwe'll cover these APIs hands-on throughout the series):\n\n```python\n# Spawn different actor types across processes\nhost = this_host()\ntrainer_procs = host.spawn_procs(per_host={\"gpus\": 1})\ngenerator_procs = host.spawn_procs(per_host={\"gpus\": 4})\n\ntrainer = trainer_procs.spawn(\"trainer\", TrainerActor)\ngenerators = generator_procs.spawn(\"generators\", GeneratorActor)\n\n# Wire them together\nfor batch in training_loop:\n    # Call all generators (returns a ValueMesh)\n    sample_mesh = generators.generate.call(prompts).get()\n    # Extract values from the ValueMesh before passing along\n    samples = list(sample_mesh.values())\n    trainer.train_step.call_one(samples).get()\n```\n\nLet's make this concrete with a real program you can run.\n\"\"\")", "code_hash": "8d0b08e0fb70fea08acecfb09374c176", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "PKri", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Your First Monarch Program\n\nThe simplest possible Monarch program \u2014 two actors playing ping pong.\n\nReference: [ping_pong example](https://meta-pytorch.org/monarch/generated/examples/ping_pong.html)\n\"\"\")", "code_hash": "cb07500e453eac3cf305031c17180850", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Xref", "name": "_"}, {"code": "from monarch.actor import Actor, endpoint, current_rank, this_host\n\nclass PingPong(Actor):\n    def __init__(self):\n        rank = current_rank().rank\n        self.name = \"Ping\" if rank == 0 else \"Pong\"\n        self.count = 0\n\n    @endpoint\n    def ping(self, message: str) -\u003E str:\n        self.count += 1\n        print(f\"{self.name} received: {message} (count: {self.count})\")\n        return f\"pong from {self.name}\"\n\n# Spawn two actors on separate processes\nhost = this_host()\nprocs = host.spawn_procs(per_host={\"gpus\": 2})\nactors = procs.spawn(\"players\", PingPong)\n\n# Get individual actors via slicing\nping_actor = actors.slice(gpus=0)\npong_actor = actors.slice(gpus=1)\n\n# Play ping pong \u2014 call_one targets a single actor\nfor i in range(3):\n    response = ping_actor.ping.call_one(f\"round {i}\").get()\n    print(f\"Got: {response}\")\n    response = pong_actor.ping.call_one(f\"round {i}\").get()\n    print(f\"Got: {response}\")\n\n# .call() broadcasts to ALL actors and returns a ValueMesh \u2014 a dict-like\n# container mapping each actor's position to its return value.\nresults = actors.ping.call(\"hello everyone\").get()\nfor point, response in results.items():\n    print(f\"Actor at {point}: {response}\")", "code_hash": "0652f334956e48b327dd0c3d94b9127b", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "SFPL", "name": "_"}, {"code": "mo.md(r\"\"\"\n## The Monarch Ontology\n\nNow that you've run code, let's name the pieces. Monarch has a strict\nhierarchy:\n\n```\nWORLD (gang-scheduled group of processes)\n\u251c\u2500\u2500 PROC 0 (single actor runtime instance)\n\u2502   \u2514\u2500\u2500 Actor \"players\" (pid=0, a.k.a. \"Ping\")\n\u2502       \u2514\u2500\u2500 Port 0 (ping endpoint)\n\u2514\u2500\u2500 PROC 1\n    \u2514\u2500\u2500 Actor \"players\" (pid=1, a.k.a. \"Pong\")\n        \u2514\u2500\u2500 Port 0 (ping endpoint)\n```\n\nIn Monarch, a **mesh** is a named, multi-dimensional collection of identical\nresources that you can address and operate on as a group. A HostMesh contains\nhosts, a ProcMesh contains processes, an ActorMesh contains actor instances \u2014\neach layer spawns the next.\n\n**Definitions:**\n\n- **World**: A fixed group of processes launched together via gang scheduling\n  (all processes start together as a group \u2014 if any fails to start, none do)\n- **Proc**: A single actor runtime instance. One proc runs on one GPU (or CPU).\n- **Actor**: An independent async unit with its own mailbox. Communicates only\n  through messages \u2014 never shares memory.\n- **Port**: A typed message endpoint. Each `@endpoint` decorator creates a port.\n\nIn the ping-pong example above:\n- The **World** is the group of 2 procs we spawned\n- Each **Proc** hosts one PingPong **Actor**\n- The `ping` method is a **Port**\n\"\"\")", "code_hash": "fe5bab43dc1653fb7ed53d253d51157d", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "BYtC", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Why It Scales\n\nMonarch is designed to run millions of actors. Most actor systems use a\nglobal routing table \u2014 Monarch doesn't. Instead, every entity has a\nhierarchical ID that **encodes the routing path directly**:\n\n```\nActorId = (ProcId, actor_name, pid)\nProcId  = Ranked(WorldId, rank)\n```\n\nA HostMesh contains hosts, each host runs procs (a ProcMesh), and each proc\nhosts actors (an ActorMesh). The ActorId tells you exactly where to route\nwithout any lookup:\n\n```\nExample: my_job[5].worker[3]\n\n  rank 5 -\u003E host 2 (if 2 procs per host) -\u003E dial addr2:port\n  Then local delivery to worker[3]'s mailbox: O(1)\n```\n\n**Why this beats a global table:**\n\n| Operation | Global Table | Monarch Hierarchical |\n|-----------|--------------|---------------------|\n| Spawn | O(consensus) | O(1) local |\n| Route (local) | O(cache miss) | O(1) hash |\n| Route (cross-host) | O(cache miss) | O(log procs) + O(1) local |\n| Failure | Global invalidation | Local supervision |\n| Memory | O(actors) per node | O(procs) per node |\n\"\"\")", "code_hash": "38e4641b41405370fa84bbfc389baa18", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "RGSE", "name": "_"}, {"code": "mo.md(r\"\"\"\n## Summary\n\n**Key takeaways:**\n\n1. **Born from pain**: Monarch was built for the reality of frontier training \u2014\n   hundreds of failures across thousands of GPUs\n2. **Single controller**: One Python script orchestrates distributed compute\n3. **Actors, not threads**: Independent workers communicating via messages,\n   never sharing memory\n4. **Hierarchical addressing**: O(1) local routing, no global registry, scales\n   to millions of actors\n5. **Rust + Tokio**: Performance without GC pauses\n\nYou've seen how Monarch's actors work. But right now, developing distributed\nsystems means SSH, submit, wait, check logs, repeat. What if you could iterate\nas fast as local development? That's what we'll build next.\n\"\"\")", "code_hash": "2651074511b1f1edd179d802f40ee199", "config": {"column": null, "disabled": false, "hide_code": false}, "id": "Kclp", "name": "_"}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "session": {"cells": [{"code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e", "console": [], "id": "Hbol", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "3c97da95ae698efc82d0b9b848a84d79", "console": [], "id": "MJUe", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch1 id=\"monarch-history-vision\"\u003EMonarch: History \u0026amp; Vision\u003C/h1\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "4f52b743526376554bb79c91d8bd89e0", "console": [], "id": "vblA", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"training-at-the-frontier-hurts\"\u003ETraining at the Frontier Hurts\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EBefore we look at any code, let's talk about \u003Cstrong\u003Ewhy Monarch exists\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EDuring Llama 3 pre-training, Meta ran 16,384 GPUs for 54 days and hit\n\u003Cstrong\u003E419 unexpected interruptions\u003C/strong\u003E \u2014 roughly one failure every 3 hours.\nThe breakdown tells you a lot about what goes wrong at scale:\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003ECause\u003C/th\u003E\n\u003Cth\u003E% of interruptions\u003C/th\u003E\n\u003Cth\u003ECount\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EFaulty GPUs\u003C/td\u003E\n\u003Ctd\u003E30.1%\u003C/td\u003E\n\u003Ctd\u003E148\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EGPU HBM3 errors\u003C/td\u003E\n\u003Ctd\u003E17.2%\u003C/td\u003E\n\u003Ctd\u003E72\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ESoftware bugs\u003C/td\u003E\n\u003Ctd\u003E12.9%\u003C/td\u003E\n\u003Ctd\u003E54\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ENetwork / cables\u003C/td\u003E\n\u003Ctd\u003E8.4%\u003C/td\u003E\n\u003Ctd\u003E35\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003E...\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003Ctd\u003E\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\n\u003Cspan class=\"paragraph\"\u003EThis is \"just\" for 16K GPUs. If you further scale workloads to tens of thousands of GPUs, you should expect failures\nevery hour or more frequently. The distributed system must handle this gracefully \u2014 detect, checkpoint, recover, keep going\nautomatically, without requiring someone to SSH in to restart things manually.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EMonarch was built for this reality.\u003C/strong\u003E It's a PyTorch-native distributed\nsystems framework designed from the ground up for fault tolerance, flexible\ncommunication patterns, and scale. Let's see how it got here.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cem\u003E(Failure data from the \u003Ca href=\"https://arxiv.org/abs/2407.21783\" rel=\"noopener noreferrer\" target=\"_blank\"\u003ELlama 3 paper\u003C/a\u003E;\nsee also \u003Ca href=\"https://pytorch.org/blog/introducing-pytorch-monarch/\" rel=\"noopener noreferrer\" target=\"_blank\"\u003EIntroducing PyTorch Monarch\u003C/a\u003E)\u003C/em\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e790d8a1795856fccf3677f473010b75", "console": [], "id": "bkHC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat you'll learn:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EWhy Monarch exists (the pain that drove its creation)\u003C/li\u003E\n\u003Cli\u003EThe tensor engine origin story\u003C/li\u003E\n\u003Cli\u003EThe actor model and why it matters for distributed ML\u003C/li\u003E\n\u003Cli\u003EYour first Monarch program: ping-pong actors\u003C/li\u003E\n\u003Cli\u003EThe Monarch ontology: World, Proc, Actor, Port\u003C/li\u003E\n\u003Cli\u003EHow Monarch scales\u003C/li\u003E\n\u003C/ol\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "e41987afdfd8de124911801d71e6c724", "console": [], "id": "lEQa", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"the-tensor-engine-origin-story\"\u003EThe Tensor Engine Origin Story\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe first step toward solving this was rethinking how we orchestrate\ndistributed computation.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch began as a \u003Cstrong\u003Etensor engine\u003C/strong\u003E for distributed PyTorch.\nIt was built as a \"single controller\" that executed DTensor operations.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EIn other words, in Monarch we have a \u003Cstrong\u003Esingle controller\u003C/strong\u003E that orchestrates many GPUs,\ninstead of SPMD (Single Program, Multiple Data) where every rank runs the same script.\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    CONTROLLER (Python)                           \u2502\n\u2502                                                                  \u2502\n\u2502   # Create a mesh: 4 hosts x 8 GPUs = 32 GPUs total              \u2502\n\u2502   mesh = DeviceMesh(hosts=4, gpus_per_host=8, dims=(\u0026quot;dp\u0026quot;, \u0026quot;tp\u0026quot;)) \u2502\n\u2502                                                                  \u2502\n\u2502   with mesh.activate():                                          \u2502\n\u2502       loss = model(X)                                            \u2502\n\u2502       loss.backward()                                            \u2502\n\u2502       p.grad.reduce_(\u0026quot;dp\u0026quot;, reduction=\u0026quot;avg\u0026quot;)  # all-reduce        \u2502\n\u2502       optimizer.step()                                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                            \u2502 tensor commands\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u25bc                   \u25bc                   \u25bc\n   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Host 0  \u2502         \u2502 Host 1  \u2502         \u2502 Host 2  \u2502  ...\n   \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502         \u2502 8 GPUs  \u2502\n   \u2502 dp=0    \u2502         \u2502 dp=1    \u2502         \u2502 dp=2    \u2502\n   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EThis allows one Python script to orchestrate thousands of GPUs - bypassing SPMD-imposed complexities like per-rank checks, scattered logging, etc. Complex control flow becomes more natural to express in code.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThe tensor engine still exists today, but Monarch has evolved beyond it.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "8d0b08e0fb70fea08acecfb09374c176", "console": [], "id": "PKri", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"evolution-to-actors\"\u003EEvolution to Actors\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EWhile building the tensor engine, the Monarch team realized that the system\nunderneath \u2014 the Rust runtime managing processes, message routing, and\nscheduling \u2014 was far more general than just tensor orchestration. The\n\u003Cstrong\u003Eactor model\u003C/strong\u003E underpinning everything was powerful on its own.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ESo the APIs shifted to bring those primitives directly to Python. Instead of\nonly exposing tensor operations, Monarch now lets you define arbitrary\n\u003Cstrong\u003Eactors\u003C/strong\u003E that communicate via \u003Cstrong\u003Emessages\u003C/strong\u003E.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhat is an actor?\u003C/strong\u003E In the formal sense, an actor is a concurrent unit of\ncomputation that:\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003EHas \u003Cstrong\u003Eprivate state\u003C/strong\u003E \u2014 no shared memory with other actors\u003C/li\u003E\n\u003Cli\u003ECommunicates exclusively by \u003Cstrong\u003Esending and receiving messages\u003C/strong\u003E\u003C/li\u003E\n\u003Cli\u003ECan \u003Cstrong\u003Ecreate new actors\u003C/strong\u003E, send messages, and decide how to handle the next\n   message it receives\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EA useful analogy: think of actors as workers in separate offices. They can't\nwalk over and read each other's notebooks \u2014 they can only communicate by\npassing notes through mail slots.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EThis model composes naturally with PyTorch's existing ecosystem. You can wrap any SPMD code with Monarch's actors,\nand command a group or \"gang\" of actors as a single addressable unit, and wire them together however your workload requires.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003ETake RL for example (don't worry about the details of this snippet \u2014\nwe'll cover these APIs hands-on throughout the series):\u003C/span\u003E\n\u003Cdiv class=\"language-python codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"c1\"\u003E# Spawn different actor types across processes\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ethis_host\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Etrainer_procs\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn_procs\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eper_host\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"p\"\u003E{\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;gpus\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"p\"\u003E})\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerator_procs\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn_procs\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eper_host\u003C/span\u003E\u003Cspan class=\"o\"\u003E=\u003C/span\u003E\u003Cspan class=\"p\"\u003E{\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;gpus\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E \u003Cspan class=\"mi\"\u003E4\u003C/span\u003E\u003Cspan class=\"p\"\u003E})\u003C/span\u003E\n\n\u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Etrainer_procs\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;trainer\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003ETrainerActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\u003Cspan class=\"n\"\u003Egenerators\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Egenerator_procs\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Espawn\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"s2\"\u003E\u0026quot;generators\u0026quot;\u003C/span\u003E\u003Cspan class=\"p\"\u003E,\u003C/span\u003E \u003Cspan class=\"n\"\u003EGeneratorActor\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\n\n\u003Cspan class=\"c1\"\u003E# Wire them together\u003C/span\u003E\n\u003Cspan class=\"k\"\u003Efor\u003C/span\u003E \u003Cspan class=\"n\"\u003Ebatch\u003C/span\u003E \u003Cspan class=\"ow\"\u003Ein\u003C/span\u003E \u003Cspan class=\"n\"\u003Etraining_loop\u003C/span\u003E\u003Cspan class=\"p\"\u003E:\u003C/span\u003E\n    \u003Cspan class=\"c1\"\u003E# Call all generators (returns a ValueMesh)\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Esample_mesh\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"n\"\u003Egenerators\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Egenerate\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Eprompts\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n    \u003Cspan class=\"c1\"\u003E# Extract values from the ValueMesh before passing along\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Esamples\u003C/span\u003E \u003Cspan class=\"o\"\u003E=\u003C/span\u003E \u003Cspan class=\"nb\"\u003Elist\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Esample_mesh\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Evalues\u003C/span\u003E\u003Cspan class=\"p\"\u003E())\u003C/span\u003E\n    \u003Cspan class=\"n\"\u003Etrainer\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Etrain_step\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Ecall_one\u003C/span\u003E\u003Cspan class=\"p\"\u003E(\u003C/span\u003E\u003Cspan class=\"n\"\u003Esamples\u003C/span\u003E\u003Cspan class=\"p\"\u003E)\u003C/span\u003E\u003Cspan class=\"o\"\u003E.\u003C/span\u003E\u003Cspan class=\"n\"\u003Eget\u003C/span\u003E\u003Cspan class=\"p\"\u003E()\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003ELet's make this concrete with a real program you can run.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "cb07500e453eac3cf305031c17180850", "console": [], "id": "Xref", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"your-first-monarch-program\"\u003EYour First Monarch Program\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EThe simplest possible Monarch program \u2014 two actors playing ping pong.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003EReference: \u003Ca href=\"https://meta-pytorch.org/monarch/generated/examples/ping_pong.html\" rel=\"noopener noreferrer\" target=\"_blank\"\u003Eping_pong example\u003C/a\u003E\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "0652f334956e48b327dd0c3d94b9127b", "console": [{"mimetype": "text/plain", "name": "stderr", "text": "Monarch internal logs are being written to /tmp/allencwang/monarch_log.log; execution id allencwang_Feb-06_08:31_218\n", "type": "stream"}, {"mimetype": "text/plain", "name": "stdout", "text": "Ping received: round 0 (count: 1)\nGot: pong from Ping\nPong received: round 0 (count: 1)\nGot: pong from Pong\nPing received: round 1 (count: 2)\nGot: pong from Ping\nPong received: round 1 (count: 2)\nGot: pong from Pong\nPing received: round 2 (count: 3)\nGot: pong from Ping\nPong received: round 2 (count: 3)\nGot: pong from Pong\nPing received: hello everyone (count: 4)\nPong received: hello everyone (count: 4)\nActor at {'gpus': 0/2}: pong from Ping\nActor at {'gpus': 1/2}: pong from Pong\n", "type": "stream"}], "id": "SFPL", "outputs": [{"data": {"text/plain": ""}, "type": "data"}]}, {"code_hash": "fe5bab43dc1653fb7ed53d253d51157d", "console": [], "id": "BYtC", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"the-monarch-ontology\"\u003EThe Monarch Ontology\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003ENow that you've run code, let's name the pieces. Monarch has a strict\nhierarchy:\u003C/span\u003E\n\u003Cdiv class=\"language-text codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EWORLD (gang-scheduled group of processes)\n\u251c\u2500\u2500 PROC 0 (single actor runtime instance)\n\u2502   \u2514\u2500\u2500 Actor \u0026quot;players\u0026quot; (pid=0, a.k.a. \u0026quot;Ping\u0026quot;)\n\u2502       \u2514\u2500\u2500 Port 0 (ping endpoint)\n\u2514\u2500\u2500 PROC 1\n    \u2514\u2500\u2500 Actor \u0026quot;players\u0026quot; (pid=1, a.k.a. \u0026quot;Pong\u0026quot;)\n        \u2514\u2500\u2500 Port 0 (ping endpoint)\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EIn Monarch, a \u003Cstrong\u003Emesh\u003C/strong\u003E is a named, multi-dimensional collection of identical\nresources that you can address and operate on as a group. A HostMesh contains\nhosts, a ProcMesh contains processes, an ActorMesh contains actor instances \u2014\neach layer spawns the next.\u003C/span\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EDefinitions:\u003C/strong\u003E\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003E\u003Cstrong\u003EWorld\u003C/strong\u003E: A fixed group of processes launched together via gang scheduling\n  (all processes start together as a group \u2014 if any fails to start, none do)\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EProc\u003C/strong\u003E: A single actor runtime instance. One proc runs on one GPU (or CPU).\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EActor\u003C/strong\u003E: An independent async unit with its own mailbox. Communicates only\n  through messages \u2014 never shares memory.\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EPort\u003C/strong\u003E: A typed message endpoint. Each \u003Ccode\u003E@endpoint\u003C/code\u003E decorator creates a port.\u003C/li\u003E\n\u003C/ul\u003E\n\u003Cspan class=\"paragraph\"\u003EIn the ping-pong example above:\u003C/span\u003E\n\u003Cul\u003E\n\u003Cli\u003EThe \u003Cstrong\u003EWorld\u003C/strong\u003E is the group of 2 procs we spawned\u003C/li\u003E\n\u003Cli\u003EEach \u003Cstrong\u003EProc\u003C/strong\u003E hosts one PingPong \u003Cstrong\u003EActor\u003C/strong\u003E\u003C/li\u003E\n\u003Cli\u003EThe \u003Ccode\u003Eping\u003C/code\u003E method is a \u003Cstrong\u003EPort\u003C/strong\u003E\u003C/li\u003E\n\u003C/ul\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "38e4641b41405370fa84bbfc389baa18", "console": [], "id": "RGSE", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"why-it-scales\"\u003EWhy It Scales\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003EMonarch is designed to run millions of actors. Most actor systems use a\nglobal routing table \u2014 Monarch doesn't. Instead, every entity has a\nhierarchical ID that \u003Cstrong\u003Eencodes the routing path directly\u003C/strong\u003E:\u003C/span\u003E\n\u003Cdiv class=\"language-scdoc codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003EActorId = (ProcId, actor_name, pid)\nProcId  = Ranked(WorldId, rank)\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003EA HostMesh contains hosts, each host runs procs (a ProcMesh), and each proc\nhosts actors (an ActorMesh). The ActorId tells you exactly where to route\nwithout any lookup:\u003C/span\u003E\n\u003Cdiv class=\"language-actionscript3 codehilite\"\u003E\u003Cpre\u003E\u003Cspan\u003E\u003C/span\u003E\u003Ccode\u003E\u003Cspan class=\"n\"\u003EExample\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Emy_job\u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E5\u003C/span\u003E\u003Cspan class=\"o\"\u003E].\u003C/span\u003E\u003Cspan class=\"n\"\u003Eworker\u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\n\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003Erank\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E5\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"k\"\u003Eif\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"mi\"\u003E2\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eprocs\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eper\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Ehost\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"o\"\u003E-\u0026gt;\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Edial\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eaddr2\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"n\"\u003Eport\u003C/span\u003E\n\u003Cspan class=\"w\"\u003E  \u003C/span\u003E\u003Cspan class=\"n\"\u003EThen\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Elocal\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Edelivery\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eto\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Eworker\u003C/span\u003E\u003Cspan class=\"o\"\u003E[\u003C/span\u003E\u003Cspan class=\"mi\"\u003E3\u003C/span\u003E\u003Cspan class=\"o\"\u003E]\u003C/span\u003E\u003Cspan class=\"err\"\u003E\u0026#39;\u003C/span\u003E\u003Cspan class=\"n\"\u003Es\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003Emailbox\u003C/span\u003E\u003Cspan class=\"o\"\u003E:\u003C/span\u003E\u003Cspan class=\"w\"\u003E \u003C/span\u003E\u003Cspan class=\"n\"\u003EO\u003C/span\u003E\u003Cspan class=\"o\"\u003E(\u003C/span\u003E\u003Cspan class=\"mi\"\u003E1\u003C/span\u003E\u003Cspan class=\"o\"\u003E)\u003C/span\u003E\n\u003C/code\u003E\u003C/pre\u003E\u003C/div\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EWhy this beats a global table:\u003C/strong\u003E\u003C/span\u003E\n\u003Ctable\u003E\n\u003Cthead\u003E\n\u003Ctr\u003E\n\u003Cth\u003EOperation\u003C/th\u003E\n\u003Cth\u003EGlobal Table\u003C/th\u003E\n\u003Cth\u003EMonarch Hierarchical\u003C/th\u003E\n\u003C/tr\u003E\n\u003C/thead\u003E\n\u003Ctbody\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ESpawn\u003C/td\u003E\n\u003Ctd\u003EO(consensus)\u003C/td\u003E\n\u003Ctd\u003EO(1) local\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ERoute (local)\u003C/td\u003E\n\u003Ctd\u003EO(cache miss)\u003C/td\u003E\n\u003Ctd\u003EO(1) hash\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003ERoute (cross-host)\u003C/td\u003E\n\u003Ctd\u003EO(cache miss)\u003C/td\u003E\n\u003Ctd\u003EO(log procs) + O(1) local\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EFailure\u003C/td\u003E\n\u003Ctd\u003EGlobal invalidation\u003C/td\u003E\n\u003Ctd\u003ELocal supervision\u003C/td\u003E\n\u003C/tr\u003E\n\u003Ctr\u003E\n\u003Ctd\u003EMemory\u003C/td\u003E\n\u003Ctd\u003EO(actors) per node\u003C/td\u003E\n\u003Ctd\u003EO(procs) per node\u003C/td\u003E\n\u003C/tr\u003E\n\u003C/tbody\u003E\n\u003C/table\u003E\u003C/span\u003E"}, "type": "data"}]}, {"code_hash": "2651074511b1f1edd179d802f40ee199", "console": [], "id": "Kclp", "outputs": [{"data": {"text/markdown": "\u003Cspan class=\"markdown prose dark:prose-invert contents\"\u003E\u003Ch2 id=\"summary\"\u003ESummary\u003C/h2\u003E\n\u003Cspan class=\"paragraph\"\u003E\u003Cstrong\u003EKey takeaways:\u003C/strong\u003E\u003C/span\u003E\n\u003Col\u003E\n\u003Cli\u003E\u003Cstrong\u003EBorn from pain\u003C/strong\u003E: Monarch was built for the reality of frontier training \u2014\n   hundreds of failures across thousands of GPUs\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ESingle controller\u003C/strong\u003E: One Python script orchestrates distributed compute\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EActors, not threads\u003C/strong\u003E: Independent workers communicating via messages,\n   never sharing memory\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003EHierarchical addressing\u003C/strong\u003E: O(1) local routing, no global registry, scales\n   to millions of actors\u003C/li\u003E\n\u003Cli\u003E\u003Cstrong\u003ERust + Tokio\u003C/strong\u003E: Performance without GC pauses\u003C/li\u003E\n\u003C/ol\u003E\n\u003Cspan class=\"paragraph\"\u003EYou've seen how Monarch's actors work. But right now, developing distributed\nsystems means SSH, submit, wait, check logs, repeat. What if you could iterate\nas fast as local development? That's what we'll build next.\u003C/span\u003E\u003C/span\u003E"}, "type": "data"}]}], "metadata": {"marimo_version": "0.19.7"}, "version": "1"},
            "runtimeConfig": null,
        };
    </script>
  
<marimo-code hidden="">
    import%20marimo%0A%0A__generated_with%20%3D%20%220.19.7%22%0Aapp%20%3D%20marimo.App(width%3D%22medium%22)%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20import%20marimo%20as%20mo%0A%20%20%20%20return%20(mo%2C)%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%20Monarch%3A%20History%20%26%20Vision%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Training%20at%20the%20Frontier%20Hurts%0A%0A%20%20%20%20Before%20we%20look%20at%20any%20code%2C%20let's%20talk%20about%20**why%20Monarch%20exists**.%0A%0A%20%20%20%20During%20Llama%203%20pre-training%2C%20Meta%20ran%2016%2C384%20GPUs%20for%2054%20days%20and%20hit%0A%20%20%20%20**419%20unexpected%20interruptions**%20%E2%80%94%20roughly%20one%20failure%20every%203%20hours.%0A%20%20%20%20The%20breakdown%20tells%20you%20a%20lot%20about%20what%20goes%20wrong%20at%20scale%3A%0A%0A%20%20%20%20%7C%20Cause%20%7C%20%25%20of%20interruptions%20%7C%20Count%20%7C%0A%20%20%20%20%7C-------%7C-------------------%7C-------%7C%0A%20%20%20%20%7C%20Faulty%20GPUs%20%7C%2030.1%25%20%7C%20148%20%7C%0A%20%20%20%20%7C%20GPU%20HBM3%20errors%20%7C%2017.2%25%20%7C%2072%20%7C%0A%20%20%20%20%7C%20Software%20bugs%20%7C%2012.9%25%20%7C%2054%20%7C%0A%20%20%20%20%7C%20Network%20%2F%20cables%20%7C%208.4%25%20%7C%2035%20%7C%0A%20%20%20%20...%0A%0A%20%20%20%20This%20is%20%22just%22%20for%2016K%20GPUs.%20If%20you%20further%20scale%20workloads%20to%20tens%20of%20thousands%20of%20GPUs%2C%20you%20should%20expect%20failures%0A%20%20%20%20every%20hour%20or%20more%20frequently.%20The%20distributed%20system%20must%20handle%20this%20gracefully%20%E2%80%94%20detect%2C%20checkpoint%2C%20recover%2C%20keep%20going%0A%20%20%20%20automatically%2C%20without%20requiring%20someone%20to%20SSH%20in%20to%20restart%20things%20manually.%0A%0A%20%20%20%20**Monarch%20was%20built%20for%20this%20reality.**%20It's%20a%20PyTorch-native%20distributed%0A%20%20%20%20systems%20framework%20designed%20from%20the%20ground%20up%20for%20fault%20tolerance%2C%20flexible%0A%20%20%20%20communication%20patterns%2C%20and%20scale.%20Let's%20see%20how%20it%20got%20here.%0A%0A%20%20%20%20*(Failure%20data%20from%20the%20%5BLlama%203%20paper%5D(https%3A%2F%2Farxiv.org%2Fabs%2F2407.21783)%3B%0A%20%20%20%20see%20also%20%5BIntroducing%20PyTorch%20Monarch%5D(https%3A%2F%2Fpytorch.org%2Fblog%2Fintroducing-pytorch-monarch%2F))*%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20**What%20you'll%20learn%3A**%0A%0A%20%20%20%201.%20Why%20Monarch%20exists%20(the%20pain%20that%20drove%20its%20creation)%0A%20%20%20%202.%20The%20tensor%20engine%20origin%20story%0A%20%20%20%203.%20The%20actor%20model%20and%20why%20it%20matters%20for%20distributed%20ML%0A%20%20%20%204.%20Your%20first%20Monarch%20program%3A%20ping-pong%20actors%0A%20%20%20%205.%20The%20Monarch%20ontology%3A%20World%2C%20Proc%2C%20Actor%2C%20Port%0A%20%20%20%206.%20How%20Monarch%20scales%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20The%20Tensor%20Engine%20Origin%20Story%0A%0A%20%20%20%20The%20first%20step%20toward%20solving%20this%20was%20rethinking%20how%20we%20orchestrate%0A%20%20%20%20distributed%20computation.%0A%0A%20%20%20%20Monarch%20began%20as%20a%20**tensor%20engine**%20for%20distributed%20PyTorch.%0A%20%20%20%20It%20was%20built%20as%20a%20%22single%20controller%22%20that%20executed%20DTensor%20operations.%0A%0A%20%20%20%20In%20other%20words%2C%20in%20Monarch%20we%20have%20a%20**single%20controller**%20that%20orchestrates%20many%20GPUs%2C%0A%20%20%20%20instead%20of%20SPMD%20(Single%20Program%2C%20Multiple%20Data)%20where%20every%20rank%20runs%20the%20same%20script.%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20CONTROLLER%20(Python)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%23%20Create%20a%20mesh%3A%204%20hosts%20x%208%20GPUs%20%3D%2032%20GPUs%20total%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20mesh%20%3D%20DeviceMesh(hosts%3D4%2C%20gpus_per_host%3D8%2C%20dims%3D(%22dp%22%2C%20%22tp%22))%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20with%20mesh.activate()%3A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20loss%20%3D%20model(X)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20loss.backward()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20p.grad.reduce_(%22dp%22%2C%20reduction%3D%22avg%22)%20%20%23%20all-reduce%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20optimizer.step()%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%AC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%82%20tensor%20commands%0A%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%BC%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%E2%96%BC%0A%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%20%20%20%20%20%20%20%20%20%E2%94%8C%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%90%0A%20%20%20%20%20%20%20%E2%94%82%20Host%200%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20Host%201%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20Host%202%20%20%E2%94%82%20%20...%0A%20%20%20%20%20%20%20%E2%94%82%208%20GPUs%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%208%20GPUs%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%208%20GPUs%20%20%E2%94%82%0A%20%20%20%20%20%20%20%E2%94%82%20dp%3D0%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20dp%3D1%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%20%20%E2%94%82%20dp%3D2%20%20%20%20%E2%94%82%0A%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%80%E2%94%98%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20This%20allows%20one%20Python%20script%20to%20orchestrate%20thousands%20of%20GPUs%20-%20bypassing%20SPMD-imposed%20complexities%20like%20per-rank%20checks%2C%20scattered%20logging%2C%20etc.%20Complex%20control%20flow%20becomes%20more%20natural%20to%20express%20in%20code.%0A%0A%20%20%20%20The%20tensor%20engine%20still%20exists%20today%2C%20but%20Monarch%20has%20evolved%20beyond%20it.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Evolution%20to%20Actors%0A%0A%20%20%20%20While%20building%20the%20tensor%20engine%2C%20the%20Monarch%20team%20realized%20that%20the%20system%0A%20%20%20%20underneath%20%E2%80%94%20the%20Rust%20runtime%20managing%20processes%2C%20message%20routing%2C%20and%0A%20%20%20%20scheduling%20%E2%80%94%20was%20far%20more%20general%20than%20just%20tensor%20orchestration.%20The%0A%20%20%20%20**actor%20model**%20underpinning%20everything%20was%20powerful%20on%20its%20own.%0A%0A%20%20%20%20So%20the%20APIs%20shifted%20to%20bring%20those%20primitives%20directly%20to%20Python.%20Instead%20of%0A%20%20%20%20only%20exposing%20tensor%20operations%2C%20Monarch%20now%20lets%20you%20define%20arbitrary%0A%20%20%20%20**actors**%20that%20communicate%20via%20**messages**.%0A%0A%20%20%20%20**What%20is%20an%20actor%3F**%20In%20the%20formal%20sense%2C%20an%20actor%20is%20a%20concurrent%20unit%20of%0A%20%20%20%20computation%20that%3A%0A%0A%20%20%20%201.%20Has%20**private%20state**%20%E2%80%94%20no%20shared%20memory%20with%20other%20actors%0A%20%20%20%202.%20Communicates%20exclusively%20by%20**sending%20and%20receiving%20messages**%0A%20%20%20%203.%20Can%20**create%20new%20actors**%2C%20send%20messages%2C%20and%20decide%20how%20to%20handle%20the%20next%0A%20%20%20%20%20%20%20message%20it%20receives%0A%0A%20%20%20%20A%20useful%20analogy%3A%20think%20of%20actors%20as%20workers%20in%20separate%20offices.%20They%20can't%0A%20%20%20%20walk%20over%20and%20read%20each%20other's%20notebooks%20%E2%80%94%20they%20can%20only%20communicate%20by%0A%20%20%20%20passing%20notes%20through%20mail%20slots.%0A%0A%20%20%20%20This%20model%20composes%20naturally%20with%20PyTorch's%20existing%20ecosystem.%20You%20can%20wrap%20any%20SPMD%20code%20with%20Monarch's%20actors%2C%0A%20%20%20%20and%20command%20a%20group%20or%20%22gang%22%20of%20actors%20as%20a%20single%20addressable%20unit%2C%20and%20wire%20them%20together%20however%20your%20workload%20requires.%0A%0A%20%20%20%20Take%20RL%20for%20example%20(don't%20worry%20about%20the%20details%20of%20this%20snippet%20%E2%80%94%0A%20%20%20%20we'll%20cover%20these%20APIs%20hands-on%20throughout%20the%20series)%3A%0A%0A%20%20%20%20%60%60%60python%0A%20%20%20%20%23%20Spawn%20different%20actor%20types%20across%20processes%0A%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20trainer_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22gpus%22%3A%201%7D)%0A%20%20%20%20generator_procs%20%3D%20host.spawn_procs(per_host%3D%7B%22gpus%22%3A%204%7D)%0A%0A%20%20%20%20trainer%20%3D%20trainer_procs.spawn(%22trainer%22%2C%20TrainerActor)%0A%20%20%20%20generators%20%3D%20generator_procs.spawn(%22generators%22%2C%20GeneratorActor)%0A%0A%20%20%20%20%23%20Wire%20them%20together%0A%20%20%20%20for%20batch%20in%20training_loop%3A%0A%20%20%20%20%20%20%20%20%23%20Call%20all%20generators%20(returns%20a%20ValueMesh)%0A%20%20%20%20%20%20%20%20sample_mesh%20%3D%20generators.generate.call(prompts).get()%0A%20%20%20%20%20%20%20%20%23%20Extract%20values%20from%20the%20ValueMesh%20before%20passing%20along%0A%20%20%20%20%20%20%20%20samples%20%3D%20list(sample_mesh.values())%0A%20%20%20%20%20%20%20%20trainer.train_step.call_one(samples).get()%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20Let's%20make%20this%20concrete%20with%20a%20real%20program%20you%20can%20run.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Your%20First%20Monarch%20Program%0A%0A%20%20%20%20The%20simplest%20possible%20Monarch%20program%20%E2%80%94%20two%20actors%20playing%20ping%20pong.%0A%0A%20%20%20%20Reference%3A%20%5Bping_pong%20example%5D(https%3A%2F%2Fmeta-pytorch.org%2Fmonarch%2Fgenerated%2Fexamples%2Fping_pong.html)%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_()%3A%0A%20%20%20%20from%20monarch.actor%20import%20Actor%2C%20endpoint%2C%20current_rank%2C%20this_host%0A%0A%20%20%20%20class%20PingPong(Actor)%3A%0A%20%20%20%20%20%20%20%20def%20__init__(self)%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20rank%20%3D%20current_rank().rank%0A%20%20%20%20%20%20%20%20%20%20%20%20self.name%20%3D%20%22Ping%22%20if%20rank%20%3D%3D%200%20else%20%22Pong%22%0A%20%20%20%20%20%20%20%20%20%20%20%20self.count%20%3D%200%0A%0A%20%20%20%20%20%20%20%20%40endpoint%0A%20%20%20%20%20%20%20%20def%20ping(self%2C%20message%3A%20str)%20-%3E%20str%3A%0A%20%20%20%20%20%20%20%20%20%20%20%20self.count%20%2B%3D%201%0A%20%20%20%20%20%20%20%20%20%20%20%20print(f%22%7Bself.name%7D%20received%3A%20%7Bmessage%7D%20(count%3A%20%7Bself.count%7D)%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20return%20f%22pong%20from%20%7Bself.name%7D%22%0A%0A%20%20%20%20%23%20Spawn%20two%20actors%20on%20separate%20processes%0A%20%20%20%20host%20%3D%20this_host()%0A%20%20%20%20procs%20%3D%20host.spawn_procs(per_host%3D%7B%22gpus%22%3A%202%7D)%0A%20%20%20%20actors%20%3D%20procs.spawn(%22players%22%2C%20PingPong)%0A%0A%20%20%20%20%23%20Get%20individual%20actors%20via%20slicing%0A%20%20%20%20ping_actor%20%3D%20actors.slice(gpus%3D0)%0A%20%20%20%20pong_actor%20%3D%20actors.slice(gpus%3D1)%0A%0A%20%20%20%20%23%20Play%20ping%20pong%20%E2%80%94%20call_one%20targets%20a%20single%20actor%0A%20%20%20%20for%20i%20in%20range(3)%3A%0A%20%20%20%20%20%20%20%20response%20%3D%20ping_actor.ping.call_one(f%22round%20%7Bi%7D%22).get()%0A%20%20%20%20%20%20%20%20print(f%22Got%3A%20%7Bresponse%7D%22)%0A%20%20%20%20%20%20%20%20response%20%3D%20pong_actor.ping.call_one(f%22round%20%7Bi%7D%22).get()%0A%20%20%20%20%20%20%20%20print(f%22Got%3A%20%7Bresponse%7D%22)%0A%0A%20%20%20%20%23%20.call()%20broadcasts%20to%20ALL%20actors%20and%20returns%20a%20ValueMesh%20%E2%80%94%20a%20dict-like%0A%20%20%20%20%23%20container%20mapping%20each%20actor's%20position%20to%20its%20return%20value.%0A%20%20%20%20results%20%3D%20actors.ping.call(%22hello%20everyone%22).get()%0A%20%20%20%20for%20point%2C%20response%20in%20results.items()%3A%0A%20%20%20%20%20%20%20%20print(f%22Actor%20at%20%7Bpoint%7D%3A%20%7Bresponse%7D%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20The%20Monarch%20Ontology%0A%0A%20%20%20%20Now%20that%20you've%20run%20code%2C%20let's%20name%20the%20pieces.%20Monarch%20has%20a%20strict%0A%20%20%20%20hierarchy%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20WORLD%20(gang-scheduled%20group%20of%20processes)%0A%20%20%20%20%E2%94%9C%E2%94%80%E2%94%80%20PROC%200%20(single%20actor%20runtime%20instance)%0A%20%20%20%20%E2%94%82%20%20%20%E2%94%94%E2%94%80%E2%94%80%20Actor%20%22players%22%20(pid%3D0%2C%20a.k.a.%20%22Ping%22)%0A%20%20%20%20%E2%94%82%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%20Port%200%20(ping%20endpoint)%0A%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%20PROC%201%0A%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%20Actor%20%22players%22%20(pid%3D1%2C%20a.k.a.%20%22Pong%22)%0A%20%20%20%20%20%20%20%20%20%20%20%20%E2%94%94%E2%94%80%E2%94%80%20Port%200%20(ping%20endpoint)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20In%20Monarch%2C%20a%20**mesh**%20is%20a%20named%2C%20multi-dimensional%20collection%20of%20identical%0A%20%20%20%20resources%20that%20you%20can%20address%20and%20operate%20on%20as%20a%20group.%20A%20HostMesh%20contains%0A%20%20%20%20hosts%2C%20a%20ProcMesh%20contains%20processes%2C%20an%20ActorMesh%20contains%20actor%20instances%20%E2%80%94%0A%20%20%20%20each%20layer%20spawns%20the%20next.%0A%0A%20%20%20%20**Definitions%3A**%0A%0A%20%20%20%20-%20**World**%3A%20A%20fixed%20group%20of%20processes%20launched%20together%20via%20gang%20scheduling%0A%20%20%20%20%20%20(all%20processes%20start%20together%20as%20a%20group%20%E2%80%94%20if%20any%20fails%20to%20start%2C%20none%20do)%0A%20%20%20%20-%20**Proc**%3A%20A%20single%20actor%20runtime%20instance.%20One%20proc%20runs%20on%20one%20GPU%20(or%20CPU).%0A%20%20%20%20-%20**Actor**%3A%20An%20independent%20async%20unit%20with%20its%20own%20mailbox.%20Communicates%20only%0A%20%20%20%20%20%20through%20messages%20%E2%80%94%20never%20shares%20memory.%0A%20%20%20%20-%20**Port**%3A%20A%20typed%20message%20endpoint.%20Each%20%60%40endpoint%60%20decorator%20creates%20a%20port.%0A%0A%20%20%20%20In%20the%20ping-pong%20example%20above%3A%0A%20%20%20%20-%20The%20**World**%20is%20the%20group%20of%202%20procs%20we%20spawned%0A%20%20%20%20-%20Each%20**Proc**%20hosts%20one%20PingPong%20**Actor**%0A%20%20%20%20-%20The%20%60ping%60%20method%20is%20a%20**Port**%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Why%20It%20Scales%0A%0A%20%20%20%20Monarch%20is%20designed%20to%20run%20millions%20of%20actors.%20Most%20actor%20systems%20use%20a%0A%20%20%20%20global%20routing%20table%20%E2%80%94%20Monarch%20doesn't.%20Instead%2C%20every%20entity%20has%20a%0A%20%20%20%20hierarchical%20ID%20that%20**encodes%20the%20routing%20path%20directly**%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20ActorId%20%3D%20(ProcId%2C%20actor_name%2C%20pid)%0A%20%20%20%20ProcId%20%20%3D%20Ranked(WorldId%2C%20rank)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20A%20HostMesh%20contains%20hosts%2C%20each%20host%20runs%20procs%20(a%20ProcMesh)%2C%20and%20each%20proc%0A%20%20%20%20hosts%20actors%20(an%20ActorMesh).%20The%20ActorId%20tells%20you%20exactly%20where%20to%20route%0A%20%20%20%20without%20any%20lookup%3A%0A%0A%20%20%20%20%60%60%60%0A%20%20%20%20Example%3A%20my_job%5B5%5D.worker%5B3%5D%0A%0A%20%20%20%20%20%20rank%205%20-%3E%20host%202%20(if%202%20procs%20per%20host)%20-%3E%20dial%20addr2%3Aport%0A%20%20%20%20%20%20Then%20local%20delivery%20to%20worker%5B3%5D's%20mailbox%3A%20O(1)%0A%20%20%20%20%60%60%60%0A%0A%20%20%20%20**Why%20this%20beats%20a%20global%20table%3A**%0A%0A%20%20%20%20%7C%20Operation%20%7C%20Global%20Table%20%7C%20Monarch%20Hierarchical%20%7C%0A%20%20%20%20%7C-----------%7C--------------%7C---------------------%7C%0A%20%20%20%20%7C%20Spawn%20%7C%20O(consensus)%20%7C%20O(1)%20local%20%7C%0A%20%20%20%20%7C%20Route%20(local)%20%7C%20O(cache%20miss)%20%7C%20O(1)%20hash%20%7C%0A%20%20%20%20%7C%20Route%20(cross-host)%20%7C%20O(cache%20miss)%20%7C%20O(log%20procs)%20%2B%20O(1)%20local%20%7C%0A%20%20%20%20%7C%20Failure%20%7C%20Global%20invalidation%20%7C%20Local%20supervision%20%7C%0A%20%20%20%20%7C%20Memory%20%7C%20O(actors)%20per%20node%20%7C%20O(procs)%20per%20node%20%7C%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0A%40app.cell%0Adef%20_(mo)%3A%0A%20%20%20%20mo.md(r%22%22%22%0A%20%20%20%20%23%23%20Summary%0A%0A%20%20%20%20**Key%20takeaways%3A**%0A%0A%20%20%20%201.%20**Born%20from%20pain**%3A%20Monarch%20was%20built%20for%20the%20reality%20of%20frontier%20training%20%E2%80%94%0A%20%20%20%20%20%20%20hundreds%20of%20failures%20across%20thousands%20of%20GPUs%0A%20%20%20%202.%20**Single%20controller**%3A%20One%20Python%20script%20orchestrates%20distributed%20compute%0A%20%20%20%203.%20**Actors%2C%20not%20threads**%3A%20Independent%20workers%20communicating%20via%20messages%2C%0A%20%20%20%20%20%20%20never%20sharing%20memory%0A%20%20%20%204.%20**Hierarchical%20addressing**%3A%20O(1)%20local%20routing%2C%20no%20global%20registry%2C%20scales%0A%20%20%20%20%20%20%20to%20millions%20of%20actors%0A%20%20%20%205.%20**Rust%20%2B%20Tokio**%3A%20Performance%20without%20GC%20pauses%0A%0A%20%20%20%20You've%20seen%20how%20Monarch's%20actors%20work.%20But%20right%20now%2C%20developing%20distributed%0A%20%20%20%20systems%20means%20SSH%2C%20submit%2C%20wait%2C%20check%20logs%2C%20repeat.%20What%20if%20you%20could%20iterate%0A%20%20%20%20as%20fast%20as%20local%20development%3F%20That's%20what%20we'll%20build%20next.%0A%20%20%20%20%22%22%22)%0A%20%20%20%20return%0A%0A%0Aif%20__name__%20%3D%3D%20%22__main__%22%3A%0A%20%20%20%20app.run()%0A
</marimo-code>

<marimo-code-hash hidden="">9be1c461a3228a76822869ea3936d9f8</marimo-code-hash>
</body>
</html>
